{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f9daec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROBOFLOW_API_KEY configurada?: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"C:/Users/david/Desktop/Uni/potato-dry-matter-optics-ml\")\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # lee el archivo .env\n",
    "\n",
    "ROBOFLOW_API_KEY = os.environ[\"ROBOFLOW_API_KEY\"]\n",
    "os.environ[\"ROBOFLOW_API_KEY\"] = ROBOFLOW_API_KEY\n",
    "\n",
    "# Comprobación rápida\n",
    "print(\"ROBOFLOW_API_KEY configurada?:\", \"ROBOFLOW_API_KEY\" in os.environ)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "756510f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "ModelDependencyMissing: Your `inference` configuration does not support SAM model. Use pip install 'inference[sam]' to install missing requirements.To suppress this warning, set CORE_MODEL_SAM_ENABLED to False.\n",
      "ModelDependencyMissing: Your `inference` configuration does not support SAM2 model. Use pip install 'inference[sam]' to install missing requirements.To suppress this warning, set CORE_MODEL_SAM2_ENABLED to False.\n",
      "ModelDependencyMissing: Your `inference` configuration does not support SAM3 model. Install SAM3 dependencies and set CORE_MODEL_SAM3_ENABLED to True.\n",
      "ModelDependencyMissing: Your `inference` configuration does not support Gaze Detection model. Use pip install 'inference[gaze]' to install missing requirements.To suppress this warning, set CORE_MODEL_GAZE_ENABLED to False.\n",
      "ModelDependencyMissing: Your `inference` configuration does not support GroundingDINO model. Use pip install 'inference[grounding-dino]' to install missing requirements.To suppress this warning, set CORE_MODEL_GROUNDINGDINO_ENABLED to False.\n",
      "ModelDependencyMissing: Your `inference` configuration does not support YoloWorld model. Use pip install 'inference[yolo-world]' to install missing requirements.To suppress this warning, set CORE_MODEL_YOLO_WORLD_ENABLED to False.\n",
      "UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n",
      "UserWarning: Specified provider 'OpenVINOExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n",
      "UserWarning: Specified provider 'CoreMLExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo cargado correctamente: potato-detection-3et6q/11\n"
     ]
    }
   ],
   "source": [
    "from inference import get_model\n",
    "\n",
    "# ID del modelo tal como aparece en Roboflow (deploy > Python)\n",
    "MODEL_ID = \"potato-detection-3et6q/11\"  # si cambia la versión, actualiza aquí\n",
    "\n",
    "# Cargar el modelo\n",
    "model = get_model(MODEL_ID)\n",
    "\n",
    "print(\"Modelo cargado correctamente:\", MODEL_ID)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbd928b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "def run_potato_detection(image_path: str, confidence_threshold: float = 0.4):\n",
    "    \"\"\"\n",
    "    Ejecuta el modelo de Roboflow sobre una imagen y devuelve:\n",
    "      - raw_result: objeto ObjectDetectionInferenceResponse\n",
    "      - detections: lista de dicts con clase, confianza y bbox en formato (x1, y1, x2, y2)\n",
    "    \"\"\"\n",
    "    # Cargar imagen (solo para saber tamaño, el modelo puede usar la ruta directamente)\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    w, h = image.size\n",
    "\n",
    "    # Inferencia\n",
    "    raw = model.infer(image_path, confidence=confidence_threshold)\n",
    "\n",
    "    # Si devuelve lista, nos quedamos con el primer elemento (caso normal)\n",
    "    raw_result = raw[0] if isinstance(raw, list) else raw\n",
    "\n",
    "    # >>> AQUÍ ESTABA EL ERROR: raw_result es un objeto, no un dict\n",
    "    predictions = getattr(raw_result, \"predictions\", [])\n",
    "\n",
    "    detections: List[Dict[str, Any]] = []\n",
    "\n",
    "    for det in predictions:\n",
    "        # det es un ObjectDetectionPrediction\n",
    "        cls = det.class_name          # nombre de la clase (tipo de patata)\n",
    "        conf = det.confidence         # confianza (0-1)\n",
    "        x = det.x\n",
    "        y = det.y\n",
    "        bw = det.width\n",
    "        bh = det.height\n",
    "\n",
    "        # Pasar de (centro x,y + ancho/alto) a esquinas (x1, y1, x2, y2)\n",
    "        x1 = int(x - bw / 2)\n",
    "        y1 = int(y - bh / 2)\n",
    "        x2 = int(x + bw / 2)\n",
    "        y2 = int(y + bh / 2)\n",
    "\n",
    "        # Clip a los límites de la imagen\n",
    "        x1 = max(0, x1)\n",
    "        y1 = max(0, y1)\n",
    "        x2 = min(w, x2)\n",
    "        y2 = min(h, y2)\n",
    "\n",
    "        detections.append({\n",
    "            \"class\": cls,\n",
    "            \"confidence\": float(conf),\n",
    "            \"bbox_xyxy\": (x1, y1, x2, y2),\n",
    "        })\n",
    "\n",
    "    return raw_result, detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9236b1b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== OUTPUT BRUTO DEL MODELO ===\n",
      "visualization=None inference_id=None frame_id=None time=None image=InferenceResponseImage(width=1200, height=1600) predictions=[ObjectDetectionPrediction(x=596.5, y=771.0, width=717.0, height=582.0, confidence=0.7184754610061646, class_name='Sprouted potato', class_confidence=None, class_id=4, tracker_id=None, detection_id='a8fb00b7-519e-4d96-aa23-cc53d898a614', parent_id=None)]\n",
      "\n",
      "=== DETECCIONES PROCESADAS ===\n",
      "Patata 1:\n",
      "  Clase (tipo): Sprouted potato\n",
      "  Confianza: 0.718\n",
      "  Bounding box (x1, y1, x2, y2): (238, 480, 955, 1062)\n"
     ]
    }
   ],
   "source": [
    "IMAGE_PATH = \"data/input/raw/test_img1.jpg\"  # <-- cambia esto\n",
    "\n",
    "raw_result, detections = run_potato_detection(IMAGE_PATH, confidence_threshold=0.4)\n",
    "\n",
    "print(\"=== OUTPUT BRUTO DEL MODELO ===\")\n",
    "print(raw_result)  # Aquí ves TODO el JSON que devuelve el modelo\n",
    "\n",
    "print(\"\\n=== DETECCIONES PROCESADAS ===\")\n",
    "for i, det in enumerate(detections, start=1):\n",
    "    print(f\"Patata {i}:\")\n",
    "    print(f\"  Clase (tipo): {det['class']}\")\n",
    "    print(f\"  Confianza: {det['confidence']:.3f}\")\n",
    "    print(f\"  Bounding box (x1, y1, x2, y2): {det['bbox_xyxy']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f952a886",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import os\n",
    "\n",
    "def save_detections_image(image_path: str, detections, output_path: str):\n",
    "    # Cargar imagen\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    # Fuente para el texto\n",
    "    try:\n",
    "        font = ImageFont.truetype(\"arial.ttf\", 18)\n",
    "    except:\n",
    "        font = ImageFont.load_default()\n",
    "\n",
    "    for det in detections:\n",
    "        x1, y1, x2, y2 = det[\"bbox_xyxy\"]\n",
    "        label = f\"{det['class']} {det['confidence']:.2f}\"\n",
    "\n",
    "        # Caja\n",
    "        draw.rectangle([x1, y1, x2, y2], outline=\"red\", width=3)\n",
    "\n",
    "        # Fondo para texto\n",
    "        text_x, text_y = x1, max(0, y1 - 22)\n",
    "        w_text = 8 * len(label)\n",
    "        h_text = 20\n",
    "        draw.rectangle(\n",
    "            [text_x, text_y, text_x + w_text, text_y + h_text],\n",
    "            fill=\"red\"\n",
    "        )\n",
    "\n",
    "        # Texto\n",
    "        draw.text((text_x + 2, text_y + 2), label, fill=\"white\", font=font)\n",
    "\n",
    "    # Crear carpeta si no existe\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    image.save(output_path)\n",
    "    print(f\"Imagen con detecciones guardada en: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b73c5650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagen con detecciones guardada en: data/output/detections/test_img1_detected.jpg\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_PATH = \"data/output/detections/test_img1_detected.jpg\"\n",
    "\n",
    "# Suponiendo que ya has hecho:\n",
    "# raw_result, detections = run_potato_detection(IMAGE_PATH, confidence_threshold=0.4)\n",
    "\n",
    "save_detections_image(IMAGE_PATH, detections, OUTPUT_PATH)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "potato-detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
