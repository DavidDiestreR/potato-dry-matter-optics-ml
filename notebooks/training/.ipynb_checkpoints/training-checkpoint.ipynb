{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5f0a4b4",
   "metadata": {},
   "source": [
    "# Notebook per Predicció de Matèria Seca (MS) en Patates\n",
    "\n",
    "Aquest notebook entrena una xarxa neuronal per predir el percentatge de \n",
    "matèria seca a partir de les característiques de color i NIR de les patates.\n",
    "\n",
    "Columnes del dataset:\n",
    "- id_mostra: identificador únic\n",
    "- ruta_imatges: ruta a la imatge\n",
    "- color_promig_R, color_promig_G, color_promig_B: colors mitjans RGB\n",
    "- desviació_R, desviació_G, desviació_B: desviacions estàndard dels canals\n",
    "- canal_NIR: valor del canal infraroig proper\n",
    "- MS_experimental: percentatge de matèria seca (TARGET)\n",
    "- lot: identificador del lot\n",
    "- data: data de captura"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dff3330",
   "metadata": {},
   "source": [
    "## 1. IMPORTACIÓ DE LLIBRERIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99ec2f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.13.0\n",
      "GPU disponible: []\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error, r2_score\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuració per reproducibilitat\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU disponible: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93a611f",
   "metadata": {},
   "source": [
    "## 2. CÀRREGA I EXPLORACIÓ DE DADES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f923b0f",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] El sistema no puede encontrar la ruta especificada: '/d/potato-dry-matter-optics-ml'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# IMPORTANT: Canvia aquesta ruta per la del teu dataset\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/d/potato-dry-matter-optics-ml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m RUTA_DATASET \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/input/training/training_set.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Carregar les dades\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] El sistema no puede encontrar la ruta especificada: '/d/potato-dry-matter-optics-ml'"
     ]
    }
   ],
   "source": [
    "# IMPORTANT: Canvia aquesta ruta per la del teu dataset\n",
    "os.chdir(\"D:/potato-dry-matter-optics-ml\")\n",
    "RUTA_DATASET = \"data/input/training/training_set.csv\"\n",
    "\n",
    "# Carregar les dades\n",
    "df = pd.read_csv(RUTA_DATASET)\n",
    "\n",
    "print(\"\\n=== INFORMACIÓ DEL DATASET ===\")\n",
    "print(f\"Nombre de mostres: {len(df)}\")\n",
    "print(f\"\\nColumnes disponibles:\\n{df.columns.tolist()}\")\n",
    "print(f\"\\nPrimeres files:\")\n",
    "print(df.head())\n",
    "\n",
    "# Estadístiques descriptives\n",
    "print(\"\\n=== ESTADÍSTIQUES DESCRIPTIVES ===\")\n",
    "print(df.describe())\n",
    "\n",
    "# Comprovar valors nuls\n",
    "print(\"\\n=== VALORS NULS ===\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Visualització de la distribució de MS\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.hist(df['MS_experimental'], bins=30, edgecolor='black', alpha=0.7)\n",
    "plt.xlabel('MS Experimental (%)')\n",
    "plt.ylabel('Freqüència')\n",
    "plt.title('Distribució de Matèria Seca')\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.boxplot(df['MS_experimental'])\n",
    "plt.ylabel('MS Experimental (%)')\n",
    "plt.title('Boxplot de MS')\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "# Correlació entre features i MS\n",
    "features_cols = ['color_promig_R', 'color_promig_G', 'color_promig_B', \n",
    "                 'desviació_R', 'desviació_G', 'desviació_B', 'canal_NIR']\n",
    "correlations = df[features_cols + ['MS_experimental']].corr()['MS_experimental'].drop('MS_experimental')\n",
    "correlations.plot(kind='barh')\n",
    "plt.xlabel('Correlació amb MS')\n",
    "plt.title('Correlacions amb MS')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dda5e5a",
   "metadata": {},
   "source": [
    "## 3. PREPARACIÓ DE LES DADES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f4b983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar les columnes d'entrada (features) i sortida (target)\n",
    "feature_cols = ['color_promig_R', 'color_promig_G', 'color_promig_B',\n",
    "                'desviació_R', 'desviació_G', 'desviació_B', 'canal_NIR']\n",
    "target_col = 'MS_experimental'\n",
    "\n",
    "# Extreure X (inputs) i y (target)\n",
    "X = df[feature_cols].values\n",
    "y = df[target_col].values\n",
    "\n",
    "print(\"\\n=== PREPARACIÓ DE DADES ===\")\n",
    "print(f\"Shape de X (features): {X.shape}\")\n",
    "print(f\"Shape de y (target): {y.shape}\")\n",
    "\n",
    "# Separar en conjunt d'entrenament (80%) i validació (20%)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\nConjunt d'entrenament: {X_train.shape[0]} mostres\")\n",
    "print(f\"Conjunt de validació: {X_val.shape[0]} mostres\")\n",
    "\n",
    "# Normalització (StandardScaler)\n",
    "# És important normalitzar per ajudar a la xarxa neuronal a convergir millor\n",
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "X_val_scaled = scaler_X.transform(X_val)\n",
    "\n",
    "y_train_scaled = scaler_y.fit_transform(y_train.reshape(-1, 1)).flatten()\n",
    "y_val_scaled = scaler_y.transform(y_val.reshape(-1, 1)).flatten()\n",
    "\n",
    "print(\"\\n=== NORMALITZACIÓ COMPLETADA ===\")\n",
    "print(f\"Mitjana X_train: {X_train_scaled.mean(axis=0)}\")\n",
    "print(f\"Desviació estàndard X_train: {X_train_scaled.std(axis=0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9added1a",
   "metadata": {},
   "source": [
    "## 4. DEFINICIÓ DEL MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0049b62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_model(n_features, n_neurons_1=64, n_neurons_2=32, \n",
    "                learning_rate=0.001, dropout_rate=0.2):\n",
    "    \"\"\"\n",
    "    Crea una xarxa neuronal densa per regressió.\n",
    "    \n",
    "    Paràmetres:\n",
    "    -----------\n",
    "    n_features : int\n",
    "        Nombre de features d'entrada\n",
    "    n_neurons_1 : int\n",
    "        Neurones a la primera capa oculta\n",
    "    n_neurons_2 : int\n",
    "        Neurones a la segona capa oculta\n",
    "    learning_rate : float\n",
    "        Taxa d'aprenentatge per Adam\n",
    "    dropout_rate : float\n",
    "        Taxa de dropout per regularització\n",
    "    \n",
    "    Retorna:\n",
    "    --------\n",
    "    model : keras.Model\n",
    "        Model compilat\n",
    "    \"\"\"\n",
    "    model = keras.Sequential([\n",
    "        # Capa d'entrada\n",
    "        layers.Input(shape=(n_features,)),\n",
    "        \n",
    "        # Primera capa oculta\n",
    "        layers.Dense(n_neurons_1, activation='relu', name='hidden_1'),\n",
    "        layers.Dropout(dropout_rate, name='dropout_1'),\n",
    "        \n",
    "        # Segona capa oculta\n",
    "        layers.Dense(n_neurons_2, activation='relu', name='hidden_2'),\n",
    "        layers.Dropout(dropout_rate, name='dropout_2'),\n",
    "        \n",
    "        # Tercera capa oculta (opcional)\n",
    "        layers.Dense(16, activation='relu', name='hidden_3'),\n",
    "        \n",
    "        # Capa de sortida (regressió, 1 neurona sense activació)\n",
    "        layers.Dense(1, name='output')\n",
    "    ])\n",
    "    \n",
    "    # Compilar el model\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='mse',  # Mean Squared Error per regressió\n",
    "        metrics=['mae']  # Mean Absolute Error com a mètrica addicional\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Crear el model amb configuració per defecte\n",
    "n_features = X_train_scaled.shape[1]\n",
    "model = crear_model(n_features)\n",
    "\n",
    "print(\"\\n=== ARQUITECTURA DEL MODEL ===\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f7b3c2",
   "metadata": {},
   "source": [
    "## 5. ENTRENAMENT DEL MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adeb877c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks per millorar l'entrenament\n",
    "callbacks = [\n",
    "    # EarlyStopping: para l'entrenament si no millora en 20 èpoques\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=20,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    \n",
    "    # ReduceLROnPlateau: redueix la taxa d'aprenentatge si no millora\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=10,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"\\n=== COMENÇANT ENTRENAMENT ===\")\n",
    "\n",
    "# Entrenar el model\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train_scaled,\n",
    "    validation_data=(X_val_scaled, y_val_scaled),\n",
    "    epochs=200,\n",
    "    batch_size=16,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n=== ENTRENAMENT COMPLETAT ===\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b486cc",
   "metadata": {},
   "source": [
    "## 6. VISUALITZACIÓ DEL PROCÉS D'ENTRENAMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffaf5cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "# Loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Train Loss', linewidth=2)\n",
    "plt.plot(history.history['val_loss'], label='Val Loss', linewidth=2)\n",
    "plt.xlabel('Època')\n",
    "plt.ylabel('Loss (MSE)')\n",
    "plt.title('Evolució del Loss')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "# MAE\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['mae'], label='Train MAE', linewidth=2)\n",
    "plt.plot(history.history['val_mae'], label='Val MAE', linewidth=2)\n",
    "plt.xlabel('Època')\n",
    "plt.ylabel('MAE')\n",
    "plt.title('Evolució del Mean Absolute Error')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb0f8ef",
   "metadata": {},
   "source": [
    "## 7. AVALUACIÓ DEL MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801f0341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediccions en el conjunt de validació (normalitzat)\n",
    "y_val_pred_scaled = model.predict(X_val_scaled, verbose=0).flatten()\n",
    "\n",
    "# Desnormalitzar les prediccions per obtenir valors reals\n",
    "y_val_pred = scaler_y.inverse_transform(y_val_pred_scaled.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Calcular mètriques\n",
    "mape = mean_absolute_percentage_error(y_val, y_val_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_val, y_val_pred))\n",
    "mae = np.mean(np.abs(y_val - y_val_pred))\n",
    "r2 = r2_score(y_val, y_val_pred)\n",
    "\n",
    "print(\"\\n=== RESULTATS EN EL CONJUNT DE VALIDACIÓ ===\")\n",
    "print(f\"MAPE (Mean Absolute Percentage Error): {mape*100:.2f}%\")\n",
    "print(f\"RMSE (Root Mean Squared Error): {rmse:.3f}\")\n",
    "print(f\"MAE (Mean Absolute Error): {mae:.3f}\")\n",
    "print(f\"R² (Coeficient de determinació): {r2:.3f}\")\n",
    "\n",
    "# Interpretació dels resultats\n",
    "print(\"\\n=== INTERPRETACIÓ ===\")\n",
    "if mape < 0.15:\n",
    "    print(\"✓ Excel·lent! MAPE < 15% - El model és molt precís\")\n",
    "elif mape < 0.20:\n",
    "    print(\"✓ Acceptable. MAPE entre 15-20% - El model és força bo\")\n",
    "else:\n",
    "    print(\"✗ Millorable. MAPE > 20% - Caldria més dades o millor preprocessament\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fec10e3",
   "metadata": {},
   "source": [
    "## 8. VISUALITZACIÓ DE PREDICCIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69963627",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "# Gràfic de dispersió: valor real vs predit\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(y_val, y_val_pred, alpha=0.6, edgecolor='black')\n",
    "plt.plot([y_val.min(), y_val.max()], [y_val.min(), y_val.max()], \n",
    "         'r--', linewidth=2, label='Predicció perfecta')\n",
    "plt.xlabel('MS Real (%)')\n",
    "plt.ylabel('MS Predita (%)')\n",
    "plt.title(f'Prediccions vs Valors Reals\\nR² = {r2:.3f}')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "# Distribució dels errors\n",
    "plt.subplot(1, 2, 2)\n",
    "errors = y_val - y_val_pred\n",
    "plt.hist(errors, bins=20, edgecolor='black', alpha=0.7)\n",
    "plt.axvline(x=0, color='r', linestyle='--', linewidth=2)\n",
    "plt.xlabel('Error (Real - Predit)')\n",
    "plt.ylabel('Freqüència')\n",
    "plt.title(f'Distribució dels Errors\\nMAE = {mae:.3f}')\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e7e119",
   "metadata": {},
   "source": [
    "## 9. GRIDSEARCH PER OPTIMITZACIÓ (OPCIONAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408f3327",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridsearch_manual(X_train, y_train, X_val, y_val, configuracions):\n",
    "    \"\"\"\n",
    "    Cerca manual de la millor configuració d'hiperparàmetres.\n",
    "    \n",
    "    Paràmetres:\n",
    "    -----------\n",
    "    configuracions : list of dict\n",
    "        Llista de diccionaris amb diferents configuracions a provar\n",
    "    \n",
    "    Retorna:\n",
    "    --------\n",
    "    millor_config : dict\n",
    "        Millor configuració trobada\n",
    "    resultats : list\n",
    "        Resultats de totes les configuracions\n",
    "    \"\"\"\n",
    "    resultats = []\n",
    "    \n",
    "    for i, config in enumerate(configuracions):\n",
    "        print(f\"\\n--- Provant configuració {i+1}/{len(configuracions)} ---\")\n",
    "        print(f\"Config: {config}\")\n",
    "        \n",
    "        # Crear i entrenar model\n",
    "        model_temp = crear_model(n_features, **config)\n",
    "        \n",
    "        history_temp = model_temp.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=100,\n",
    "            batch_size=16,\n",
    "            callbacks=[EarlyStopping(monitor='val_loss', patience=15, \n",
    "                                    restore_best_weights=True, verbose=0)],\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        # Avaluar\n",
    "        y_pred_temp = model_temp.predict(X_val, verbose=0).flatten()\n",
    "        y_pred_real = scaler_y.inverse_transform(y_pred_temp.reshape(-1, 1)).flatten()\n",
    "        y_val_real = scaler_y.inverse_transform(y_val.reshape(-1, 1)).flatten()\n",
    "        \n",
    "        mape_temp = mean_absolute_percentage_error(y_val_real, y_pred_real)\n",
    "        \n",
    "        resultats.append({\n",
    "            'config': config,\n",
    "            'mape': mape_temp,\n",
    "            'val_loss': min(history_temp.history['val_loss'])\n",
    "        })\n",
    "        \n",
    "        print(f\"MAPE: {mape_temp*100:.2f}%\")\n",
    "    \n",
    "    # Trobar la millor configuració\n",
    "    millor = min(resultats, key=lambda x: x['mape'])\n",
    "    print(f\"\\n=== MILLOR CONFIGURACIÓ ===\")\n",
    "    print(f\"Config: {millor['config']}\")\n",
    "    print(f\"MAPE: {millor['mape']*100:.2f}%\")\n",
    "    \n",
    "    return millor, resultats\n",
    "\n",
    "\n",
    "# Exemple de configuracions a provar (descomenta per executar)\n",
    "\"\"\"\n",
    "configuracions_exemple = [\n",
    "    {'n_neurons_1': 32, 'n_neurons_2': 16, 'learning_rate': 0.001, 'dropout_rate': 0.1},\n",
    "    {'n_neurons_1': 64, 'n_neurons_2': 32, 'learning_rate': 0.001, 'dropout_rate': 0.2},\n",
    "    {'n_neurons_1': 128, 'n_neurons_2': 64, 'learning_rate': 0.0005, 'dropout_rate': 0.2},\n",
    "    {'n_neurons_1': 64, 'n_neurons_2': 32, 'learning_rate': 0.01, 'dropout_rate': 0.3},\n",
    "]\n",
    "\n",
    "millor_config, tots_resultats = gridsearch_manual(\n",
    "    X_train_scaled, y_train_scaled, \n",
    "    X_val_scaled, y_val_scaled,\n",
    "    configuracions_exemple\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88616f4a",
   "metadata": {},
   "source": [
    "## 10. FUNCIÓ PER PREDIR NOVES MOSTRES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade0ea9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predir_ms(nova_mostra, scaler_X, scaler_y, model):\n",
    "    \"\"\"\n",
    "    Prediu el % de MS per una nova mostra.\n",
    "    \n",
    "    Paràmetres:\n",
    "    -----------\n",
    "    nova_mostra : dict o array\n",
    "        Si és dict, ha de tenir les claus: 'color_promig_R', 'color_promig_G', \n",
    "        'color_promig_B', 'desviació_R', 'desviació_G', 'desviació_B', 'canal_NIR'\n",
    "        Si és array, ha de tenir els valors en aquest ordre\n",
    "    \n",
    "    Retorna:\n",
    "    --------\n",
    "    ms_predita : float\n",
    "        Percentatge de matèria seca predit\n",
    "    \"\"\"\n",
    "    # Convertir a array si és diccionari\n",
    "    if isinstance(nova_mostra, dict):\n",
    "        X_nova = np.array([[\n",
    "            nova_mostra['color_promig_R'],\n",
    "            nova_mostra['color_promig_G'],\n",
    "            nova_mostra['color_promig_B'],\n",
    "            nova_mostra['desviació_R'],\n",
    "            nova_mostra['desviació_G'],\n",
    "            nova_mostra['desviació_B'],\n",
    "            nova_mostra['canal_NIR']\n",
    "        ]])\n",
    "    else:\n",
    "        X_nova = np.array(nova_mostra).reshape(1, -1)\n",
    "    \n",
    "    # Normalitzar\n",
    "    X_nova_scaled = scaler_X.transform(X_nova)\n",
    "    \n",
    "    # Predir\n",
    "    y_pred_scaled = model.predict(X_nova_scaled, verbose=0)\n",
    "    \n",
    "    # Desnormalitzar\n",
    "    y_pred = scaler_y.inverse_transform(y_pred_scaled).flatten()[0]\n",
    "    \n",
    "    return y_pred\n",
    "\n",
    "\n",
    "# Exemple d'ús\n",
    "print(\"\\n=== EXEMPLE DE PREDICCIÓ ===\")\n",
    "mostra_exemple = {\n",
    "    'color_promig_R': 150.0,\n",
    "    'color_promig_G': 140.0,\n",
    "    'color_promig_B': 120.0,\n",
    "    'desviació_R': 20.0,\n",
    "    'desviació_G': 18.0,\n",
    "    'desviació_B': 15.0,\n",
    "    'canal_NIR': 0.65\n",
    "}\n",
    "\n",
    "ms_predita = predir_ms(mostra_exemple, scaler_X, scaler_y, model)\n",
    "print(f\"Mostra: {mostra_exemple}\")\n",
    "print(f\"MS predita: {ms_predita:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc48127",
   "metadata": {},
   "source": [
    "## 11. GUARDAR EL MODEL I SCALERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9bbe77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el model\n",
    "model.save('model_prediccio_ms.keras')\n",
    "print(\"\\n✓ Model guardat com 'model_prediccio_ms.keras'\")\n",
    "\n",
    "# Guardar els scalers amb numpy\n",
    "import pickle\n",
    "with open('scaler_X.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler_X, f)\n",
    "with open('scaler_y.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler_y, f)\n",
    "print(\"✓ Scalers guardats com 'scaler_X.pkl' i 'scaler_y.pkl'\")\n",
    "\n",
    "print(\"\\n=== PROCÉS COMPLETAT ===\")\n",
    "print(\"Per carregar el model en el futur:\")\n",
    "print(\"  model = keras.models.load_model('model_prediccio_ms.keras')\")\n",
    "print(\"  with open('scaler_X.pkl', 'rb') as f: scaler_X = pickle.load(f)\")\n",
    "print(\"  with open('scaler_y.pkl', 'rb') as f: scaler_y = pickle.load(f)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (prediccio_ms_patates)",
   "language": "python",
   "name": "prediccio_ms_patates"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
