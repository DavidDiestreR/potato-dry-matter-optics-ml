{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b99bbe34",
   "metadata": {},
   "source": [
    "# Notebook per Predicció de Matèria Seca (MS) en Patates\n",
    "\n",
    "Aquest notebook entrena una xarxa neuronal per predir el percentatge de \n",
    "matèria seca a partir de les característiques de color i NIR de les patates.\n",
    "\n",
    "Columnes del dataset:\n",
    "- id_mostra: identificador únic\n",
    "- ruta_imatges: ruta a la imatge\n",
    "- color_promig_R, color_promig_G, color_promig_B: colors mitjans RGB\n",
    "- desviació_R, desviació_G, desviació_B: desviacions estàndard dels canals\n",
    "- canal_NIR: valor del canal infraroig proper\n",
    "- MS_experimental: percentatge de matèria seca (TARGET)\n",
    "- lot: identificador del lot\n",
    "- data: data de captura\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2916d40",
   "metadata": {},
   "source": [
    "## 1. IMPORTACIÓ DE LLIBRERIES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f41661d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.13.0\n",
      "GPU disponible: []\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error, r2_score\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuració per reproducibilitat\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU disponible: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a366e400",
   "metadata": {},
   "source": [
    "## 2. CÀRREGA I EXPLORACIÓ DE DADES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8682f2e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== INFORMACIÓ DEL DATASET ===\n",
      "Nombre de mostres: 10\n",
      "\n",
      "Columnes disponibles:\n",
      "['id_mostra', 'ruta_imatges', 'color_promig_R', 'color_promig_G', 'color_promig_B', 'desviació_R', 'desviació_G', 'desviació_B', 'canal_NIR', 'MS_experimental', 'lot', 'data']\n",
      "\n",
      "Primeres files:\n",
      "   id_mostra          ruta_imatges  color_promig_R  color_promig_G  \\\n",
      "0          1  data/images/L1_1.png           158.3           132.7   \n",
      "1          2  data/images/L1_2.png           162.9           136.4   \n",
      "2          3  data/images/L1_3.png           149.6           128.3   \n",
      "3          4  data/images/L2_4.png           171.2           142.5   \n",
      "4          5  data/images/L2_5.png           167.8           140.1   \n",
      "\n",
      "   color_promig_B  desviació_R  desviació_G  desviació_B  canal_NIR  \\\n",
      "0            96.4         12.5         10.2          8.7      0.742   \n",
      "1           101.2         11.8          9.6          7.9      0.755   \n",
      "2            93.1         13.1         11.0          9.2      0.731   \n",
      "3           107.8         10.4          8.9          7.3      0.769   \n",
      "4           104.6          9.9          8.4          7.0      0.761   \n",
      "\n",
      "   MS_experimental lot        data  \n",
      "0             21.8  L1  2025-03-01  \n",
      "1             22.3  L1  2025-03-01  \n",
      "2             20.9  L1  2025-03-01  \n",
      "3             23.7  L2  2025-03-05  \n",
      "4             23.1  L2  2025-03-05  \n",
      "\n",
      "=== ESTADÍSTIQUES DESCRIPTIVES ===\n",
      "       id_mostra  color_promig_R  color_promig_G  color_promig_B  desviació_R  \\\n",
      "count   10.00000       10.000000        10.00000       10.000000    10.000000   \n",
      "mean     5.50000      159.770000       134.82000      100.690000    11.760000   \n",
      "std      3.02765       12.310614         9.19043        7.735409     1.650724   \n",
      "min      1.00000      140.200000       120.90000       90.700000     9.800000   \n",
      "25%      3.25000      150.550000       128.90000       93.925000    10.175000   \n",
      "50%      5.50000      160.600000       134.55000       99.700000    11.900000   \n",
      "75%      7.75000      170.350000       141.90000      107.000000    12.950000   \n",
      "max     10.00000      176.500000       148.20000      112.300000    14.300000   \n",
      "\n",
      "       desviació_G  desviació_B  canal_NIR  MS_experimental  \n",
      "count    10.000000    10.000000  10.000000         10.00000  \n",
      "mean      9.780000     8.140000   0.748900         22.18000  \n",
      "std       1.292543     1.005761   0.022576          1.61438  \n",
      "min       8.100000     6.900000   0.715000         19.80000  \n",
      "25%       8.600000     7.225000   0.733000         21.02500  \n",
      "50%       9.850000     8.200000   0.748500         22.05000  \n",
      "75%      10.800000     9.000000   0.767000         23.55000  \n",
      "max      11.800000     9.600000   0.781000         24.50000  \n",
      "\n",
      "=== VALORS NULS ===\n",
      "id_mostra          0\n",
      "ruta_imatges       0\n",
      "color_promig_R     0\n",
      "color_promig_G     0\n",
      "color_promig_B     0\n",
      "desviació_R        0\n",
      "desviació_G        0\n",
      "desviació_B        0\n",
      "canal_NIR          0\n",
      "MS_experimental    0\n",
      "lot                0\n",
      "data               0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# IMPORTANT: Canvia aquesta ruta per la del dataset\n",
    "os.chdir(\"D:/potato-dry-matter-optics-ml\")\n",
    "RUTA_DATASET = \"data/input/training/training_set.csv\"\n",
    "\n",
    "# Carregar les dades\n",
    "df = pd.read_csv(RUTA_DATASET)\n",
    "\n",
    "print(\"\\n=== INFORMACIÓ DEL DATASET ===\")\n",
    "print(f\"Nombre de mostres: {len(df)}\")\n",
    "print(f\"\\nColumnes disponibles:\\n{df.columns.tolist()}\")\n",
    "print(f\"\\nPrimeres files:\")\n",
    "print(df.head())\n",
    "\n",
    "# Estadístiques descriptives\n",
    "print(\"\\n=== ESTADÍSTIQUES DESCRIPTIVES ===\")\n",
    "print(df.describe())\n",
    "\n",
    "# Comprovar valors nuls\n",
    "print(\"\\n=== VALORS NULS ===\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Visualització de la distribució de MS\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.hist(df['MS_experimental'], bins=30, edgecolor='black', alpha=0.7)\n",
    "plt.xlabel('MS Experimental (%)')\n",
    "plt.ylabel('Freqüència')\n",
    "plt.title('Distribució de Matèria Seca')\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.boxplot(df['MS_experimental'])\n",
    "plt.ylabel('MS Experimental (%)')\n",
    "plt.title('Boxplot de MS')\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "# Correlació entre features i MS\n",
    "features_cols = ['color_promig_R', 'color_promig_G', 'color_promig_B', \n",
    "                 'desviació_R', 'desviació_G', 'desviació_B', 'canal_NIR']\n",
    "correlations = df[features_cols + ['MS_experimental']].corr()['MS_experimental'].drop('MS_experimental')\n",
    "correlations.plot(kind='barh')\n",
    "plt.xlabel('Correlació amb MS')\n",
    "plt.title('Correlacions amb MS')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bee5dd9",
   "metadata": {},
   "source": [
    "## 3. PREPARACIÓ DE LES DADES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aad18e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== PREPARACIÓ DE DADES ===\n",
      "Shape de X (features): (10, 7)\n",
      "Shape de y (target): (10,)\n",
      "\n",
      "Conjunt d'entrenament: 8 mostres\n",
      "Conjunt de validació: 2 mostres\n",
      "\n",
      "=== NORMALITZACIÓ COMPLETADA ===\n",
      "Mitjana X_train: [-2.19269047e-15  1.30451205e-15 -1.77635684e-15 -1.16573418e-15\n",
      "  5.55111512e-16  4.71844785e-16  3.38618023e-15]\n",
      "Desviació estàndard X_train: [1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Seleccionar les columnes d'entrada (features) i sortida (target)\n",
    "feature_cols = ['color_promig_R', 'color_promig_G', 'color_promig_B',\n",
    "                'desviació_R', 'desviació_G', 'desviació_B', 'canal_NIR']\n",
    "target_col = 'MS_experimental'\n",
    "\n",
    "# Extreure X (inputs) i y (target)\n",
    "X = df[feature_cols].values\n",
    "y = df[target_col].values\n",
    "\n",
    "print(\"\\n=== PREPARACIÓ DE DADES ===\")\n",
    "print(f\"Shape de X (features): {X.shape}\")\n",
    "print(f\"Shape de y (target): {y.shape}\")\n",
    "\n",
    "# Separar en conjunt d'entrenament (80%) i validació (20%)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\nConjunt d'entrenament: {X_train.shape[0]} mostres\")\n",
    "print(f\"Conjunt de validació: {X_val.shape[0]} mostres\")\n",
    "\n",
    "# Normalització (StandardScaler)\n",
    "# És important normalitzar per ajudar a la xarxa neuronal a convergir millor\n",
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "X_val_scaled = scaler_X.transform(X_val)\n",
    "\n",
    "y_train_scaled = scaler_y.fit_transform(y_train.reshape(-1, 1)).flatten()\n",
    "y_val_scaled = scaler_y.transform(y_val.reshape(-1, 1)).flatten()\n",
    "\n",
    "print(\"\\n=== NORMALITZACIÓ COMPLETADA ===\")\n",
    "print(f\"Mitjana X_train: {X_train_scaled.mean(axis=0)}\")\n",
    "print(f\"Desviació estàndard X_train: {X_train_scaled.std(axis=0)}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b165f99",
   "metadata": {},
   "source": [
    "## 4. DEFINICIÓ DEL MODEL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71b2b28e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== NOMBRE DE FEATURES: 7 ===\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def crear_model(n_features, arquitectura=[64, 32, 16], \n",
    "                learning_rate=0.001, dropout_rate=0.2):\n",
    "    \"\"\"\n",
    "    Crea una xarxa neuronal densa per regressió amb arquitectura flexible.\n",
    "    \n",
    "    Paràmetres:\n",
    "    -----------\n",
    "    n_features : int\n",
    "        Nombre de features d'entrada\n",
    "    arquitectura : list\n",
    "        Llista amb el nombre de neurones per cada capa oculta\n",
    "        Exemple: [64, 128, 20, 10] crea 4 capes amb 64, 128, 20 i 10 neurones\n",
    "    learning_rate : float\n",
    "        Taxa d'aprenentatge per Adam\n",
    "    dropout_rate : float\n",
    "        Taxa de dropout per regularització (s'aplica després de cada capa)\n",
    "    \n",
    "    Retorna:\n",
    "    --------\n",
    "    model : keras.Model\n",
    "        Model compilat\n",
    "    \"\"\"\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    # Capa d'entrada\n",
    "    model.add(layers.Input(shape=(n_features,)))\n",
    "    \n",
    "    # Afegir capes ocultes segons l'arquitectura especificada\n",
    "    for i, n_neurons in enumerate(arquitectura):\n",
    "        model.add(layers.Dense(n_neurons, activation='relu', \n",
    "                              name=f'hidden_{i+1}'))\n",
    "        model.add(layers.Dropout(dropout_rate, name=f'dropout_{i+1}'))\n",
    "    \n",
    "    # Capa de sortida (regressió, 1 neurona sense activació)\n",
    "    model.add(layers.Dense(1, name='output'))\n",
    "    \n",
    "    # Compilar el model\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='mse',  # Mean Squared Error per regressió\n",
    "        metrics=['mae']  # Mean Absolute Error com a mètrica addicional\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# NOTA: No creem el model aquí perquè ho farem després del GridSearch\n",
    "n_features = X_train_scaled.shape[1]\n",
    "print(f\"\\n=== NOMBRE DE FEATURES: {n_features} ===\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236afc32",
   "metadata": {},
   "source": [
    "## 5. GRIDSEARCH PER TROBAR LA MILLOR CONFIGURACIÓ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da5038c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "S'executarà GridSearch amb 10 configuracions diferents\n",
      "\n",
      "\n",
      "======================================================================\n",
      "INICI DEL GRIDSEARCH\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "CONFIGURACIÓ 1/10\n",
      "======================================================================\n",
      "Arquitectura: [32, 16]\n",
      "Learning rate: 0.001\n",
      "Dropout rate: 0.1\n",
      "Batch size: 16\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.1794 - mae: 1.2759\n",
      "Epoch 1: val_loss improved from inf to 3.02464, saving model to checkpoints\\config_1_arch_32_16.h5\n",
      "1/1 [==============================] - 1s 696ms/step - loss: 2.1794 - mae: 1.2759 - val_loss: 3.0246 - val_mae: 1.4141 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4579 - mae: 1.0424\n",
      "Epoch 2: val_loss improved from 3.02464 to 2.86151, saving model to checkpoints\\config_1_arch_32_16.h5\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.4579 - mae: 1.0424 - val_loss: 2.8615 - val_mae: 1.3739 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2972 - mae: 0.9837\n",
      "Epoch 3: val_loss improved from 2.86151 to 2.70105, saving model to checkpoints\\config_1_arch_32_16.h5\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.2972 - mae: 0.9837 - val_loss: 2.7011 - val_mae: 1.3334 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6396 - mae: 1.0952\n",
      "Epoch 4: val_loss improved from 2.70105 to 2.54416, saving model to checkpoints\\config_1_arch_32_16.h5\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.6396 - mae: 1.0952 - val_loss: 2.5442 - val_mae: 1.2931 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0887 - mae: 0.9109\n",
      "Epoch 5: val_loss improved from 2.54416 to 2.39678, saving model to checkpoints\\config_1_arch_32_16.h5\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.0887 - mae: 0.9109 - val_loss: 2.3968 - val_mae: 1.2539 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3109 - mae: 0.9286\n",
      "Epoch 6: val_loss improved from 2.39678 to 2.25260, saving model to checkpoints\\config_1_arch_32_16.h5\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.3109 - mae: 0.9286 - val_loss: 2.2526 - val_mae: 1.2146 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1246 - mae: 0.9180\n",
      "Epoch 7: val_loss improved from 2.25260 to 2.11262, saving model to checkpoints\\config_1_arch_32_16.h5\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.1246 - mae: 0.9180 - val_loss: 2.1126 - val_mae: 1.1751 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1683 - mae: 0.9473\n",
      "Epoch 8: val_loss improved from 2.11262 to 1.98509, saving model to checkpoints\\config_1_arch_32_16.h5\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.1683 - mae: 0.9473 - val_loss: 1.9851 - val_mae: 1.1374 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6623 - mae: 1.0404\n",
      "Epoch 9: val_loss improved from 1.98509 to 1.86334, saving model to checkpoints\\config_1_arch_32_16.h5\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.6623 - mae: 1.0404 - val_loss: 1.8633 - val_mae: 1.1001 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7469 - mae: 0.7081\n",
      "Epoch 10: val_loss improved from 1.86334 to 1.74320, saving model to checkpoints\\config_1_arch_32_16.h5\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.7469 - mae: 0.7081 - val_loss: 1.7432 - val_mae: 1.0612 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7898 - mae: 0.7467\n",
      "Epoch 11: val_loss improved from 1.74320 to 1.62761, saving model to checkpoints\\config_1_arch_32_16.h5\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7898 - mae: 0.7467 - val_loss: 1.6276 - val_mae: 1.0224 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6487 - mae: 0.6297\n",
      "Epoch 12: val_loss improved from 1.62761 to 1.51491, saving model to checkpoints\\config_1_arch_32_16.h5\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6487 - mae: 0.6297 - val_loss: 1.5149 - val_mae: 0.9828 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9554 - mae: 0.8202\n",
      "Epoch 13: val_loss improved from 1.51491 to 1.40263, saving model to checkpoints\\config_1_arch_32_16.h5\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.9554 - mae: 0.8202 - val_loss: 1.4026 - val_mae: 0.9420 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6219 - mae: 0.6212\n",
      "Epoch 14: val_loss improved from 1.40263 to 1.29458, saving model to checkpoints\\config_1_arch_32_16.h5\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6219 - mae: 0.6212 - val_loss: 1.2946 - val_mae: 0.9011 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5701 - mae: 0.6252\n",
      "Epoch 15: val_loss improved from 1.29458 to 1.19453, saving model to checkpoints\\config_1_arch_32_16.h5\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5701 - mae: 0.6252 - val_loss: 1.1945 - val_mae: 0.8613 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9818 - mae: 0.8509\n",
      "Epoch 16: val_loss improved from 1.19453 to 1.10069, saving model to checkpoints\\config_1_arch_32_16.h5\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.9818 - mae: 0.8509 - val_loss: 1.1007 - val_mae: 0.8222 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4361 - mae: 0.5499\n",
      "Epoch 17: val_loss improved from 1.10069 to 0.99939, saving model to checkpoints\\config_1_arch_32_16.h5\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4361 - mae: 0.5499 - val_loss: 0.9994 - val_mae: 0.7792 - lr: 0.0010\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6821 - mae: 0.6916\n",
      "Epoch 18: val_loss improved from 0.99939 to 0.90491, saving model to checkpoints\\config_1_arch_32_16.h5\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6821 - mae: 0.6916 - val_loss: 0.9049 - val_mae: 0.7386 - lr: 0.0010\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3549 - mae: 0.4712\n",
      "Epoch 19: val_loss improved from 0.90491 to 0.81798, saving model to checkpoints\\config_1_arch_32_16.h5\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3549 - mae: 0.4712 - val_loss: 0.8180 - val_mae: 0.7007 - lr: 0.0010\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2085 - mae: 0.3330\n",
      "Epoch 20: val_loss improved from 0.81798 to 0.73567, saving model to checkpoints\\config_1_arch_32_16.h5\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2085 - mae: 0.3330 - val_loss: 0.7357 - val_mae: 0.6627 - lr: 0.0010\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7192 - mae: 0.6357\n",
      "Epoch 21: val_loss improved from 0.73567 to 0.65880, saving model to checkpoints\\config_1_arch_32_16.h5\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.7192 - mae: 0.6357 - val_loss: 0.6588 - val_mae: 0.6252 - lr: 0.0010\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3678 - mae: 0.4979\n",
      "Epoch 22: val_loss improved from 0.65880 to 0.59311, saving model to checkpoints\\config_1_arch_32_16.h5\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3678 - mae: 0.4979 - val_loss: 0.5931 - val_mae: 0.5909 - lr: 0.0010\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3024 - mae: 0.4253\n",
      "Epoch 23: val_loss improved from 0.59311 to 0.53190, saving model to checkpoints\\config_1_arch_32_16.h5\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.3024 - mae: 0.4253 - val_loss: 0.5319 - val_mae: 0.5572 - lr: 0.0010\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3536 - mae: 0.4803\n",
      "Epoch 24: val_loss improved from 0.53190 to 0.48721, saving model to checkpoints\\config_1_arch_32_16.h5\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.3536 - mae: 0.4803 - val_loss: 0.4872 - val_mae: 0.5301 - lr: 0.0010\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2379 - mae: 0.3910\n",
      "Epoch 25: val_loss improved from 0.48721 to 0.44623, saving model to checkpoints\\config_1_arch_32_16.h5\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2379 - mae: 0.3910 - val_loss: 0.4462 - val_mae: 0.5040 - lr: 0.0010\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2340 - mae: 0.3893\n",
      "Epoch 26: val_loss improved from 0.44623 to 0.40814, saving model to checkpoints\\config_1_arch_32_16.h5\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2340 - mae: 0.3893 - val_loss: 0.4081 - val_mae: 0.4783 - lr: 0.0010\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1696 - mae: 0.3258\n",
      "Epoch 27: val_loss improved from 0.40814 to 0.37175, saving model to checkpoints\\config_1_arch_32_16.h5\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1696 - mae: 0.3258 - val_loss: 0.3717 - val_mae: 0.4526 - lr: 0.0010\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1868 - mae: 0.3122\n",
      "Epoch 28: val_loss improved from 0.37175 to 0.33643, saving model to checkpoints\\config_1_arch_32_16.h5\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1868 - mae: 0.3122 - val_loss: 0.3364 - val_mae: 0.4263 - lr: 0.0010\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2384 - mae: 0.2792\n",
      "Epoch 29: val_loss improved from 0.33643 to 0.30288, saving model to checkpoints\\config_1_arch_32_16.h5\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2384 - mae: 0.2792 - val_loss: 0.3029 - val_mae: 0.3999 - lr: 0.0010\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2189 - mae: 0.3372\n",
      "Epoch 30: val_loss improved from 0.30288 to 0.27078, saving model to checkpoints\\config_1_arch_32_16.h5\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2189 - mae: 0.3372 - val_loss: 0.2708 - val_mae: 0.3732 - lr: 0.0010\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0936 - mae: 0.2264\n",
      "Epoch 31: val_loss improved from 0.27078 to 0.24151, saving model to checkpoints\\config_1_arch_32_16.h5\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0936 - mae: 0.2264 - val_loss: 0.2415 - val_mae: 0.3476 - lr: 0.0010\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2678 - mae: 0.3865\n",
      "Epoch 32: val_loss improved from 0.24151 to 0.21425, saving model to checkpoints\\config_1_arch_32_16.h5\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2678 - mae: 0.3865 - val_loss: 0.2143 - val_mae: 0.3328 - lr: 0.0010\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1227 - mae: 0.2979\n",
      "Epoch 33: val_loss improved from 0.21425 to 0.18892, saving model to checkpoints\\config_1_arch_32_16.h5\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1227 - mae: 0.2979 - val_loss: 0.1889 - val_mae: 0.3180 - lr: 0.0010\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0709 - mae: 0.1830\n",
      "Epoch 34: val_loss improved from 0.18892 to 0.16583, saving model to checkpoints\\config_1_arch_32_16.h5\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0709 - mae: 0.1830 - val_loss: 0.1658 - val_mae: 0.3036 - lr: 0.0010\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0204 - mae: 0.1223\n",
      "Epoch 35: val_loss improved from 0.16583 to 0.14528, saving model to checkpoints\\config_1_arch_32_16.h5\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0204 - mae: 0.1223 - val_loss: 0.1453 - val_mae: 0.2897 - lr: 0.0010\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1900 - mae: 0.3648\n",
      "Epoch 36: val_loss improved from 0.14528 to 0.12652, saving model to checkpoints\\config_1_arch_32_16.h5\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1900 - mae: 0.3648 - val_loss: 0.1265 - val_mae: 0.2760 - lr: 0.0010\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0694 - mae: 0.2095\n",
      "Epoch 37: val_loss improved from 0.12652 to 0.10950, saving model to checkpoints\\config_1_arch_32_16.h5\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0694 - mae: 0.2095 - val_loss: 0.1095 - val_mae: 0.2625 - lr: 0.0010\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0610 - mae: 0.1915\n",
      "Epoch 38: val_loss improved from 0.10950 to 0.09428, saving model to checkpoints\\config_1_arch_32_16.h5\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0610 - mae: 0.1915 - val_loss: 0.0943 - val_mae: 0.2494 - lr: 0.0010\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0463 - mae: 0.1626\n",
      "Epoch 39: val_loss improved from 0.09428 to 0.08135, saving model to checkpoints\\config_1_arch_32_16.h5\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0463 - mae: 0.1626 - val_loss: 0.0813 - val_mae: 0.2373 - lr: 0.0010\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0400 - mae: 0.1764\n",
      "Epoch 40: val_loss improved from 0.08135 to 0.07006, saving model to checkpoints\\config_1_arch_32_16.h5\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0400 - mae: 0.1764 - val_loss: 0.0701 - val_mae: 0.2256 - lr: 0.0010\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0885 - mae: 0.2709\n",
      "Epoch 41: val_loss improved from 0.07006 to 0.06014, saving model to checkpoints\\config_1_arch_32_16.h5\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0885 - mae: 0.2709 - val_loss: 0.0601 - val_mae: 0.2144 - lr: 0.0010\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0303 - mae: 0.1420\n",
      "Epoch 42: val_loss improved from 0.06014 to 0.05192, saving model to checkpoints\\config_1_arch_32_16.h5\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0303 - mae: 0.1420 - val_loss: 0.0519 - val_mae: 0.2040 - lr: 0.0010\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0983 - mae: 0.2363\n",
      "Epoch 43: val_loss improved from 0.05192 to 0.04472, saving model to checkpoints\\config_1_arch_32_16.h5\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0983 - mae: 0.2363 - val_loss: 0.0447 - val_mae: 0.1940 - lr: 0.0010\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0499 - mae: 0.1646\n",
      "Epoch 44: val_loss improved from 0.04472 to 0.03884, saving model to checkpoints\\config_1_arch_32_16.h5\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0499 - mae: 0.1646 - val_loss: 0.0388 - val_mae: 0.1849 - lr: 0.0010\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1024 - mae: 0.2556\n",
      "Epoch 45: val_loss improved from 0.03884 to 0.03373, saving model to checkpoints\\config_1_arch_32_16.h5\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1024 - mae: 0.2556 - val_loss: 0.0337 - val_mae: 0.1759 - lr: 0.0010\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0683 - mae: 0.2037\n",
      "Epoch 46: val_loss improved from 0.03373 to 0.02921, saving model to checkpoints\\config_1_arch_32_16.h5\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0683 - mae: 0.2037 - val_loss: 0.0292 - val_mae: 0.1668 - lr: 0.0010\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0899 - mae: 0.2196\n",
      "Epoch 47: val_loss improved from 0.02921 to 0.02556, saving model to checkpoints\\config_1_arch_32_16.h5\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0899 - mae: 0.2196 - val_loss: 0.0256 - val_mae: 0.1582 - lr: 0.0010\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1296 - mae: 0.2932\n",
      "Epoch 48: val_loss improved from 0.02556 to 0.02227, saving model to checkpoints\\config_1_arch_32_16.h5\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.1296 - mae: 0.2932 - val_loss: 0.0223 - val_mae: 0.1491 - lr: 0.0010\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1702 - mae: 0.2709\n",
      "Epoch 49: val_loss improved from 0.02227 to 0.02011, saving model to checkpoints\\config_1_arch_32_16.h5\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1702 - mae: 0.2709 - val_loss: 0.0201 - val_mae: 0.1417 - lr: 0.0010\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0456 - mae: 0.1624\n",
      "Epoch 50: val_loss improved from 0.02011 to 0.01833, saving model to checkpoints\\config_1_arch_32_16.h5\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0456 - mae: 0.1624 - val_loss: 0.0183 - val_mae: 0.1342 - lr: 0.0010\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0591 - mae: 0.1723\n",
      "Epoch 51: val_loss improved from 0.01833 to 0.01710, saving model to checkpoints\\config_1_arch_32_16.h5\n",
      "1/1 [==============================] - 0s 433ms/step - loss: 0.0591 - mae: 0.1723 - val_loss: 0.0171 - val_mae: 0.1273 - lr: 0.0010\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0408 - mae: 0.1662\n",
      "Epoch 52: val_loss improved from 0.01710 to 0.01621, saving model to checkpoints\\config_1_arch_32_16.h5\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.0408 - mae: 0.1662 - val_loss: 0.0162 - val_mae: 0.1203 - lr: 0.0010\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0821 - mae: 0.2067\n",
      "Epoch 53: val_loss improved from 0.01621 to 0.01579, saving model to checkpoints\\config_1_arch_32_16.h5\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.0821 - mae: 0.2067 - val_loss: 0.0158 - val_mae: 0.1149 - lr: 0.0010\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0324 - mae: 0.1468\n",
      "Epoch 54: val_loss improved from 0.01579 to 0.01561, saving model to checkpoints\\config_1_arch_32_16.h5\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 0.0324 - mae: 0.1468 - val_loss: 0.0156 - val_mae: 0.1104 - lr: 0.0010\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1839 - mae: 0.2703\n",
      "Epoch 55: val_loss improved from 0.01561 to 0.01556, saving model to checkpoints\\config_1_arch_32_16.h5\n",
      "1/1 [==============================] - 0s 333ms/step - loss: 0.1839 - mae: 0.2703 - val_loss: 0.0156 - val_mae: 0.1072 - lr: 0.0010\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0480 - mae: 0.1940\n",
      "Epoch 56: val_loss did not improve from 0.01556\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0480 - mae: 0.1940 - val_loss: 0.0156 - val_mae: 0.1046 - lr: 0.0010\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0694 - mae: 0.2229\n",
      "Epoch 57: val_loss did not improve from 0.01556\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0694 - mae: 0.2229 - val_loss: 0.0156 - val_mae: 0.1034 - lr: 0.0010\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0516 - mae: 0.1876\n",
      "Epoch 58: val_loss did not improve from 0.01556\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0516 - mae: 0.1876 - val_loss: 0.0156 - val_mae: 0.1033 - lr: 0.0010\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0465 - mae: 0.1762\n",
      "Epoch 59: val_loss improved from 0.01556 to 0.01550, saving model to checkpoints\\config_1_arch_32_16.h5\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.0465 - mae: 0.1762 - val_loss: 0.0155 - val_mae: 0.1041 - lr: 0.0010\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0191 - mae: 0.1016\n",
      "Epoch 60: val_loss improved from 0.01550 to 0.01546, saving model to checkpoints\\config_1_arch_32_16.h5\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.0191 - mae: 0.1016 - val_loss: 0.0155 - val_mae: 0.1056 - lr: 0.0010\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1613 - mae: 0.2856\n",
      "Epoch 61: val_loss improved from 0.01546 to 0.01543, saving model to checkpoints\\config_1_arch_32_16.h5\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.1613 - mae: 0.2856 - val_loss: 0.0154 - val_mae: 0.1067 - lr: 0.0010\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2635 - mae: 0.3052\n",
      "Epoch 62: val_loss improved from 0.01543 to 0.01539, saving model to checkpoints\\config_1_arch_32_16.h5\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.2635 - mae: 0.3052 - val_loss: 0.0154 - val_mae: 0.1070 - lr: 0.0010\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0740 - mae: 0.2439\n",
      "Epoch 63: val_loss improved from 0.01539 to 0.01535, saving model to checkpoints\\config_1_arch_32_16.h5\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.0740 - mae: 0.2439 - val_loss: 0.0154 - val_mae: 0.1089 - lr: 0.0010\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0423 - mae: 0.1529\n",
      "Epoch 64: val_loss did not improve from 0.01535\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0423 - mae: 0.1529 - val_loss: 0.0154 - val_mae: 0.1106 - lr: 0.0010\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0636 - mae: 0.2006\n",
      "Epoch 65: val_loss did not improve from 0.01535\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0636 - mae: 0.2006 - val_loss: 0.0154 - val_mae: 0.1125 - lr: 0.0010\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0140 - mae: 0.1011\n",
      "Epoch 66: val_loss did not improve from 0.01535\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0140 - mae: 0.1011 - val_loss: 0.0155 - val_mae: 0.1143 - lr: 0.0010\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0207 - mae: 0.1171\n",
      "Epoch 67: val_loss did not improve from 0.01535\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0207 - mae: 0.1171 - val_loss: 0.0156 - val_mae: 0.1162 - lr: 0.0010\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1232 - mae: 0.2606\n",
      "Epoch 68: val_loss did not improve from 0.01535\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1232 - mae: 0.2606 - val_loss: 0.0156 - val_mae: 0.1170 - lr: 0.0010\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0458 - mae: 0.1734\n",
      "Epoch 69: val_loss did not improve from 0.01535\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0458 - mae: 0.1734 - val_loss: 0.0156 - val_mae: 0.1173 - lr: 0.0010\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0449 - mae: 0.1535\n",
      "Epoch 70: val_loss did not improve from 0.01535\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0449 - mae: 0.1535 - val_loss: 0.0157 - val_mae: 0.1179 - lr: 0.0010\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0726 - mae: 0.1911\n",
      "Epoch 71: val_loss did not improve from 0.01535\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0726 - mae: 0.1911 - val_loss: 0.0156 - val_mae: 0.1176 - lr: 0.0010\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0867 - mae: 0.2452\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.01535\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0867 - mae: 0.2452 - val_loss: 0.0157 - val_mae: 0.1180 - lr: 0.0010\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0542 - mae: 0.1902\n",
      "Epoch 73: val_loss did not improve from 0.01535\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0542 - mae: 0.1902 - val_loss: 0.0157 - val_mae: 0.1189 - lr: 5.0000e-04\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2666 - mae: 0.3507\n",
      "Epoch 74: val_loss did not improve from 0.01535\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2666 - mae: 0.3507 - val_loss: 0.0158 - val_mae: 0.1199 - lr: 5.0000e-04\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0968 - mae: 0.2339\n",
      "Epoch 75: val_loss did not improve from 0.01535\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0968 - mae: 0.2339 - val_loss: 0.0159 - val_mae: 0.1209 - lr: 5.0000e-04\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0519 - mae: 0.1835\n",
      "Epoch 76: val_loss did not improve from 0.01535\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0519 - mae: 0.1835 - val_loss: 0.0160 - val_mae: 0.1214 - lr: 5.0000e-04\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1706 - mae: 0.2821\n",
      "Epoch 77: val_loss did not improve from 0.01535\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1706 - mae: 0.2821 - val_loss: 0.0161 - val_mae: 0.1221 - lr: 5.0000e-04\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1154 - mae: 0.2646\n",
      "Epoch 78: val_loss did not improve from 0.01535\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.1154 - mae: 0.2646 - val_loss: 0.0161 - val_mae: 0.1225 - lr: 5.0000e-04\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0689 - mae: 0.2132\n",
      "Epoch 79: val_loss did not improve from 0.01535\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0689 - mae: 0.2132 - val_loss: 0.0161 - val_mae: 0.1229 - lr: 5.0000e-04\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0870 - mae: 0.2350\n",
      "Epoch 80: val_loss did not improve from 0.01535\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0870 - mae: 0.2350 - val_loss: 0.0161 - val_mae: 0.1228 - lr: 5.0000e-04\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0924 - mae: 0.2250\n",
      "Epoch 81: val_loss did not improve from 0.01535\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0924 - mae: 0.2250 - val_loss: 0.0161 - val_mae: 0.1228 - lr: 5.0000e-04\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0542 - mae: 0.1640\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.01535\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0542 - mae: 0.1640 - val_loss: 0.0161 - val_mae: 0.1231 - lr: 5.0000e-04\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1883 - mae: 0.2627Restoring model weights from the end of the best epoch: 63.\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.01535\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1883 - mae: 0.2627 - val_loss: 0.0161 - val_mae: 0.1231 - lr: 2.5000e-04\n",
      "Epoch 83: early stopping\n",
      "\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "RESULTATS CONFIG 1:\n",
      "  MAPE: 0.70%\n",
      "  RMSE: 0.182\n",
      "  MAE: 0.160\n",
      "  R²: 0.973\n",
      "  Èpoques entrenades: 83\n",
      "  Checkpoint guardat a: checkpoints/config_1_arch_32_16.keras\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "\n",
      "======================================================================\n",
      "CONFIGURACIÓ 2/10\n",
      "======================================================================\n",
      "Arquitectura: [64, 32]\n",
      "Learning rate: 0.001\n",
      "Dropout rate: 0.2\n",
      "Batch size: 16\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2933 - mae: 0.9779\n",
      "Epoch 1: val_loss improved from inf to 1.86928, saving model to checkpoints\\config_2_arch_64_32.h5\n",
      "1/1 [==============================] - 1s 844ms/step - loss: 1.2933 - mae: 0.9779 - val_loss: 1.8693 - val_mae: 1.0957 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0976 - mae: 0.9011\n",
      "Epoch 2: val_loss improved from 1.86928 to 1.64780, saving model to checkpoints\\config_2_arch_64_32.h5\n",
      "1/1 [==============================] - 0s 489ms/step - loss: 1.0976 - mae: 0.9011 - val_loss: 1.6478 - val_mae: 1.0226 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0154 - mae: 0.8572\n",
      "Epoch 3: val_loss improved from 1.64780 to 1.45272, saving model to checkpoints\\config_2_arch_64_32.h5\n",
      "1/1 [==============================] - 0s 295ms/step - loss: 1.0154 - mae: 0.8572 - val_loss: 1.4527 - val_mae: 0.9542 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8096 - mae: 0.7803\n",
      "Epoch 4: val_loss improved from 1.45272 to 1.27001, saving model to checkpoints\\config_2_arch_64_32.h5\n",
      "1/1 [==============================] - 1s 763ms/step - loss: 0.8096 - mae: 0.7803 - val_loss: 1.2700 - val_mae: 0.8857 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5911 - mae: 0.6606\n",
      "Epoch 5: val_loss improved from 1.27001 to 1.09973, saving model to checkpoints\\config_2_arch_64_32.h5\n",
      "1/1 [==============================] - 0s 428ms/step - loss: 0.5911 - mae: 0.6606 - val_loss: 1.0997 - val_mae: 0.8173 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6974 - mae: 0.7298\n",
      "Epoch 6: val_loss improved from 1.09973 to 0.94014, saving model to checkpoints\\config_2_arch_64_32.h5\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 0.6974 - mae: 0.7298 - val_loss: 0.9401 - val_mae: 0.7482 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6237 - mae: 0.6067\n",
      "Epoch 7: val_loss improved from 0.94014 to 0.79074, saving model to checkpoints\\config_2_arch_64_32.h5\n",
      "1/1 [==============================] - 0s 485ms/step - loss: 0.6237 - mae: 0.6067 - val_loss: 0.7907 - val_mae: 0.6777 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5195 - mae: 0.6384\n",
      "Epoch 8: val_loss improved from 0.79074 to 0.65308, saving model to checkpoints\\config_2_arch_64_32.h5\n",
      "1/1 [==============================] - 0s 280ms/step - loss: 0.5195 - mae: 0.6384 - val_loss: 0.6531 - val_mae: 0.6068 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5343 - mae: 0.5913\n",
      "Epoch 9: val_loss improved from 0.65308 to 0.52933, saving model to checkpoints\\config_2_arch_64_32.h5\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.5343 - mae: 0.5913 - val_loss: 0.5293 - val_mae: 0.5362 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3017 - mae: 0.4298\n",
      "Epoch 10: val_loss improved from 0.52933 to 0.42550, saving model to checkpoints\\config_2_arch_64_32.h5\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.3017 - mae: 0.4298 - val_loss: 0.4255 - val_mae: 0.4712 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4292 - mae: 0.5188\n",
      "Epoch 11: val_loss improved from 0.42550 to 0.33196, saving model to checkpoints\\config_2_arch_64_32.h5\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 0.4292 - mae: 0.5188 - val_loss: 0.3320 - val_mae: 0.4092 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2334 - mae: 0.3860\n",
      "Epoch 12: val_loss improved from 0.33196 to 0.24848, saving model to checkpoints\\config_2_arch_64_32.h5\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.2334 - mae: 0.3860 - val_loss: 0.2485 - val_mae: 0.3660 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2244 - mae: 0.3801\n",
      "Epoch 13: val_loss improved from 0.24848 to 0.17759, saving model to checkpoints\\config_2_arch_64_32.h5\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.2244 - mae: 0.3801 - val_loss: 0.1776 - val_mae: 0.3224 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0485 - mae: 0.1898\n",
      "Epoch 14: val_loss improved from 0.17759 to 0.12537, saving model to checkpoints\\config_2_arch_64_32.h5\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.0485 - mae: 0.1898 - val_loss: 0.1254 - val_mae: 0.2837 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0673 - mae: 0.2058\n",
      "Epoch 15: val_loss improved from 0.12537 to 0.08700, saving model to checkpoints\\config_2_arch_64_32.h5\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.0673 - mae: 0.2058 - val_loss: 0.0870 - val_mae: 0.2497 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2975 - mae: 0.3949\n",
      "Epoch 16: val_loss improved from 0.08700 to 0.05843, saving model to checkpoints\\config_2_arch_64_32.h5\n",
      "1/1 [==============================] - 0s 447ms/step - loss: 0.2975 - mae: 0.3949 - val_loss: 0.0584 - val_mae: 0.2180 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0844 - mae: 0.2614\n",
      "Epoch 17: val_loss improved from 0.05843 to 0.03840, saving model to checkpoints\\config_2_arch_64_32.h5\n",
      "1/1 [==============================] - 0s 463ms/step - loss: 0.0844 - mae: 0.2614 - val_loss: 0.0384 - val_mae: 0.1881 - lr: 0.0010\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1000 - mae: 0.2519\n",
      "Epoch 18: val_loss improved from 0.03840 to 0.02573, saving model to checkpoints\\config_2_arch_64_32.h5\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.1000 - mae: 0.2519 - val_loss: 0.0257 - val_mae: 0.1602 - lr: 0.0010\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1672 - mae: 0.2961\n",
      "Epoch 19: val_loss improved from 0.02573 to 0.01942, saving model to checkpoints\\config_2_arch_64_32.h5\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.1672 - mae: 0.2961 - val_loss: 0.0194 - val_mae: 0.1342 - lr: 0.0010\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0749 - mae: 0.2315\n",
      "Epoch 20: val_loss improved from 0.01942 to 0.01831, saving model to checkpoints\\config_2_arch_64_32.h5\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0749 - mae: 0.2315 - val_loss: 0.0183 - val_mae: 0.1112 - lr: 0.0010\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1159 - mae: 0.2758\n",
      "Epoch 21: val_loss did not improve from 0.01831\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1159 - mae: 0.2758 - val_loss: 0.0200 - val_mae: 0.1054 - lr: 0.0010\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1509 - mae: 0.3438\n",
      "Epoch 22: val_loss did not improve from 0.01831\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1509 - mae: 0.3438 - val_loss: 0.0232 - val_mae: 0.1298 - lr: 0.0010\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2381 - mae: 0.3179\n",
      "Epoch 23: val_loss did not improve from 0.01831\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2381 - mae: 0.3179 - val_loss: 0.0266 - val_mae: 0.1481 - lr: 0.0010\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1883 - mae: 0.3435\n",
      "Epoch 24: val_loss did not improve from 0.01831\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1883 - mae: 0.3435 - val_loss: 0.0311 - val_mae: 0.1672 - lr: 0.0010\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1183 - mae: 0.2806\n",
      "Epoch 25: val_loss did not improve from 0.01831\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1183 - mae: 0.2806 - val_loss: 0.0364 - val_mae: 0.1855 - lr: 0.0010\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1222 - mae: 0.2586\n",
      "Epoch 26: val_loss did not improve from 0.01831\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1222 - mae: 0.2586 - val_loss: 0.0426 - val_mae: 0.2036 - lr: 0.0010\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0555 - mae: 0.1915\n",
      "Epoch 27: val_loss did not improve from 0.01831\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0555 - mae: 0.1915 - val_loss: 0.0482 - val_mae: 0.2183 - lr: 0.0010\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1398 - mae: 0.3013\n",
      "Epoch 28: val_loss did not improve from 0.01831\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1398 - mae: 0.3013 - val_loss: 0.0528 - val_mae: 0.2291 - lr: 0.0010\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1012 - mae: 0.2290\n",
      "Epoch 29: val_loss did not improve from 0.01831\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1012 - mae: 0.2290 - val_loss: 0.0531 - val_mae: 0.2298 - lr: 0.0010\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0303 - mae: 0.1403\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.01831\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0303 - mae: 0.1403 - val_loss: 0.0521 - val_mae: 0.2278 - lr: 0.0010\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0996 - mae: 0.2719\n",
      "Epoch 31: val_loss did not improve from 0.01831\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0996 - mae: 0.2719 - val_loss: 0.0506 - val_mae: 0.2243 - lr: 5.0000e-04\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1674 - mae: 0.3285\n",
      "Epoch 32: val_loss did not improve from 0.01831\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1674 - mae: 0.3285 - val_loss: 0.0469 - val_mae: 0.2153 - lr: 5.0000e-04\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1107 - mae: 0.2206\n",
      "Epoch 33: val_loss did not improve from 0.01831\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1107 - mae: 0.2206 - val_loss: 0.0426 - val_mae: 0.2043 - lr: 5.0000e-04\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0479 - mae: 0.1761\n",
      "Epoch 34: val_loss did not improve from 0.01831\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0479 - mae: 0.1761 - val_loss: 0.0386 - val_mae: 0.1934 - lr: 5.0000e-04\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2809 - mae: 0.4433\n",
      "Epoch 35: val_loss did not improve from 0.01831\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2809 - mae: 0.4433 - val_loss: 0.0333 - val_mae: 0.1773 - lr: 5.0000e-04\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1488 - mae: 0.3036\n",
      "Epoch 36: val_loss did not improve from 0.01831\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1488 - mae: 0.3036 - val_loss: 0.0283 - val_mae: 0.1597 - lr: 5.0000e-04\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1419 - mae: 0.2668\n",
      "Epoch 37: val_loss did not improve from 0.01831\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1419 - mae: 0.2668 - val_loss: 0.0243 - val_mae: 0.1424 - lr: 5.0000e-04\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1476 - mae: 0.2443\n",
      "Epoch 38: val_loss did not improve from 0.01831\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1476 - mae: 0.2443 - val_loss: 0.0212 - val_mae: 0.1265 - lr: 5.0000e-04\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0995 - mae: 0.2181\n",
      "Epoch 39: val_loss did not improve from 0.01831\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0995 - mae: 0.2181 - val_loss: 0.0190 - val_mae: 0.1115 - lr: 5.0000e-04\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0687 - mae: 0.2169\n",
      "Epoch 40: val_loss improved from 0.01831 to 0.01747, saving model to checkpoints\\config_2_arch_64_32.h5\n",
      "1/1 [==============================] - 1s 640ms/step - loss: 0.0687 - mae: 0.2169 - val_loss: 0.0175 - val_mae: 0.0972 - lr: 5.0000e-04\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0787 - mae: 0.2383\n",
      "Epoch 41: val_loss improved from 0.01747 to 0.01649, saving model to checkpoints\\config_2_arch_64_32.h5\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.0787 - mae: 0.2383 - val_loss: 0.0165 - val_mae: 0.0981 - lr: 5.0000e-04\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0301 - mae: 0.1299\n",
      "Epoch 42: val_loss improved from 0.01649 to 0.01608, saving model to checkpoints\\config_2_arch_64_32.h5\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.0301 - mae: 0.1299 - val_loss: 0.0161 - val_mae: 0.1057 - lr: 5.0000e-04\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0602 - mae: 0.1889\n",
      "Epoch 43: val_loss did not improve from 0.01608\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0602 - mae: 0.1889 - val_loss: 0.0161 - val_mae: 0.1132 - lr: 5.0000e-04\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0752 - mae: 0.2270\n",
      "Epoch 44: val_loss did not improve from 0.01608\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0752 - mae: 0.2270 - val_loss: 0.0166 - val_mae: 0.1211 - lr: 5.0000e-04\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0696 - mae: 0.1839\n",
      "Epoch 45: val_loss did not improve from 0.01608\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0696 - mae: 0.1839 - val_loss: 0.0176 - val_mae: 0.1291 - lr: 5.0000e-04\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0637 - mae: 0.2097\n",
      "Epoch 46: val_loss did not improve from 0.01608\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0637 - mae: 0.2097 - val_loss: 0.0190 - val_mae: 0.1365 - lr: 5.0000e-04\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0575 - mae: 0.1851\n",
      "Epoch 47: val_loss did not improve from 0.01608\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0575 - mae: 0.1851 - val_loss: 0.0204 - val_mae: 0.1426 - lr: 5.0000e-04\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0447 - mae: 0.1632\n",
      "Epoch 48: val_loss did not improve from 0.01608\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0447 - mae: 0.1632 - val_loss: 0.0222 - val_mae: 0.1491 - lr: 5.0000e-04\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0585 - mae: 0.1923\n",
      "Epoch 49: val_loss did not improve from 0.01608\n",
      "1/1 [==============================] - 0s 473ms/step - loss: 0.0585 - mae: 0.1923 - val_loss: 0.0239 - val_mae: 0.1542 - lr: 5.0000e-04\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0970 - mae: 0.2847\n",
      "Epoch 50: val_loss did not improve from 0.01608\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0970 - mae: 0.2847 - val_loss: 0.0258 - val_mae: 0.1593 - lr: 5.0000e-04\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0373 - mae: 0.1740\n",
      "Epoch 51: val_loss did not improve from 0.01608\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0373 - mae: 0.1740 - val_loss: 0.0273 - val_mae: 0.1630 - lr: 5.0000e-04\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1515 - mae: 0.2556\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.01608\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1515 - mae: 0.2556 - val_loss: 0.0278 - val_mae: 0.1643 - lr: 5.0000e-04\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0645 - mae: 0.2222\n",
      "Epoch 53: val_loss did not improve from 0.01608\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0645 - mae: 0.2222 - val_loss: 0.0282 - val_mae: 0.1652 - lr: 2.5000e-04\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0790 - mae: 0.2431\n",
      "Epoch 54: val_loss did not improve from 0.01608\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0790 - mae: 0.2431 - val_loss: 0.0285 - val_mae: 0.1658 - lr: 2.5000e-04\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0575 - mae: 0.2238\n",
      "Epoch 55: val_loss did not improve from 0.01608\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0575 - mae: 0.2238 - val_loss: 0.0286 - val_mae: 0.1660 - lr: 2.5000e-04\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0520 - mae: 0.1512\n",
      "Epoch 56: val_loss did not improve from 0.01608\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0520 - mae: 0.1512 - val_loss: 0.0284 - val_mae: 0.1658 - lr: 2.5000e-04\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0822 - mae: 0.2465\n",
      "Epoch 57: val_loss did not improve from 0.01608\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0822 - mae: 0.2465 - val_loss: 0.0287 - val_mae: 0.1664 - lr: 2.5000e-04\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1346 - mae: 0.2931\n",
      "Epoch 58: val_loss did not improve from 0.01608\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1346 - mae: 0.2931 - val_loss: 0.0285 - val_mae: 0.1660 - lr: 2.5000e-04\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0955 - mae: 0.2669\n",
      "Epoch 59: val_loss did not improve from 0.01608\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0955 - mae: 0.2669 - val_loss: 0.0282 - val_mae: 0.1654 - lr: 2.5000e-04\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0901 - mae: 0.2435\n",
      "Epoch 60: val_loss did not improve from 0.01608\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0901 - mae: 0.2435 - val_loss: 0.0280 - val_mae: 0.1649 - lr: 2.5000e-04\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1220 - mae: 0.2869\n",
      "Epoch 61: val_loss did not improve from 0.01608\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1220 - mae: 0.2869 - val_loss: 0.0275 - val_mae: 0.1637 - lr: 2.5000e-04\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0606 - mae: 0.1977Restoring model weights from the end of the best epoch: 42.\n",
      "\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.01608\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0606 - mae: 0.1977 - val_loss: 0.0271 - val_mae: 0.1628 - lr: 2.5000e-04\n",
      "Epoch 62: early stopping\n",
      "\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "RESULTATS CONFIG 2:\n",
      "  MAPE: 0.69%\n",
      "  RMSE: 0.187\n",
      "  MAE: 0.155\n",
      "  R²: 0.971\n",
      "  Èpoques entrenades: 62\n",
      "  Checkpoint guardat a: checkpoints/config_2_arch_64_32.keras\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "\n",
      "======================================================================\n",
      "CONFIGURACIÓ 3/10\n",
      "======================================================================\n",
      "Arquitectura: [64, 32, 16]\n",
      "Learning rate: 0.001\n",
      "Dropout rate: 0.2\n",
      "Batch size: 16\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5360 - mae: 1.0562\n",
      "Epoch 1: val_loss improved from inf to 1.38336, saving model to checkpoints\\config_3_arch_64_32_16.h5\n",
      "1/1 [==============================] - 1s 707ms/step - loss: 1.5360 - mae: 1.0562 - val_loss: 1.3834 - val_mae: 0.9434 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9525 - mae: 0.8174\n",
      "Epoch 2: val_loss improved from 1.38336 to 1.25109, saving model to checkpoints\\config_3_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.9525 - mae: 0.8174 - val_loss: 1.2511 - val_mae: 0.8929 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0116 - mae: 0.9104\n",
      "Epoch 3: val_loss improved from 1.25109 to 1.12448, saving model to checkpoints\\config_3_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.0116 - mae: 0.9104 - val_loss: 1.1245 - val_mae: 0.8416 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7995 - mae: 0.7540\n",
      "Epoch 4: val_loss improved from 1.12448 to 1.00266, saving model to checkpoints\\config_3_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.7995 - mae: 0.7540 - val_loss: 1.0027 - val_mae: 0.7898 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0678 - mae: 0.8646\n",
      "Epoch 5: val_loss improved from 1.00266 to 0.88724, saving model to checkpoints\\config_3_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.0678 - mae: 0.8646 - val_loss: 0.8872 - val_mae: 0.7375 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5688 - mae: 0.6176\n",
      "Epoch 6: val_loss improved from 0.88724 to 0.78257, saving model to checkpoints\\config_3_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5688 - mae: 0.6176 - val_loss: 0.7826 - val_mae: 0.6872 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6969 - mae: 0.7229\n",
      "Epoch 7: val_loss improved from 0.78257 to 0.68706, saving model to checkpoints\\config_3_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6969 - mae: 0.7229 - val_loss: 0.6871 - val_mae: 0.6386 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1330 - mae: 0.8397\n",
      "Epoch 8: val_loss improved from 0.68706 to 0.59816, saving model to checkpoints\\config_3_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.1330 - mae: 0.8397 - val_loss: 0.5982 - val_mae: 0.5900 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4670 - mae: 0.6059\n",
      "Epoch 9: val_loss improved from 0.59816 to 0.51573, saving model to checkpoints\\config_3_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.4670 - mae: 0.6059 - val_loss: 0.5157 - val_mae: 0.5420 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5855 - mae: 0.6239\n",
      "Epoch 10: val_loss improved from 0.51573 to 0.44475, saving model to checkpoints\\config_3_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5855 - mae: 0.6239 - val_loss: 0.4448 - val_mae: 0.4979 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4144 - mae: 0.5569\n",
      "Epoch 11: val_loss improved from 0.44475 to 0.38178, saving model to checkpoints\\config_3_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4144 - mae: 0.5569 - val_loss: 0.3818 - val_mae: 0.4558 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6788 - mae: 0.6691\n",
      "Epoch 12: val_loss improved from 0.38178 to 0.33083, saving model to checkpoints\\config_3_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6788 - mae: 0.6691 - val_loss: 0.3308 - val_mae: 0.4192 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5938 - mae: 0.6635\n",
      "Epoch 13: val_loss improved from 0.33083 to 0.28543, saving model to checkpoints\\config_3_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5938 - mae: 0.6635 - val_loss: 0.2854 - val_mae: 0.3840 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2314 - mae: 0.3829\n",
      "Epoch 14: val_loss improved from 0.28543 to 0.24695, saving model to checkpoints\\config_3_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2314 - mae: 0.3829 - val_loss: 0.2469 - val_mae: 0.3516 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4791 - mae: 0.5476\n",
      "Epoch 15: val_loss improved from 0.24695 to 0.21770, saving model to checkpoints\\config_3_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4791 - mae: 0.5476 - val_loss: 0.2177 - val_mae: 0.3356 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1645 - mae: 0.3598\n",
      "Epoch 16: val_loss improved from 0.21770 to 0.19068, saving model to checkpoints\\config_3_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1645 - mae: 0.3598 - val_loss: 0.1907 - val_mae: 0.3202 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3390 - mae: 0.4632\n",
      "Epoch 17: val_loss improved from 0.19068 to 0.16637, saving model to checkpoints\\config_3_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3390 - mae: 0.4632 - val_loss: 0.1664 - val_mae: 0.3053 - lr: 0.0010\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3131 - mae: 0.4485\n",
      "Epoch 18: val_loss improved from 0.16637 to 0.14368, saving model to checkpoints\\config_3_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3131 - mae: 0.4485 - val_loss: 0.1437 - val_mae: 0.2902 - lr: 0.0010\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2969 - mae: 0.3799\n",
      "Epoch 19: val_loss improved from 0.14368 to 0.12351, saving model to checkpoints\\config_3_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2969 - mae: 0.3799 - val_loss: 0.1235 - val_mae: 0.2756 - lr: 0.0010\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2141 - mae: 0.3671\n",
      "Epoch 20: val_loss improved from 0.12351 to 0.10368, saving model to checkpoints\\config_3_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2141 - mae: 0.3671 - val_loss: 0.1037 - val_mae: 0.2600 - lr: 0.0010\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1662 - mae: 0.3619\n",
      "Epoch 21: val_loss improved from 0.10368 to 0.08697, saving model to checkpoints\\config_3_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1662 - mae: 0.3619 - val_loss: 0.0870 - val_mae: 0.2454 - lr: 0.0010\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2337 - mae: 0.3480\n",
      "Epoch 22: val_loss improved from 0.08697 to 0.07234, saving model to checkpoints\\config_3_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2337 - mae: 0.3480 - val_loss: 0.0723 - val_mae: 0.2311 - lr: 0.0010\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3658 - mae: 0.5017\n",
      "Epoch 23: val_loss improved from 0.07234 to 0.06264, saving model to checkpoints\\config_3_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3658 - mae: 0.5017 - val_loss: 0.0626 - val_mae: 0.2203 - lr: 0.0010\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5845 - mae: 0.6319\n",
      "Epoch 24: val_loss improved from 0.06264 to 0.05381, saving model to checkpoints\\config_3_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.5845 - mae: 0.6319 - val_loss: 0.0538 - val_mae: 0.2094 - lr: 0.0010\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4218 - mae: 0.5112\n",
      "Epoch 25: val_loss improved from 0.05381 to 0.04830, saving model to checkpoints\\config_3_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4218 - mae: 0.5112 - val_loss: 0.0483 - val_mae: 0.2016 - lr: 0.0010\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2452 - mae: 0.3889\n",
      "Epoch 26: val_loss improved from 0.04830 to 0.04303, saving model to checkpoints\\config_3_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.2452 - mae: 0.3889 - val_loss: 0.0430 - val_mae: 0.1936 - lr: 0.0010\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1497 - mae: 0.3121\n",
      "Epoch 27: val_loss improved from 0.04303 to 0.03934, saving model to checkpoints\\config_3_arch_64_32_16.h5\n",
      "1/1 [==============================] - 1s 622ms/step - loss: 0.1497 - mae: 0.3121 - val_loss: 0.0393 - val_mae: 0.1874 - lr: 0.0010\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1857 - mae: 0.3462\n",
      "Epoch 28: val_loss did not improve from 0.03934\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1857 - mae: 0.3462 - val_loss: 0.0396 - val_mae: 0.1875 - lr: 0.0010\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1801 - mae: 0.3184\n",
      "Epoch 29: val_loss improved from 0.03934 to 0.03845, saving model to checkpoints\\config_3_arch_64_32_16.h5\n",
      "1/1 [==============================] - 1s 586ms/step - loss: 0.1801 - mae: 0.3184 - val_loss: 0.0384 - val_mae: 0.1855 - lr: 0.0010\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3928 - mae: 0.4714\n",
      "Epoch 30: val_loss did not improve from 0.03845\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3928 - mae: 0.4714 - val_loss: 0.0390 - val_mae: 0.1863 - lr: 0.0010\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3358 - mae: 0.4349\n",
      "Epoch 31: val_loss did not improve from 0.03845\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.3358 - mae: 0.4349 - val_loss: 0.0387 - val_mae: 0.1856 - lr: 0.0010\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1670 - mae: 0.3224\n",
      "Epoch 32: val_loss did not improve from 0.03845\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1670 - mae: 0.3224 - val_loss: 0.0393 - val_mae: 0.1861 - lr: 0.0010\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2975 - mae: 0.3880\n",
      "Epoch 33: val_loss did not improve from 0.03845\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2975 - mae: 0.3880 - val_loss: 0.0416 - val_mae: 0.1894 - lr: 0.0010\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1779 - mae: 0.3746\n",
      "Epoch 34: val_loss did not improve from 0.03845\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1779 - mae: 0.3746 - val_loss: 0.0459 - val_mae: 0.1952 - lr: 0.0010\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2211 - mae: 0.3188\n",
      "Epoch 35: val_loss did not improve from 0.03845\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2211 - mae: 0.3188 - val_loss: 0.0530 - val_mae: 0.2040 - lr: 0.0010\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0791 - mae: 0.2334\n",
      "Epoch 36: val_loss did not improve from 0.03845\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0791 - mae: 0.2334 - val_loss: 0.0617 - val_mae: 0.2136 - lr: 0.0010\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2829 - mae: 0.3959\n",
      "Epoch 37: val_loss did not improve from 0.03845\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2829 - mae: 0.3959 - val_loss: 0.0708 - val_mae: 0.2227 - lr: 0.0010\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1020 - mae: 0.2366\n",
      "Epoch 38: val_loss did not improve from 0.03845\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1020 - mae: 0.2366 - val_loss: 0.0791 - val_mae: 0.2302 - lr: 0.0010\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1817 - mae: 0.3293\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.03845\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1817 - mae: 0.3293 - val_loss: 0.0859 - val_mae: 0.2359 - lr: 0.0010\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2022 - mae: 0.3360\n",
      "Epoch 40: val_loss did not improve from 0.03845\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2022 - mae: 0.3360 - val_loss: 0.0878 - val_mae: 0.2372 - lr: 5.0000e-04\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3454 - mae: 0.4115\n",
      "Epoch 41: val_loss did not improve from 0.03845\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3454 - mae: 0.4115 - val_loss: 0.0885 - val_mae: 0.2379 - lr: 5.0000e-04\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1803 - mae: 0.3507\n",
      "Epoch 42: val_loss did not improve from 0.03845\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1803 - mae: 0.3507 - val_loss: 0.0881 - val_mae: 0.2375 - lr: 5.0000e-04\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0123 - mae: 0.0981\n",
      "Epoch 43: val_loss did not improve from 0.03845\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0123 - mae: 0.0981 - val_loss: 0.0877 - val_mae: 0.2373 - lr: 5.0000e-04\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0673 - mae: 0.2324\n",
      "Epoch 44: val_loss did not improve from 0.03845\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0673 - mae: 0.2324 - val_loss: 0.0872 - val_mae: 0.2370 - lr: 5.0000e-04\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3033 - mae: 0.4688\n",
      "Epoch 45: val_loss did not improve from 0.03845\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3033 - mae: 0.4688 - val_loss: 0.0875 - val_mae: 0.2374 - lr: 5.0000e-04\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1665 - mae: 0.3241\n",
      "Epoch 46: val_loss did not improve from 0.03845\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1665 - mae: 0.3241 - val_loss: 0.0880 - val_mae: 0.2380 - lr: 5.0000e-04\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3503 - mae: 0.4921\n",
      "Epoch 47: val_loss did not improve from 0.03845\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.3503 - mae: 0.4921 - val_loss: 0.0876 - val_mae: 0.2378 - lr: 5.0000e-04\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1126 - mae: 0.2879\n",
      "Epoch 48: val_loss did not improve from 0.03845\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1126 - mae: 0.2879 - val_loss: 0.0874 - val_mae: 0.2378 - lr: 5.0000e-04\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1835 - mae: 0.3474Restoring model weights from the end of the best epoch: 29.\n",
      "\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.03845\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1835 - mae: 0.3474 - val_loss: 0.0860 - val_mae: 0.2367 - lr: 5.0000e-04\n",
      "Epoch 49: early stopping\n",
      "\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "RESULTATS CONFIG 3:\n",
      "  MAPE: 1.15%\n",
      "  RMSE: 0.288\n",
      "  MAE: 0.273\n",
      "  R²: 0.931\n",
      "  Èpoques entrenades: 49\n",
      "  Checkpoint guardat a: checkpoints/config_3_arch_64_32_16.keras\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "\n",
      "======================================================================\n",
      "CONFIGURACIÓ 4/10\n",
      "======================================================================\n",
      "Arquitectura: [128, 64, 32]\n",
      "Learning rate: 0.0005\n",
      "Dropout rate: 0.2\n",
      "Batch size: 16\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8246 - mae: 0.7811\n",
      "Epoch 1: val_loss improved from inf to 0.87007, saving model to checkpoints\\config_4_arch_128_64_32.h5\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8246 - mae: 0.7811 - val_loss: 0.8701 - val_mae: 0.7490 - lr: 5.0000e-04\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8599 - mae: 0.7767\n",
      "Epoch 2: val_loss improved from 0.87007 to 0.76254, saving model to checkpoints\\config_4_arch_128_64_32.h5\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.8599 - mae: 0.7767 - val_loss: 0.7625 - val_mae: 0.6978 - lr: 5.0000e-04\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4010 - mae: 0.5250\n",
      "Epoch 3: val_loss improved from 0.76254 to 0.66726, saving model to checkpoints\\config_4_arch_128_64_32.h5\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.4010 - mae: 0.5250 - val_loss: 0.6673 - val_mae: 0.6490 - lr: 5.0000e-04\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5417 - mae: 0.6456\n",
      "Epoch 4: val_loss improved from 0.66726 to 0.58162, saving model to checkpoints\\config_4_arch_128_64_32.h5\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5417 - mae: 0.6456 - val_loss: 0.5816 - val_mae: 0.6020 - lr: 5.0000e-04\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6359 - mae: 0.6597\n",
      "Epoch 5: val_loss improved from 0.58162 to 0.50510, saving model to checkpoints\\config_4_arch_128_64_32.h5\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6359 - mae: 0.6597 - val_loss: 0.5051 - val_mae: 0.5572 - lr: 5.0000e-04\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7053 - mae: 0.6920\n",
      "Epoch 6: val_loss improved from 0.50510 to 0.44122, saving model to checkpoints\\config_4_arch_128_64_32.h5\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 0.7053 - mae: 0.6920 - val_loss: 0.4412 - val_mae: 0.5169 - lr: 5.0000e-04\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5568 - mae: 0.6166\n",
      "Epoch 7: val_loss improved from 0.44122 to 0.38271, saving model to checkpoints\\config_4_arch_128_64_32.h5\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5568 - mae: 0.6166 - val_loss: 0.3827 - val_mae: 0.4774 - lr: 5.0000e-04\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3338 - mae: 0.5121\n",
      "Epoch 8: val_loss improved from 0.38271 to 0.32831, saving model to checkpoints\\config_4_arch_128_64_32.h5\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3338 - mae: 0.5121 - val_loss: 0.3283 - val_mae: 0.4382 - lr: 5.0000e-04\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2099 - mae: 0.3224\n",
      "Epoch 9: val_loss improved from 0.32831 to 0.27838, saving model to checkpoints\\config_4_arch_128_64_32.h5\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.2099 - mae: 0.3224 - val_loss: 0.2784 - val_mae: 0.3996 - lr: 5.0000e-04\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3486 - mae: 0.4964\n",
      "Epoch 10: val_loss improved from 0.27838 to 0.23438, saving model to checkpoints\\config_4_arch_128_64_32.h5\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3486 - mae: 0.4964 - val_loss: 0.2344 - val_mae: 0.3621 - lr: 5.0000e-04\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2557 - mae: 0.3950\n",
      "Epoch 11: val_loss improved from 0.23438 to 0.19381, saving model to checkpoints\\config_4_arch_128_64_32.h5\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.2557 - mae: 0.3950 - val_loss: 0.1938 - val_mae: 0.3245 - lr: 5.0000e-04\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2064 - mae: 0.3797\n",
      "Epoch 12: val_loss improved from 0.19381 to 0.15817, saving model to checkpoints\\config_4_arch_128_64_32.h5\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.2064 - mae: 0.3797 - val_loss: 0.1582 - val_mae: 0.2878 - lr: 5.0000e-04\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1753 - mae: 0.3110\n",
      "Epoch 13: val_loss improved from 0.15817 to 0.12832, saving model to checkpoints\\config_4_arch_128_64_32.h5\n",
      "1/1 [==============================] - 1s 653ms/step - loss: 0.1753 - mae: 0.3110 - val_loss: 0.1283 - val_mae: 0.2535 - lr: 5.0000e-04\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3306 - mae: 0.4884\n",
      "Epoch 14: val_loss improved from 0.12832 to 0.10065, saving model to checkpoints\\config_4_arch_128_64_32.h5\n",
      "1/1 [==============================] - 1s 770ms/step - loss: 0.3306 - mae: 0.4884 - val_loss: 0.1007 - val_mae: 0.2311 - lr: 5.0000e-04\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2095 - mae: 0.4040\n",
      "Epoch 15: val_loss improved from 0.10065 to 0.07616, saving model to checkpoints\\config_4_arch_128_64_32.h5\n",
      "1/1 [==============================] - 1s 765ms/step - loss: 0.2095 - mae: 0.4040 - val_loss: 0.0762 - val_mae: 0.2087 - lr: 5.0000e-04\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2777 - mae: 0.4126\n",
      "Epoch 16: val_loss improved from 0.07616 to 0.05789, saving model to checkpoints\\config_4_arch_128_64_32.h5\n",
      "1/1 [==============================] - 1s 609ms/step - loss: 0.2777 - mae: 0.4126 - val_loss: 0.0579 - val_mae: 0.1892 - lr: 5.0000e-04\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0956 - mae: 0.2708\n",
      "Epoch 17: val_loss improved from 0.05789 to 0.04332, saving model to checkpoints\\config_4_arch_128_64_32.h5\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0956 - mae: 0.2708 - val_loss: 0.0433 - val_mae: 0.1709 - lr: 5.0000e-04\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0676 - mae: 0.2227\n",
      "Epoch 18: val_loss improved from 0.04332 to 0.03282, saving model to checkpoints\\config_4_arch_128_64_32.h5\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 0.0676 - mae: 0.2227 - val_loss: 0.0328 - val_mae: 0.1551 - lr: 5.0000e-04\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1736 - mae: 0.3467\n",
      "Epoch 19: val_loss improved from 0.03282 to 0.02435, saving model to checkpoints\\config_4_arch_128_64_32.h5\n",
      "1/1 [==============================] - 1s 685ms/step - loss: 0.1736 - mae: 0.3467 - val_loss: 0.0244 - val_mae: 0.1398 - lr: 5.0000e-04\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1380 - mae: 0.3457\n",
      "Epoch 20: val_loss improved from 0.02435 to 0.01711, saving model to checkpoints\\config_4_arch_128_64_32.h5\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 0.1380 - mae: 0.3457 - val_loss: 0.0171 - val_mae: 0.1235 - lr: 5.0000e-04\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1206 - mae: 0.2770\n",
      "Epoch 21: val_loss improved from 0.01711 to 0.01226, saving model to checkpoints\\config_4_arch_128_64_32.h5\n",
      "1/1 [==============================] - 1s 536ms/step - loss: 0.1206 - mae: 0.2770 - val_loss: 0.0123 - val_mae: 0.1089 - lr: 5.0000e-04\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0638 - mae: 0.1863\n",
      "Epoch 22: val_loss improved from 0.01226 to 0.00981, saving model to checkpoints\\config_4_arch_128_64_32.h5\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 0.0638 - mae: 0.1863 - val_loss: 0.0098 - val_mae: 0.0990 - lr: 5.0000e-04\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1411 - mae: 0.2978\n",
      "Epoch 23: val_loss improved from 0.00981 to 0.00829, saving model to checkpoints\\config_4_arch_128_64_32.h5\n",
      "1/1 [==============================] - 1s 507ms/step - loss: 0.1411 - mae: 0.2978 - val_loss: 0.0083 - val_mae: 0.0905 - lr: 5.0000e-04\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1533 - mae: 0.3450\n",
      "Epoch 24: val_loss improved from 0.00829 to 0.00799, saving model to checkpoints\\config_4_arch_128_64_32.h5\n",
      "1/1 [==============================] - 0s 294ms/step - loss: 0.1533 - mae: 0.3450 - val_loss: 0.0080 - val_mae: 0.0885 - lr: 5.0000e-04\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1001 - mae: 0.2541\n",
      "Epoch 25: val_loss improved from 0.00799 to 0.00789, saving model to checkpoints\\config_4_arch_128_64_32.h5\n",
      "1/1 [==============================] - 0s 375ms/step - loss: 0.1001 - mae: 0.2541 - val_loss: 0.0079 - val_mae: 0.0878 - lr: 5.0000e-04\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0406 - mae: 0.1186\n",
      "Epoch 26: val_loss did not improve from 0.00789\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0406 - mae: 0.1186 - val_loss: 0.0080 - val_mae: 0.0886 - lr: 5.0000e-04\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1425 - mae: 0.2809\n",
      "Epoch 27: val_loss did not improve from 0.00789\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1425 - mae: 0.2809 - val_loss: 0.0081 - val_mae: 0.0898 - lr: 5.0000e-04\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0683 - mae: 0.2158\n",
      "Epoch 28: val_loss did not improve from 0.00789\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0683 - mae: 0.2158 - val_loss: 0.0081 - val_mae: 0.0898 - lr: 5.0000e-04\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1309 - mae: 0.2816\n",
      "Epoch 29: val_loss did not improve from 0.00789\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1309 - mae: 0.2816 - val_loss: 0.0080 - val_mae: 0.0890 - lr: 5.0000e-04\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0487 - mae: 0.1723\n",
      "Epoch 30: val_loss improved from 0.00789 to 0.00772, saving model to checkpoints\\config_4_arch_128_64_32.h5\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0487 - mae: 0.1723 - val_loss: 0.0077 - val_mae: 0.0872 - lr: 5.0000e-04\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0611 - mae: 0.1914\n",
      "Epoch 31: val_loss did not improve from 0.00772\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0611 - mae: 0.1914 - val_loss: 0.0077 - val_mae: 0.0875 - lr: 5.0000e-04\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0825 - mae: 0.2313\n",
      "Epoch 32: val_loss improved from 0.00772 to 0.00764, saving model to checkpoints\\config_4_arch_128_64_32.h5\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0825 - mae: 0.2313 - val_loss: 0.0076 - val_mae: 0.0868 - lr: 5.0000e-04\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1230 - mae: 0.2395\n",
      "Epoch 33: val_loss improved from 0.00764 to 0.00746, saving model to checkpoints\\config_4_arch_128_64_32.h5\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1230 - mae: 0.2395 - val_loss: 0.0075 - val_mae: 0.0856 - lr: 5.0000e-04\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1477 - mae: 0.3375\n",
      "Epoch 34: val_loss did not improve from 0.00746\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1477 - mae: 0.3375 - val_loss: 0.0080 - val_mae: 0.0895 - lr: 5.0000e-04\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0711 - mae: 0.2066\n",
      "Epoch 35: val_loss did not improve from 0.00746\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0711 - mae: 0.2066 - val_loss: 0.0090 - val_mae: 0.0949 - lr: 5.0000e-04\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0616 - mae: 0.1750\n",
      "Epoch 36: val_loss did not improve from 0.00746\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0616 - mae: 0.1750 - val_loss: 0.0095 - val_mae: 0.0971 - lr: 5.0000e-04\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1074 - mae: 0.2856\n",
      "Epoch 37: val_loss did not improve from 0.00746\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1074 - mae: 0.2856 - val_loss: 0.0093 - val_mae: 0.0964 - lr: 5.0000e-04\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1302 - mae: 0.2530\n",
      "Epoch 38: val_loss did not improve from 0.00746\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1302 - mae: 0.2530 - val_loss: 0.0093 - val_mae: 0.0964 - lr: 5.0000e-04\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1102 - mae: 0.2796\n",
      "Epoch 39: val_loss did not improve from 0.00746\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1102 - mae: 0.2796 - val_loss: 0.0090 - val_mae: 0.0949 - lr: 5.0000e-04\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0693 - mae: 0.2396\n",
      "Epoch 40: val_loss did not improve from 0.00746\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0693 - mae: 0.2396 - val_loss: 0.0085 - val_mae: 0.0921 - lr: 5.0000e-04\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2552 - mae: 0.3192\n",
      "Epoch 41: val_loss did not improve from 0.00746\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2552 - mae: 0.3192 - val_loss: 0.0077 - val_mae: 0.0871 - lr: 5.0000e-04\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0966 - mae: 0.2830\n",
      "Epoch 42: val_loss improved from 0.00746 to 0.00723, saving model to checkpoints\\config_4_arch_128_64_32.h5\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0966 - mae: 0.2830 - val_loss: 0.0072 - val_mae: 0.0826 - lr: 5.0000e-04\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0224 - mae: 0.1106\n",
      "Epoch 43: val_loss improved from 0.00723 to 0.00691, saving model to checkpoints\\config_4_arch_128_64_32.h5\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0224 - mae: 0.1106 - val_loss: 0.0069 - val_mae: 0.0785 - lr: 5.0000e-04\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0623 - mae: 0.1836\n",
      "Epoch 44: val_loss improved from 0.00691 to 0.00687, saving model to checkpoints\\config_4_arch_128_64_32.h5\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0623 - mae: 0.1836 - val_loss: 0.0069 - val_mae: 0.0777 - lr: 5.0000e-04\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0727 - mae: 0.1935\n",
      "Epoch 45: val_loss did not improve from 0.00687\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0727 - mae: 0.1935 - val_loss: 0.0070 - val_mae: 0.0793 - lr: 5.0000e-04\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1604 - mae: 0.3148\n",
      "Epoch 46: val_loss did not improve from 0.00687\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1604 - mae: 0.3148 - val_loss: 0.0077 - val_mae: 0.0863 - lr: 5.0000e-04\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0596 - mae: 0.1815\n",
      "Epoch 47: val_loss did not improve from 0.00687\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0596 - mae: 0.1815 - val_loss: 0.0086 - val_mae: 0.0925 - lr: 5.0000e-04\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0641 - mae: 0.1613\n",
      "Epoch 48: val_loss did not improve from 0.00687\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0641 - mae: 0.1613 - val_loss: 0.0095 - val_mae: 0.0972 - lr: 5.0000e-04\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0500 - mae: 0.1595\n",
      "Epoch 49: val_loss did not improve from 0.00687\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0500 - mae: 0.1595 - val_loss: 0.0106 - val_mae: 0.1024 - lr: 5.0000e-04\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0885 - mae: 0.2588\n",
      "Epoch 50: val_loss did not improve from 0.00687\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0885 - mae: 0.2588 - val_loss: 0.0118 - val_mae: 0.1068 - lr: 5.0000e-04\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1205 - mae: 0.2559\n",
      "Epoch 51: val_loss did not improve from 0.00687\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1205 - mae: 0.2559 - val_loss: 0.0128 - val_mae: 0.1102 - lr: 5.0000e-04\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0086 - mae: 0.0787\n",
      "Epoch 52: val_loss did not improve from 0.00687\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0086 - mae: 0.0787 - val_loss: 0.0135 - val_mae: 0.1126 - lr: 5.0000e-04\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1169 - mae: 0.2399\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 53: val_loss did not improve from 0.00687\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1169 - mae: 0.2399 - val_loss: 0.0140 - val_mae: 0.1139 - lr: 5.0000e-04\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2620 - mae: 0.4448\n",
      "Epoch 54: val_loss did not improve from 0.00687\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2620 - mae: 0.4448 - val_loss: 0.0136 - val_mae: 0.1129 - lr: 2.5000e-04\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0936 - mae: 0.2411\n",
      "Epoch 55: val_loss did not improve from 0.00687\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0936 - mae: 0.2411 - val_loss: 0.0133 - val_mae: 0.1119 - lr: 2.5000e-04\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2151 - mae: 0.3431\n",
      "Epoch 56: val_loss did not improve from 0.00687\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2151 - mae: 0.3431 - val_loss: 0.0129 - val_mae: 0.1103 - lr: 2.5000e-04\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0810 - mae: 0.2399\n",
      "Epoch 57: val_loss did not improve from 0.00687\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0810 - mae: 0.2399 - val_loss: 0.0128 - val_mae: 0.1101 - lr: 2.5000e-04\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1545 - mae: 0.3304\n",
      "Epoch 58: val_loss did not improve from 0.00687\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1545 - mae: 0.3304 - val_loss: 0.0128 - val_mae: 0.1099 - lr: 2.5000e-04\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1287 - mae: 0.2793\n",
      "Epoch 59: val_loss did not improve from 0.00687\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1287 - mae: 0.2793 - val_loss: 0.0123 - val_mae: 0.1083 - lr: 2.5000e-04\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1196 - mae: 0.2336\n",
      "Epoch 60: val_loss did not improve from 0.00687\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1196 - mae: 0.2336 - val_loss: 0.0115 - val_mae: 0.1055 - lr: 2.5000e-04\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0563 - mae: 0.1912\n",
      "Epoch 61: val_loss did not improve from 0.00687\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0563 - mae: 0.1912 - val_loss: 0.0107 - val_mae: 0.1023 - lr: 2.5000e-04\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0341 - mae: 0.1455\n",
      "Epoch 62: val_loss did not improve from 0.00687\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0341 - mae: 0.1455 - val_loss: 0.0098 - val_mae: 0.0987 - lr: 2.5000e-04\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1735 - mae: 0.2945\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 63: val_loss did not improve from 0.00687\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1735 - mae: 0.2945 - val_loss: 0.0090 - val_mae: 0.0946 - lr: 2.5000e-04\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0924 - mae: 0.2278Restoring model weights from the end of the best epoch: 44.\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.00687\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0924 - mae: 0.2278 - val_loss: 0.0086 - val_mae: 0.0929 - lr: 1.2500e-04\n",
      "Epoch 64: early stopping\n",
      "\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "RESULTATS CONFIG 4:\n",
      "  MAPE: 0.50%\n",
      "  RMSE: 0.122\n",
      "  MAE: 0.114\n",
      "  R²: 0.988\n",
      "  Èpoques entrenades: 64\n",
      "  Checkpoint guardat a: checkpoints/config_4_arch_128_64_32.keras\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "\n",
      "======================================================================\n",
      "CONFIGURACIÓ 5/10\n",
      "======================================================================\n",
      "Arquitectura: [128, 64, 32, 16]\n",
      "Learning rate: 0.001\n",
      "Dropout rate: 0.3\n",
      "Batch size: 16\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7629 - mae: 0.7455\n",
      "Epoch 1: val_loss improved from inf to 0.83775, saving model to checkpoints\\config_5_arch_128_64_32_16.h5\n",
      "1/1 [==============================] - 1s 823ms/step - loss: 0.7629 - mae: 0.7455 - val_loss: 0.8378 - val_mae: 0.7343 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7025 - mae: 0.6913\n",
      "Epoch 2: val_loss improved from 0.83775 to 0.75257, saving model to checkpoints\\config_5_arch_128_64_32_16.h5\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.7025 - mae: 0.6913 - val_loss: 0.7526 - val_mae: 0.6919 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7858 - mae: 0.7374\n",
      "Epoch 3: val_loss improved from 0.75257 to 0.67074, saving model to checkpoints\\config_5_arch_128_64_32_16.h5\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.7858 - mae: 0.7374 - val_loss: 0.6707 - val_mae: 0.6475 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8773 - mae: 0.7865\n",
      "Epoch 4: val_loss improved from 0.67074 to 0.59806, saving model to checkpoints\\config_5_arch_128_64_32_16.h5\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.8773 - mae: 0.7865 - val_loss: 0.5981 - val_mae: 0.6065 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1925 - mae: 0.8368\n",
      "Epoch 5: val_loss improved from 0.59806 to 0.53439, saving model to checkpoints\\config_5_arch_128_64_32_16.h5\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1925 - mae: 0.8368 - val_loss: 0.5344 - val_mae: 0.5686 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8395 - mae: 0.7699\n",
      "Epoch 6: val_loss improved from 0.53439 to 0.47850, saving model to checkpoints\\config_5_arch_128_64_32_16.h5\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8395 - mae: 0.7699 - val_loss: 0.4785 - val_mae: 0.5334 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6560 - mae: 0.6562\n",
      "Epoch 7: val_loss improved from 0.47850 to 0.42861, saving model to checkpoints\\config_5_arch_128_64_32_16.h5\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6560 - mae: 0.6562 - val_loss: 0.4286 - val_mae: 0.5005 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6933 - mae: 0.6377\n",
      "Epoch 8: val_loss improved from 0.42861 to 0.37784, saving model to checkpoints\\config_5_arch_128_64_32_16.h5\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.6933 - mae: 0.6377 - val_loss: 0.3778 - val_mae: 0.4654 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5838 - mae: 0.5664\n",
      "Epoch 9: val_loss improved from 0.37784 to 0.33063, saving model to checkpoints\\config_5_arch_128_64_32_16.h5\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5838 - mae: 0.5664 - val_loss: 0.3306 - val_mae: 0.4313 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0559 - mae: 0.8332\n",
      "Epoch 10: val_loss improved from 0.33063 to 0.29257, saving model to checkpoints\\config_5_arch_128_64_32_16.h5\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.0559 - mae: 0.8332 - val_loss: 0.2926 - val_mae: 0.4019 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3296 - mae: 0.5051\n",
      "Epoch 11: val_loss improved from 0.29257 to 0.25914, saving model to checkpoints\\config_5_arch_128_64_32_16.h5\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.3296 - mae: 0.5051 - val_loss: 0.2591 - val_mae: 0.3744 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6345 - mae: 0.6738\n",
      "Epoch 12: val_loss improved from 0.25914 to 0.22459, saving model to checkpoints\\config_5_arch_128_64_32_16.h5\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6345 - mae: 0.6738 - val_loss: 0.2246 - val_mae: 0.3439 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5276 - mae: 0.6175\n",
      "Epoch 13: val_loss improved from 0.22459 to 0.18765, saving model to checkpoints\\config_5_arch_128_64_32_16.h5\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5276 - mae: 0.6175 - val_loss: 0.1876 - val_mae: 0.3080 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6007 - mae: 0.6405\n",
      "Epoch 14: val_loss improved from 0.18765 to 0.15153, saving model to checkpoints\\config_5_arch_128_64_32_16.h5\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6007 - mae: 0.6405 - val_loss: 0.1515 - val_mae: 0.2816 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4089 - mae: 0.5469\n",
      "Epoch 15: val_loss improved from 0.15153 to 0.13094, saving model to checkpoints\\config_5_arch_128_64_32_16.h5\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.4089 - mae: 0.5469 - val_loss: 0.1309 - val_mae: 0.2665 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6568 - mae: 0.5817\n",
      "Epoch 16: val_loss improved from 0.13094 to 0.11608, saving model to checkpoints\\config_5_arch_128_64_32_16.h5\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6568 - mae: 0.5817 - val_loss: 0.1161 - val_mae: 0.2548 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3294 - mae: 0.4484\n",
      "Epoch 17: val_loss improved from 0.11608 to 0.10786, saving model to checkpoints\\config_5_arch_128_64_32_16.h5\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3294 - mae: 0.4484 - val_loss: 0.1079 - val_mae: 0.2474 - lr: 0.0010\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5880 - mae: 0.5980\n",
      "Epoch 18: val_loss improved from 0.10786 to 0.10758, saving model to checkpoints\\config_5_arch_128_64_32_16.h5\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.5880 - mae: 0.5980 - val_loss: 0.1076 - val_mae: 0.2458 - lr: 0.0010\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5055 - mae: 0.5750\n",
      "Epoch 19: val_loss improved from 0.10758 to 0.10493, saving model to checkpoints\\config_5_arch_128_64_32_16.h5\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5055 - mae: 0.5750 - val_loss: 0.1049 - val_mae: 0.2426 - lr: 0.0010\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4130 - mae: 0.5626\n",
      "Epoch 20: val_loss improved from 0.10493 to 0.10047, saving model to checkpoints\\config_5_arch_128_64_32_16.h5\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4130 - mae: 0.5626 - val_loss: 0.1005 - val_mae: 0.2382 - lr: 0.0010\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6340 - mae: 0.6223\n",
      "Epoch 21: val_loss improved from 0.10047 to 0.09384, saving model to checkpoints\\config_5_arch_128_64_32_16.h5\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6340 - mae: 0.6223 - val_loss: 0.0938 - val_mae: 0.2318 - lr: 0.0010\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6379 - mae: 0.6168\n",
      "Epoch 22: val_loss improved from 0.09384 to 0.08762, saving model to checkpoints\\config_5_arch_128_64_32_16.h5\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6379 - mae: 0.6168 - val_loss: 0.0876 - val_mae: 0.2258 - lr: 0.0010\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3402 - mae: 0.5062\n",
      "Epoch 23: val_loss improved from 0.08762 to 0.08452, saving model to checkpoints\\config_5_arch_128_64_32_16.h5\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.3402 - mae: 0.5062 - val_loss: 0.0845 - val_mae: 0.2223 - lr: 0.0010\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1690 - mae: 0.2959\n",
      "Epoch 24: val_loss did not improve from 0.08452\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1690 - mae: 0.2959 - val_loss: 0.0850 - val_mae: 0.2221 - lr: 0.0010\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4339 - mae: 0.5001\n",
      "Epoch 25: val_loss did not improve from 0.08452\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.4339 - mae: 0.5001 - val_loss: 0.0852 - val_mae: 0.2217 - lr: 0.0010\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3908 - mae: 0.4933\n",
      "Epoch 26: val_loss improved from 0.08452 to 0.08431, saving model to checkpoints\\config_5_arch_128_64_32_16.h5\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.3908 - mae: 0.4933 - val_loss: 0.0843 - val_mae: 0.2205 - lr: 0.0010\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3151 - mae: 0.4484\n",
      "Epoch 27: val_loss improved from 0.08431 to 0.07876, saving model to checkpoints\\config_5_arch_128_64_32_16.h5\n",
      "1/1 [==============================] - 0s 289ms/step - loss: 0.3151 - mae: 0.4484 - val_loss: 0.0788 - val_mae: 0.2150 - lr: 0.0010\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2376 - mae: 0.4294\n",
      "Epoch 28: val_loss improved from 0.07876 to 0.06983, saving model to checkpoints\\config_5_arch_128_64_32_16.h5\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2376 - mae: 0.4294 - val_loss: 0.0698 - val_mae: 0.2058 - lr: 0.0010\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2208 - mae: 0.3958\n",
      "Epoch 29: val_loss improved from 0.06983 to 0.06350, saving model to checkpoints\\config_5_arch_128_64_32_16.h5\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2208 - mae: 0.3958 - val_loss: 0.0635 - val_mae: 0.1987 - lr: 0.0010\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7176 - mae: 0.7095\n",
      "Epoch 30: val_loss improved from 0.06350 to 0.05962, saving model to checkpoints\\config_5_arch_128_64_32_16.h5\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.7176 - mae: 0.7095 - val_loss: 0.0596 - val_mae: 0.1938 - lr: 0.0010\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1606 - mae: 0.3143\n",
      "Epoch 31: val_loss improved from 0.05962 to 0.05264, saving model to checkpoints\\config_5_arch_128_64_32_16.h5\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1606 - mae: 0.3143 - val_loss: 0.0526 - val_mae: 0.1849 - lr: 0.0010\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5980 - mae: 0.6421\n",
      "Epoch 32: val_loss improved from 0.05264 to 0.04615, saving model to checkpoints\\config_5_arch_128_64_32_16.h5\n",
      "1/1 [==============================] - 1s 543ms/step - loss: 0.5980 - mae: 0.6421 - val_loss: 0.0461 - val_mae: 0.1760 - lr: 0.0010\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3630 - mae: 0.4365\n",
      "Epoch 33: val_loss improved from 0.04615 to 0.03901, saving model to checkpoints\\config_5_arch_128_64_32_16.h5\n",
      "1/1 [==============================] - 0s 495ms/step - loss: 0.3630 - mae: 0.4365 - val_loss: 0.0390 - val_mae: 0.1656 - lr: 0.0010\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0867 - mae: 0.2251\n",
      "Epoch 34: val_loss improved from 0.03901 to 0.03353, saving model to checkpoints\\config_5_arch_128_64_32_16.h5\n",
      "1/1 [==============================] - 1s 908ms/step - loss: 0.0867 - mae: 0.2251 - val_loss: 0.0335 - val_mae: 0.1568 - lr: 0.0010\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3840 - mae: 0.4288\n",
      "Epoch 35: val_loss did not improve from 0.03353\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3840 - mae: 0.4288 - val_loss: 0.0368 - val_mae: 0.1610 - lr: 0.0010\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4480 - mae: 0.5480\n",
      "Epoch 36: val_loss did not improve from 0.03353\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.4480 - mae: 0.5480 - val_loss: 0.0393 - val_mae: 0.1643 - lr: 0.0010\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1266 - mae: 0.2914\n",
      "Epoch 37: val_loss did not improve from 0.03353\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1266 - mae: 0.2914 - val_loss: 0.0415 - val_mae: 0.1669 - lr: 0.0010\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2438 - mae: 0.4038\n",
      "Epoch 38: val_loss did not improve from 0.03353\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2438 - mae: 0.4038 - val_loss: 0.0419 - val_mae: 0.1675 - lr: 0.0010\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2969 - mae: 0.3988\n",
      "Epoch 39: val_loss did not improve from 0.03353\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2969 - mae: 0.3988 - val_loss: 0.0407 - val_mae: 0.1661 - lr: 0.0010\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5116 - mae: 0.5203\n",
      "Epoch 40: val_loss did not improve from 0.03353\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5116 - mae: 0.5203 - val_loss: 0.0384 - val_mae: 0.1632 - lr: 0.0010\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3684 - mae: 0.5088\n",
      "Epoch 41: val_loss did not improve from 0.03353\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.3684 - mae: 0.5088 - val_loss: 0.0340 - val_mae: 0.1572 - lr: 0.0010\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2250 - mae: 0.3561\n",
      "Epoch 42: val_loss improved from 0.03353 to 0.02867, saving model to checkpoints\\config_5_arch_128_64_32_16.h5\n",
      "1/1 [==============================] - 1s 673ms/step - loss: 0.2250 - mae: 0.3561 - val_loss: 0.0287 - val_mae: 0.1491 - lr: 0.0010\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2981 - mae: 0.3807\n",
      "Epoch 43: val_loss improved from 0.02867 to 0.02433, saving model to checkpoints\\config_5_arch_128_64_32_16.h5\n",
      "1/1 [==============================] - 1s 783ms/step - loss: 0.2981 - mae: 0.3807 - val_loss: 0.0243 - val_mae: 0.1417 - lr: 0.0010\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3367 - mae: 0.4798\n",
      "Epoch 44: val_loss improved from 0.02433 to 0.02203, saving model to checkpoints\\config_5_arch_128_64_32_16.h5\n",
      "1/1 [==============================] - 1s 721ms/step - loss: 0.3367 - mae: 0.4798 - val_loss: 0.0220 - val_mae: 0.1374 - lr: 0.0010\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3608 - mae: 0.5016\n",
      "Epoch 45: val_loss improved from 0.02203 to 0.02107, saving model to checkpoints\\config_5_arch_128_64_32_16.h5\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.3608 - mae: 0.5016 - val_loss: 0.0211 - val_mae: 0.1355 - lr: 0.0010\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2393 - mae: 0.6835\n",
      "Epoch 46: val_loss did not improve from 0.02107\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.2393 - mae: 0.6835 - val_loss: 0.0256 - val_mae: 0.1450 - lr: 0.0010\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2598 - mae: 0.4256\n",
      "Epoch 47: val_loss did not improve from 0.02107\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2598 - mae: 0.4256 - val_loss: 0.0328 - val_mae: 0.1576 - lr: 0.0010\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3524 - mae: 0.4964\n",
      "Epoch 48: val_loss did not improve from 0.02107\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3524 - mae: 0.4964 - val_loss: 0.0402 - val_mae: 0.1686 - lr: 0.0010\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3449 - mae: 0.4672\n",
      "Epoch 49: val_loss did not improve from 0.02107\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3449 - mae: 0.4672 - val_loss: 0.0551 - val_mae: 0.1872 - lr: 0.0010\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2244 - mae: 0.4200\n",
      "Epoch 50: val_loss did not improve from 0.02107\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2244 - mae: 0.4200 - val_loss: 0.0692 - val_mae: 0.2021 - lr: 0.0010\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1450 - mae: 0.3200\n",
      "Epoch 51: val_loss did not improve from 0.02107\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1450 - mae: 0.3200 - val_loss: 0.0833 - val_mae: 0.2155 - lr: 0.0010\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3097 - mae: 0.4310\n",
      "Epoch 52: val_loss did not improve from 0.02107\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.3097 - mae: 0.4310 - val_loss: 0.0956 - val_mae: 0.2265 - lr: 0.0010\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2133 - mae: 0.4133\n",
      "Epoch 53: val_loss did not improve from 0.02107\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2133 - mae: 0.4133 - val_loss: 0.1038 - val_mae: 0.2335 - lr: 0.0010\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3384 - mae: 0.4359\n",
      "Epoch 54: val_loss did not improve from 0.02107\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3384 - mae: 0.4359 - val_loss: 0.1065 - val_mae: 0.2355 - lr: 0.0010\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3014 - mae: 0.4240\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.02107\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.3014 - mae: 0.4240 - val_loss: 0.1034 - val_mae: 0.2327 - lr: 0.0010\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1551 - mae: 0.2892\n",
      "Epoch 56: val_loss did not improve from 0.02107\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1551 - mae: 0.2892 - val_loss: 0.1028 - val_mae: 0.2320 - lr: 5.0000e-04\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3782 - mae: 0.4792\n",
      "Epoch 57: val_loss did not improve from 0.02107\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.3782 - mae: 0.4792 - val_loss: 0.1044 - val_mae: 0.2332 - lr: 5.0000e-04\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3165 - mae: 0.3923\n",
      "Epoch 58: val_loss did not improve from 0.02107\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.3165 - mae: 0.3923 - val_loss: 0.1053 - val_mae: 0.2340 - lr: 5.0000e-04\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5139 - mae: 0.5804\n",
      "Epoch 59: val_loss did not improve from 0.02107\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5139 - mae: 0.5804 - val_loss: 0.1047 - val_mae: 0.2336 - lr: 5.0000e-04\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2512 - mae: 0.4421\n",
      "Epoch 60: val_loss did not improve from 0.02107\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2512 - mae: 0.4421 - val_loss: 0.1047 - val_mae: 0.2337 - lr: 5.0000e-04\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2049 - mae: 0.3572\n",
      "Epoch 61: val_loss did not improve from 0.02107\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2049 - mae: 0.3572 - val_loss: 0.1032 - val_mae: 0.2326 - lr: 5.0000e-04\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3960 - mae: 0.5247\n",
      "Epoch 62: val_loss did not improve from 0.02107\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.3960 - mae: 0.5247 - val_loss: 0.1004 - val_mae: 0.2303 - lr: 5.0000e-04\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2576 - mae: 0.4234\n",
      "Epoch 63: val_loss did not improve from 0.02107\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2576 - mae: 0.4234 - val_loss: 0.1003 - val_mae: 0.2301 - lr: 5.0000e-04\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1795 - mae: 0.3602\n",
      "Epoch 64: val_loss did not improve from 0.02107\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1795 - mae: 0.3602 - val_loss: 0.0984 - val_mae: 0.2284 - lr: 5.0000e-04\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2907 - mae: 0.4620Restoring model weights from the end of the best epoch: 45.\n",
      "\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.02107\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.2907 - mae: 0.4620 - val_loss: 0.0944 - val_mae: 0.2250 - lr: 5.0000e-04\n",
      "Epoch 65: early stopping\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000018677DDFA30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "RESULTATS CONFIG 5:\n",
      "  MAPE: 0.84%\n",
      "  RMSE: 0.214\n",
      "  MAE: 0.199\n",
      "  R²: 0.962\n",
      "  Èpoques entrenades: 65\n",
      "  Checkpoint guardat a: checkpoints/config_5_arch_128_64_32_16.keras\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "\n",
      "======================================================================\n",
      "CONFIGURACIÓ 6/10\n",
      "======================================================================\n",
      "Arquitectura: [64, 128, 64, 32]\n",
      "Learning rate: 0.0005\n",
      "Dropout rate: 0.25\n",
      "Batch size: 16\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1139 - mae: 0.9160\n",
      "Epoch 1: val_loss improved from inf to 1.16777, saving model to checkpoints\\config_6_arch_64_128_64_32.h5\n",
      "1/1 [==============================] - 1s 989ms/step - loss: 1.1139 - mae: 0.9160 - val_loss: 1.1678 - val_mae: 0.8729 - lr: 5.0000e-04\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0420 - mae: 0.8572\n",
      "Epoch 2: val_loss improved from 1.16777 to 1.10276, saving model to checkpoints\\config_6_arch_64_128_64_32.h5\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 1.0420 - mae: 0.8572 - val_loss: 1.1028 - val_mae: 0.8490 - lr: 5.0000e-04\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9431 - mae: 0.8788\n",
      "Epoch 3: val_loss improved from 1.10276 to 1.03340, saving model to checkpoints\\config_6_arch_64_128_64_32.h5\n",
      "1/1 [==============================] - 0s 454ms/step - loss: 0.9431 - mae: 0.8788 - val_loss: 1.0334 - val_mae: 0.8223 - lr: 5.0000e-04\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1005 - mae: 0.9076\n",
      "Epoch 4: val_loss improved from 1.03340 to 0.96180, saving model to checkpoints\\config_6_arch_64_128_64_32.h5\n",
      "1/1 [==============================] - 1s 514ms/step - loss: 1.1005 - mae: 0.9076 - val_loss: 0.9618 - val_mae: 0.7929 - lr: 5.0000e-04\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9838 - mae: 0.8652\n",
      "Epoch 5: val_loss improved from 0.96180 to 0.89274, saving model to checkpoints\\config_6_arch_64_128_64_32.h5\n",
      "1/1 [==============================] - 0s 295ms/step - loss: 0.9838 - mae: 0.8652 - val_loss: 0.8927 - val_mae: 0.7628 - lr: 5.0000e-04\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8973 - mae: 0.8151\n",
      "Epoch 6: val_loss improved from 0.89274 to 0.82413, saving model to checkpoints\\config_6_arch_64_128_64_32.h5\n",
      "1/1 [==============================] - 1s 605ms/step - loss: 0.8973 - mae: 0.8151 - val_loss: 0.8241 - val_mae: 0.7320 - lr: 5.0000e-04\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7282 - mae: 0.7093\n",
      "Epoch 7: val_loss improved from 0.82413 to 0.75674, saving model to checkpoints\\config_6_arch_64_128_64_32.h5\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.7282 - mae: 0.7093 - val_loss: 0.7567 - val_mae: 0.7004 - lr: 5.0000e-04\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7897 - mae: 0.7269\n",
      "Epoch 8: val_loss improved from 0.75674 to 0.69500, saving model to checkpoints\\config_6_arch_64_128_64_32.h5\n",
      "1/1 [==============================] - 0s 441ms/step - loss: 0.7897 - mae: 0.7269 - val_loss: 0.6950 - val_mae: 0.6701 - lr: 5.0000e-04\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5990 - mae: 0.6700\n",
      "Epoch 9: val_loss improved from 0.69500 to 0.63699, saving model to checkpoints\\config_6_arch_64_128_64_32.h5\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.5990 - mae: 0.6700 - val_loss: 0.6370 - val_mae: 0.6401 - lr: 5.0000e-04\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7845 - mae: 0.7172\n",
      "Epoch 10: val_loss improved from 0.63699 to 0.58703, saving model to checkpoints\\config_6_arch_64_128_64_32.h5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.7845 - mae: 0.7172 - val_loss: 0.5870 - val_mae: 0.6130 - lr: 5.0000e-04\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5321 - mae: 0.6047\n",
      "Epoch 11: val_loss improved from 0.58703 to 0.54293, saving model to checkpoints\\config_6_arch_64_128_64_32.h5\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.5321 - mae: 0.6047 - val_loss: 0.5429 - val_mae: 0.5879 - lr: 5.0000e-04\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4902 - mae: 0.5866\n",
      "Epoch 12: val_loss improved from 0.54293 to 0.50133, saving model to checkpoints\\config_6_arch_64_128_64_32.h5\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.4902 - mae: 0.5866 - val_loss: 0.5013 - val_mae: 0.5632 - lr: 5.0000e-04\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6870 - mae: 0.7382\n",
      "Epoch 13: val_loss improved from 0.50133 to 0.46116, saving model to checkpoints\\config_6_arch_64_128_64_32.h5\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6870 - mae: 0.7382 - val_loss: 0.4612 - val_mae: 0.5383 - lr: 5.0000e-04\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5033 - mae: 0.5926\n",
      "Epoch 14: val_loss improved from 0.46116 to 0.42748, saving model to checkpoints\\config_6_arch_64_128_64_32.h5\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.5033 - mae: 0.5926 - val_loss: 0.4275 - val_mae: 0.5158 - lr: 5.0000e-04\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4393 - mae: 0.5690\n",
      "Epoch 15: val_loss improved from 0.42748 to 0.39419, saving model to checkpoints\\config_6_arch_64_128_64_32.h5\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.4393 - mae: 0.5690 - val_loss: 0.3942 - val_mae: 0.4927 - lr: 5.0000e-04\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6211 - mae: 0.6738\n",
      "Epoch 16: val_loss improved from 0.39419 to 0.36236, saving model to checkpoints\\config_6_arch_64_128_64_32.h5\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.6211 - mae: 0.6738 - val_loss: 0.3624 - val_mae: 0.4695 - lr: 5.0000e-04\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2948 - mae: 0.4811\n",
      "Epoch 17: val_loss improved from 0.36236 to 0.33146, saving model to checkpoints\\config_6_arch_64_128_64_32.h5\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.2948 - mae: 0.4811 - val_loss: 0.3315 - val_mae: 0.4461 - lr: 5.0000e-04\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5866 - mae: 0.6138\n",
      "Epoch 18: val_loss improved from 0.33146 to 0.30331, saving model to checkpoints\\config_6_arch_64_128_64_32.h5\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.5866 - mae: 0.6138 - val_loss: 0.3033 - val_mae: 0.4241 - lr: 5.0000e-04\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6088 - mae: 0.6544\n",
      "Epoch 19: val_loss improved from 0.30331 to 0.27162, saving model to checkpoints\\config_6_arch_64_128_64_32.h5\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 0.6088 - mae: 0.6544 - val_loss: 0.2716 - val_mae: 0.3985 - lr: 5.0000e-04\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4269 - mae: 0.5882\n",
      "Epoch 20: val_loss improved from 0.27162 to 0.24134, saving model to checkpoints\\config_6_arch_64_128_64_32.h5\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4269 - mae: 0.5882 - val_loss: 0.2413 - val_mae: 0.3723 - lr: 5.0000e-04\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4253 - mae: 0.4830\n",
      "Epoch 21: val_loss improved from 0.24134 to 0.21378, saving model to checkpoints\\config_6_arch_64_128_64_32.h5\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.4253 - mae: 0.4830 - val_loss: 0.2138 - val_mae: 0.3470 - lr: 5.0000e-04\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3005 - mae: 0.3923\n",
      "Epoch 22: val_loss improved from 0.21378 to 0.19074, saving model to checkpoints\\config_6_arch_64_128_64_32.h5\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.3005 - mae: 0.3923 - val_loss: 0.1907 - val_mae: 0.3248 - lr: 5.0000e-04\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4361 - mae: 0.5143\n",
      "Epoch 23: val_loss improved from 0.19074 to 0.16836, saving model to checkpoints\\config_6_arch_64_128_64_32.h5\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.4361 - mae: 0.5143 - val_loss: 0.1684 - val_mae: 0.3019 - lr: 5.0000e-04\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1475 - mae: 0.2927\n",
      "Epoch 24: val_loss improved from 0.16836 to 0.14764, saving model to checkpoints\\config_6_arch_64_128_64_32.h5\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.1475 - mae: 0.2927 - val_loss: 0.1476 - val_mae: 0.2796 - lr: 5.0000e-04\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2119 - mae: 0.4075\n",
      "Epoch 25: val_loss improved from 0.14764 to 0.12715, saving model to checkpoints\\config_6_arch_64_128_64_32.h5\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2119 - mae: 0.4075 - val_loss: 0.1271 - val_mae: 0.2560 - lr: 5.0000e-04\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2607 - mae: 0.4028\n",
      "Epoch 26: val_loss improved from 0.12715 to 0.10880, saving model to checkpoints\\config_6_arch_64_128_64_32.h5\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.2607 - mae: 0.4028 - val_loss: 0.1088 - val_mae: 0.2337 - lr: 5.0000e-04\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3849 - mae: 0.4941\n",
      "Epoch 27: val_loss improved from 0.10880 to 0.09491, saving model to checkpoints\\config_6_arch_64_128_64_32.h5\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3849 - mae: 0.4941 - val_loss: 0.0949 - val_mae: 0.2221 - lr: 5.0000e-04\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0865 - mae: 0.2519\n",
      "Epoch 28: val_loss improved from 0.09491 to 0.08150, saving model to checkpoints\\config_6_arch_64_128_64_32.h5\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0865 - mae: 0.2519 - val_loss: 0.0815 - val_mae: 0.2100 - lr: 5.0000e-04\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3360 - mae: 0.4571\n",
      "Epoch 29: val_loss improved from 0.08150 to 0.06944, saving model to checkpoints\\config_6_arch_64_128_64_32.h5\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.3360 - mae: 0.4571 - val_loss: 0.0694 - val_mae: 0.1981 - lr: 5.0000e-04\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1639 - mae: 0.2571\n",
      "Epoch 30: val_loss improved from 0.06944 to 0.05972, saving model to checkpoints\\config_6_arch_64_128_64_32.h5\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1639 - mae: 0.2571 - val_loss: 0.0597 - val_mae: 0.1879 - lr: 5.0000e-04\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5122 - mae: 0.5412\n",
      "Epoch 31: val_loss improved from 0.05972 to 0.05412, saving model to checkpoints\\config_6_arch_64_128_64_32.h5\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.5122 - mae: 0.5412 - val_loss: 0.0541 - val_mae: 0.1814 - lr: 5.0000e-04\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2879 - mae: 0.4574\n",
      "Epoch 32: val_loss improved from 0.05412 to 0.04709, saving model to checkpoints\\config_6_arch_64_128_64_32.h5\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 0.2879 - mae: 0.4574 - val_loss: 0.0471 - val_mae: 0.1727 - lr: 5.0000e-04\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2856 - mae: 0.4482\n",
      "Epoch 33: val_loss improved from 0.04709 to 0.04305, saving model to checkpoints\\config_6_arch_64_128_64_32.h5\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2856 - mae: 0.4482 - val_loss: 0.0430 - val_mae: 0.1671 - lr: 5.0000e-04\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4739 - mae: 0.5340\n",
      "Epoch 34: val_loss improved from 0.04305 to 0.03923, saving model to checkpoints\\config_6_arch_64_128_64_32.h5\n",
      "1/1 [==============================] - 1s 672ms/step - loss: 0.4739 - mae: 0.5340 - val_loss: 0.0392 - val_mae: 0.1616 - lr: 5.0000e-04\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0927 - mae: 0.2640\n",
      "Epoch 35: val_loss improved from 0.03923 to 0.03421, saving model to checkpoints\\config_6_arch_64_128_64_32.h5\n",
      "1/1 [==============================] - 1s 703ms/step - loss: 0.0927 - mae: 0.2640 - val_loss: 0.0342 - val_mae: 0.1538 - lr: 5.0000e-04\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2382 - mae: 0.4220\n",
      "Epoch 36: val_loss improved from 0.03421 to 0.03005, saving model to checkpoints\\config_6_arch_64_128_64_32.h5\n",
      "1/1 [==============================] - 1s 574ms/step - loss: 0.2382 - mae: 0.4220 - val_loss: 0.0301 - val_mae: 0.1468 - lr: 5.0000e-04\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1024 - mae: 0.2751\n",
      "Epoch 37: val_loss improved from 0.03005 to 0.02716, saving model to checkpoints\\config_6_arch_64_128_64_32.h5\n",
      "1/1 [==============================] - 1s 743ms/step - loss: 0.1024 - mae: 0.2751 - val_loss: 0.0272 - val_mae: 0.1415 - lr: 5.0000e-04\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2592 - mae: 0.3929\n",
      "Epoch 38: val_loss improved from 0.02716 to 0.02690, saving model to checkpoints\\config_6_arch_64_128_64_32.h5\n",
      "1/1 [==============================] - 1s 601ms/step - loss: 0.2592 - mae: 0.3929 - val_loss: 0.0269 - val_mae: 0.1405 - lr: 5.0000e-04\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0925 - mae: 0.2234\n",
      "Epoch 39: val_loss improved from 0.02690 to 0.02586, saving model to checkpoints\\config_6_arch_64_128_64_32.h5\n",
      "1/1 [==============================] - 0s 474ms/step - loss: 0.0925 - mae: 0.2234 - val_loss: 0.0259 - val_mae: 0.1382 - lr: 5.0000e-04\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1136 - mae: 0.2597\n",
      "Epoch 40: val_loss did not improve from 0.02586\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1136 - mae: 0.2597 - val_loss: 0.0268 - val_mae: 0.1396 - lr: 5.0000e-04\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4722 - mae: 0.5313\n",
      "Epoch 41: val_loss improved from 0.02586 to 0.02585, saving model to checkpoints\\config_6_arch_64_128_64_32.h5\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.4722 - mae: 0.5313 - val_loss: 0.0259 - val_mae: 0.1378 - lr: 5.0000e-04\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0439 - mae: 0.1915\n",
      "Epoch 42: val_loss improved from 0.02585 to 0.02524, saving model to checkpoints\\config_6_arch_64_128_64_32.h5\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0439 - mae: 0.1915 - val_loss: 0.0252 - val_mae: 0.1365 - lr: 5.0000e-04\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0592 - mae: 0.1931\n",
      "Epoch 43: val_loss did not improve from 0.02524\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0592 - mae: 0.1931 - val_loss: 0.0254 - val_mae: 0.1367 - lr: 5.0000e-04\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1150 - mae: 0.2620\n",
      "Epoch 44: val_loss did not improve from 0.02524\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1150 - mae: 0.2620 - val_loss: 0.0262 - val_mae: 0.1381 - lr: 5.0000e-04\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2875 - mae: 0.4031\n",
      "Epoch 45: val_loss did not improve from 0.02524\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2875 - mae: 0.4031 - val_loss: 0.0277 - val_mae: 0.1406 - lr: 5.0000e-04\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2287 - mae: 0.4191\n",
      "Epoch 46: val_loss did not improve from 0.02524\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2287 - mae: 0.4191 - val_loss: 0.0301 - val_mae: 0.1445 - lr: 5.0000e-04\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0772 - mae: 0.2386\n",
      "Epoch 47: val_loss did not improve from 0.02524\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0772 - mae: 0.2386 - val_loss: 0.0318 - val_mae: 0.1472 - lr: 5.0000e-04\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3386 - mae: 0.4345\n",
      "Epoch 48: val_loss did not improve from 0.02524\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3386 - mae: 0.4345 - val_loss: 0.0358 - val_mae: 0.1532 - lr: 5.0000e-04\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3490 - mae: 0.4656\n",
      "Epoch 49: val_loss did not improve from 0.02524\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3490 - mae: 0.4656 - val_loss: 0.0418 - val_mae: 0.1616 - lr: 5.0000e-04\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1925 - mae: 0.2991\n",
      "Epoch 50: val_loss did not improve from 0.02524\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1925 - mae: 0.2991 - val_loss: 0.0483 - val_mae: 0.1696 - lr: 5.0000e-04\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2878 - mae: 0.3794\n",
      "Epoch 51: val_loss did not improve from 0.02524\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2878 - mae: 0.3794 - val_loss: 0.0524 - val_mae: 0.1744 - lr: 5.0000e-04\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1562 - mae: 0.3412\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.02524\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1562 - mae: 0.3412 - val_loss: 0.0581 - val_mae: 0.1809 - lr: 5.0000e-04\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1153 - mae: 0.3011\n",
      "Epoch 53: val_loss did not improve from 0.02524\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1153 - mae: 0.3011 - val_loss: 0.0600 - val_mae: 0.1829 - lr: 2.5000e-04\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2842 - mae: 0.4458\n",
      "Epoch 54: val_loss did not improve from 0.02524\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2842 - mae: 0.4458 - val_loss: 0.0604 - val_mae: 0.1832 - lr: 2.5000e-04\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0469 - mae: 0.1600\n",
      "Epoch 55: val_loss did not improve from 0.02524\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0469 - mae: 0.1600 - val_loss: 0.0603 - val_mae: 0.1830 - lr: 2.5000e-04\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1125 - mae: 0.2660\n",
      "Epoch 56: val_loss did not improve from 0.02524\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1125 - mae: 0.2660 - val_loss: 0.0598 - val_mae: 0.1822 - lr: 2.5000e-04\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1126 - mae: 0.2715\n",
      "Epoch 57: val_loss did not improve from 0.02524\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1126 - mae: 0.2715 - val_loss: 0.0585 - val_mae: 0.1807 - lr: 2.5000e-04\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1019 - mae: 0.2192\n",
      "Epoch 58: val_loss did not improve from 0.02524\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1019 - mae: 0.2192 - val_loss: 0.0585 - val_mae: 0.1805 - lr: 2.5000e-04\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1328 - mae: 0.2894\n",
      "Epoch 59: val_loss did not improve from 0.02524\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1328 - mae: 0.2894 - val_loss: 0.0579 - val_mae: 0.1798 - lr: 2.5000e-04\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0478 - mae: 0.1896\n",
      "Epoch 60: val_loss did not improve from 0.02524\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0478 - mae: 0.1896 - val_loss: 0.0579 - val_mae: 0.1795 - lr: 2.5000e-04\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3223 - mae: 0.4018\n",
      "Epoch 61: val_loss did not improve from 0.02524\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3223 - mae: 0.4018 - val_loss: 0.0569 - val_mae: 0.1782 - lr: 2.5000e-04\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2425 - mae: 0.3599Restoring model weights from the end of the best epoch: 42.\n",
      "\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.02524\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2425 - mae: 0.3599 - val_loss: 0.0590 - val_mae: 0.1805 - lr: 2.5000e-04\n",
      "Epoch 62: early stopping\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000018677A11AB0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "RESULTATS CONFIG 6:\n",
      "  MAPE: 0.84%\n",
      "  RMSE: 0.234\n",
      "  MAE: 0.201\n",
      "  R²: 0.955\n",
      "  Èpoques entrenades: 62\n",
      "  Checkpoint guardat a: checkpoints/config_6_arch_64_128_64_32.keras\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "\n",
      "======================================================================\n",
      "CONFIGURACIÓ 7/10\n",
      "======================================================================\n",
      "Arquitectura: [64, 32, 16]\n",
      "Learning rate: 0.01\n",
      "Dropout rate: 0.2\n",
      "Batch size: 16\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6584 - mae: 0.9825\n",
      "Epoch 1: val_loss improved from inf to 2.05766, saving model to checkpoints\\config_7_arch_64_32_16.h5\n",
      "1/1 [==============================] - 1s 706ms/step - loss: 1.6584 - mae: 0.9825 - val_loss: 2.0577 - val_mae: 1.1512 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7074 - mae: 0.6452\n",
      "Epoch 2: val_loss improved from 2.05766 to 1.50874, saving model to checkpoints\\config_7_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.7074 - mae: 0.6452 - val_loss: 1.5087 - val_mae: 0.9740 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7842 - mae: 0.6571\n",
      "Epoch 3: val_loss improved from 1.50874 to 1.30516, saving model to checkpoints\\config_7_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.7842 - mae: 0.6571 - val_loss: 1.3052 - val_mae: 0.8904 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5495 - mae: 0.5554\n",
      "Epoch 4: val_loss improved from 1.30516 to 1.02889, saving model to checkpoints\\config_7_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5495 - mae: 0.5554 - val_loss: 1.0289 - val_mae: 0.7763 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3363 - mae: 0.4130\n",
      "Epoch 5: val_loss improved from 1.02889 to 0.80242, saving model to checkpoints\\config_7_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3363 - mae: 0.4130 - val_loss: 0.8024 - val_mae: 0.6713 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4290 - mae: 0.5502\n",
      "Epoch 6: val_loss improved from 0.80242 to 0.60033, saving model to checkpoints\\config_7_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.4290 - mae: 0.5502 - val_loss: 0.6003 - val_mae: 0.5622 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1994 - mae: 0.3500\n",
      "Epoch 7: val_loss improved from 0.60033 to 0.42278, saving model to checkpoints\\config_7_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1994 - mae: 0.3500 - val_loss: 0.4228 - val_mae: 0.4739 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1974 - mae: 0.3755\n",
      "Epoch 8: val_loss improved from 0.42278 to 0.26371, saving model to checkpoints\\config_7_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1974 - mae: 0.3755 - val_loss: 0.2637 - val_mae: 0.4063 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0827 - mae: 0.2540\n",
      "Epoch 9: val_loss improved from 0.26371 to 0.15786, saving model to checkpoints\\config_7_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0827 - mae: 0.2540 - val_loss: 0.1579 - val_mae: 0.3457 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3304 - mae: 0.4197\n",
      "Epoch 10: val_loss improved from 0.15786 to 0.08824, saving model to checkpoints\\config_7_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3304 - mae: 0.4197 - val_loss: 0.0882 - val_mae: 0.2850 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2279 - mae: 0.3446\n",
      "Epoch 11: val_loss improved from 0.08824 to 0.05187, saving model to checkpoints\\config_7_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2279 - mae: 0.3446 - val_loss: 0.0519 - val_mae: 0.2262 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2952 - mae: 0.4449\n",
      "Epoch 12: val_loss improved from 0.05187 to 0.04767, saving model to checkpoints\\config_7_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2952 - mae: 0.4449 - val_loss: 0.0477 - val_mae: 0.1670 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4956 - mae: 0.5140\n",
      "Epoch 13: val_loss did not improve from 0.04767\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.4956 - mae: 0.5140 - val_loss: 0.0582 - val_mae: 0.1967 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3316 - mae: 0.5158\n",
      "Epoch 14: val_loss did not improve from 0.04767\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3316 - mae: 0.5158 - val_loss: 0.0499 - val_mae: 0.1747 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1774 - mae: 0.3884\n",
      "Epoch 15: val_loss did not improve from 0.04767\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1774 - mae: 0.3884 - val_loss: 0.0532 - val_mae: 0.2239 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5572 - mae: 0.6222\n",
      "Epoch 16: val_loss did not improve from 0.04767\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5572 - mae: 0.6222 - val_loss: 0.0931 - val_mae: 0.2967 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1802 - mae: 0.2860\n",
      "Epoch 17: val_loss did not improve from 0.04767\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1802 - mae: 0.2860 - val_loss: 0.1643 - val_mae: 0.3620 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0828 - mae: 0.2304\n",
      "Epoch 18: val_loss did not improve from 0.04767\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0828 - mae: 0.2304 - val_loss: 0.2604 - val_mae: 0.4216 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2479 - mae: 0.3498\n",
      "Epoch 19: val_loss did not improve from 0.04767\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2479 - mae: 0.3498 - val_loss: 0.3645 - val_mae: 0.4710 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0641 - mae: 0.2088\n",
      "Epoch 20: val_loss did not improve from 0.04767\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0641 - mae: 0.2088 - val_loss: 0.4360 - val_mae: 0.5014 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3599 - mae: 0.4376\n",
      "Epoch 21: val_loss did not improve from 0.04767\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3599 - mae: 0.4376 - val_loss: 0.4477 - val_mae: 0.5060 - lr: 0.0100\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3420 - mae: 0.4691\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.04767\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.3420 - mae: 0.4691 - val_loss: 0.4278 - val_mae: 0.4978 - lr: 0.0100\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2842 - mae: 0.4632\n",
      "Epoch 23: val_loss did not improve from 0.04767\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2842 - mae: 0.4632 - val_loss: 0.3927 - val_mae: 0.4829 - lr: 0.0050\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5093 - mae: 0.5418\n",
      "Epoch 24: val_loss did not improve from 0.04767\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5093 - mae: 0.5418 - val_loss: 0.3538 - val_mae: 0.4658 - lr: 0.0050\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2592 - mae: 0.3828\n",
      "Epoch 25: val_loss did not improve from 0.04767\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2592 - mae: 0.3828 - val_loss: 0.3114 - val_mae: 0.4459 - lr: 0.0050\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2874 - mae: 0.3949\n",
      "Epoch 26: val_loss did not improve from 0.04767\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.2874 - mae: 0.3949 - val_loss: 0.2639 - val_mae: 0.4223 - lr: 0.0050\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0766 - mae: 0.2308\n",
      "Epoch 27: val_loss did not improve from 0.04767\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0766 - mae: 0.2308 - val_loss: 0.2129 - val_mae: 0.3931 - lr: 0.0050\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1461 - mae: 0.3108\n",
      "Epoch 28: val_loss did not improve from 0.04767\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1461 - mae: 0.3108 - val_loss: 0.1674 - val_mae: 0.3629 - lr: 0.0050\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4056 - mae: 0.5149\n",
      "Epoch 29: val_loss did not improve from 0.04767\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4056 - mae: 0.5149 - val_loss: 0.1297 - val_mae: 0.3333 - lr: 0.0050\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1518 - mae: 0.3227\n",
      "Epoch 30: val_loss did not improve from 0.04767\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1518 - mae: 0.3227 - val_loss: 0.1042 - val_mae: 0.3092 - lr: 0.0050\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1629 - mae: 0.2788\n",
      "Epoch 31: val_loss did not improve from 0.04767\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1629 - mae: 0.2788 - val_loss: 0.0856 - val_mae: 0.2876 - lr: 0.0050\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1710 - mae: 0.3313Restoring model weights from the end of the best epoch: 12.\n",
      "\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.04767\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1710 - mae: 0.3313 - val_loss: 0.0739 - val_mae: 0.2708 - lr: 0.0050\n",
      "Epoch 32: early stopping\n",
      "\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "RESULTATS CONFIG 7:\n",
      "  MAPE: 1.09%\n",
      "  RMSE: 0.321\n",
      "  MAE: 0.246\n",
      "  R²: 0.915\n",
      "  Èpoques entrenades: 32\n",
      "  Checkpoint guardat a: checkpoints/config_7_arch_64_32_16.keras\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "\n",
      "======================================================================\n",
      "CONFIGURACIÓ 8/10\n",
      "======================================================================\n",
      "Arquitectura: [64, 32, 16]\n",
      "Learning rate: 0.0001\n",
      "Dropout rate: 0.2\n",
      "Batch size: 16\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1220 - mae: 0.9350\n",
      "Epoch 1: val_loss improved from inf to 1.61499, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 1s 705ms/step - loss: 1.1220 - mae: 0.9350 - val_loss: 1.6150 - val_mae: 1.0387 - lr: 1.0000e-04\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2586 - mae: 0.9938\n",
      "Epoch 2: val_loss improved from 1.61499 to 1.59812, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.2586 - mae: 0.9938 - val_loss: 1.5981 - val_mae: 1.0333 - lr: 1.0000e-04\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1810 - mae: 0.9741\n",
      "Epoch 3: val_loss improved from 1.59812 to 1.58392, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.1810 - mae: 0.9741 - val_loss: 1.5839 - val_mae: 1.0286 - lr: 1.0000e-04\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9658 - mae: 0.8679\n",
      "Epoch 4: val_loss improved from 1.58392 to 1.56906, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.9658 - mae: 0.8679 - val_loss: 1.5691 - val_mae: 1.0236 - lr: 1.0000e-04\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2669 - mae: 0.9841\n",
      "Epoch 5: val_loss improved from 1.56906 to 1.55394, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.2669 - mae: 0.9841 - val_loss: 1.5539 - val_mae: 1.0186 - lr: 1.0000e-04\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1766 - mae: 0.9336\n",
      "Epoch 6: val_loss improved from 1.55394 to 1.54028, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.1766 - mae: 0.9336 - val_loss: 1.5403 - val_mae: 1.0140 - lr: 1.0000e-04\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9061 - mae: 0.8408\n",
      "Epoch 7: val_loss improved from 1.54028 to 1.52616, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.9061 - mae: 0.8408 - val_loss: 1.5262 - val_mae: 1.0092 - lr: 1.0000e-04\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1623 - mae: 0.9411\n",
      "Epoch 8: val_loss improved from 1.52616 to 1.51353, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.1623 - mae: 0.9411 - val_loss: 1.5135 - val_mae: 1.0049 - lr: 1.0000e-04\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7750 - mae: 0.7875\n",
      "Epoch 9: val_loss improved from 1.51353 to 1.50082, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.7750 - mae: 0.7875 - val_loss: 1.5008 - val_mae: 1.0006 - lr: 1.0000e-04\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8473 - mae: 0.8160\n",
      "Epoch 10: val_loss improved from 1.50082 to 1.48799, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.8473 - mae: 0.8160 - val_loss: 1.4880 - val_mae: 0.9962 - lr: 1.0000e-04\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1147 - mae: 0.9318\n",
      "Epoch 11: val_loss improved from 1.48799 to 1.47526, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.1147 - mae: 0.9318 - val_loss: 1.4753 - val_mae: 0.9918 - lr: 1.0000e-04\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8504 - mae: 0.8236\n",
      "Epoch 12: val_loss improved from 1.47526 to 1.46223, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.8504 - mae: 0.8236 - val_loss: 1.4622 - val_mae: 0.9873 - lr: 1.0000e-04\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0491 - mae: 0.9053\n",
      "Epoch 13: val_loss improved from 1.46223 to 1.44946, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.0491 - mae: 0.9053 - val_loss: 1.4495 - val_mae: 0.9828 - lr: 1.0000e-04\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9023 - mae: 0.7979\n",
      "Epoch 14: val_loss improved from 1.44946 to 1.43643, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.9023 - mae: 0.7979 - val_loss: 1.4364 - val_mae: 0.9783 - lr: 1.0000e-04\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9763 - mae: 0.8860\n",
      "Epoch 15: val_loss improved from 1.43643 to 1.42392, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.9763 - mae: 0.8860 - val_loss: 1.4239 - val_mae: 0.9739 - lr: 1.0000e-04\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2637 - mae: 1.0008\n",
      "Epoch 16: val_loss improved from 1.42392 to 1.41141, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.2637 - mae: 1.0008 - val_loss: 1.4114 - val_mae: 0.9696 - lr: 1.0000e-04\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1193 - mae: 0.9220\n",
      "Epoch 17: val_loss improved from 1.41141 to 1.39810, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 1.1193 - mae: 0.9220 - val_loss: 1.3981 - val_mae: 0.9649 - lr: 1.0000e-04\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9359 - mae: 0.8619\n",
      "Epoch 18: val_loss improved from 1.39810 to 1.38503, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.9359 - mae: 0.8619 - val_loss: 1.3850 - val_mae: 0.9603 - lr: 1.0000e-04\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0359 - mae: 0.8926\n",
      "Epoch 19: val_loss improved from 1.38503 to 1.37222, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.0359 - mae: 0.8926 - val_loss: 1.3722 - val_mae: 0.9558 - lr: 1.0000e-04\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7373 - mae: 0.7402\n",
      "Epoch 20: val_loss improved from 1.37222 to 1.35951, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.7373 - mae: 0.7402 - val_loss: 1.3595 - val_mae: 0.9513 - lr: 1.0000e-04\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1602 - mae: 0.8958\n",
      "Epoch 21: val_loss improved from 1.35951 to 1.34648, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.1602 - mae: 0.8958 - val_loss: 1.3465 - val_mae: 0.9466 - lr: 1.0000e-04\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2017 - mae: 0.9261\n",
      "Epoch 22: val_loss improved from 1.34648 to 1.33420, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.2017 - mae: 0.9261 - val_loss: 1.3342 - val_mae: 0.9422 - lr: 1.0000e-04\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9339 - mae: 0.8445\n",
      "Epoch 23: val_loss improved from 1.33420 to 1.32136, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.9339 - mae: 0.8445 - val_loss: 1.3214 - val_mae: 0.9375 - lr: 1.0000e-04\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9207 - mae: 0.8452\n",
      "Epoch 24: val_loss improved from 1.32136 to 1.30881, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.9207 - mae: 0.8452 - val_loss: 1.3088 - val_mae: 0.9330 - lr: 1.0000e-04\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9179 - mae: 0.8331\n",
      "Epoch 25: val_loss improved from 1.30881 to 1.29615, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.9179 - mae: 0.8331 - val_loss: 1.2962 - val_mae: 0.9283 - lr: 1.0000e-04\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8610 - mae: 0.8161\n",
      "Epoch 26: val_loss improved from 1.29615 to 1.28356, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.8610 - mae: 0.8161 - val_loss: 1.2836 - val_mae: 0.9237 - lr: 1.0000e-04\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6605 - mae: 0.7187\n",
      "Epoch 27: val_loss improved from 1.28356 to 1.27129, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6605 - mae: 0.7187 - val_loss: 1.2713 - val_mae: 0.9192 - lr: 1.0000e-04\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9876 - mae: 0.8604\n",
      "Epoch 28: val_loss improved from 1.27129 to 1.25891, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.9876 - mae: 0.8604 - val_loss: 1.2589 - val_mae: 0.9146 - lr: 1.0000e-04\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0941 - mae: 0.9105\n",
      "Epoch 29: val_loss improved from 1.25891 to 1.24623, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.0941 - mae: 0.9105 - val_loss: 1.2462 - val_mae: 0.9099 - lr: 1.0000e-04\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9717 - mae: 0.7940\n",
      "Epoch 30: val_loss improved from 1.24623 to 1.23357, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.9717 - mae: 0.7940 - val_loss: 1.2336 - val_mae: 0.9051 - lr: 1.0000e-04\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9277 - mae: 0.8539\n",
      "Epoch 31: val_loss improved from 1.23357 to 1.22060, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.9277 - mae: 0.8539 - val_loss: 1.2206 - val_mae: 0.9003 - lr: 1.0000e-04\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8892 - mae: 0.8187\n",
      "Epoch 32: val_loss improved from 1.22060 to 1.20802, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.8892 - mae: 0.8187 - val_loss: 1.2080 - val_mae: 0.8955 - lr: 1.0000e-04\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8165 - mae: 0.7730\n",
      "Epoch 33: val_loss improved from 1.20802 to 1.19575, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.8165 - mae: 0.7730 - val_loss: 1.1957 - val_mae: 0.8908 - lr: 1.0000e-04\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9335 - mae: 0.8600\n",
      "Epoch 34: val_loss improved from 1.19575 to 1.18278, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.9335 - mae: 0.8600 - val_loss: 1.1828 - val_mae: 0.8858 - lr: 1.0000e-04\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7504 - mae: 0.7435\n",
      "Epoch 35: val_loss improved from 1.18278 to 1.17047, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.7504 - mae: 0.7435 - val_loss: 1.1705 - val_mae: 0.8810 - lr: 1.0000e-04\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9782 - mae: 0.8702\n",
      "Epoch 36: val_loss improved from 1.17047 to 1.15788, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.9782 - mae: 0.8702 - val_loss: 1.1579 - val_mae: 0.8762 - lr: 1.0000e-04\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8689 - mae: 0.8076\n",
      "Epoch 37: val_loss improved from 1.15788 to 1.14587, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.8689 - mae: 0.8076 - val_loss: 1.1459 - val_mae: 0.8715 - lr: 1.0000e-04\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0561 - mae: 0.9070\n",
      "Epoch 38: val_loss improved from 1.14587 to 1.13347, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 1.0561 - mae: 0.9070 - val_loss: 1.1335 - val_mae: 0.8666 - lr: 1.0000e-04\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8110 - mae: 0.7998\n",
      "Epoch 39: val_loss improved from 1.13347 to 1.12115, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.8110 - mae: 0.7998 - val_loss: 1.1212 - val_mae: 0.8618 - lr: 1.0000e-04\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9785 - mae: 0.8513\n",
      "Epoch 40: val_loss improved from 1.12115 to 1.10879, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.9785 - mae: 0.8513 - val_loss: 1.1088 - val_mae: 0.8568 - lr: 1.0000e-04\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7534 - mae: 0.7551\n",
      "Epoch 41: val_loss improved from 1.10879 to 1.09646, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7534 - mae: 0.7551 - val_loss: 1.0965 - val_mae: 0.8519 - lr: 1.0000e-04\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9789 - mae: 0.8552\n",
      "Epoch 42: val_loss improved from 1.09646 to 1.08409, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.9789 - mae: 0.8552 - val_loss: 1.0841 - val_mae: 0.8468 - lr: 1.0000e-04\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8029 - mae: 0.7758\n",
      "Epoch 43: val_loss improved from 1.08409 to 1.07206, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.8029 - mae: 0.7758 - val_loss: 1.0721 - val_mae: 0.8419 - lr: 1.0000e-04\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9198 - mae: 0.8339\n",
      "Epoch 44: val_loss improved from 1.07206 to 1.06019, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.9198 - mae: 0.8339 - val_loss: 1.0602 - val_mae: 0.8370 - lr: 1.0000e-04\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7971 - mae: 0.7332\n",
      "Epoch 45: val_loss improved from 1.06019 to 1.04845, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.7971 - mae: 0.7332 - val_loss: 1.0485 - val_mae: 0.8321 - lr: 1.0000e-04\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7335 - mae: 0.7651\n",
      "Epoch 46: val_loss improved from 1.04845 to 1.03676, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.7335 - mae: 0.7651 - val_loss: 1.0368 - val_mae: 0.8273 - lr: 1.0000e-04\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0444 - mae: 0.9026\n",
      "Epoch 47: val_loss improved from 1.03676 to 1.02571, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.0444 - mae: 0.9026 - val_loss: 1.0257 - val_mae: 0.8227 - lr: 1.0000e-04\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7925 - mae: 0.7704\n",
      "Epoch 48: val_loss improved from 1.02571 to 1.01490, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.7925 - mae: 0.7704 - val_loss: 1.0149 - val_mae: 0.8181 - lr: 1.0000e-04\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8188 - mae: 0.8039\n",
      "Epoch 49: val_loss improved from 1.01490 to 1.00430, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.8188 - mae: 0.8039 - val_loss: 1.0043 - val_mae: 0.8137 - lr: 1.0000e-04\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6110 - mae: 0.6804\n",
      "Epoch 50: val_loss improved from 1.00430 to 0.99358, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6110 - mae: 0.6804 - val_loss: 0.9936 - val_mae: 0.8092 - lr: 1.0000e-04\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9794 - mae: 0.8857\n",
      "Epoch 51: val_loss improved from 0.99358 to 0.98242, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.9794 - mae: 0.8857 - val_loss: 0.9824 - val_mae: 0.8044 - lr: 1.0000e-04\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8564 - mae: 0.7916\n",
      "Epoch 52: val_loss improved from 0.98242 to 0.97175, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.8564 - mae: 0.7916 - val_loss: 0.9718 - val_mae: 0.7999 - lr: 1.0000e-04\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6738 - mae: 0.7180\n",
      "Epoch 53: val_loss improved from 0.97175 to 0.96148, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6738 - mae: 0.7180 - val_loss: 0.9615 - val_mae: 0.7955 - lr: 1.0000e-04\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7868 - mae: 0.7851\n",
      "Epoch 54: val_loss improved from 0.96148 to 0.95137, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 476ms/step - loss: 0.7868 - mae: 0.7851 - val_loss: 0.9514 - val_mae: 0.7912 - lr: 1.0000e-04\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9646 - mae: 0.8595\n",
      "Epoch 55: val_loss improved from 0.95137 to 0.94187, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 465ms/step - loss: 0.9646 - mae: 0.8595 - val_loss: 0.9419 - val_mae: 0.7871 - lr: 1.0000e-04\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7686 - mae: 0.7100\n",
      "Epoch 56: val_loss improved from 0.94187 to 0.93225, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 470ms/step - loss: 0.7686 - mae: 0.7100 - val_loss: 0.9322 - val_mae: 0.7829 - lr: 1.0000e-04\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7130 - mae: 0.7020\n",
      "Epoch 57: val_loss improved from 0.93225 to 0.92290, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 1s 554ms/step - loss: 0.7130 - mae: 0.7020 - val_loss: 0.9229 - val_mae: 0.7788 - lr: 1.0000e-04\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8332 - mae: 0.8047\n",
      "Epoch 58: val_loss improved from 0.92290 to 0.91340, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8332 - mae: 0.8047 - val_loss: 0.9134 - val_mae: 0.7746 - lr: 1.0000e-04\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6371 - mae: 0.6867\n",
      "Epoch 59: val_loss improved from 0.91340 to 0.90374, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 1s 558ms/step - loss: 0.6371 - mae: 0.6867 - val_loss: 0.9037 - val_mae: 0.7703 - lr: 1.0000e-04\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8772 - mae: 0.8303\n",
      "Epoch 60: val_loss improved from 0.90374 to 0.89416, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 0.8772 - mae: 0.8303 - val_loss: 0.8942 - val_mae: 0.7660 - lr: 1.0000e-04\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7710 - mae: 0.7722\n",
      "Epoch 61: val_loss improved from 0.89416 to 0.88476, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 1s 597ms/step - loss: 0.7710 - mae: 0.7722 - val_loss: 0.8848 - val_mae: 0.7618 - lr: 1.0000e-04\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8444 - mae: 0.7990\n",
      "Epoch 62: val_loss improved from 0.88476 to 0.87505, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.8444 - mae: 0.7990 - val_loss: 0.8751 - val_mae: 0.7574 - lr: 1.0000e-04\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6712 - mae: 0.7020\n",
      "Epoch 63: val_loss improved from 0.87505 to 0.86512, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 1s 515ms/step - loss: 0.6712 - mae: 0.7020 - val_loss: 0.8651 - val_mae: 0.7530 - lr: 1.0000e-04\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7197 - mae: 0.7111\n",
      "Epoch 64: val_loss improved from 0.86512 to 0.85518, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 1s 550ms/step - loss: 0.7197 - mae: 0.7111 - val_loss: 0.8552 - val_mae: 0.7484 - lr: 1.0000e-04\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8157 - mae: 0.7824\n",
      "Epoch 65: val_loss improved from 0.85518 to 0.84550, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.8157 - mae: 0.7824 - val_loss: 0.8455 - val_mae: 0.7440 - lr: 1.0000e-04\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6216 - mae: 0.6845\n",
      "Epoch 66: val_loss improved from 0.84550 to 0.83565, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 437ms/step - loss: 0.6216 - mae: 0.6845 - val_loss: 0.8356 - val_mae: 0.7395 - lr: 1.0000e-04\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7274 - mae: 0.7137\n",
      "Epoch 67: val_loss improved from 0.83565 to 0.82590, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.7274 - mae: 0.7137 - val_loss: 0.8259 - val_mae: 0.7350 - lr: 1.0000e-04\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7151 - mae: 0.7211\n",
      "Epoch 68: val_loss improved from 0.82590 to 0.81586, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.7151 - mae: 0.7211 - val_loss: 0.8159 - val_mae: 0.7304 - lr: 1.0000e-04\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7497 - mae: 0.7617\n",
      "Epoch 69: val_loss improved from 0.81586 to 0.80579, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 0.7497 - mae: 0.7617 - val_loss: 0.8058 - val_mae: 0.7257 - lr: 1.0000e-04\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6433 - mae: 0.6721\n",
      "Epoch 70: val_loss improved from 0.80579 to 0.79602, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 1s 649ms/step - loss: 0.6433 - mae: 0.6721 - val_loss: 0.7960 - val_mae: 0.7210 - lr: 1.0000e-04\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6936 - mae: 0.7260\n",
      "Epoch 71: val_loss improved from 0.79602 to 0.78664, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.6936 - mae: 0.7260 - val_loss: 0.7866 - val_mae: 0.7166 - lr: 1.0000e-04\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7887 - mae: 0.7857\n",
      "Epoch 72: val_loss improved from 0.78664 to 0.77664, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.7887 - mae: 0.7857 - val_loss: 0.7766 - val_mae: 0.7118 - lr: 1.0000e-04\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7106 - mae: 0.7059\n",
      "Epoch 73: val_loss improved from 0.77664 to 0.76699, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 284ms/step - loss: 0.7106 - mae: 0.7059 - val_loss: 0.7670 - val_mae: 0.7071 - lr: 1.0000e-04\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7360 - mae: 0.7374\n",
      "Epoch 74: val_loss improved from 0.76699 to 0.75771, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.7360 - mae: 0.7374 - val_loss: 0.7577 - val_mae: 0.7026 - lr: 1.0000e-04\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9478 - mae: 0.8594\n",
      "Epoch 75: val_loss improved from 0.75771 to 0.74824, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.9478 - mae: 0.8594 - val_loss: 0.7482 - val_mae: 0.6980 - lr: 1.0000e-04\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5600 - mae: 0.6297\n",
      "Epoch 76: val_loss improved from 0.74824 to 0.73934, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.5600 - mae: 0.6297 - val_loss: 0.7393 - val_mae: 0.6936 - lr: 1.0000e-04\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7344 - mae: 0.7194\n",
      "Epoch 77: val_loss improved from 0.73934 to 0.73059, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.7344 - mae: 0.7194 - val_loss: 0.7306 - val_mae: 0.6893 - lr: 1.0000e-04\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9585 - mae: 0.8498\n",
      "Epoch 78: val_loss improved from 0.73059 to 0.72182, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.9585 - mae: 0.8498 - val_loss: 0.7218 - val_mae: 0.6849 - lr: 1.0000e-04\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9042 - mae: 0.8398\n",
      "Epoch 79: val_loss improved from 0.72182 to 0.71252, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.9042 - mae: 0.8398 - val_loss: 0.7125 - val_mae: 0.6803 - lr: 1.0000e-04\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0016 - mae: 0.8422\n",
      "Epoch 80: val_loss improved from 0.71252 to 0.70352, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 1.0016 - mae: 0.8422 - val_loss: 0.7035 - val_mae: 0.6757 - lr: 1.0000e-04\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8099 - mae: 0.7540\n",
      "Epoch 81: val_loss improved from 0.70352 to 0.69476, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.8099 - mae: 0.7540 - val_loss: 0.6948 - val_mae: 0.6713 - lr: 1.0000e-04\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9127 - mae: 0.8276\n",
      "Epoch 82: val_loss improved from 0.69476 to 0.68640, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.9127 - mae: 0.8276 - val_loss: 0.6864 - val_mae: 0.6670 - lr: 1.0000e-04\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6037 - mae: 0.6539\n",
      "Epoch 83: val_loss improved from 0.68640 to 0.67830, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.6037 - mae: 0.6539 - val_loss: 0.6783 - val_mae: 0.6628 - lr: 1.0000e-04\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6790 - mae: 0.7343\n",
      "Epoch 84: val_loss improved from 0.67830 to 0.66981, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6790 - mae: 0.7343 - val_loss: 0.6698 - val_mae: 0.6584 - lr: 1.0000e-04\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7578 - mae: 0.7671\n",
      "Epoch 85: val_loss improved from 0.66981 to 0.66104, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 0.7578 - mae: 0.7671 - val_loss: 0.6610 - val_mae: 0.6538 - lr: 1.0000e-04\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6719 - mae: 0.7148\n",
      "Epoch 86: val_loss improved from 0.66104 to 0.65243, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6719 - mae: 0.7148 - val_loss: 0.6524 - val_mae: 0.6493 - lr: 1.0000e-04\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6969 - mae: 0.7150\n",
      "Epoch 87: val_loss improved from 0.65243 to 0.64390, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6969 - mae: 0.7150 - val_loss: 0.6439 - val_mae: 0.6448 - lr: 1.0000e-04\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7351 - mae: 0.7330\n",
      "Epoch 88: val_loss improved from 0.64390 to 0.63587, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.7351 - mae: 0.7330 - val_loss: 0.6359 - val_mae: 0.6405 - lr: 1.0000e-04\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6345 - mae: 0.6765\n",
      "Epoch 89: val_loss improved from 0.63587 to 0.62761, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6345 - mae: 0.6765 - val_loss: 0.6276 - val_mae: 0.6361 - lr: 1.0000e-04\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6066 - mae: 0.6715\n",
      "Epoch 90: val_loss improved from 0.62761 to 0.61953, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6066 - mae: 0.6715 - val_loss: 0.6195 - val_mae: 0.6318 - lr: 1.0000e-04\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7106 - mae: 0.7089\n",
      "Epoch 91: val_loss improved from 0.61953 to 0.61147, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.7106 - mae: 0.7089 - val_loss: 0.6115 - val_mae: 0.6274 - lr: 1.0000e-04\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5503 - mae: 0.6294\n",
      "Epoch 92: val_loss improved from 0.61147 to 0.60382, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5503 - mae: 0.6294 - val_loss: 0.6038 - val_mae: 0.6232 - lr: 1.0000e-04\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6327 - mae: 0.7064\n",
      "Epoch 93: val_loss improved from 0.60382 to 0.59597, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6327 - mae: 0.7064 - val_loss: 0.5960 - val_mae: 0.6188 - lr: 1.0000e-04\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6498 - mae: 0.6897\n",
      "Epoch 94: val_loss improved from 0.59597 to 0.58798, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6498 - mae: 0.6897 - val_loss: 0.5880 - val_mae: 0.6144 - lr: 1.0000e-04\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6748 - mae: 0.7157\n",
      "Epoch 95: val_loss improved from 0.58798 to 0.58011, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6748 - mae: 0.7157 - val_loss: 0.5801 - val_mae: 0.6100 - lr: 1.0000e-04\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8365 - mae: 0.7972\n",
      "Epoch 96: val_loss improved from 0.58011 to 0.57251, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.8365 - mae: 0.7972 - val_loss: 0.5725 - val_mae: 0.6057 - lr: 1.0000e-04\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6723 - mae: 0.6830\n",
      "Epoch 97: val_loss improved from 0.57251 to 0.56515, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6723 - mae: 0.6830 - val_loss: 0.5651 - val_mae: 0.6016 - lr: 1.0000e-04\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7363 - mae: 0.7129\n",
      "Epoch 98: val_loss improved from 0.56515 to 0.55766, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 1s 559ms/step - loss: 0.7363 - mae: 0.7129 - val_loss: 0.5577 - val_mae: 0.5973 - lr: 1.0000e-04\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6941 - mae: 0.7310\n",
      "Epoch 99: val_loss improved from 0.55766 to 0.55004, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6941 - mae: 0.7310 - val_loss: 0.5500 - val_mae: 0.5929 - lr: 1.0000e-04\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5885 - mae: 0.6723\n",
      "Epoch 100: val_loss improved from 0.55004 to 0.54236, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5885 - mae: 0.6723 - val_loss: 0.5424 - val_mae: 0.5884 - lr: 1.0000e-04\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8242 - mae: 0.7728\n",
      "Epoch 101: val_loss improved from 0.54236 to 0.53500, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.8242 - mae: 0.7728 - val_loss: 0.5350 - val_mae: 0.5841 - lr: 1.0000e-04\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6331 - mae: 0.6987\n",
      "Epoch 102: val_loss improved from 0.53500 to 0.52761, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6331 - mae: 0.6987 - val_loss: 0.5276 - val_mae: 0.5798 - lr: 1.0000e-04\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7879 - mae: 0.7485\n",
      "Epoch 103: val_loss improved from 0.52761 to 0.52008, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.7879 - mae: 0.7485 - val_loss: 0.5201 - val_mae: 0.5753 - lr: 1.0000e-04\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5154 - mae: 0.5968\n",
      "Epoch 104: val_loss improved from 0.52008 to 0.51303, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5154 - mae: 0.5968 - val_loss: 0.5130 - val_mae: 0.5711 - lr: 1.0000e-04\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6101 - mae: 0.6188\n",
      "Epoch 105: val_loss improved from 0.51303 to 0.50637, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6101 - mae: 0.6188 - val_loss: 0.5064 - val_mae: 0.5671 - lr: 1.0000e-04\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5549 - mae: 0.5974\n",
      "Epoch 106: val_loss improved from 0.50637 to 0.49992, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5549 - mae: 0.5974 - val_loss: 0.4999 - val_mae: 0.5633 - lr: 1.0000e-04\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5726 - mae: 0.6121\n",
      "Epoch 107: val_loss improved from 0.49992 to 0.49347, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5726 - mae: 0.6121 - val_loss: 0.4935 - val_mae: 0.5593 - lr: 1.0000e-04\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8046 - mae: 0.7346\n",
      "Epoch 108: val_loss improved from 0.49347 to 0.48656, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.8046 - mae: 0.7346 - val_loss: 0.4866 - val_mae: 0.5552 - lr: 1.0000e-04\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5404 - mae: 0.5901\n",
      "Epoch 109: val_loss improved from 0.48656 to 0.48043, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5404 - mae: 0.5901 - val_loss: 0.4804 - val_mae: 0.5514 - lr: 1.0000e-04\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7949 - mae: 0.7718\n",
      "Epoch 110: val_loss improved from 0.48043 to 0.47413, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.7949 - mae: 0.7718 - val_loss: 0.4741 - val_mae: 0.5476 - lr: 1.0000e-04\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5838 - mae: 0.5940\n",
      "Epoch 111: val_loss improved from 0.47413 to 0.46796, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5838 - mae: 0.5940 - val_loss: 0.4680 - val_mae: 0.5438 - lr: 1.0000e-04\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5552 - mae: 0.6198\n",
      "Epoch 112: val_loss improved from 0.46796 to 0.46181, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.5552 - mae: 0.6198 - val_loss: 0.4618 - val_mae: 0.5400 - lr: 1.0000e-04\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4803 - mae: 0.5803\n",
      "Epoch 113: val_loss improved from 0.46181 to 0.45586, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 1s 757ms/step - loss: 0.4803 - mae: 0.5803 - val_loss: 0.4559 - val_mae: 0.5363 - lr: 1.0000e-04\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5595 - mae: 0.6481\n",
      "Epoch 114: val_loss improved from 0.45586 to 0.44971, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 1s 506ms/step - loss: 0.5595 - mae: 0.6481 - val_loss: 0.4497 - val_mae: 0.5324 - lr: 1.0000e-04\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7739 - mae: 0.7699\n",
      "Epoch 115: val_loss improved from 0.44971 to 0.44355, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 1s 687ms/step - loss: 0.7739 - mae: 0.7699 - val_loss: 0.4435 - val_mae: 0.5285 - lr: 1.0000e-04\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6808 - mae: 0.6769\n",
      "Epoch 116: val_loss improved from 0.44355 to 0.43773, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 460ms/step - loss: 0.6808 - mae: 0.6769 - val_loss: 0.4377 - val_mae: 0.5248 - lr: 1.0000e-04\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6762 - mae: 0.6759\n",
      "Epoch 117: val_loss improved from 0.43773 to 0.43198, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 0.6762 - mae: 0.6759 - val_loss: 0.4320 - val_mae: 0.5211 - lr: 1.0000e-04\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7844 - mae: 0.7840\n",
      "Epoch 118: val_loss improved from 0.43198 to 0.42621, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 1s 647ms/step - loss: 0.7844 - mae: 0.7840 - val_loss: 0.4262 - val_mae: 0.5173 - lr: 1.0000e-04\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4891 - mae: 0.5464\n",
      "Epoch 119: val_loss improved from 0.42621 to 0.42050, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 0.4891 - mae: 0.5464 - val_loss: 0.4205 - val_mae: 0.5136 - lr: 1.0000e-04\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3883 - mae: 0.4681\n",
      "Epoch 120: val_loss improved from 0.42050 to 0.41525, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.3883 - mae: 0.4681 - val_loss: 0.4152 - val_mae: 0.5102 - lr: 1.0000e-04\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4607 - mae: 0.5254\n",
      "Epoch 121: val_loss improved from 0.41525 to 0.41012, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 286ms/step - loss: 0.4607 - mae: 0.5254 - val_loss: 0.4101 - val_mae: 0.5068 - lr: 1.0000e-04\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6319 - mae: 0.6722\n",
      "Epoch 122: val_loss improved from 0.41012 to 0.40452, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 0.6319 - mae: 0.6722 - val_loss: 0.4045 - val_mae: 0.5031 - lr: 1.0000e-04\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7222 - mae: 0.7424\n",
      "Epoch 123: val_loss improved from 0.40452 to 0.39879, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 1s 611ms/step - loss: 0.7222 - mae: 0.7424 - val_loss: 0.3988 - val_mae: 0.4992 - lr: 1.0000e-04\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6414 - mae: 0.5975\n",
      "Epoch 124: val_loss improved from 0.39879 to 0.39352, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 461ms/step - loss: 0.6414 - mae: 0.5975 - val_loss: 0.3935 - val_mae: 0.4956 - lr: 1.0000e-04\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5252 - mae: 0.5910\n",
      "Epoch 125: val_loss improved from 0.39352 to 0.38843, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 310ms/step - loss: 0.5252 - mae: 0.5910 - val_loss: 0.3884 - val_mae: 0.4922 - lr: 1.0000e-04\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6732 - mae: 0.7076\n",
      "Epoch 126: val_loss improved from 0.38843 to 0.38286, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 0.6732 - mae: 0.7076 - val_loss: 0.3829 - val_mae: 0.4883 - lr: 1.0000e-04\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6244 - mae: 0.6653\n",
      "Epoch 127: val_loss improved from 0.38286 to 0.37735, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.6244 - mae: 0.6653 - val_loss: 0.3773 - val_mae: 0.4845 - lr: 1.0000e-04\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5786 - mae: 0.5975\n",
      "Epoch 128: val_loss improved from 0.37735 to 0.37216, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.5786 - mae: 0.5975 - val_loss: 0.3722 - val_mae: 0.4809 - lr: 1.0000e-04\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6473 - mae: 0.6969\n",
      "Epoch 129: val_loss improved from 0.37216 to 0.36695, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.6473 - mae: 0.6969 - val_loss: 0.3670 - val_mae: 0.4772 - lr: 1.0000e-04\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6130 - mae: 0.6263\n",
      "Epoch 130: val_loss improved from 0.36695 to 0.36208, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.6130 - mae: 0.6263 - val_loss: 0.3621 - val_mae: 0.4738 - lr: 1.0000e-04\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5420 - mae: 0.6015\n",
      "Epoch 131: val_loss improved from 0.36208 to 0.35730, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 0.5420 - mae: 0.6015 - val_loss: 0.3573 - val_mae: 0.4704 - lr: 1.0000e-04\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6705 - mae: 0.6781\n",
      "Epoch 132: val_loss improved from 0.35730 to 0.35213, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.6705 - mae: 0.6781 - val_loss: 0.3521 - val_mae: 0.4668 - lr: 1.0000e-04\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7318 - mae: 0.7286\n",
      "Epoch 133: val_loss improved from 0.35213 to 0.34678, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 287ms/step - loss: 0.7318 - mae: 0.7286 - val_loss: 0.3468 - val_mae: 0.4629 - lr: 1.0000e-04\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6761 - mae: 0.6757\n",
      "Epoch 134: val_loss improved from 0.34678 to 0.34142, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 288ms/step - loss: 0.6761 - mae: 0.6757 - val_loss: 0.3414 - val_mae: 0.4591 - lr: 1.0000e-04\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5001 - mae: 0.5611\n",
      "Epoch 135: val_loss improved from 0.34142 to 0.33596, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.5001 - mae: 0.5611 - val_loss: 0.3360 - val_mae: 0.4551 - lr: 1.0000e-04\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4184 - mae: 0.4736\n",
      "Epoch 136: val_loss improved from 0.33596 to 0.33114, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.4184 - mae: 0.4736 - val_loss: 0.3311 - val_mae: 0.4516 - lr: 1.0000e-04\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7176 - mae: 0.7114\n",
      "Epoch 137: val_loss improved from 0.33114 to 0.32628, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 0.7176 - mae: 0.7114 - val_loss: 0.3263 - val_mae: 0.4480 - lr: 1.0000e-04\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4479 - mae: 0.5075\n",
      "Epoch 138: val_loss improved from 0.32628 to 0.32151, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.4479 - mae: 0.5075 - val_loss: 0.3215 - val_mae: 0.4445 - lr: 1.0000e-04\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4644 - mae: 0.5667\n",
      "Epoch 139: val_loss improved from 0.32151 to 0.31684, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 288ms/step - loss: 0.4644 - mae: 0.5667 - val_loss: 0.3168 - val_mae: 0.4411 - lr: 1.0000e-04\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4973 - mae: 0.6014\n",
      "Epoch 140: val_loss improved from 0.31684 to 0.31181, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.4973 - mae: 0.6014 - val_loss: 0.3118 - val_mae: 0.4373 - lr: 1.0000e-04\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4202 - mae: 0.5251\n",
      "Epoch 141: val_loss improved from 0.31181 to 0.30695, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.4202 - mae: 0.5251 - val_loss: 0.3069 - val_mae: 0.4336 - lr: 1.0000e-04\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6483 - mae: 0.6786\n",
      "Epoch 142: val_loss improved from 0.30695 to 0.30212, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.6483 - mae: 0.6786 - val_loss: 0.3021 - val_mae: 0.4300 - lr: 1.0000e-04\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7065 - mae: 0.7202\n",
      "Epoch 143: val_loss improved from 0.30212 to 0.29667, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7065 - mae: 0.7202 - val_loss: 0.2967 - val_mae: 0.4258 - lr: 1.0000e-04\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4797 - mae: 0.5400\n",
      "Epoch 144: val_loss improved from 0.29667 to 0.29149, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.4797 - mae: 0.5400 - val_loss: 0.2915 - val_mae: 0.4218 - lr: 1.0000e-04\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5500 - mae: 0.6142\n",
      "Epoch 145: val_loss improved from 0.29149 to 0.28656, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.5500 - mae: 0.6142 - val_loss: 0.2866 - val_mae: 0.4179 - lr: 1.0000e-04\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5341 - mae: 0.5943\n",
      "Epoch 146: val_loss improved from 0.28656 to 0.28167, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.5341 - mae: 0.5943 - val_loss: 0.2817 - val_mae: 0.4141 - lr: 1.0000e-04\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4520 - mae: 0.4851\n",
      "Epoch 147: val_loss improved from 0.28167 to 0.27717, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.4520 - mae: 0.4851 - val_loss: 0.2772 - val_mae: 0.4105 - lr: 1.0000e-04\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5007 - mae: 0.6045\n",
      "Epoch 148: val_loss improved from 0.27717 to 0.27277, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.5007 - mae: 0.6045 - val_loss: 0.2728 - val_mae: 0.4070 - lr: 1.0000e-04\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7173 - mae: 0.7057\n",
      "Epoch 149: val_loss improved from 0.27277 to 0.26842, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7173 - mae: 0.7057 - val_loss: 0.2684 - val_mae: 0.4035 - lr: 1.0000e-04\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5875 - mae: 0.6220\n",
      "Epoch 150: val_loss improved from 0.26842 to 0.26402, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.5875 - mae: 0.6220 - val_loss: 0.2640 - val_mae: 0.4000 - lr: 1.0000e-04\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4188 - mae: 0.5324\n",
      "Epoch 151: val_loss improved from 0.26402 to 0.25975, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.4188 - mae: 0.5324 - val_loss: 0.2597 - val_mae: 0.3965 - lr: 1.0000e-04\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5541 - mae: 0.6267\n",
      "Epoch 152: val_loss improved from 0.25975 to 0.25589, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.5541 - mae: 0.6267 - val_loss: 0.2559 - val_mae: 0.3933 - lr: 1.0000e-04\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4480 - mae: 0.5349\n",
      "Epoch 153: val_loss improved from 0.25589 to 0.25205, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4480 - mae: 0.5349 - val_loss: 0.2520 - val_mae: 0.3902 - lr: 1.0000e-04\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5867 - mae: 0.6274\n",
      "Epoch 154: val_loss improved from 0.25205 to 0.24833, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5867 - mae: 0.6274 - val_loss: 0.2483 - val_mae: 0.3871 - lr: 1.0000e-04\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4953 - mae: 0.5561\n",
      "Epoch 155: val_loss improved from 0.24833 to 0.24470, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.4953 - mae: 0.5561 - val_loss: 0.2447 - val_mae: 0.3841 - lr: 1.0000e-04\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4065 - mae: 0.5157\n",
      "Epoch 156: val_loss improved from 0.24470 to 0.24146, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 1s 510ms/step - loss: 0.4065 - mae: 0.5157 - val_loss: 0.2415 - val_mae: 0.3814 - lr: 1.0000e-04\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4385 - mae: 0.5036\n",
      "Epoch 157: val_loss improved from 0.24146 to 0.23830, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.4385 - mae: 0.5036 - val_loss: 0.2383 - val_mae: 0.3788 - lr: 1.0000e-04\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5140 - mae: 0.5764\n",
      "Epoch 158: val_loss improved from 0.23830 to 0.23480, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5140 - mae: 0.5764 - val_loss: 0.2348 - val_mae: 0.3758 - lr: 1.0000e-04\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4460 - mae: 0.5795\n",
      "Epoch 159: val_loss improved from 0.23480 to 0.23111, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4460 - mae: 0.5795 - val_loss: 0.2311 - val_mae: 0.3727 - lr: 1.0000e-04\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4861 - mae: 0.6245\n",
      "Epoch 160: val_loss improved from 0.23111 to 0.22727, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.4861 - mae: 0.6245 - val_loss: 0.2273 - val_mae: 0.3693 - lr: 1.0000e-04\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5019 - mae: 0.4955\n",
      "Epoch 161: val_loss improved from 0.22727 to 0.22372, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5019 - mae: 0.4955 - val_loss: 0.2237 - val_mae: 0.3662 - lr: 1.0000e-04\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6200 - mae: 0.6644\n",
      "Epoch 162: val_loss improved from 0.22372 to 0.22018, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6200 - mae: 0.6644 - val_loss: 0.2202 - val_mae: 0.3631 - lr: 1.0000e-04\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4989 - mae: 0.5538\n",
      "Epoch 163: val_loss improved from 0.22018 to 0.21674, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4989 - mae: 0.5538 - val_loss: 0.2167 - val_mae: 0.3600 - lr: 1.0000e-04\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6908 - mae: 0.7294\n",
      "Epoch 164: val_loss improved from 0.21674 to 0.21309, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6908 - mae: 0.7294 - val_loss: 0.2131 - val_mae: 0.3568 - lr: 1.0000e-04\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5338 - mae: 0.5532\n",
      "Epoch 165: val_loss improved from 0.21309 to 0.20979, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.5338 - mae: 0.5532 - val_loss: 0.2098 - val_mae: 0.3538 - lr: 1.0000e-04\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6523 - mae: 0.6270\n",
      "Epoch 166: val_loss improved from 0.20979 to 0.20680, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6523 - mae: 0.6270 - val_loss: 0.2068 - val_mae: 0.3511 - lr: 1.0000e-04\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5101 - mae: 0.6327\n",
      "Epoch 167: val_loss improved from 0.20680 to 0.20333, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5101 - mae: 0.6327 - val_loss: 0.2033 - val_mae: 0.3480 - lr: 1.0000e-04\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4390 - mae: 0.5554\n",
      "Epoch 168: val_loss improved from 0.20333 to 0.19985, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4390 - mae: 0.5554 - val_loss: 0.1999 - val_mae: 0.3448 - lr: 1.0000e-04\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3969 - mae: 0.4857\n",
      "Epoch 169: val_loss improved from 0.19985 to 0.19656, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3969 - mae: 0.4857 - val_loss: 0.1966 - val_mae: 0.3417 - lr: 1.0000e-04\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4982 - mae: 0.5802\n",
      "Epoch 170: val_loss improved from 0.19656 to 0.19324, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.4982 - mae: 0.5802 - val_loss: 0.1932 - val_mae: 0.3386 - lr: 1.0000e-04\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4065 - mae: 0.5213\n",
      "Epoch 171: val_loss improved from 0.19324 to 0.19047, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4065 - mae: 0.5213 - val_loss: 0.1905 - val_mae: 0.3359 - lr: 1.0000e-04\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4624 - mae: 0.5554\n",
      "Epoch 172: val_loss improved from 0.19047 to 0.18817, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4624 - mae: 0.5554 - val_loss: 0.1882 - val_mae: 0.3337 - lr: 1.0000e-04\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3621 - mae: 0.4497\n",
      "Epoch 173: val_loss improved from 0.18817 to 0.18629, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3621 - mae: 0.4497 - val_loss: 0.1863 - val_mae: 0.3320 - lr: 1.0000e-04\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4771 - mae: 0.5809\n",
      "Epoch 174: val_loss improved from 0.18629 to 0.18440, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4771 - mae: 0.5809 - val_loss: 0.1844 - val_mae: 0.3302 - lr: 1.0000e-04\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5439 - mae: 0.6164\n",
      "Epoch 175: val_loss improved from 0.18440 to 0.18227, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5439 - mae: 0.6164 - val_loss: 0.1823 - val_mae: 0.3281 - lr: 1.0000e-04\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6013 - mae: 0.6381\n",
      "Epoch 176: val_loss improved from 0.18227 to 0.17988, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6013 - mae: 0.6381 - val_loss: 0.1799 - val_mae: 0.3257 - lr: 1.0000e-04\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5990 - mae: 0.6545\n",
      "Epoch 177: val_loss improved from 0.17988 to 0.17766, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.5990 - mae: 0.6545 - val_loss: 0.1777 - val_mae: 0.3236 - lr: 1.0000e-04\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5625 - mae: 0.6165\n",
      "Epoch 178: val_loss improved from 0.17766 to 0.17544, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 399ms/step - loss: 0.5625 - mae: 0.6165 - val_loss: 0.1754 - val_mae: 0.3214 - lr: 1.0000e-04\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4993 - mae: 0.5675\n",
      "Epoch 179: val_loss improved from 0.17544 to 0.17321, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 1s 674ms/step - loss: 0.4993 - mae: 0.5675 - val_loss: 0.1732 - val_mae: 0.3191 - lr: 1.0000e-04\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5895 - mae: 0.6349\n",
      "Epoch 180: val_loss improved from 0.17321 to 0.17059, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 1s 591ms/step - loss: 0.5895 - mae: 0.6349 - val_loss: 0.1706 - val_mae: 0.3165 - lr: 1.0000e-04\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4966 - mae: 0.4680\n",
      "Epoch 181: val_loss improved from 0.17059 to 0.16824, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 1s 681ms/step - loss: 0.4966 - mae: 0.4680 - val_loss: 0.1682 - val_mae: 0.3142 - lr: 1.0000e-04\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4688 - mae: 0.5186\n",
      "Epoch 182: val_loss improved from 0.16824 to 0.16585, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 0.4688 - mae: 0.5186 - val_loss: 0.1658 - val_mae: 0.3118 - lr: 1.0000e-04\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4910 - mae: 0.5774\n",
      "Epoch 183: val_loss improved from 0.16585 to 0.16347, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 1s 544ms/step - loss: 0.4910 - mae: 0.5774 - val_loss: 0.1635 - val_mae: 0.3093 - lr: 1.0000e-04\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3769 - mae: 0.4914\n",
      "Epoch 184: val_loss improved from 0.16347 to 0.16120, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 477ms/step - loss: 0.3769 - mae: 0.4914 - val_loss: 0.1612 - val_mae: 0.3070 - lr: 1.0000e-04\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3314 - mae: 0.4668\n",
      "Epoch 185: val_loss improved from 0.16120 to 0.15904, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 1s 519ms/step - loss: 0.3314 - mae: 0.4668 - val_loss: 0.1590 - val_mae: 0.3048 - lr: 1.0000e-04\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4819 - mae: 0.5484\n",
      "Epoch 186: val_loss improved from 0.15904 to 0.15697, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 1s 643ms/step - loss: 0.4819 - mae: 0.5484 - val_loss: 0.1570 - val_mae: 0.3027 - lr: 1.0000e-04\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5640 - mae: 0.6092\n",
      "Epoch 187: val_loss improved from 0.15697 to 0.15544, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 0.5640 - mae: 0.6092 - val_loss: 0.1554 - val_mae: 0.3011 - lr: 1.0000e-04\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4272 - mae: 0.5163\n",
      "Epoch 188: val_loss improved from 0.15544 to 0.15396, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4272 - mae: 0.5163 - val_loss: 0.1540 - val_mae: 0.2996 - lr: 1.0000e-04\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4547 - mae: 0.5175\n",
      "Epoch 189: val_loss improved from 0.15396 to 0.15252, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 444ms/step - loss: 0.4547 - mae: 0.5175 - val_loss: 0.1525 - val_mae: 0.2980 - lr: 1.0000e-04\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4490 - mae: 0.5914\n",
      "Epoch 190: val_loss improved from 0.15252 to 0.15088, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 1s 519ms/step - loss: 0.4490 - mae: 0.5914 - val_loss: 0.1509 - val_mae: 0.2962 - lr: 1.0000e-04\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6539 - mae: 0.7081\n",
      "Epoch 191: val_loss improved from 0.15088 to 0.14898, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 1s 580ms/step - loss: 0.6539 - mae: 0.7081 - val_loss: 0.1490 - val_mae: 0.2940 - lr: 1.0000e-04\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5905 - mae: 0.6834\n",
      "Epoch 192: val_loss improved from 0.14898 to 0.14691, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5905 - mae: 0.6834 - val_loss: 0.1469 - val_mae: 0.2917 - lr: 1.0000e-04\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4957 - mae: 0.5875\n",
      "Epoch 193: val_loss improved from 0.14691 to 0.14452, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.4957 - mae: 0.5875 - val_loss: 0.1445 - val_mae: 0.2889 - lr: 1.0000e-04\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4417 - mae: 0.5221\n",
      "Epoch 194: val_loss improved from 0.14452 to 0.14221, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.4417 - mae: 0.5221 - val_loss: 0.1422 - val_mae: 0.2862 - lr: 1.0000e-04\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3720 - mae: 0.4960\n",
      "Epoch 195: val_loss improved from 0.14221 to 0.14013, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3720 - mae: 0.4960 - val_loss: 0.1401 - val_mae: 0.2837 - lr: 1.0000e-04\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5807 - mae: 0.6413\n",
      "Epoch 196: val_loss improved from 0.14013 to 0.13789, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.5807 - mae: 0.6413 - val_loss: 0.1379 - val_mae: 0.2811 - lr: 1.0000e-04\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2982 - mae: 0.4353\n",
      "Epoch 197: val_loss improved from 0.13789 to 0.13564, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2982 - mae: 0.4353 - val_loss: 0.1356 - val_mae: 0.2784 - lr: 1.0000e-04\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4566 - mae: 0.5398\n",
      "Epoch 198: val_loss improved from 0.13564 to 0.13346, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4566 - mae: 0.5398 - val_loss: 0.1335 - val_mae: 0.2758 - lr: 1.0000e-04\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3739 - mae: 0.5091\n",
      "Epoch 199: val_loss improved from 0.13346 to 0.13138, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3739 - mae: 0.5091 - val_loss: 0.1314 - val_mae: 0.2733 - lr: 1.0000e-04\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3508 - mae: 0.5031\n",
      "Epoch 200: val_loss improved from 0.13138 to 0.12933, saving model to checkpoints\\config_8_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3508 - mae: 0.5031 - val_loss: 0.1293 - val_mae: 0.2709 - lr: 1.0000e-04\n",
      "\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "RESULTATS CONFIG 8:\n",
      "  MAPE: 1.64%\n",
      "  RMSE: 0.529\n",
      "  MAE: 0.398\n",
      "  R²: 0.769\n",
      "  Èpoques entrenades: 200\n",
      "  Checkpoint guardat a: checkpoints/config_8_arch_64_32_16.keras\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "\n",
      "======================================================================\n",
      "CONFIGURACIÓ 9/10\n",
      "======================================================================\n",
      "Arquitectura: [64, 32, 16]\n",
      "Learning rate: 0.001\n",
      "Dropout rate: 0.4\n",
      "Batch size: 16\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1304 - mae: 0.9457\n",
      "Epoch 1: val_loss improved from inf to 1.32592, saving model to checkpoints\\config_9_arch_64_32_16.h5\n",
      "1/1 [==============================] - 1s 710ms/step - loss: 1.1304 - mae: 0.9457 - val_loss: 1.3259 - val_mae: 0.9243 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0605 - mae: 0.8904\n",
      "Epoch 2: val_loss improved from 1.32592 to 1.22282, saving model to checkpoints\\config_9_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.0605 - mae: 0.8904 - val_loss: 1.2228 - val_mae: 0.8842 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7340 - mae: 0.6843\n",
      "Epoch 3: val_loss improved from 1.22282 to 1.13851, saving model to checkpoints\\config_9_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.7340 - mae: 0.6843 - val_loss: 1.1385 - val_mae: 0.8501 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9142 - mae: 0.8030\n",
      "Epoch 4: val_loss improved from 1.13851 to 1.05713, saving model to checkpoints\\config_9_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.9142 - mae: 0.8030 - val_loss: 1.0571 - val_mae: 0.8172 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4960 - mae: 0.5068\n",
      "Epoch 5: val_loss improved from 1.05713 to 0.98522, saving model to checkpoints\\config_9_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4960 - mae: 0.5068 - val_loss: 0.9852 - val_mae: 0.7874 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4590 - mae: 0.5315\n",
      "Epoch 6: val_loss improved from 0.98522 to 0.93281, saving model to checkpoints\\config_9_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4590 - mae: 0.5315 - val_loss: 0.9328 - val_mae: 0.7640 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4564 - mae: 0.5368\n",
      "Epoch 7: val_loss improved from 0.93281 to 0.88191, saving model to checkpoints\\config_9_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.4564 - mae: 0.5368 - val_loss: 0.8819 - val_mae: 0.7408 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4443 - mae: 0.5682\n",
      "Epoch 8: val_loss improved from 0.88191 to 0.83065, saving model to checkpoints\\config_9_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4443 - mae: 0.5682 - val_loss: 0.8307 - val_mae: 0.7167 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6418 - mae: 0.6621\n",
      "Epoch 9: val_loss improved from 0.83065 to 0.78240, saving model to checkpoints\\config_9_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6418 - mae: 0.6621 - val_loss: 0.7824 - val_mae: 0.6935 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8073 - mae: 0.6862\n",
      "Epoch 10: val_loss improved from 0.78240 to 0.73614, saving model to checkpoints\\config_9_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.8073 - mae: 0.6862 - val_loss: 0.7361 - val_mae: 0.6696 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5242 - mae: 0.5517\n",
      "Epoch 11: val_loss improved from 0.73614 to 0.69566, saving model to checkpoints\\config_9_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5242 - mae: 0.5517 - val_loss: 0.6957 - val_mae: 0.6478 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8942 - mae: 0.7807\n",
      "Epoch 12: val_loss improved from 0.69566 to 0.65591, saving model to checkpoints\\config_9_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.8942 - mae: 0.7807 - val_loss: 0.6559 - val_mae: 0.6261 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4353 - mae: 0.4886\n",
      "Epoch 13: val_loss improved from 0.65591 to 0.61658, saving model to checkpoints\\config_9_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4353 - mae: 0.4886 - val_loss: 0.6166 - val_mae: 0.6049 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8891 - mae: 0.8459\n",
      "Epoch 14: val_loss improved from 0.61658 to 0.57858, saving model to checkpoints\\config_9_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.8891 - mae: 0.8459 - val_loss: 0.5786 - val_mae: 0.5838 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5875 - mae: 0.6679\n",
      "Epoch 15: val_loss improved from 0.57858 to 0.54381, saving model to checkpoints\\config_9_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 483ms/step - loss: 0.5875 - mae: 0.6679 - val_loss: 0.5438 - val_mae: 0.5638 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5614 - mae: 0.5167\n",
      "Epoch 16: val_loss improved from 0.54381 to 0.51482, saving model to checkpoints\\config_9_arch_64_32_16.h5\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5614 - mae: 0.5167 - val_loss: 0.5148 - val_mae: 0.5462 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3150 - mae: 0.4775\n",
      "Epoch 17: val_loss improved from 0.51482 to 0.49082, saving model to checkpoints\\config_9_arch_64_32_16.h5\n",
      "1/1 [==============================] - 1s 579ms/step - loss: 0.3150 - mae: 0.4775 - val_loss: 0.4908 - val_mae: 0.5306 - lr: 0.0010\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4587 - mae: 0.5851\n",
      "Epoch 18: val_loss improved from 0.49082 to 0.46765, saving model to checkpoints\\config_9_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 331ms/step - loss: 0.4587 - mae: 0.5851 - val_loss: 0.4677 - val_mae: 0.5155 - lr: 0.0010\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5298 - mae: 0.6536\n",
      "Epoch 19: val_loss improved from 0.46765 to 0.44342, saving model to checkpoints\\config_9_arch_64_32_16.h5\n",
      "1/1 [==============================] - 1s 771ms/step - loss: 0.5298 - mae: 0.6536 - val_loss: 0.4434 - val_mae: 0.4995 - lr: 0.0010\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3981 - mae: 0.4622\n",
      "Epoch 20: val_loss improved from 0.44342 to 0.42084, saving model to checkpoints\\config_9_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 0.3981 - mae: 0.4622 - val_loss: 0.4208 - val_mae: 0.4840 - lr: 0.0010\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4863 - mae: 0.5074\n",
      "Epoch 21: val_loss improved from 0.42084 to 0.39751, saving model to checkpoints\\config_9_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 0.4863 - mae: 0.5074 - val_loss: 0.3975 - val_mae: 0.4678 - lr: 0.0010\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4215 - mae: 0.4936\n",
      "Epoch 22: val_loss improved from 0.39751 to 0.37685, saving model to checkpoints\\config_9_arch_64_32_16.h5\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4215 - mae: 0.4936 - val_loss: 0.3769 - val_mae: 0.4530 - lr: 0.0010\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4110 - mae: 0.4993\n",
      "Epoch 23: val_loss improved from 0.37685 to 0.35633, saving model to checkpoints\\config_9_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.4110 - mae: 0.4993 - val_loss: 0.3563 - val_mae: 0.4379 - lr: 0.0010\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5689 - mae: 0.5673\n",
      "Epoch 24: val_loss improved from 0.35633 to 0.33602, saving model to checkpoints\\config_9_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5689 - mae: 0.5673 - val_loss: 0.3360 - val_mae: 0.4223 - lr: 0.0010\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7221 - mae: 0.7462\n",
      "Epoch 25: val_loss improved from 0.33602 to 0.31475, saving model to checkpoints\\config_9_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.7221 - mae: 0.7462 - val_loss: 0.3147 - val_mae: 0.4057 - lr: 0.0010\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2020 - mae: 0.3555\n",
      "Epoch 26: val_loss improved from 0.31475 to 0.29318, saving model to checkpoints\\config_9_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.2020 - mae: 0.3555 - val_loss: 0.2932 - val_mae: 0.3885 - lr: 0.0010\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2986 - mae: 0.4278\n",
      "Epoch 27: val_loss improved from 0.29318 to 0.27333, saving model to checkpoints\\config_9_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.2986 - mae: 0.4278 - val_loss: 0.2733 - val_mae: 0.3722 - lr: 0.0010\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1464 - mae: 0.3072\n",
      "Epoch 28: val_loss improved from 0.27333 to 0.25669, saving model to checkpoints\\config_9_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1464 - mae: 0.3072 - val_loss: 0.2567 - val_mae: 0.3583 - lr: 0.0010\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4576 - mae: 0.9673\n",
      "Epoch 29: val_loss improved from 0.25669 to 0.24014, saving model to checkpoints\\config_9_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.4576 - mae: 0.9673 - val_loss: 0.2401 - val_mae: 0.3492 - lr: 0.0010\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6652 - mae: 0.6056\n",
      "Epoch 30: val_loss improved from 0.24014 to 0.22405, saving model to checkpoints\\config_9_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.6652 - mae: 0.6056 - val_loss: 0.2241 - val_mae: 0.3401 - lr: 0.0010\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4634 - mae: 0.5308\n",
      "Epoch 31: val_loss improved from 0.22405 to 0.20729, saving model to checkpoints\\config_9_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.4634 - mae: 0.5308 - val_loss: 0.2073 - val_mae: 0.3308 - lr: 0.0010\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6245 - mae: 0.6076\n",
      "Epoch 32: val_loss improved from 0.20729 to 0.19177, saving model to checkpoints\\config_9_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6245 - mae: 0.6076 - val_loss: 0.1918 - val_mae: 0.3214 - lr: 0.0010\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3477 - mae: 0.5096\n",
      "Epoch 33: val_loss improved from 0.19177 to 0.17681, saving model to checkpoints\\config_9_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.3477 - mae: 0.5096 - val_loss: 0.1768 - val_mae: 0.3118 - lr: 0.0010\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1470 - mae: 0.3286\n",
      "Epoch 34: val_loss improved from 0.17681 to 0.16441, saving model to checkpoints\\config_9_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1470 - mae: 0.3286 - val_loss: 0.1644 - val_mae: 0.3034 - lr: 0.0010\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3768 - mae: 0.4487\n",
      "Epoch 35: val_loss improved from 0.16441 to 0.14888, saving model to checkpoints\\config_9_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3768 - mae: 0.4487 - val_loss: 0.1489 - val_mae: 0.2927 - lr: 0.0010\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5874 - mae: 0.6845\n",
      "Epoch 36: val_loss improved from 0.14888 to 0.13749, saving model to checkpoints\\config_9_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5874 - mae: 0.6845 - val_loss: 0.1375 - val_mae: 0.2846 - lr: 0.0010\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7914 - mae: 0.6208\n",
      "Epoch 37: val_loss improved from 0.13749 to 0.12938, saving model to checkpoints\\config_9_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.7914 - mae: 0.6208 - val_loss: 0.1294 - val_mae: 0.2789 - lr: 0.0010\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3054 - mae: 0.4000\n",
      "Epoch 38: val_loss improved from 0.12938 to 0.12569, saving model to checkpoints\\config_9_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3054 - mae: 0.4000 - val_loss: 0.1257 - val_mae: 0.2763 - lr: 0.0010\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7443 - mae: 0.6458\n",
      "Epoch 39: val_loss improved from 0.12569 to 0.12157, saving model to checkpoints\\config_9_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.7443 - mae: 0.6458 - val_loss: 0.1216 - val_mae: 0.2735 - lr: 0.0010\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1766 - mae: 0.3172\n",
      "Epoch 40: val_loss improved from 0.12157 to 0.11784, saving model to checkpoints\\config_9_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1766 - mae: 0.3172 - val_loss: 0.1178 - val_mae: 0.2708 - lr: 0.0010\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3293 - mae: 0.3972\n",
      "Epoch 41: val_loss improved from 0.11784 to 0.11460, saving model to checkpoints\\config_9_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3293 - mae: 0.3972 - val_loss: 0.1146 - val_mae: 0.2684 - lr: 0.0010\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5433 - mae: 0.5306\n",
      "Epoch 42: val_loss did not improve from 0.11460\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5433 - mae: 0.5306 - val_loss: 0.1146 - val_mae: 0.2685 - lr: 0.0010\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6308 - mae: 0.5657\n",
      "Epoch 43: val_loss did not improve from 0.11460\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6308 - mae: 0.5657 - val_loss: 0.1151 - val_mae: 0.2689 - lr: 0.0010\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5523 - mae: 0.6774\n",
      "Epoch 44: val_loss improved from 0.11460 to 0.11415, saving model to checkpoints\\config_9_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5523 - mae: 0.6774 - val_loss: 0.1141 - val_mae: 0.2684 - lr: 0.0010\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1577 - mae: 0.3556\n",
      "Epoch 45: val_loss improved from 0.11415 to 0.11263, saving model to checkpoints\\config_9_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1577 - mae: 0.3556 - val_loss: 0.1126 - val_mae: 0.2674 - lr: 0.0010\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5229 - mae: 0.5510\n",
      "Epoch 46: val_loss improved from 0.11263 to 0.11074, saving model to checkpoints\\config_9_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5229 - mae: 0.5510 - val_loss: 0.1107 - val_mae: 0.2661 - lr: 0.0010\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2021 - mae: 0.3423\n",
      "Epoch 47: val_loss improved from 0.11074 to 0.11023, saving model to checkpoints\\config_9_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2021 - mae: 0.3423 - val_loss: 0.1102 - val_mae: 0.2660 - lr: 0.0010\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3042 - mae: 0.4679\n",
      "Epoch 48: val_loss did not improve from 0.11023\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.3042 - mae: 0.4679 - val_loss: 0.1112 - val_mae: 0.2670 - lr: 0.0010\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4109 - mae: 0.5619\n",
      "Epoch 49: val_loss improved from 0.11023 to 0.10963, saving model to checkpoints\\config_9_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4109 - mae: 0.5619 - val_loss: 0.1096 - val_mae: 0.2656 - lr: 0.0010\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5127 - mae: 0.5073\n",
      "Epoch 50: val_loss improved from 0.10963 to 0.10703, saving model to checkpoints\\config_9_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.5127 - mae: 0.5073 - val_loss: 0.1070 - val_mae: 0.2632 - lr: 0.0010\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4227 - mae: 0.5393\n",
      "Epoch 51: val_loss improved from 0.10703 to 0.10315, saving model to checkpoints\\config_9_arch_64_32_16.h5\n",
      "1/1 [==============================] - 1s 568ms/step - loss: 0.4227 - mae: 0.5393 - val_loss: 0.1031 - val_mae: 0.2598 - lr: 0.0010\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1911 - mae: 0.3516\n",
      "Epoch 52: val_loss improved from 0.10315 to 0.10198, saving model to checkpoints\\config_9_arch_64_32_16.h5\n",
      "1/1 [==============================] - 1s 610ms/step - loss: 0.1911 - mae: 0.3516 - val_loss: 0.1020 - val_mae: 0.2588 - lr: 0.0010\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2856 - mae: 0.4385\n",
      "Epoch 53: val_loss improved from 0.10198 to 0.09903, saving model to checkpoints\\config_9_arch_64_32_16.h5\n",
      "1/1 [==============================] - 1s 628ms/step - loss: 0.2856 - mae: 0.4385 - val_loss: 0.0990 - val_mae: 0.2563 - lr: 0.0010\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6668 - mae: 0.6426\n",
      "Epoch 54: val_loss improved from 0.09903 to 0.09718, saving model to checkpoints\\config_9_arch_64_32_16.h5\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.6668 - mae: 0.6426 - val_loss: 0.0972 - val_mae: 0.2545 - lr: 0.0010\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7963 - mae: 0.7083\n",
      "Epoch 55: val_loss improved from 0.09718 to 0.09375, saving model to checkpoints\\config_9_arch_64_32_16.h5\n",
      "1/1 [==============================] - 1s 674ms/step - loss: 0.7963 - mae: 0.7083 - val_loss: 0.0937 - val_mae: 0.2514 - lr: 0.0010\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7809 - mae: 0.6409\n",
      "Epoch 56: val_loss did not improve from 0.09375\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.7809 - mae: 0.6409 - val_loss: 0.1016 - val_mae: 0.2587 - lr: 0.0010\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3029 - mae: 0.4745\n",
      "Epoch 57: val_loss did not improve from 0.09375\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.3029 - mae: 0.4745 - val_loss: 0.1095 - val_mae: 0.2652 - lr: 0.0010\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2522 - mae: 0.4072\n",
      "Epoch 58: val_loss did not improve from 0.09375\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.2522 - mae: 0.4072 - val_loss: 0.1164 - val_mae: 0.2706 - lr: 0.0010\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6036 - mae: 0.6185\n",
      "Epoch 59: val_loss did not improve from 0.09375\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6036 - mae: 0.6185 - val_loss: 0.1206 - val_mae: 0.2736 - lr: 0.0010\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1245 - mae: 0.2971\n",
      "Epoch 60: val_loss did not improve from 0.09375\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1245 - mae: 0.2971 - val_loss: 0.1236 - val_mae: 0.2757 - lr: 0.0010\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5672 - mae: 0.5773\n",
      "Epoch 61: val_loss did not improve from 0.09375\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5672 - mae: 0.5773 - val_loss: 0.1255 - val_mae: 0.2770 - lr: 0.0010\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1997 - mae: 0.3917\n",
      "Epoch 62: val_loss did not improve from 0.09375\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1997 - mae: 0.3917 - val_loss: 0.1294 - val_mae: 0.2798 - lr: 0.0010\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6490 - mae: 0.6127\n",
      "Epoch 63: val_loss did not improve from 0.09375\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6490 - mae: 0.6127 - val_loss: 0.1399 - val_mae: 0.2873 - lr: 0.0010\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6921 - mae: 0.5752\n",
      "Epoch 64: val_loss did not improve from 0.09375\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6921 - mae: 0.5752 - val_loss: 0.1578 - val_mae: 0.2994 - lr: 0.0010\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7581 - mae: 0.5387\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.09375\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.7581 - mae: 0.5387 - val_loss: 0.1749 - val_mae: 0.3103 - lr: 0.0010\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2545 - mae: 0.4055\n",
      "Epoch 66: val_loss did not improve from 0.09375\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2545 - mae: 0.4055 - val_loss: 0.1836 - val_mae: 0.3155 - lr: 5.0000e-04\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4331 - mae: 0.4522\n",
      "Epoch 67: val_loss did not improve from 0.09375\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.4331 - mae: 0.4522 - val_loss: 0.1908 - val_mae: 0.3198 - lr: 5.0000e-04\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8214 - mae: 0.7509\n",
      "Epoch 68: val_loss did not improve from 0.09375\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.8214 - mae: 0.7509 - val_loss: 0.1971 - val_mae: 0.3233 - lr: 5.0000e-04\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1402 - mae: 0.3215\n",
      "Epoch 69: val_loss did not improve from 0.09375\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1402 - mae: 0.3215 - val_loss: 0.2018 - val_mae: 0.3260 - lr: 5.0000e-04\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3425 - mae: 0.4700\n",
      "Epoch 70: val_loss did not improve from 0.09375\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.3425 - mae: 0.4700 - val_loss: 0.2064 - val_mae: 0.3286 - lr: 5.0000e-04\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5530 - mae: 0.6078\n",
      "Epoch 71: val_loss did not improve from 0.09375\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5530 - mae: 0.6078 - val_loss: 0.2096 - val_mae: 0.3303 - lr: 5.0000e-04\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3098 - mae: 0.3931\n",
      "Epoch 72: val_loss did not improve from 0.09375\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3098 - mae: 0.3931 - val_loss: 0.2120 - val_mae: 0.3316 - lr: 5.0000e-04\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3774 - mae: 0.5040\n",
      "Epoch 73: val_loss did not improve from 0.09375\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3774 - mae: 0.5040 - val_loss: 0.2140 - val_mae: 0.3327 - lr: 5.0000e-04\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3056 - mae: 0.3999\n",
      "Epoch 74: val_loss did not improve from 0.09375\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3056 - mae: 0.3999 - val_loss: 0.2147 - val_mae: 0.3331 - lr: 5.0000e-04\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5480 - mae: 0.5829Restoring model weights from the end of the best epoch: 55.\n",
      "\n",
      "Epoch 75: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.09375\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5480 - mae: 0.5829 - val_loss: 0.2143 - val_mae: 0.3329 - lr: 5.0000e-04\n",
      "Epoch 75: early stopping\n",
      "\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "RESULTATS CONFIG 9:\n",
      "  MAPE: 1.53%\n",
      "  RMSE: 0.450\n",
      "  MAE: 0.370\n",
      "  R²: 0.832\n",
      "  Èpoques entrenades: 75\n",
      "  Checkpoint guardat a: checkpoints/config_9_arch_64_32_16.keras\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "\n",
      "======================================================================\n",
      "CONFIGURACIÓ 10/10\n",
      "======================================================================\n",
      "Arquitectura: [128, 128, 64, 32, 16]\n",
      "Learning rate: 0.0005\n",
      "Dropout rate: 0.3\n",
      "Batch size: 16\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1469 - mae: 0.9349\n",
      "Epoch 1: val_loss improved from inf to 1.60989, saving model to checkpoints\\config_10_arch_128_128_64_32_16.h5\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.1469 - mae: 0.9349 - val_loss: 1.6099 - val_mae: 1.0276 - lr: 5.0000e-04\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9629 - mae: 0.8572\n",
      "Epoch 2: val_loss improved from 1.60989 to 1.59997, saving model to checkpoints\\config_10_arch_128_128_64_32_16.h5\n",
      "1/1 [==============================] - 1s 700ms/step - loss: 0.9629 - mae: 0.8572 - val_loss: 1.6000 - val_mae: 1.0230 - lr: 5.0000e-04\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9460 - mae: 0.8278\n",
      "Epoch 3: val_loss improved from 1.59997 to 1.57899, saving model to checkpoints\\config_10_arch_128_128_64_32_16.h5\n",
      "1/1 [==============================] - 1s 748ms/step - loss: 0.9460 - mae: 0.8278 - val_loss: 1.5790 - val_mae: 1.0145 - lr: 5.0000e-04\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1522 - mae: 0.9283\n",
      "Epoch 4: val_loss improved from 1.57899 to 1.56638, saving model to checkpoints\\config_10_arch_128_128_64_32_16.h5\n",
      "1/1 [==============================] - 0s 308ms/step - loss: 1.1522 - mae: 0.9283 - val_loss: 1.5664 - val_mae: 1.0090 - lr: 5.0000e-04\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9883 - mae: 0.8582\n",
      "Epoch 5: val_loss improved from 1.56638 to 1.55688, saving model to checkpoints\\config_10_arch_128_128_64_32_16.h5\n",
      "1/1 [==============================] - 0s 484ms/step - loss: 0.9883 - mae: 0.8582 - val_loss: 1.5569 - val_mae: 1.0048 - lr: 5.0000e-04\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8564 - mae: 0.7898\n",
      "Epoch 6: val_loss improved from 1.55688 to 1.53641, saving model to checkpoints\\config_10_arch_128_128_64_32_16.h5\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 0.8564 - mae: 0.7898 - val_loss: 1.5364 - val_mae: 0.9971 - lr: 5.0000e-04\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9217 - mae: 0.8336\n",
      "Epoch 7: val_loss improved from 1.53641 to 1.50628, saving model to checkpoints\\config_10_arch_128_128_64_32_16.h5\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.9217 - mae: 0.8336 - val_loss: 1.5063 - val_mae: 0.9868 - lr: 5.0000e-04\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9360 - mae: 0.8428\n",
      "Epoch 8: val_loss improved from 1.50628 to 1.47606, saving model to checkpoints\\config_10_arch_128_128_64_32_16.h5\n",
      "1/1 [==============================] - 1s 525ms/step - loss: 0.9360 - mae: 0.8428 - val_loss: 1.4761 - val_mae: 0.9762 - lr: 5.0000e-04\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0491 - mae: 0.8857\n",
      "Epoch 9: val_loss improved from 1.47606 to 1.44850, saving model to checkpoints\\config_10_arch_128_128_64_32_16.h5\n",
      "1/1 [==============================] - 1s 704ms/step - loss: 1.0491 - mae: 0.8857 - val_loss: 1.4485 - val_mae: 0.9665 - lr: 5.0000e-04\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0398 - mae: 0.8880\n",
      "Epoch 10: val_loss improved from 1.44850 to 1.41708, saving model to checkpoints\\config_10_arch_128_128_64_32_16.h5\n",
      "1/1 [==============================] - 0s 457ms/step - loss: 1.0398 - mae: 0.8880 - val_loss: 1.4171 - val_mae: 0.9553 - lr: 5.0000e-04\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8654 - mae: 0.8072\n",
      "Epoch 11: val_loss improved from 1.41708 to 1.39516, saving model to checkpoints\\config_10_arch_128_128_64_32_16.h5\n",
      "1/1 [==============================] - 1s 756ms/step - loss: 0.8654 - mae: 0.8072 - val_loss: 1.3952 - val_mae: 0.9472 - lr: 5.0000e-04\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0681 - mae: 0.9107\n",
      "Epoch 12: val_loss improved from 1.39516 to 1.37712, saving model to checkpoints\\config_10_arch_128_128_64_32_16.h5\n",
      "1/1 [==============================] - 1s 608ms/step - loss: 1.0681 - mae: 0.9107 - val_loss: 1.3771 - val_mae: 0.9403 - lr: 5.0000e-04\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8196 - mae: 0.7970\n",
      "Epoch 13: val_loss improved from 1.37712 to 1.35435, saving model to checkpoints\\config_10_arch_128_128_64_32_16.h5\n",
      "1/1 [==============================] - 1s 749ms/step - loss: 0.8196 - mae: 0.7970 - val_loss: 1.3543 - val_mae: 0.9318 - lr: 5.0000e-04\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9136 - mae: 0.8278\n",
      "Epoch 14: val_loss improved from 1.35435 to 1.33333, saving model to checkpoints\\config_10_arch_128_128_64_32_16.h5\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 0.9136 - mae: 0.8278 - val_loss: 1.3333 - val_mae: 0.9239 - lr: 5.0000e-04\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9420 - mae: 0.8442\n",
      "Epoch 15: val_loss improved from 1.33333 to 1.31441, saving model to checkpoints\\config_10_arch_128_128_64_32_16.h5\n",
      "1/1 [==============================] - 1s 804ms/step - loss: 0.9420 - mae: 0.8442 - val_loss: 1.3144 - val_mae: 0.9170 - lr: 5.0000e-04\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8646 - mae: 0.8108\n",
      "Epoch 16: val_loss improved from 1.31441 to 1.28782, saving model to checkpoints\\config_10_arch_128_128_64_32_16.h5\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.8646 - mae: 0.8108 - val_loss: 1.2878 - val_mae: 0.9070 - lr: 5.0000e-04\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8986 - mae: 0.8408\n",
      "Epoch 17: val_loss improved from 1.28782 to 1.26091, saving model to checkpoints\\config_10_arch_128_128_64_32_16.h5\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8986 - mae: 0.8408 - val_loss: 1.2609 - val_mae: 0.8965 - lr: 5.0000e-04\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8854 - mae: 0.8122\n",
      "Epoch 18: val_loss improved from 1.26091 to 1.23610, saving model to checkpoints\\config_10_arch_128_128_64_32_16.h5\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.8854 - mae: 0.8122 - val_loss: 1.2361 - val_mae: 0.8867 - lr: 5.0000e-04\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7436 - mae: 0.7616\n",
      "Epoch 19: val_loss improved from 1.23610 to 1.21033, saving model to checkpoints\\config_10_arch_128_128_64_32_16.h5\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.7436 - mae: 0.7616 - val_loss: 1.2103 - val_mae: 0.8766 - lr: 5.0000e-04\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8813 - mae: 0.8167\n",
      "Epoch 20: val_loss improved from 1.21033 to 1.18455, saving model to checkpoints\\config_10_arch_128_128_64_32_16.h5\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.8813 - mae: 0.8167 - val_loss: 1.1845 - val_mae: 0.8664 - lr: 5.0000e-04\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8360 - mae: 0.8041\n",
      "Epoch 21: val_loss improved from 1.18455 to 1.15826, saving model to checkpoints\\config_10_arch_128_128_64_32_16.h5\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.8360 - mae: 0.8041 - val_loss: 1.1583 - val_mae: 0.8560 - lr: 5.0000e-04\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7536 - mae: 0.7550\n",
      "Epoch 22: val_loss improved from 1.15826 to 1.13142, saving model to checkpoints\\config_10_arch_128_128_64_32_16.h5\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.7536 - mae: 0.7550 - val_loss: 1.1314 - val_mae: 0.8451 - lr: 5.0000e-04\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7965 - mae: 0.7912\n",
      "Epoch 23: val_loss improved from 1.13142 to 1.10512, saving model to checkpoints\\config_10_arch_128_128_64_32_16.h5\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7965 - mae: 0.7912 - val_loss: 1.1051 - val_mae: 0.8344 - lr: 5.0000e-04\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0371 - mae: 0.8847\n",
      "Epoch 24: val_loss improved from 1.10512 to 1.07653, saving model to checkpoints\\config_10_arch_128_128_64_32_16.h5\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.0371 - mae: 0.8847 - val_loss: 1.0765 - val_mae: 0.8224 - lr: 5.0000e-04\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7579 - mae: 0.7393\n",
      "Epoch 25: val_loss improved from 1.07653 to 1.04407, saving model to checkpoints\\config_10_arch_128_128_64_32_16.h5\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.7579 - mae: 0.7393 - val_loss: 1.0441 - val_mae: 0.8087 - lr: 5.0000e-04\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8297 - mae: 0.7764\n",
      "Epoch 26: val_loss improved from 1.04407 to 1.01189, saving model to checkpoints\\config_10_arch_128_128_64_32_16.h5\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.8297 - mae: 0.7764 - val_loss: 1.0119 - val_mae: 0.7946 - lr: 5.0000e-04\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6500 - mae: 0.7112\n",
      "Epoch 27: val_loss improved from 1.01189 to 0.98124, saving model to checkpoints\\config_10_arch_128_128_64_32_16.h5\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6500 - mae: 0.7112 - val_loss: 0.9812 - val_mae: 0.7811 - lr: 5.0000e-04\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7299 - mae: 0.7119\n",
      "Epoch 28: val_loss improved from 0.98124 to 0.94941, saving model to checkpoints\\config_10_arch_128_128_64_32_16.h5\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.7299 - mae: 0.7119 - val_loss: 0.9494 - val_mae: 0.7667 - lr: 5.0000e-04\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8929 - mae: 0.8134\n",
      "Epoch 29: val_loss improved from 0.94941 to 0.92215, saving model to checkpoints\\config_10_arch_128_128_64_32_16.h5\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.8929 - mae: 0.8134 - val_loss: 0.9221 - val_mae: 0.7540 - lr: 5.0000e-04\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8959 - mae: 0.8017\n",
      "Epoch 30: val_loss improved from 0.92215 to 0.89639, saving model to checkpoints\\config_10_arch_128_128_64_32_16.h5\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.8959 - mae: 0.8017 - val_loss: 0.8964 - val_mae: 0.7418 - lr: 5.0000e-04\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8250 - mae: 0.7110\n",
      "Epoch 31: val_loss improved from 0.89639 to 0.87204, saving model to checkpoints\\config_10_arch_128_128_64_32_16.h5\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.8250 - mae: 0.7110 - val_loss: 0.8720 - val_mae: 0.7302 - lr: 5.0000e-04\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7452 - mae: 0.7287\n",
      "Epoch 32: val_loss improved from 0.87204 to 0.84922, saving model to checkpoints\\config_10_arch_128_128_64_32_16.h5\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.7452 - mae: 0.7287 - val_loss: 0.8492 - val_mae: 0.7191 - lr: 5.0000e-04\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7351 - mae: 0.7354\n",
      "Epoch 33: val_loss improved from 0.84922 to 0.82619, saving model to checkpoints\\config_10_arch_128_128_64_32_16.h5\n",
      "1/1 [==============================] - 1s 700ms/step - loss: 0.7351 - mae: 0.7354 - val_loss: 0.8262 - val_mae: 0.7079 - lr: 5.0000e-04\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6584 - mae: 0.7068\n",
      "Epoch 34: val_loss improved from 0.82619 to 0.80430, saving model to checkpoints\\config_10_arch_128_128_64_32_16.h5\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6584 - mae: 0.7068 - val_loss: 0.8043 - val_mae: 0.6972 - lr: 5.0000e-04\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7073 - mae: 0.7244\n",
      "Epoch 35: val_loss improved from 0.80430 to 0.78012, saving model to checkpoints\\config_10_arch_128_128_64_32_16.h5\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7073 - mae: 0.7244 - val_loss: 0.7801 - val_mae: 0.6852 - lr: 5.0000e-04\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5768 - mae: 0.6448\n",
      "Epoch 36: val_loss improved from 0.78012 to 0.75495, saving model to checkpoints\\config_10_arch_128_128_64_32_16.h5\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5768 - mae: 0.6448 - val_loss: 0.7549 - val_mae: 0.6725 - lr: 5.0000e-04\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5414 - mae: 0.6471\n",
      "Epoch 37: val_loss improved from 0.75495 to 0.72763, saving model to checkpoints\\config_10_arch_128_128_64_32_16.h5\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5414 - mae: 0.6471 - val_loss: 0.7276 - val_mae: 0.6584 - lr: 5.0000e-04\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7162 - mae: 0.6573\n",
      "Epoch 38: val_loss improved from 0.72763 to 0.70003, saving model to checkpoints\\config_10_arch_128_128_64_32_16.h5\n",
      "1/1 [==============================] - 1s 731ms/step - loss: 0.7162 - mae: 0.6573 - val_loss: 0.7000 - val_mae: 0.6439 - lr: 5.0000e-04\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7519 - mae: 0.6467\n",
      "Epoch 39: val_loss improved from 0.70003 to 0.67030, saving model to checkpoints\\config_10_arch_128_128_64_32_16.h5\n",
      "1/1 [==============================] - 1s 647ms/step - loss: 0.7519 - mae: 0.6467 - val_loss: 0.6703 - val_mae: 0.6281 - lr: 5.0000e-04\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7521 - mae: 0.7185\n",
      "Epoch 40: val_loss improved from 0.67030 to 0.64103, saving model to checkpoints\\config_10_arch_128_128_64_32_16.h5\n",
      "1/1 [==============================] - 1s 783ms/step - loss: 0.7521 - mae: 0.7185 - val_loss: 0.6410 - val_mae: 0.6119 - lr: 5.0000e-04\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3718 - mae: 0.5268\n",
      "Epoch 41: val_loss improved from 0.64103 to 0.61166, saving model to checkpoints\\config_10_arch_128_128_64_32_16.h5\n",
      "1/1 [==============================] - 1s 592ms/step - loss: 0.3718 - mae: 0.5268 - val_loss: 0.6117 - val_mae: 0.5951 - lr: 5.0000e-04\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3254 - mae: 0.5038\n",
      "Epoch 42: val_loss improved from 0.61166 to 0.58096, saving model to checkpoints\\config_10_arch_128_128_64_32_16.h5\n",
      "1/1 [==============================] - 0s 287ms/step - loss: 0.3254 - mae: 0.5038 - val_loss: 0.5810 - val_mae: 0.5772 - lr: 5.0000e-04\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2683 - mae: 0.4553\n",
      "Epoch 43: val_loss improved from 0.58096 to 0.55034, saving model to checkpoints\\config_10_arch_128_128_64_32_16.h5\n",
      "1/1 [==============================] - 1s 503ms/step - loss: 0.2683 - mae: 0.4553 - val_loss: 0.5503 - val_mae: 0.5588 - lr: 5.0000e-04\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2462 - mae: 0.3961\n",
      "Epoch 44: val_loss improved from 0.55034 to 0.51925, saving model to checkpoints\\config_10_arch_128_128_64_32_16.h5\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.2462 - mae: 0.3961 - val_loss: 0.5192 - val_mae: 0.5397 - lr: 5.0000e-04\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5727 - mae: 0.6055\n",
      "Epoch 45: val_loss improved from 0.51925 to 0.49230, saving model to checkpoints\\config_10_arch_128_128_64_32_16.h5\n",
      "1/1 [==============================] - 0s 289ms/step - loss: 0.5727 - mae: 0.6055 - val_loss: 0.4923 - val_mae: 0.5226 - lr: 5.0000e-04\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4554 - mae: 0.5846\n",
      "Epoch 46: val_loss improved from 0.49230 to 0.46317, saving model to checkpoints\\config_10_arch_128_128_64_32_16.h5\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.4554 - mae: 0.5846 - val_loss: 0.4632 - val_mae: 0.5036 - lr: 5.0000e-04\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3722 - mae: 0.4569\n",
      "Epoch 47: val_loss improved from 0.46317 to 0.43360, saving model to checkpoints\\config_10_arch_128_128_64_32_16.h5\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.3722 - mae: 0.4569 - val_loss: 0.4336 - val_mae: 0.4836 - lr: 5.0000e-04\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3611 - mae: 0.5228\n",
      "Epoch 48: val_loss improved from 0.43360 to 0.40385, saving model to checkpoints\\config_10_arch_128_128_64_32_16.h5\n",
      "1/1 [==============================] - 0s 291ms/step - loss: 0.3611 - mae: 0.5228 - val_loss: 0.4039 - val_mae: 0.4627 - lr: 5.0000e-04\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5730 - mae: 0.5982\n",
      "Epoch 49: val_loss improved from 0.40385 to 0.37637, saving model to checkpoints\\config_10_arch_128_128_64_32_16.h5\n",
      "1/1 [==============================] - 0s 288ms/step - loss: 0.5730 - mae: 0.5982 - val_loss: 0.3764 - val_mae: 0.4426 - lr: 5.0000e-04\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4486 - mae: 0.4712\n",
      "Epoch 50: val_loss improved from 0.37637 to 0.34916, saving model to checkpoints\\config_10_arch_128_128_64_32_16.h5\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 0.4486 - mae: 0.4712 - val_loss: 0.3492 - val_mae: 0.4220 - lr: 5.0000e-04\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3394 - mae: 0.3913\n",
      "Epoch 51: val_loss improved from 0.34916 to 0.32454, saving model to checkpoints\\config_10_arch_128_128_64_32_16.h5\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 0.3394 - mae: 0.3913 - val_loss: 0.3245 - val_mae: 0.4030 - lr: 5.0000e-04\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3860 - mae: 0.4829\n",
      "Epoch 52: val_loss improved from 0.32454 to 0.30133, saving model to checkpoints\\config_10_arch_128_128_64_32_16.h5\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 0.3860 - mae: 0.4829 - val_loss: 0.3013 - val_mae: 0.3926 - lr: 5.0000e-04\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7129 - mae: 0.6461\n",
      "Epoch 53: val_loss improved from 0.30133 to 0.28025, saving model to checkpoints\\config_10_arch_128_128_64_32_16.h5\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.7129 - mae: 0.6461 - val_loss: 0.2802 - val_mae: 0.3828 - lr: 5.0000e-04\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4481 - mae: 0.5095\n",
      "Epoch 54: val_loss improved from 0.28025 to 0.26073, saving model to checkpoints\\config_10_arch_128_128_64_32_16.h5\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.4481 - mae: 0.5095 - val_loss: 0.2607 - val_mae: 0.3734 - lr: 5.0000e-04\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4030 - mae: 0.5016\n",
      "Epoch 55: val_loss improved from 0.26073 to 0.24662, saving model to checkpoints\\config_10_arch_128_128_64_32_16.h5\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.4030 - mae: 0.5016 - val_loss: 0.2466 - val_mae: 0.3663 - lr: 5.0000e-04\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3088 - mae: 0.4669\n",
      "Epoch 56: val_loss improved from 0.24662 to 0.23577, saving model to checkpoints\\config_10_arch_128_128_64_32_16.h5\n",
      "1/1 [==============================] - 1s 635ms/step - loss: 0.3088 - mae: 0.4669 - val_loss: 0.2358 - val_mae: 0.3607 - lr: 5.0000e-04\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4032 - mae: 0.4888\n",
      "Epoch 57: val_loss improved from 0.23577 to 0.22527, saving model to checkpoints\\config_10_arch_128_128_64_32_16.h5\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.4032 - mae: 0.4888 - val_loss: 0.2253 - val_mae: 0.3552 - lr: 5.0000e-04\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4459 - mae: 0.5525\n",
      "Epoch 58: val_loss improved from 0.22527 to 0.21329, saving model to checkpoints\\config_10_arch_128_128_64_32_16.h5\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.4459 - mae: 0.5525 - val_loss: 0.2133 - val_mae: 0.3487 - lr: 5.0000e-04\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2677 - mae: 0.4401\n",
      "Epoch 59: val_loss improved from 0.21329 to 0.20526, saving model to checkpoints\\config_10_arch_128_128_64_32_16.h5\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.2677 - mae: 0.4401 - val_loss: 0.2053 - val_mae: 0.3442 - lr: 5.0000e-04\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2956 - mae: 0.4099\n",
      "Epoch 60: val_loss improved from 0.20526 to 0.19727, saving model to checkpoints\\config_10_arch_128_128_64_32_16.h5\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.2956 - mae: 0.4099 - val_loss: 0.1973 - val_mae: 0.3397 - lr: 5.0000e-04\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1297 - mae: 0.3311\n",
      "Epoch 61: val_loss improved from 0.19727 to 0.19075, saving model to checkpoints\\config_10_arch_128_128_64_32_16.h5\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.1297 - mae: 0.3311 - val_loss: 0.1908 - val_mae: 0.3359 - lr: 5.0000e-04\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2043 - mae: 0.4033\n",
      "Epoch 62: val_loss improved from 0.19075 to 0.18397, saving model to checkpoints\\config_10_arch_128_128_64_32_16.h5\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2043 - mae: 0.4033 - val_loss: 0.1840 - val_mae: 0.3318 - lr: 5.0000e-04\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4646 - mae: 0.5628\n",
      "Epoch 63: val_loss improved from 0.18397 to 0.17566, saving model to checkpoints\\config_10_arch_128_128_64_32_16.h5\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.4646 - mae: 0.5628 - val_loss: 0.1757 - val_mae: 0.3267 - lr: 5.0000e-04\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3328 - mae: 0.5175\n",
      "Epoch 64: val_loss improved from 0.17566 to 0.16497, saving model to checkpoints\\config_10_arch_128_128_64_32_16.h5\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.3328 - mae: 0.5175 - val_loss: 0.1650 - val_mae: 0.3198 - lr: 5.0000e-04\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2943 - mae: 0.4733\n",
      "Epoch 65: val_loss improved from 0.16497 to 0.15826, saving model to checkpoints\\config_10_arch_128_128_64_32_16.h5\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2943 - mae: 0.4733 - val_loss: 0.1583 - val_mae: 0.3153 - lr: 5.0000e-04\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3138 - mae: 0.4798\n",
      "Epoch 66: val_loss improved from 0.15826 to 0.14915, saving model to checkpoints\\config_10_arch_128_128_64_32_16.h5\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.3138 - mae: 0.4798 - val_loss: 0.1491 - val_mae: 0.3091 - lr: 5.0000e-04\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5210 - mae: 0.6031\n",
      "Epoch 67: val_loss improved from 0.14915 to 0.13924, saving model to checkpoints\\config_10_arch_128_128_64_32_16.h5\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.5210 - mae: 0.6031 - val_loss: 0.1392 - val_mae: 0.3023 - lr: 5.0000e-04\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6050 - mae: 0.6105\n",
      "Epoch 68: val_loss improved from 0.13924 to 0.13570, saving model to checkpoints\\config_10_arch_128_128_64_32_16.h5\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6050 - mae: 0.6105 - val_loss: 0.1357 - val_mae: 0.2998 - lr: 5.0000e-04\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1285 - mae: 0.2921\n",
      "Epoch 69: val_loss did not improve from 0.13570\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1285 - mae: 0.2921 - val_loss: 0.1366 - val_mae: 0.3004 - lr: 5.0000e-04\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4907 - mae: 0.6320\n",
      "Epoch 70: val_loss did not improve from 0.13570\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4907 - mae: 0.6320 - val_loss: 0.1376 - val_mae: 0.3012 - lr: 5.0000e-04\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0922 - mae: 0.2520\n",
      "Epoch 71: val_loss did not improve from 0.13570\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0922 - mae: 0.2520 - val_loss: 0.1368 - val_mae: 0.3005 - lr: 5.0000e-04\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4684 - mae: 0.5016\n",
      "Epoch 72: val_loss improved from 0.13570 to 0.13528, saving model to checkpoints\\config_10_arch_128_128_64_32_16.h5\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4684 - mae: 0.5016 - val_loss: 0.1353 - val_mae: 0.2994 - lr: 5.0000e-04\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1805 - mae: 0.3459\n",
      "Epoch 73: val_loss improved from 0.13528 to 0.13317, saving model to checkpoints\\config_10_arch_128_128_64_32_16.h5\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.1805 - mae: 0.3459 - val_loss: 0.1332 - val_mae: 0.2978 - lr: 5.0000e-04\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1414 - mae: 0.2952\n",
      "Epoch 74: val_loss improved from 0.13317 to 0.13027, saving model to checkpoints\\config_10_arch_128_128_64_32_16.h5\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.1414 - mae: 0.2952 - val_loss: 0.1303 - val_mae: 0.2957 - lr: 5.0000e-04\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5436 - mae: 0.4998\n",
      "Epoch 75: val_loss did not improve from 0.13027\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5436 - mae: 0.4998 - val_loss: 0.1364 - val_mae: 0.3001 - lr: 5.0000e-04\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0866 - mae: 0.8009\n",
      "Epoch 76: val_loss did not improve from 0.13027\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.0866 - mae: 0.8009 - val_loss: 0.1529 - val_mae: 0.3113 - lr: 5.0000e-04\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4475 - mae: 0.4771\n",
      "Epoch 77: val_loss did not improve from 0.13027\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4475 - mae: 0.4771 - val_loss: 0.1722 - val_mae: 0.3237 - lr: 5.0000e-04\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2745 - mae: 0.4609\n",
      "Epoch 78: val_loss did not improve from 0.13027\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.2745 - mae: 0.4609 - val_loss: 0.1948 - val_mae: 0.3371 - lr: 5.0000e-04\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3300 - mae: 0.5016\n",
      "Epoch 79: val_loss did not improve from 0.13027\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3300 - mae: 0.5016 - val_loss: 0.2139 - val_mae: 0.3477 - lr: 5.0000e-04\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4565 - mae: 0.5387\n",
      "Epoch 80: val_loss did not improve from 0.13027\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.4565 - mae: 0.5387 - val_loss: 0.2293 - val_mae: 0.3558 - lr: 5.0000e-04\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2529 - mae: 0.3470\n",
      "Epoch 81: val_loss did not improve from 0.13027\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2529 - mae: 0.3470 - val_loss: 0.2397 - val_mae: 0.3612 - lr: 5.0000e-04\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2061 - mae: 0.3746\n",
      "Epoch 82: val_loss did not improve from 0.13027\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2061 - mae: 0.3746 - val_loss: 0.2486 - val_mae: 0.3657 - lr: 5.0000e-04\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2229 - mae: 0.3520\n",
      "Epoch 83: val_loss did not improve from 0.13027\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2229 - mae: 0.3520 - val_loss: 0.2572 - val_mae: 0.3699 - lr: 5.0000e-04\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5151 - mae: 0.4923\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.13027\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5151 - mae: 0.4923 - val_loss: 0.2668 - val_mae: 0.3744 - lr: 5.0000e-04\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3051 - mae: 0.4152\n",
      "Epoch 85: val_loss did not improve from 0.13027\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3051 - mae: 0.4152 - val_loss: 0.2706 - val_mae: 0.3761 - lr: 2.5000e-04\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3640 - mae: 0.4643\n",
      "Epoch 86: val_loss did not improve from 0.13027\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.3640 - mae: 0.4643 - val_loss: 0.2728 - val_mae: 0.3771 - lr: 2.5000e-04\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5717 - mae: 0.5739\n",
      "Epoch 87: val_loss did not improve from 0.13027\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5717 - mae: 0.5739 - val_loss: 0.2752 - val_mae: 0.3782 - lr: 2.5000e-04\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3520 - mae: 0.4580\n",
      "Epoch 88: val_loss did not improve from 0.13027\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3520 - mae: 0.4580 - val_loss: 0.2764 - val_mae: 0.3787 - lr: 2.5000e-04\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4065 - mae: 0.5143\n",
      "Epoch 89: val_loss did not improve from 0.13027\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4065 - mae: 0.5143 - val_loss: 0.2765 - val_mae: 0.3787 - lr: 2.5000e-04\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2915 - mae: 0.4094\n",
      "Epoch 90: val_loss did not improve from 0.13027\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2915 - mae: 0.4094 - val_loss: 0.2749 - val_mae: 0.3780 - lr: 2.5000e-04\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1668 - mae: 0.3767\n",
      "Epoch 91: val_loss did not improve from 0.13027\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1668 - mae: 0.3767 - val_loss: 0.2735 - val_mae: 0.3774 - lr: 2.5000e-04\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3759 - mae: 0.5176\n",
      "Epoch 92: val_loss did not improve from 0.13027\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.3759 - mae: 0.5176 - val_loss: 0.2711 - val_mae: 0.3763 - lr: 2.5000e-04\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3048 - mae: 0.4019\n",
      "Epoch 93: val_loss did not improve from 0.13027\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.3048 - mae: 0.4019 - val_loss: 0.2691 - val_mae: 0.3755 - lr: 2.5000e-04\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3746 - mae: 0.4972Restoring model weights from the end of the best epoch: 74.\n",
      "\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 94: val_loss did not improve from 0.13027\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.3746 - mae: 0.4972 - val_loss: 0.2660 - val_mae: 0.3741 - lr: 2.5000e-04\n",
      "Epoch 94: early stopping\n",
      "\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "RESULTATS CONFIG 10:\n",
      "  MAPE: 1.80%\n",
      "  RMSE: 0.531\n",
      "  MAE: 0.435\n",
      "  R²: 0.767\n",
      "  Èpoques entrenades: 94\n",
      "  Checkpoint guardat a: checkpoints/config_10_arch_128_128_64_32_16.keras\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "\n",
      "======================================================================\n",
      "MILLOR CONFIGURACIÓ TROBADA\n",
      "======================================================================\n",
      "Config ID: 4\n",
      "Arquitectura: [128, 64, 32]\n",
      "Learning rate: 0.0005\n",
      "Dropout rate: 0.2\n",
      "\n",
      "MÈTRIQUES:\n",
      "  MAPE: 0.50%\n",
      "  RMSE: 0.122\n",
      "  MAE: 0.114\n",
      "  R²: 0.988\n",
      "\n",
      "Checkpoint: checkpoints/config_4_arch_128_64_32.h5\n",
      "======================================================================\n",
      "\n",
      "✓ Resultats guardats a 'checkpoints/resultats_gridsearch.json'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Crear directori per guardar checkpoints\n",
    "os.makedirs('checkpoints', exist_ok=True)\n",
    "\n",
    "def gridsearch_amb_checkpoints(X_train, y_train, X_val, y_val, configuracions):\n",
    "    \"\"\"\n",
    "    Cerca manual de la millor configuració d'hiperparàmetres amb checkpoints.\n",
    "    \n",
    "    Paràmetres:\n",
    "    -----------\n",
    "    configuracions : list of dict\n",
    "        Llista de diccionaris amb diferents configuracions a provar\n",
    "        Cada config ha de tenir: 'arquitectura', 'learning_rate', 'dropout_rate'\n",
    "    \n",
    "    Retorna:\n",
    "    --------\n",
    "    millor_config : dict\n",
    "        Millor configuració trobada\n",
    "    resultats : list\n",
    "        Resultats de totes les configuracions\n",
    "    \"\"\"\n",
    "    resultats = []\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"INICI DEL GRIDSEARCH\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    for i, config in enumerate(configuracions):\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"CONFIGURACIÓ {i+1}/{len(configuracions)}\")\n",
    "        print(f\"{'='*70}\")\n",
    "        print(f\"Arquitectura: {config['arquitectura']}\")\n",
    "        print(f\"Learning rate: {config['learning_rate']}\")\n",
    "        print(f\"Dropout rate: {config['dropout_rate']}\")\n",
    "        print(f\"Batch size: {config.get('batch_size', 16)}\")\n",
    "        \n",
    "        # Crear nom únic per aquesta configuració\n",
    "        config_name = f\"config_{i+1}_arch_{'_'.join(map(str, config['arquitectura']))}\"\n",
    "        checkpoint_path = f\"checkpoints/{config_name}.keras\"\n",
    "        \n",
    "        # Crear i entrenar model\n",
    "        model_temp = crear_model(\n",
    "            n_features, \n",
    "            arquitectura=config['arquitectura'],\n",
    "            learning_rate=config['learning_rate'],\n",
    "            dropout_rate=config['dropout_rate']\n",
    "        )\n",
    "        \n",
    "        # Callbacks per aquest entrenament\n",
    "        callbacks_temp = [\n",
    "            EarlyStopping(\n",
    "                monitor='val_loss', \n",
    "                patience=20, \n",
    "                restore_best_weights=True, \n",
    "                verbose=1\n",
    "            ),\n",
    "            ReduceLROnPlateau(\n",
    "                monitor='val_loss',\n",
    "                factor=0.5,\n",
    "                patience=10,\n",
    "                min_lr=1e-7,\n",
    "                verbose=1\n",
    "            ),\n",
    "            # Guardar el millor model d'aquesta configuració (format .h5 per compatibilitat)\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                checkpoint_path.replace('.keras', '.h5'),\n",
    "                monitor='val_loss',\n",
    "                save_best_only=True,\n",
    "                verbose=1\n",
    "            )\n",
    "        ]\n",
    "        \n",
    "        # Entrenar\n",
    "        history_temp = model_temp.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=200,\n",
    "            batch_size=config.get('batch_size', 16),\n",
    "            callbacks=callbacks_temp,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        # Carregar el millor model guardat\n",
    "        checkpoint_path_h5 = checkpoint_path.replace('.keras', '.h5')\n",
    "        model_temp = keras.models.load_model(checkpoint_path_h5)\n",
    "        \n",
    "        # Avaluar amb el conjunt de validació\n",
    "        y_pred_temp = model_temp.predict(X_val, verbose=0).flatten()\n",
    "        \n",
    "        # Desnormalitzar per calcular mètriques reals\n",
    "        y_pred_real = scaler_y.inverse_transform(y_pred_temp.reshape(-1, 1)).flatten()\n",
    "        y_val_real = scaler_y.inverse_transform(y_val.reshape(-1, 1)).flatten()\n",
    "        \n",
    "        # Calcular mètriques\n",
    "        mape_temp = mean_absolute_percentage_error(y_val_real, y_pred_real)\n",
    "        rmse_temp = np.sqrt(mean_squared_error(y_val_real, y_pred_real))\n",
    "        mae_temp = np.mean(np.abs(y_val_real - y_pred_real))\n",
    "        r2_temp = r2_score(y_val_real, y_pred_real)\n",
    "        \n",
    "        # Guardar resultats\n",
    "        resultat = {\n",
    "            'config_id': i + 1,\n",
    "            'config': config,\n",
    "            'checkpoint_path': checkpoint_path.replace('.keras', '.h5'),\n",
    "            'mape': mape_temp,\n",
    "            'rmse': rmse_temp,\n",
    "            'mae': mae_temp,\n",
    "            'r2': r2_temp,\n",
    "            'val_loss_final': min(history_temp.history['val_loss']),\n",
    "            'epochs_entrenats': len(history_temp.history['loss'])\n",
    "        }\n",
    "        resultats.append(resultat)\n",
    "        \n",
    "        print(f\"\\n{'─'*70}\")\n",
    "        print(f\"RESULTATS CONFIG {i+1}:\")\n",
    "        print(f\"  MAPE: {mape_temp*100:.2f}%\")\n",
    "        print(f\"  RMSE: {rmse_temp:.3f}\")\n",
    "        print(f\"  MAE: {mae_temp:.3f}\")\n",
    "        print(f\"  R²: {r2_temp:.3f}\")\n",
    "        print(f\"  Èpoques entrenades: {len(history_temp.history['loss'])}\")\n",
    "        print(f\"  Checkpoint guardat a: {checkpoint_path}\")\n",
    "        print(f\"{'─'*70}\")\n",
    "    \n",
    "    # Trobar la millor configuració (menor MAPE)\n",
    "    millor = min(resultats, key=lambda x: x['mape'])\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"MILLOR CONFIGURACIÓ TROBADA\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"Config ID: {millor['config_id']}\")\n",
    "    print(f\"Arquitectura: {millor['config']['arquitectura']}\")\n",
    "    print(f\"Learning rate: {millor['config']['learning_rate']}\")\n",
    "    print(f\"Dropout rate: {millor['config']['dropout_rate']}\")\n",
    "    print(f\"\\nMÈTRIQUES:\")\n",
    "    print(f\"  MAPE: {millor['mape']*100:.2f}%\")\n",
    "    print(f\"  RMSE: {millor['rmse']:.3f}\")\n",
    "    print(f\"  MAE: {millor['mae']:.3f}\")\n",
    "    print(f\"  R²: {millor['r2']:.3f}\")\n",
    "    print(f\"\\nCheckpoint: {millor['checkpoint_path']}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    # Guardar tots els resultats en un JSON\n",
    "    with open('checkpoints/resultats_gridsearch.json', 'w') as f:\n",
    "        # Convertir a format serialitzable\n",
    "        resultats_serialitzable = []\n",
    "        for r in resultats:\n",
    "            r_copy = r.copy()\n",
    "            for key in ['mape', 'rmse', 'mae', 'r2', 'val_loss_final']:\n",
    "                r_copy[key] = float(r_copy[key])\n",
    "            resultats_serialitzable.append(r_copy)\n",
    "        \n",
    "        json.dump({\n",
    "            'data_execucio': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            'millor_config_id': millor['config_id'],\n",
    "            'resultats': resultats_serialitzable\n",
    "        }, f, indent=2)\n",
    "    \n",
    "    print(\"✓ Resultats guardats a 'checkpoints/resultats_gridsearch.json'\\n\")\n",
    "    \n",
    "    return millor, resultats\n",
    "\n",
    "\n",
    "# Definir les configuracions a provar\n",
    "configuracions = [\n",
    "    # Configuracions simples (poques capes, poques neurones)\n",
    "    {\n",
    "        'arquitectura': [32, 16],\n",
    "        'learning_rate': 0.001,\n",
    "        'dropout_rate': 0.1,\n",
    "        'batch_size': 16\n",
    "    },\n",
    "    {\n",
    "        'arquitectura': [64, 32],\n",
    "        'learning_rate': 0.001,\n",
    "        'dropout_rate': 0.2,\n",
    "        'batch_size': 16\n",
    "    },\n",
    "    \n",
    "    # Configuracions mitjanes\n",
    "    {\n",
    "        'arquitectura': [64, 32, 16],\n",
    "        'learning_rate': 0.001,\n",
    "        'dropout_rate': 0.2,\n",
    "        'batch_size': 16\n",
    "    },\n",
    "    {\n",
    "        'arquitectura': [128, 64, 32],\n",
    "        'learning_rate': 0.0005,\n",
    "        'dropout_rate': 0.2,\n",
    "        'batch_size': 16\n",
    "    },\n",
    "    \n",
    "    # Configuracions més complexes\n",
    "    {\n",
    "        'arquitectura': [128, 64, 32, 16],\n",
    "        'learning_rate': 0.001,\n",
    "        'dropout_rate': 0.3,\n",
    "        'batch_size': 16\n",
    "    },\n",
    "    {\n",
    "        'arquitectura': [64, 128, 64, 32],\n",
    "        'learning_rate': 0.0005,\n",
    "        'dropout_rate': 0.25,\n",
    "        'batch_size': 16\n",
    "    },\n",
    "    \n",
    "    # Provar amb learning rates diferents\n",
    "    {\n",
    "        'arquitectura': [64, 32, 16],\n",
    "        'learning_rate': 0.01,\n",
    "        'dropout_rate': 0.2,\n",
    "        'batch_size': 16\n",
    "    },\n",
    "    {\n",
    "        'arquitectura': [64, 32, 16],\n",
    "        'learning_rate': 0.0001,\n",
    "        'dropout_rate': 0.2,\n",
    "        'batch_size': 16\n",
    "    },\n",
    "    \n",
    "    # Provar amb dropouts diferents\n",
    "    {\n",
    "        'arquitectura': [64, 32, 16],\n",
    "        'learning_rate': 0.001,\n",
    "        'dropout_rate': 0.4,\n",
    "        'batch_size': 16\n",
    "    },\n",
    "    \n",
    "    # Provar arquitectures més profundes\n",
    "    {\n",
    "        'arquitectura': [128, 128, 64, 32, 16],\n",
    "        'learning_rate': 0.0005,\n",
    "        'dropout_rate': 0.3,\n",
    "        'batch_size': 16\n",
    "    },\n",
    "]\n",
    "\n",
    "print(f\"\\nS'executarà GridSearch amb {len(configuracions)} configuracions diferents\\n\")\n",
    "\n",
    "# EXECUTAR GRIDSEARCH\n",
    "millor_config, tots_resultats = gridsearch_amb_checkpoints(\n",
    "    X_train_scaled, y_train_scaled, \n",
    "    X_val_scaled, y_val_scaled,\n",
    "    configuracions\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10984e0c",
   "metadata": {},
   "source": [
    "## 7. CARREGAR I AVALUAR EL MILLOR MODEL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81328889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== CARREGANT EL MILLOR MODEL ===\n",
      "Checkpoint: checkpoints/config_4_arch_128_64_32.h5\n",
      "\n",
      "=== ARQUITECTURA DEL MILLOR MODEL ===\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " hidden_1 (Dense)            (None, 128)               1024      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " hidden_2 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " hidden_3 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11393 (44.50 KB)\n",
      "Trainable params: 11393 (44.50 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "\n",
      "=== ENTRENAMENT FINAL AMB LA MILLOR CONFIGURACIÓ ===\n",
      "(Això és només per generar gràfics d'entrenament)\n",
      "\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 0s 461ms/step - loss: 0.2250 - mae: 0.4065 - val_loss: 0.0070 - val_mae: 0.0802 - lr: 5.0000e-04\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.1847 - mae: 0.3811 - val_loss: 0.0076 - val_mae: 0.0858 - lr: 5.0000e-04\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2798 - mae: 0.3931 - val_loss: 0.0090 - val_mae: 0.0950 - lr: 5.0000e-04\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0731 - mae: 0.2176 - val_loss: 0.0109 - val_mae: 0.1034 - lr: 5.0000e-04\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.1716 - mae: 0.2486 - val_loss: 0.0130 - val_mae: 0.1108 - lr: 5.0000e-04\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2416 - mae: 0.3368 - val_loss: 0.0143 - val_mae: 0.1151 - lr: 5.0000e-04\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.1767 - mae: 0.3413 - val_loss: 0.0158 - val_mae: 0.1194 - lr: 5.0000e-04\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0222 - mae: 0.1275 - val_loss: 0.0170 - val_mae: 0.1224 - lr: 5.0000e-04\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.1379 - mae: 0.2940 - val_loss: 0.0194 - val_mae: 0.1282 - lr: 5.0000e-04\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0397 - mae: 0.1736 - val_loss: 0.0209 - val_mae: 0.1317 - lr: 5.0000e-04\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1204 - mae: 0.2315\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1204 - mae: 0.2315 - val_loss: 0.0221 - val_mae: 0.1346 - lr: 5.0000e-04\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0757 - mae: 0.2173 - val_loss: 0.0227 - val_mae: 0.1357 - lr: 2.5000e-04\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.1028 - mae: 0.2677 - val_loss: 0.0231 - val_mae: 0.1367 - lr: 2.5000e-04\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1481 - mae: 0.2997 - val_loss: 0.0226 - val_mae: 0.1356 - lr: 2.5000e-04\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0829 - mae: 0.2295 - val_loss: 0.0216 - val_mae: 0.1337 - lr: 2.5000e-04\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.1653 - mae: 0.3007 - val_loss: 0.0211 - val_mae: 0.1325 - lr: 2.5000e-04\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0825 - mae: 0.2080 - val_loss: 0.0208 - val_mae: 0.1319 - lr: 2.5000e-04\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0393 - mae: 0.1617 - val_loss: 0.0210 - val_mae: 0.1324 - lr: 2.5000e-04\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1129 - mae: 0.3006 - val_loss: 0.0207 - val_mae: 0.1319 - lr: 2.5000e-04\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0667 - mae: 0.2364 - val_loss: 0.0201 - val_mae: 0.1305 - lr: 2.5000e-04\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0722 - mae: 0.2015Restoring model weights from the end of the best epoch: 1.\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0722 - mae: 0.2015 - val_loss: 0.0193 - val_mae: 0.1289 - lr: 2.5000e-04\n",
      "Epoch 21: early stopping\n",
      "\n",
      "=== ENTRENAMENT COMPLETAT ===\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABW4AAAHqCAYAAACUWtfDAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOzdBXhcZdYH8NO4uzdaTequlBo1rMACRQtL0WJdlmWRZdEPWdwdihaHIoUaVWq0TT1NJY007u7J95x35t65k0zSyMi9M//f8wQmyWRmepNM3jn3vP/Tp7W1tZUAAAAAAAAAAAAAQDWcbP0AAAAAAAAAAAAAAMAYCrcAAAAAAAAAAAAAKoPCLQAAAAAAAAAAAIDKoHALAAAAAAAAAAAAoDIo3AIAAAAAAAAAAACoDAq3AAAAAAAAAAAAACqDwi0AAAAAAAAAAACAyqBwCwAAAAAAAAAAAKAyKNwCANiRe+65h/r27UtZWVm2figAAAAA0A1YxwEAQFso3AKAXVm+fDn16dOnw7eNGzda7L7j4+Pp+uuvt9jtP/roo+Lf0JEffviBPvzwQ/rtt98oJibGYvfTGf7383HoyvV8fHx6dB8AAABgn7CO0846ju/D19eXqqqq2n0+IyODnJycxHX48WhBUVERubu7i8e8e/duk9eZMWMGDRs2zKqPKz09XTwm/t3oiaeeeop+/PFHsz8uPhYdvd7qys8QAHSdSzeuCwCgGR999BElJia2+/iQIUNIq2688UaaP3++yc+lpaXRLbfcQt999x2NGDHC6o8NAAAAwFywjlM/V1dXampqoq+++oqWLFnS7vvHRd2KigrSik8//ZQaGhrE5Q8++IDGjRtH9oALt5deeilddNFFZr/tfv360eeff97u41wABwDzQeEWAOwSnw23lwWXJDo6Wrx1tHAqKCiw+mMCAAAAMDes49TPzc2NLrjgArHbS1m4bW1tFd2hixYtovfee4+0gv8dYWFhFBcXRytWrKAXX3yRPD09bf2wVI2Pz6RJk7r9dbW1teTh4WGyM7ympoa8vLx6/Jiam5vFCQUUj8GeICoBABzS6NGjadq0aSb/2HNG7CWXXCJ/rKSkhJYuXSo+zotULpI+9NBDVF9f36XtfrzFSYnjGkzFNvz+++80e/Zs8vf3FwuWpKQkevrppzvd+tbS0kL/+9//RHcxL1B4wbl48WI6ffp0l47Dr7/+SqNGjRJfm5CQQM8//7zJ6/Ei/M033xTX5UVaYGCgOHvPnb6WXkSPHDlSLO6CgoLo4osvppSUFKPr8GO44oorKCoqSvw7wsPDxXHct2+ffJ0//vhDbOkKDg4Wjz82Npb+9re/icUhAAAAaAvWcepYx91www20bds2Sk1NlT+2bt06EZXw97//3eTX5OXliV1i3IzA62p+3I899pgotinxxyZOnCjWf35+fjRmzBjRCcv/FiXeln/++eeLdTRfh/99vC7mNWRX7dy5kw4dOkTXXnst3XTTTVReXi52sXVky5YtomDJ98WvDx5++GHxGkLprbfeEmtYjgbj7mN+TA8++KDRdfg+Fy5cKL4fvNbl78/HH3/c40iLtq8V+HJ1dbW4TSnGgNfD3f1e9Ib0emjNmjXi5yU0NFS8zuHXUVL0xObNm2nKlCni43wdlpmZSddcc414bcM/3/y66IUXXhCvfdrGSPBroSeffFI8fr7uhg0bzPb4AdQAHbcAYJeks61K/Ifd2dlZXObF5N13303Hjx+ngQMHytfhRUVOTo682Kyrq6OZM2fSyZMnxUKGYwh4scYFVS4M8oLZHHghygvF6dOn09tvvy0WKceOHRMLus7cdttt9O6779Idd9whFq28gOHFIxeF9+7dSyEhIR1+7fr168VicfLkyfTll1+KY8YLn/z8/HbX5UUdL7zuuusuevbZZ0Ux+/HHHxeLrP3794tiqbnxMeYF7pVXXikuFxcXiwUpP96//vpL/r6de+658mPngixnlPGLiLKyMvF5PibnnXeeKNTzIj4gIICys7PFAp+3xPXmrD4AAACYH9Zx2ljHnXPOOaJDlddXfLvSmvbss882Wl8rC4UTJkwQ+bf//e9/qX///rR9+3ZRdOP1GkcsSPh9fty8tmM7duygO++8U6zh+GuV+N/wz3/+k+6//37xb3n//fdFF/CAAQPEYzkTfsyMi4acL7xs2TLxMS4cmvo3cMMA3xcfQ34twI+/tLSUXn/9dXEd/n5w0wc/Xi6m87/3xIkTdOTIEfl2uNjNx5/X/K+++qpoLvjss89EUZa/h/fddx/1Fh/bWbNmidcy/PqAcRG8u9+Lzpgq8vJt8psSH1tej3MkBReTOWqD5ebmiuPM/16OdeCvKywsFMeG1+lPPPGEKFL/8ssvdO+994rXZHwSQomP36BBg8Sx5n+fqZ89AE1rBQCwIx999BGfhjf55uzsLF+vqKio1c3NrfXBBx80+vrLL7+8NTw8vLWxsVG8//bbb4uv/frrr42u9+yzz4qPr1mzRv5YXFxc63XXXdfusZw6dcroazds2CA+zv9nlZWVrX5+fq1nnXVWa0tLS4f/tkceeUR8nSQlJUW8v3TpUqPr7dy5U3y87b+trYkTJ7ZGRUW11tbWyh+rqKhoDQoKMrqf7du3i/dfeOEFo6/Pyspq9fT0bL3vvvvkj/G/n4/DmfD1vL29O/x8aWmpuO1zzz3X6OOZmZmt7u7urVdddZX8feTH9vLLL3d4W99++624zr59+874uAAAAMB2sI7T3jqO16cRERFi7VxcXCzWacuXL28tLCwU98ufl9xyyy2tPj4+rRkZGUa39/zzz4vrHj582OT9NTc3i9t//PHHW4ODg43Wy/x4PTw8jG6TjwkfB76/M6murhbr8EmTJhn9+/r06dN64sQJo+tOnz5dPM6VK1caffymm25qdXJykh/DHXfc0RoQENDp/V5xxRXiWPHaVmnBggWtXl5erWVlZeJ9fh3B98m/G2f6PrV9rcD4+6R8fdLb70XbY2HqbcmSJe1+pxcvXtzhbaxfv97o4/fff7/4OP8uKN12223i+5Kammp0bPr379/a0NDQ6eMF0DJEJQCAXfrkk09EV6byjbdBSfisNudy8dYhacsNnylfuXKliBpwcXGRt9h7e3uL7WRKfDZc6nboLe4O5eENfGa+O1OApW1A0mOR8Nlz3k7U2WPjM918TDgSgrdmSXgrFx8XJT7DzY+Lz4bzWXXpLSIiQmwBaxv5YA58xp/zr9r+27gLgjsHpH8bb5/jDoHnnntOZJElJycbbaFivO2Mt3/dfPPN4vtt6XgHAAAA6B2s47SzjuNdatwh+ttvv4lBVbzmuuyyy0xelx8Ld39yvJXysSxYsEB8ftOmTfJ1eQ3OHb0cIcY75rhDkztDeQdW27kOvNaTOnMZHxPuwOTIhjP5+uuvxTpc2qLP+DJHMpjqOuVjfOGFFxp97KqrrhLrT97yL63FeecX7xrj1xa8G6wt/vdxtBevbZV47ctRXrwWtqTufC86wmvwtq+3+E3q7lXiiDJTOCaC1/Ztjw0PlObj2PbY8PeFP6/E3w+pgxfAHqFwCwB2iQuXPJxM+TZ27Fij6/CijLdbrV27VrzPgwg4b0lZLOTFIS9s2xZUeVsTF3f5873F24FYR4PHOiLdd2RkZLvP8SKss8fGRWpeYPK/ra22H+PFOC+SeOsZL4qUb7xtzdRitLe6+m/j7wu/sJk3b57YHsjZZpydxVsBKysr5UUl563x9+z2228X7/PbK6+8YvbHDQAAAL2HdZx21nEclcAFSI5L4DeOEegohoofy88//9zucQwdOlR8Xnosu3btorlz54rLPODszz//FAVBnjHB+OS+EjdktMVZp22vZwpHInChd/78+aLYym8cjcbb8zleom12ralYCemYS98zzsrlY8GFYy5Y8hqU83ql1xzSdTta5ypvy1K6+r3oDB+3tq+3+I1/Jtoy9W/t6OPdPTYd3TaAvUDGLQA4LC728QKAz6bzZf4/L6r4DK9yIcidurzgVRZv+Uw/n5XuLHtM6oBoO8Ss7UKIC42sqwPFlI9NyoZqW/TlnN7OHhuf3eZ/D+dbtdX2Y3w7fF3O9jU1odUSU1uV/7a22v7beHEoZZNxLjB3TnAWLudicV4w43xbfuPF9+7du+m1114T+WW8+OYXGAAAAKAtWMepZx3HzRDc0cvFZB7K1RF+LFwU/b//+z+Tn5cKc5wRy0VE7gpVdhT/+OOPZE68bty6dau4rOzYVVq9erWYpyAxlSEsHXNlAZk7kfmNu6O5E/eRRx4R8yj4PnntytftaJ3LzvQaw9SQ5O4U4bv6vTCXjnYVmvp4d49Nd3YsAmgROm4BwGHxtis+I86LQF7MckFPuU2KcQdBVVVVu4Uib+GTPt8RadrrgQMHjD7+008/Gb3P4fu8DYyLjG0n5XZG2lbEgwyUuCMhJSWl08fG8Q+8/ej7778XA9gk3KXKZ9+VeJHJj4u7k02dVR8+fDiZGw/a4Em9bf9tXNyWtpaZwtvi/vOf/4jHxEM9TH3PuTj/xhtviPdNXQcAAADUD+s49azjLr74YvHG6+hJkyZ1eD1+LDx4l3c+mXosUrGQC3G8s00aKsy4e5YHW5mTdOKfu3o5gkz5tmrVKlE85s5ZJT7GbdfyX3zxhRiqZWoQGq+5OX6Au4W5qeDw4cPi47yW5TWtVIxUvsbgjuXOjiO/xuAmEmURmW+bi8xd7Tzu6vfCFvjY8CC3tut0Pjb8s8ERDwCOBB23AGCXeCFiasopL06kDlfGC0yegsvZVFwoXLRokdH1Oe+Wi3zXXXedmLDKi1s+M89TT/nsO2dvdWT8+PE0ePBgMQGVHwt3uf7www/ymX2Jj48PvfDCC3TjjTeK27vppptEJyhPn+UpudKE2rb4tjm3lbtHebHIi0J+jJwrxXlZ//jHPzo9RjyllbeFzZkzR0zi5W5UPha8wORpw5KpU6eK++GuAS5u86KUr8Nnwvnfwsfktttuo+7i+/v22287XODyv+PBBx8U3wPOCONtUY899pjoMuCuBakofscdd4gsNZ4gy7lqvAjmj/O0X8YFcf4YT7Llbgp+gSMtwjv7/gEAAIBtYB2n/nWcEq/NTK3p2nr88cdFXAA3LXCsFa9leV3G61culPKajXeR8ZqNZxfw+pwfO68Bn3/+ebPu8uK1ORcCOZaD1+CmcF4wF2k51kx6/cDdoHy8MjMzRcMAP24u/PLHpK5dXsvz6wo+9ryNnztyn376adGowa8PGK9lpZxZzu7luQ2cEfzrr7+K+C++bkf49Qp/De8a+9e//iWO4auvvtou1oHx95dzjLmgz4+FM3r5uHf1e9EZLghz3IYpnRWez4R/9vl7wz8H/Di5Q5mPy5tvvimOMx93AIdi6+loAADWmkbMb++99167r5kyZYr43NVXX23yNnlC7q233toaGRnZ6uLiIqa4PvDAA611dXVG1+OPt53aeuzYsda5c+eKabWhoaGtd955Z+uvv/4q7m/Dhg1G1121apWYrsrTX3ma7JAhQ1qfffbZTifF8pRdvs6gQYNaXV1dW0NCQlqvueYaMSm4K3766afWESNGtLq5ubXGxsa2PvPMMybvh3344YdigjE/Pp5CzBNceULs7t27ezSNuKPvkfLr33//ffnx+fv7ty5cuNBoym1+fn7r9ddf35qYmCgeF0/H5eu/9NJLrU1NTfI05YsvvljcLk/v5WnEfJz53w4AAADqgXWcdtZxfDudKSwsFI+DH0/bj991112tCQkJYu0aFBTUOnbs2NaHHnqotaqqyujxDh48WKzd+vXr1/r000+3fvDBB+I2T506JV+PH+95553X7v55rcdvHfnxxx/Fbb388ssdXuf3338X13nhhRfk2xw6dGjrxo0bW8eNGyceG78+ePDBB1sbGxvlr/v4449bZ86c2RoeHi6+N1FRUa2XX35564EDB4xu/+DBg60XXHCBWOPy9UaOHCl+B5T438qPoe3H+XXDqFGjxPeSj8/rr79u8nu/b9++1qlTp4rXFvw55THp6vfCFL6dzl5zScdD+p3+66+/TN4GH09TMjIyWq+66iqxbufHxj8Lzz33nHjt0/bY8McB7Fkf/o+ti8cAAAAAAAAAAAAAYICMWwAAAAAAAAAAAACVQeEWAAAAAAAAAAAAQGVQuAUAAAAAAAAAAABQGRRuAQAAAAAAAAAAAFQGhVsAAAAAAAAAAAAAlUHhFgAAAAAAAAAAAEBlXGz9ANSopaWFcnJyyNfXl/r06WPrhwMAAAAAeq2trVRZWUlRUVHk5IQehM5gTQsAAACg7fUsCrcmcNE2JibGUt8fAAAAAOilrKwsio6OxnHsBNa0AAAAANpez6JwawJ32koH0M/Pj6zRDVFYWEihoaHoHMFxwc8MfpfwHGMleO7FccHPizZ/jyoqKsQJdmm9Bh3DmlYd8PcGxwU/L/g9wnMMnnvVAn+T1HFcurOeReHWBCkegYu21irc1tXVifvClj8cF/zM4HcJzzHWgedeHBf8vGj79whxVl0/RljT2hb+3uC44OcFv0d4jsFzr1rgb5K6jktX1rMIBgMAAAAAAAAAAABQGRRuAQAAAAAAAAAAAFQGhVsAAAAAAAAAAAAAlUHGLQAAAGhec3MzNTY2WjT3im+fs6+QR2/Z4+Lq6krOzs5muS0AAAAALcGa1j7WtK5mXM+icAsAAACa1draSnl5eVRWVmbx++EFXWVlJYZiWeG4BAQEUEREBI41AAAAOASsae1vTRtgpvUsCrcAAACgWVLRNiwsjLy8vCxW6OPFXFNTE7m4uKCYaMHjwrdXU1NDBQUF4v3IyMhe3yYAAACA2mFNaz9r2lYzr2dRuAUAAADNbiWTirbBwcEWvS8Ubq13XDw9PcX/ebHL31vEJgAAAIA9w5rW/ta0nmZcz2I4GQAAAGiSlGnLnbZgX6TvqSVziwEAAADUAGta++RlpvUsCrcAAACgaZaKRwDbwfcUAAAAHA3WP/alj5leo6BwCwAAAAAAAAAAAKAyKNwCAAAA2IEZM2bQsmXLbP0wAAAAAAB6BOvZ9lC4BQAAALDytqnO3q6//voe3e73339PTzzxRK8eG9/3RRdd1KvbAAAAAAD7pvb1bJ8+fejWW29t97mlS5d2+Pi2b98uhpPNnz+/3efS09M7/Lfu2LGDLMnForcOAAAAAEZyc3Ply1999RX997//pdTU1HZTaCU80MDV1fWMRzEoKAhHGgAAAADI0dezMTEx9OWXX9JLL70kP5a6ujpasWIFxcbGmvya5cuX0x133EEffPABZWZmmrzeunXraOjQoUYfCw4OJktCxy0AAACAFUVERMhv/v7+4ky99D4vKAMCAujrr78WW8U8PDzos88+o+LiYrryyispOjpaTKgdPny4WHh2trUsPj6ennrqKbrhhhvI19dXLD7ffffdXj32TZs20YQJE8jd3Z0iIyPp/vvvp6amJvnz3377rXhsvEDmRew555xD1dXV4nMbN24UX+vt7S3+jVOnTqWMjIxePR5Ql7KaBmppbbX1wwAAAAAHX8+OGTNGXJc7eCV8mQu6o0ePbnd9Xq/yOva2226j888/XxRxTeH1rfLfzm9dKUj3Bgq3YHE70orp/u8O0OGcchxtAACALvj3v/9Nd911F6WkpNC8efPEAnjs2LH0yy+/0KFDh+jmm2+ma6+9lnbu3Nnp7bzwwgs0btw4Sk5OFlvDeDF69OjRHn0PsrOz6dxzz6Xx48fT/v376a233qIPP/xQLKalzgtejPPCmh83F2ovueQSam1tFcVdjmCYPn06HThwQGxF438Dpifbj4KKOrrsnR309LoMamlB8RYAAMDR2Xo9+/e//50++ugj+X1et/I61RTuGh40aBANHjyYrrnmGvF1vIZVA0QlgEXxwv3OFclUWFlPJwqq6NvbpuCIAwCARV3w2lbxd8fcWqmV+lCfDj8f6utOP995llnuizsNuOipdO+998qX77zzTvr999/pm2++oYkTJ3Z4O1xo5QWutHjm7WJcUE1MTOz2Y3rzzTdFl8Lrr78uCq58G1zM5a7bRx99VBRuuUDLjzsuLk58DXdSsJKSEiovLxcdDP379xcfS0pK6vZjAHVqbG6hq9/fSScLq8Wb70+H6f8uHo7CPAAAgMrWs2da09rTevbaa6+lBx54QM6n/fPPP0V8An9tW1zUveqqq8Rlzritqqqi9evXi91jSlOmTCEnJ+MeWF7jOjs7k6WgcAsWlVZUJT/ZnCyswtEGAACL4787eRV1mj7S3FWg1NzcTM8884zoBuBiaX19vXjj2IHOjBgxQr4sbWErKCjo0WPibonJkycbFeM47oAXtqdPn6aRI0fS7NmzRbGWuyrmzp1Ll156KQUGBoq8Mh4CwR+fM2eOWARffvnlIm4BtM/V2YnuPmcg3bUimbjZ9otdWeTm4kyPXDAExVsAAIAewHq29+vZkJAQOu+88+jjjz8W3bN8mT/WFmfz7tq1S6yzGQ8oW7RokSjmti3c8nXaNh9YsmgrHo9Fbx0c3t7MMvkYlNY0Un1TM7m7WPaHGgAAHBt3ClhCVzpuzaVtQZa3iHF3wcsvvywKo/x57mJoaGjo9HbaZm7xYrelpaVHj4kXvG2jDaQtZPxxXrSuXbuWtm3bRmvWrKHXXnuNHnroIbH9LSEhQWw54+1y3FnBi97//Oc/4vqTJk3q0eMBdTl/RBQ1NrXQPV/vJ/6pWL4tnVyc+tBD5yWheAsAAKCS9WxXOm7taT17ww03iIFj7I033jB5HR5GxrvGOE9Xucbl+y0tLRVNCBLefTZgwACyJhRuwaKSFYVbVlBRTzFBXjjqAABgMeba3qUk5bTyGXhb5LJu2bKFFi5cKDK3GC9Wjx8/btW4gSFDhtB3331nVMDlIi0Piujbt694nz/OXbj8xtOFOTLhhx9+oHvuuUd8nodB8BtvW+Pu3S+++AKFWzuycFQUlZSV05Nr04lr+u9vPUUuzk707/mDUbwFAACw8XrW1mtaW6xn58+fLxeGeedXW3wsPvnkE3r++edp1qxZRsflb3/7G33++edy4ddWMJwMLCo5s9To/YJKbW9dBQAAsAU+sy91s3JkwS233EJ5eXkWuS/O6dq3b5/RW2ZmpsgWy8rKEnlkPBBi5cqVItv27rvvFllf3FnLg8p2794trs+TewsLC8Vi/NSpU6JYy0PJMjIyREfusWPH7CrnljOAubOYJyfz4A1+cdIVnLfGLxJGjRrV7nNcKOeCubu7u/g/F8HV7rwhwfTUxcPk99/edJJeXHvMpo8JAAAAHGs9K+EdYXxf/GYq0oAHpXFX7ZIlS2jYsGFGbxz5xd24SsXFxeIxK9946JoloXALFlNV30TH8ivbddwCAABA9zz88MM0ZswY0SkwY8YMke110UUXWeQw8sAGqTNWeuPuWe6qXbVqlcgA4zzbW2+9VWw/e/DBB8XX+fn50ebNm8UACZ7Ky1EIvCVuwYIF5OXlJYq93LnAn+Mpwty9wAt2e8DRD7zVj6MheOLxtGnTxL+bC9hnKpIvXrxYZAO3xUVuzlfjwRr79+8X/+dc4DNNXlaDReNi6MmLDMXb1/44Qa+uP27TxwQAAACOs55V4jUqv5nChVnOsfX392/3OV63cgPD3r175Y/xdXlGg/Ltxx9/JEvq0yqFk4GsoqJCfNN4Md3RN9ecuD2cg5XDwsLaTafTsm0ni+iq94xfXDx6wRC6fmqCQx8Xc8CxwXHBzwt+j/D8QuLsNndySl2OlmTrqAS1stRx6ex7a+11WlfwJGR+IfLWW2/JH+NuYn4x8vTTT3f4dVdccQUNHDhQdIDwop9fHEi4aMv/1t9++81oux/nrK1YsUITa9rlf56iR38+In/+vvmDaekM6+bCqQHWbTgu+HnB7xGeY/Dc2xmsae1zTVtnpvUsMm7Bavm2LL8SHbcAAABgPzg3bc+ePXT//fcbfXzu3LliK2BHeFjbyZMn6bPPPqMnn3zSZMftP/7xD6OPcYcKD/ToSH19vXhTviiQCoc9HUrXHXwf/MJHuq/Fk+OoobmFnlp1VLz/v99TyaVPH7pxWtdO4tuLtscFcFzw84LfIzzH4LnX1N8J6c3SpPtAH6dlj4v0/TS1DuvOmgCFW7Bu4bYCGbcAAABgP4qKiqi5uZnCw8ONPs7vd5TbxoM4uNDLObjc2WEKf213bpNxd+9jjz3W7uOcNWzp/DXpRQh3jvCLFGm31IWDvKmsvC+9+We2eP+p345SbU0VLRpt/G+zZ6aOC+C44OcFv0d4jsFzr6SxsVH8reCOT36zJP5bxOsWhl1klj0u/L3k7yvn4rq6uhp9rrLSOFa0MyjcgsV+6Pdl6QaTebg6UV2j7mwCMm4BAADAHrVd5PNayNTCn18UXHXVVaLAynm/5rhNCQ+Au+eee4w6bmNiYig0NNRqUQn8+Pj+lAXKe88LIw9PL3pxnS7n9qVNpynA34+unRRHjqCj4+LocFxwXPDzgt8lPMfo8MlVLuTxydyOTuiaW9tCIpj/uPD3kv/uBwcHt4tK6E7MGwq3YBGnS2upqKpBXJ6QEEw704qpvqmFCirRcQsAAAD2IyQkRGTUtu2E5azXth2zjF+Y7d69Wwwx4wFtyi2SvMBfs2YNzZo1Swzs6OptStzd3cVbW/yiwVoFQy5Qmrq/u84ZRE0trfTqHyfE+4/8dITcXJzpygmx5Ag6Oi6ODscFxwU/L/hdwnOM7u80Px9Kb5akPAmMjlvLHhfp+2nq73931gNYOYBF7M3UdduyMbEBFO6nO5uQX4GMWwAAALAfbm5uNHbsWFq7dq3Rx/n9KVOmtLs+d74ePHhQDCKT3m699VYaPHiwuMyDztjkyZPb3SYXdU3dplb8Y84gum1Gf/n9B384SN/szrLpYwIAAABQM3TcgsXzbUfHBtKfJ4oos6SGymsbqa6xmTxcnXHkAQAAwC5wPMG1115L48aNEwXXd999lzIzM0VBVoowyM7Opk8++UR0WAwbNszo68PCwsSWOeXH7777bjr77LPp2WefpYULF9LKlStp3bp1tHXrVtIq7jq5b95gampuofe2nCKe/XHfdwfIxbkPXTw62tYPDwAAAEB1ULgFi0hWdNyOig6gMH3HrZRzGxvshSMPAAAAdmHRokVi8MTjjz9Oubm5ogC7atUqiovTZbjyx7iQ2x3cWfvll1/Sf/7zH3r44Yepf//+9NVXX8kduVou3j54bhI1NrfS8m3ponj7z6/3k4uTE10wMsrWDw8AAABAVVC4BbPjjtrDORXicv9Qb/L3cqUwX0PeWn5lHQq3AAAAYFeWLl0q3kxZvnx5p1/76KOPire2Lr30UvFmb7h4+8gFQ6ippYU+25FJLa1Ey77aRy5OfWjB8EhSo4zialqxK4v8PV3p1un9kAsIAAAAVoHCLZjd4ZxyMXxCiklgUsYty6/AgDIAAAAAR8bF28cvHEZNza305V9Z1NzSSneuSKY3nfrQ3KERpBYnCirpjQ0naeW+bFFgZsP6+tG0gaG2fmgAAADgADCcDCycbxsg/h/u524UlQAAAAC9M2PGDFq2bBkOI2iWk1Mfeuri4XTpWF2+LZ/4v/2LvbThaIEqGhGWfr6H5ry0mX5INhRt2RH9zjIAAADoHaxnzwyFW7Bs4TZG33Hrq+i4rUTHLQAAOK4LLriAzjnnHJOf2759u+hE3Lt3b6/vh7fnBwToTqACqLl4++zfRtBFo3T5tpx9e8tne2jzsUKbzWm48eO/6LxXt9Kqg3kig5d5uBpeNqUX19jksQEAADjierZPnz6UlJTU7nNff/21+Fx8fHy7z9XW1lJgYCAFBQWJy23x1/DXSm88PNbNzY2eeeYZUhsUbsFig8m83JxpULiPuNx2OBkAAICjWrJkCf3xxx+UkZHR7nMffvghjRo1isaMGWOTxwZgC85Ofej5y0bS+SN0+bYNTS100ye76c8TRVZ7DDvTiunaD3bSxW9uo3Upho7fEB93eujcJPrjnzPkj6UXVVvtcQEAADj6etbb25sKCgpEQbjt/cTGxpr8mu+++04Mix0yZAh9//33Jq8jDZXlt5ycHDFI9s477yS1QeEWzCqvvI5yynUdtSOi/cnF2aldVAIybgEAwJGdf/75FBYW1m5gVU1NDX311VdiIVxcXExXXnklRUdHk5eXFw0fPpxWrFhh1sfBi9OFCxeSj48P+fn50eWXX075+fny5/fv308zZ84kX19f8fmxY8fS7t27xed4kc6dFtzFwF29vDBetWqVWR8fOBZeM760aBQtGKbLt61vaqElH/9FO9KKLXafra2ttOV4IV3+9nZa9O4O2nLcUCiO9Pegxy4cSlv/PZNuOrsfRQV4UoCXqzyoDAAAwJFZcz3r4uJCV111lSjUSk6fPk0bN24UHzflgw8+oGuuuUa88WVTeI0bERFh9MZFYrVB4RbMal+WrttWOZiM+bi7kKers7iMwi0AADgyXnwuXrxYLHS5cCT55ptvqKGhga6++mqqq6sThdJffvmFDh06RDfffDNde+21tHPnTrM8Br7fiy66iEpKSmjTpk20du1aOnnyJC1atEi+Dj8OXmj/9ddftGfPHrr//vvJ1VVXuLr99tupvr5efC1vg+NtZVwABugNV2cneuWK0XROUrh4v66xhW5Y/hftTi8x64Hln/91R/Lpoje30bUf7KJdituPDfKiZy4ZTpv+NZOumxJPHvr1K4sL1r2Y4yaFusZmsz4mAAAALbH2enbJkiWiIMyFYcb3O3/+fAoP160ZlHhNy9253JTAb9u2baO0tDTSKhdbPwCw33zbMYrCLWeGcNctZ4IVVCIqAQAALOid6URV5h9u5EK8KO3T8RV8wohu2dSl27rhhhvoueeeE50C3NXKuIvgkksuEXlc/HbvvffK1+dtW7///rtYDE+cOLHX/5Z169bRgQMH6NSpUxQTEyM+9umnn9LQoUNFoXb8+PGiI/df//oXJSYmis8PHDhQ/nr+3N/+9jfROdHU1ESDBg0Sf+sBesvNxYneuHo03frpHtqQWkg1Dc10/Ud/0SdLJhitLXuipaWVfjuUR69vOEEpucYDxvqHetPtMwfQhSOj5B1jbSUEe9H+LN1aN7OkhgaF+/bq8QAAAFh7PXvGNa1K17OjRo2i/v3707fffiuKv1y4ffHFF00WZPkxLFiwQNw/4wIvf+zJJ580ut6///1v+s9//mP0sZ9//ln+t6gFCrdgscLtqBjjgSicc8uF28q6JqppaCIvN/z4AQCABfAitzLHrDdp7pIkF0OnTJkiFpG8OOTOgC1bttCaNWvE55ubm0UXK3cWZGdni+5WfjPX9q2UlBRRsJWKtowzwDj2gD/Hhdt77rmHbrzxRlHQ5eETl112mVgws7vuuotuu+028Xj58fPnRo4caZbHBuDu4kxvXTNW5NxyfEFVfRNd98Eu+vymiTQiuvsD95qaW+jnAzn0xoaTdKKgyuhziRG+dOesgTR/WITI2u2M1HEr5dyicAsAAFpaz5p7TWvt9ewNN9xAH330kci1raqqonPPPZdef/11o+vwfX788cf0yiuvyB/juIR//OMf9Nhjj5Gzs2EnDTcoXH/99eIydw1zM0JcXBypDSpnYDaNzS10IFtXuI0J8qRQX0OuLQtvM6AsPgQ/fgAAYAHcKWBmug1guu6EPma6X97ydccdd9Abb7whFqG8UJw9e7b43AsvvEAvvfQSvfzyy6KrlRe4y5YtE1vPzIEXp6Y6ZJUff/TRR0Vu2K+//kq//fYbPfLII/Tll1/SxRdfLAq68+bNE1vfVq9eTf/73//EY1bjQAfQJo4oeG/xOBGVsO1kMVXWN9E17++kL26aRMP6+nfpNnjI2fd7T9ObG0+KDlmlkdH+dMesgTQ7MYyczlCwlcSHeMmXM4qNbw8AAEDt69kurWlVvJ69+uqr6b777hNrVI5p4LiGtnhdykViZfyXVNDlgjJ34kpCQkJowIABRoVbU7dpa+p7RKBZR3MrRRYZGx3TfitbuKKQyzm38SHqC30GAAA70MXtXd2iXMyZKRKAM7fuvvtu+uKLL0RnwE033SQXTblbgQeHcYcAa2lpoePHj1NSUpJZ7pu7aznuICsrS+66PXLkCJWXlxvdB0cg8Bt3KfBwCV6Qc+GW8dfdeuutooj78MMP03vvvYfCLZi9ePv+deNEVMKuUyVUUddE13ywk1bcNImSIv06/DrOn/16dxa9vfGkPDRXMj4+UHTYThsY0u14j3hFx+0pDCgDAACtrWctsKa15no2KCiILrzwQvr666/p7bffNnkdHkR2xRVX0EMPPWT0ce785c8pC7dagcItmE2y0WCy9tvYwvwUhVvk3AIAgIPjYV7cDfDggw+Kgqm0VYvx2f/vvvtODFPgfC7O8MrLy+v2Qpe7C/bt22f0MTc3NxF9MGLECNG5wF0QvIBfunQpTZ8+ncaNG0e1tbVi+9ill15KCQkJYnIvZ99yri3jbgle+HLubVFREW3YsMFsRWUAJY7W+vD68XTdh7toT0YpldU0is7bL2+eRAPbZMxW1zfRFzsz6d0taVTYZq151oAQunPWAJrYL7jHB1hZuM1A4RYAAMAq61klzrZ98803KTi4/d/zwsJCkVH7008/0bBhw4w+d91119F5550nrhMaGio+VllZKR6PsuPWz8+P/P27trPHWkwn7wP0Mt92tInhEcZRCcbdDwAAAI6It5eVlpaKQirndUm4g3XMmDEijmDGjBkUERFBF110Ubdvn/O/Ro8ebfTGeWDcCfHjjz+KRfTZZ58t7r9fv34ig4xx/ldxcbHYhsYdt9xNwYVazgaTCsK333676Nw9//zzafDgwWIRDWAJPu4utPzv4+X5CcXVDXTlezvlvNqKukZ6/Y/jdNazf9D/rUoxKtpyFML3S6fQZzdO7FXRlgV4uZKfh67vJb0IUQkAAADWWM8qeXp6mizask8++UTEMUhRDUqcwevr6ytmN0j++9//UmRkpHiLiooSj52jGNSmTyuXlcFIRUWFqLDz2QKutlsat4sXFBRQWBhnbGm3lj7juQ1i+BhPAz706Dzxf6XtJ4vpyvd2iMs3n92PHjw3ySGOiyXg2OC44OcFv0d4fiGqq6ujU6dOiY5QDw/DyUFLUOZedXd7tT2z1HHp7Htr7XWaltnbmra8tpGu/WAnHThdLt4P83Wni8f0FV22PPxWacGwCLp95oAu5+F21cLXt9L+0+Vid2nK4/NFnMOZYN2G49Id+HnBceku/Mxo/7hgTWufa9o6M61n1f3TC5pRUt0girZsWJRfu6ItC1dGJaDjFgAAAAC6wd/TlT65YQIN0efbFlTW0zub0uSiLc8Yu2hUFK35x9n01jVjzV60ZXH6uARufTldiq5bAAAAsCwUbsEs9hnl27aPSWBhiqgEFG4BAAAAoLsCvNxE7EFihCHf1sWpD10+Lpr++OcMevmK0TSoTfatOcUHe8mXTyEuAQAAACwMw8nAAvm27QeTSflk/FZV30QFFcYDIwAAAAAAuiLI240+v3EivbTumBhetnhyHEUHGgqqlhQfggFlAAAAYD0o3IJVBpNJOIuMC7fouAUAAACAngr2cacnLxpu9QMoRSWw9OJqq98/AAAAOBZEJUCvNbe00r6sMjnHNsq/4wExYfqc2+qGZlHABQAAAADQigRFx206ohIAAADAwlC4hV47WVglF2FHxwR2OoEvXJFzW4ABZQAAYKapwWBf8D0FtQr0ciVfD92mRXTcAgCAOWH9Y19azPQaBVEJ0GvJmaVnzLc1VbjNr6infqE++A4AAECPuLm5kZOTE+Xk5FBoaKh4v7OTh73R2tpKTU1N5OLiYrH70CJzHxe+vYaGBiosLBTfW/6eAqgJ/5zHB3vTwexyyimrpfqmZnJ3cbb1wwIAAA3Dmta+1rStZl7PonALvbY3o2v5tlLGraSgsg5HHwAAeowXQgkJCZSbmyuKt5bECzA+a873icKt5Y+Ll5cXxcbGitsFUBseUMaF25ZWoqySWhoQhkYEAADoOaxp7XNN62Wm9azNC7dvvvkmPffcc+JF19ChQ+nll1+madOmmbzu999/T2+99Rbt27eP6uvrxfUfffRRmjdvnnyd5cuX09///vd2X1tbW0seHh1nr0LPJWfpOm6dnfrQ8L7+nV43zKjjFoVbAADoHT6DzQsiPkPe3NxsscPJC7ni4mIKDg5GMdHCx8XZ2RmdzaBq8cFe8uWM4moUbgEAoNewprWvNa2zGdezNi3cfvXVV7Rs2TJRvJ06dSq98847tGDBAjpy5Ih4EdbW5s2bac6cOfTUU09RQEAAffTRR3TBBRfQzp07afTo0fL1/Pz8KDU11ehrUbS1jIq6RjpeUCUuJ0X6kqdb51vFwpUdtxX1FnpUAADgSHhB5OrqKt4suZjj2+f1BLpAcVzAscUFKwaUFdfY9LEAAID9wJrWdlpUvNa3aeH2xRdfpCVLltCNN94o3udu29WrV4uu2qeffrrd9fnzSlzAXblyJf38889GhVv+YY+IiLDCvwAOZJVTayvJg8nOxCjjthKFWwAAAADQloQQQ8dtelG1TR8LAAAA2DeblZE5qHfPnj00d+5co4/z+9u2betyRbyyspKCgoKMPl5VVUVxcXEUHR1N559/PiUnJ5v1sUPPBpOxMD9Dxy2iEgAAAABA2x23KNwCAACAHXbcFhUViSy68PBwo4/z+3l5eV26jRdeeIGqq6vp8ssvlz+WmJgocm6HDx9OFRUV9Morr4gYhv3799PAgQNN3g7n5fKbhL9OKgzzm6XxfUhByFqzV1G4HRntf8Z/g4eLE/l6uFBlXZMo3HZ2fS0fF0vDscFxwc8Lfo/w/ILnXUf9e4R1AdhasLcb+bi7UFV9E2UgKgEAAAAsyObDydoG9fLivyvhvStWrBCDyTgqISwsTP74pEmTxJuEi7Zjxoyh1157jV599VWTt8WxDI899li7jxcWFlJdXZ1VXoCUl3PkQKvqsjQ6w493b0aJuOzn4UxezVVUUHDmroMgT33htryO8vPzO/x+a/W4WAOODY4Lfl7we4TnFzzvOurfI95tBWBLvHaND/GiQ9kVdLq0hhqaWsjNBWtVAAAAsKPCbUhIiJiy1ra7tqCgoF0XrqmhZpyN+80339A555zT6XX5RcT48ePp+PHjHV7ngQceoHvuuceo4zYmJoZCQ0PFoDNrvOjhBSDfn5YKlLw1rLxON8F7TFzQGb9vkqjAdMooraO6phby9A8iPw9Xuzou1oBjg+OCnxf8HuH5Bc+7jvr3CANnQS1xCVy4bWklUbztF+pj64cEAAAAdshmhVs3NzcaO3YsrV27li6++GL54/z+woULO+20veGGG8T/zzvvvDPeD3eA7Nu3T0QndMTd3V28tcUvQKz1IoRf9Fjz/sxh/+ly+fLY2MAuP/YIf8OAsqKqRgrwan/stXxcrAXHBscFPy/4PcLzC553HfHvEdYEoAbxwYYBZRyXgMItAAAA2F1UAne5XnvttTRu3DiaPHkyvfvuu5SZmUm33nqr3AmbnZ1Nn3zyiXifi7WLFy8WubUchyB163p6epK/v7+4zJEH/DnOs+XOWY5H4MLtG2+8YcN/qX1KziyTL4+ODezy1ykHlBVU1NGAMHQoAAAAAIB2xCsGlJ0qqqaZNn00AAAAYK9sWrhdtGgRFRcX0+OPP065ubk0bNgwWrVqFcXFxYnP88e4kCt55513qKmpiW6//XbxJrnuuuvEQDJWVlZGN998syjqcjF39OjRtHnzZpowYYIN/oWOUbjliNoRMbrCeVeE+xo6bvMrLZ8hDAAAAABgTvEhhsJtRvGZZzwAAAAAaHI42dKlS8WbKVIxVrJx48Yz3t5LL70k3sCyahuaKSW3QlweGObTYU6tKeF+isJtRb1FHh8AAAAAgKXEKaIS0otrcKABAADAIhAcCj1yMLucmngaA8ckxHQ9JqFtVEJ+BTpuAQAAAEBbQn3cydvNWR7YCwAAAGAJKNxCjyRnlsqXR8cGdOtrlVEJBZXouAUAAAAA7Q3li9Pn3J4uraXG5hZbPyQAAACwQyjcglUHk5kaTgYAAAAAoDXxIbq4hOaWVlG8BQAAADA3FG6h21pbW2mvvuPWx92FBoT5dOvrPVydyd9Tl4mLjNueHX/ekidFVQAAAACA9cXrO24Z4hIAAADAElC4hW7LLa+TIw5GxviTs1Ofbt9GuL7rljNuuRAJXff8mlSa9cJmuvv74zh2AAAAACoo3GYUIecWAAAAzA+FW+hdTEI3B5NJwvQ5t/VNLVRR24TvQhc1NbfQ5zszxeU9pyspNb8Kxw4AAADABuJDlB23NfgeAAAAgNmhcAu9Gkw2Jq57g8lM5dzmVyLntqv2ZpZRWU2j/P7qw3k9Ov4AAAAA0DvxwbqMW4aoBAAAALAEFG6h25KzDB23o3rYcRvup+u4ZQUVutgFOLP1R/ON3l992Ph9AAAAALCOUF938nJzFpcz0HELAAAAFoDCLXRLQ1MLHcwul7sMgrzdenQEw30VHbcV6Ljtqj9SCozeP5pXSenIVAMAAACwuj59+lCcPuc2q6RGRFoBAAAAmBMKt9AtKbkVonjLRsf2rNu2bcctohK6JrO4ho4XtM+0/R1xCQAAAAA2jUtoamml7LJafBcAAADArFC4hR7n246O7Vm+LQtDVEKvYhIuHxctX/79EHJuAQAAAGxB6rhlGFAGAAAA5obCLXR7OJZkdA/zbVkYohK67Y+jhpiEv0+JpwEhnuLyvqwyyi1HhwcAAACAtSWEKAaUIb4KAAAAzAyFW+iW5Cxdx627ixMlRvr2+OiF+RkybgsqMZzsTKrqm2hHWrG43DfAkwaF+9CMAYaO5zUYUgYAAABg447banwHAAAAwKxQuIUuK6ysp6wSXWfniGh/cnXu+Y+Pu4szBXq5issYTnZmW44VUmNzq7h8TlKYGIYxY4Ch4/m3Q7k9/l4AAABA77355puUkJBAHh4eNHbsWNqyZUuH1926dStNnTqVgoODydPTkxITE+mll14yus7y5cvF3/u2b3V1GOqqJvGKwm1GcY1NHwsAAADYHxdbPwDQDt6SL+nNYDLlgLLSmkYqqKin1tZW8WIETFuviEmYlRQu/t8/2EMMxOA8tV2nSqi4qp6CfQydzAAAAGAdX331FS1btkwUb7kg+84779CCBQvoyJEjFBsb2+763t7edMcdd9CIESPEZS7k3nLLLeLyzTffLF/Pz8+PUlNTjb6WC8OgHuF+7uTh6kR1jS2ISgAAAACzQ8ct9GwwWUzPB5O1HVDW0NxCZTWN+E50oKWllTboC7debs40MSFIXOZC97yhEbrrtBKtSzEMLwMAAADrefHFF2nJkiV04403UlJSEr388ssUExNDb731lsnrjx49mq688koaOnQoxcfH0zXXXEPz5s1r16XLf+sjIiKM3kBd+Hskdd1mldZQU3OLrR8SAAAA2BF03EKXJWeat+PWaEBZZR0Fervhu2HCvtNlVFzdIC5PGxhCHq7O1NKie1Ewf2g4vbM5TVz+/VAeLRrfvqsHAAAALKehoYH27NlD999/v9HH586dS9u2bevSbSQnJ4vrPvnkk0Yfr6qqori4OGpubqZRo0bRE088IYq+HamvrxdvkoqKCvF/XjdIawdL4vvgXVTWuC81iQ3yoqN5lSLWKru0hmKCDAPLHPm4nAmOC44Lfl7wu4TnGDz3OurfpJZu3A8Kt9AlzS2ttP+0rnAb5e9BEf4eZtlaJuG4hEQ0kZj0R4ohJmF2oi4mQTK8rz9F+ntQbnkdbT1RRBV1jeTnocsOBgAAAMsrKioShdXwcOO/0fx+Xl5ep18bHR1NhYWF1NTURI8++qjo2JVw7i3n3A4fPlwUYF955RURw7B//34aOHCgydt7+umn6bHHHmv3cb4Pa2Tj8ouQ8vJy8cLHyclxNvaFeRou7zuZQ+5Nfkafd9TjciY4Ljgu+HnB7xKeY/Dc66h/kyorK7t8XRRuoUuO5VdSTUOz2bptpYxbCQaUdS3fdkZiqNHnnJx0cQnLt6WLLg+OVFg4qq9Zvj8AAADQdW2z+ruS38/RCNxVu2PHDtGxO2DAABGhwCZNmiTeJFy0HTNmDL322mv06quvmry9Bx54gO655x75fS74cmRDaGioyMu1xose/jfz/TlSgXJIbD3RHl1kVVmzK4WFhRl93lGPy5nguOC44OcFv0t4jsFzr6P+TfLoxswCFG6hBzEJvc+3ZWG+hh/UgkrDtj4wyCmrpZRc3TbHkdH+RsdMMn+YrnArxSWgcAsAAGA9ISEh5Ozs3K67tqCgoF0XblsJCQni/9xVm5+fL7pupcJtW/wiYvz48XT8+PEOb8/d3V28mfpaaxUM+UWPNe9PDeJDdBm3LLOk1uS/3RGPS1fguOC44OcFv0t4jsFzryP+TXLqxn1g5QDdH0xmpsKtMioBHbdn7radnWT6xd/4+CAK1ucDb0wtpFp9ZzQAAABYnpubG40dO5bWrl1r9HF+f8qUKV2+He7QVebTmvr8vn37KDIyslePF8wvQVG4TS+qxiEGAAAAs0HHLXRJcpau49bVuQ8NjfI3y1FDVMKZ/ZGi23bHZiUab7uTODv1oTlDwunLv7KotrGZNh8vFPEJAAAAYB0cT3DttdfSuHHjaPLkyfTuu+9SZmYm3XrrrXKEQXZ2Nn3yySfi/TfeeINiY2NFji3bunUrPf/883TnnXfKt8lZtRyVwHm2HHnA8QhcuOWvBXUJ9/Ugdxcnqm9qofRiFG4BAADAfFC4hTMqr22kEwVV4vKQSD/ycHU2y1EL8VF23CIqoa2ahib682SxuBzh50FDozrOpuO4BC7cSnEJKNwCAABYz6JFi6i4uJgef/xxys3NpWHDhtGqVasoLi5OfJ4/xoVcZY4aF3NPnTpFLi4u1L9/f3rmmWfolltuka9TVlZGN998s4hg8Pf3p9GjR9PmzZtpwoQJ+NaqDM8ciAv2omP5VZRVUiuG+vKJdQAAAIDeQuEWzmifvtvWnIPJmJuLk9jiX1zdQIXIuG3nzxPF1NDUIi7PSgrrdMDJlP4h5OvuQpX1TbQuJV98HR9fAAAAsI6lS5eKN1OWL19u9D531iq7a0156aWXxBtoQ3ywtyjcNjS3iBkFMUFetn5IAAAAYAdQ2QGb5NtKwvx0w7YKKuuopaUV3w2FP44aYhJmdxCTIOEi7ewk3XUq65poe5quUxcAAAAArDugLKO4BoccAAAAzAKFW5VIya+WuyvVJjlT0XEbY76OW+WAssbmViqtaTDrbWsZDyBZn6IbTMaZadxReyYclyDhuAQAAAAAsF7HreQUcm5Vp66xmQ6eLhfD43idDQAAoBWISrCxk4VV9PSqFFqXUkBPLHSmayfHk5pwF6wUlcCxBjFBnmYf5qDMuQ1W5N46ssM5FVSgj4+YOiCEPN3OnCt89qBQ8nB1orrGFlp7JI+evGgY8tUAAAAArCA+2BCNkFGEAWW2wkXZ7LJaOppbSUfzKiglr5KO5lbQqaJqkjb3fXDdOJqdFG6zxwgAANAdKNzaWFUdZ5LqOitf33CCLhsXY7bhX+bAHQM8nEyKSegsZ7UnwvQdtyy/so6GUMcDuBwJ59RKpAiEM/Fyc6EZg8Lo98N5VFTVQLvTS2hiv2ALPkoAAAAAYHGKqIR0RCVYRXV9E6Xmc2G2klJyK0Sh9mhepYgN68yaw/ko3AIAgGagcGtjI2MCaE5SGK1NKRAdp5/tyKAbp/UjVcYkmHEwWduMW1ZYoeswBc631RXz2awz5Nu2jUvgwi3j/6NwCwAAAGB5kX4eYuYAR5+lIyrB7DsAM0tqdB20+k5aLtB2NUvYzdmJ+of5iOIuyymvNe8DBAAAsCAUblVg2TkDRdct7955a+NJunJCLHm7u9j9YDIW7qvouK2oM/vta1FBRR0dOF0uLg+J9KNI/67HU8xMDCNX5z4iM3j1oTz67/lDzN4lDQAAAADGnJz6UFyQFx0vqKLM4hpqbmlFZFUP8E6/VI43EEVaXaH2WH4l1TQ0d+nro/w9KDHSjxIjfMX/kyJ8KSHEW3wvhj6yWtwORykAAABohTqqgw4uKdKPzhkUSGuPlVJxdQMt35ZOt88cQGrquHXqQzQi2gKFW0XHLUclgHG3bVdjEiT+nq5ikNmmY4WUU64rAHNXNwAAAABYVlywtyjcNjS3UF5FHfUNMO9sCHtTVFVPa1NLKHdfmb5YW9nloqqnqzMNivAVhdkkqVAb4Uf+Xq4dfk1UgCedKKiinLJakYWL5gYAANACFG5V4sZJUbT+eKkIzX9n00m6ZlKcKMLZUk1DkzjbzQaF+5KPBbqAjQq3iEoQ1hsVbrs/OGHBsAhRuJXiElC4BQAAALC8hBDDgLL0omoUbjuRV15H57y4marqO8+jZbFBXkYdtPx//hh30XZHpL+HKNzyIN/SmkYK8nbr1tcDAADYAgq3KhEX5EEXj+5L3+3Npoq6JvpgSxrdM3ewTR8Td2tK01ctkW/LQnzciHfyt7bqIgIcXV1jM209XiQfmxF9/bt9G+cMCSenHw6K793vh/LovnmD0VEAAAAAYIWOWwnn3E4dEIJj3oFfD+a2K9pyk4iuQKvrnk2K9KXBEX5max5RdkBz1y0KtwAAoAUo3KrIXbMG0E/7c0Q+6QdbT9H1UxNsuqAwHkxmme32Ls5OFOztLrZKoeOWaEdaMdU26jK8Zg4OE3lp3RXi407j44No56kSOlVULbbsccc0AAAAAFhOvKJw29XBWY5K2h3Gnv3bcBH1FR3oadFmA45KkHAkw7AeNEgAAABYm5PV7xE6FBPkRYvGx4jL1Q3NIjLBlvYqBpONsVDhloX76QaUFVbVi6mxjmx9Su9iEiTzh0XIl7nrFgAAAAAsK14RlcAnz6HjHWY704rF5TAfV7p0TF/xOsjSmbNRbTpuAQAAtACFW5W5Y+ZAcnPRfVs+3p5us/gADuyXOm59PVyoX4iPxe5Lyrnl6bs8nM1R8TGXBpO5OTvRWQN7vr1u3lBD4fY3FG4BAAAALC7S31Os4VhGMQq3HdmeVkz1TS3i8qR4f6tFekUFGGZr5JYjog0AALQBhVuVifD3oGsnxYnLHJz/xoYTNnkcp0trRXwBGxUT0KMt+93tuGX5Dpxzm5pvmKQ7sV9Qr/K8uKNAGkqWkluBFw8AAAAAFsbDsmKCPOWoBEffSdaRTamGmITJ8X5Wu19lxq205gYAAFA7FG5V6LYZ/cnLzVlc/mJXJp0utX5GVnKWMt/WMoPJJGG+hrPfBZWOW7g1iklIDOv17c1XdN2uPoy4BAAAAABLSwjR5dxyR2meAzckdGazPt+WC93jY/ys2iAjQVQCAABoBQq3KsTDpf4+NV5c5kFlr/9h/a7bZEW+raUGk0nCjDpudV2+jmh9Sr5Z8m0l84YabgM5twAAAACWF6cYUJaOuIR2MotrKE2f/8szNHzcdc0q1uDu4ixeZzEUbgEAQCtQuFWpm6f1F9my7Js9p60+4EDKt2Wj9VvuLSVc2XHroIXb4qp6uct5ULiPGNDQW/1CfWhwuK+4vDezjPKQ5QUAAABgUfHBhjUcxyWAsU3HDDvMpg8Ktfrh6avPuS2orKcGfc4uAACAmqFwq1L+Xq5007R+8tCuV9Yds9p91zc105GcCnG5X6g3BXi5WfT+pOFkLN9BoxI2phZSqz4GbVZi77ttJfOHGeIS1hxBXAIAAACAJcXroxJYupUbL7Sy5pVMH9TzQby9mQPBeN3tyLM1AABAO1C4VbEbzkqgQC9XcXnl/hw6ll9plfs9nFNBDc26M9CjYyybb9t2OFmBgy6g1h81xCSck9T7fFtThVvEJQAAAABYVjyiEjptDtl2slhc5siCpAjr5du2LdwyDCgDAAAtQOFWxXzcXcSgMums8Itrjlk/JsHC+bYs2MednPo4bsYtb9PafKxIXA7wcjXrMLjECF+K02/Z23mqhEqqG8x22wAAAABgLNLfg1yddQtbRCUY251eSrWNzXJMgpP0AsBGhdvc8lqr3z8AAEB3oXCrctdOiqdQX11H6u+H8+jg6XK7GkwmTZSVBgU44palv9JLqKq+SVyeOThMHA9z6dOnD80fGiFHbqxTDEADAAAAAPNycXaSZxXwcLKWFn0WFtDGVEW+7WDr59sqM25ZTpnjve4AAADtQeFW5TzdnOnOWQPk919cm2q1jltPV2d5uJWlSTm3RVX1osDoSJTF1FmJ5otJkCAuAQAAAMD6cQl1jS1iCBbobDqmy7flHoVpA6yfb8sQlQAAAFqDwq0GLBofQ33123o2pBbSnowSi90XZ8xKeU8jov1F14A1SDm3XLMtrnKcBW5rayutT9F1H7g49aGzLTBdd2R0AEXoC+NbjxdRZV2j2e8DAAAAANrn3J7CgDIhp6yWjuVX6damMQEU6G3Z4ccdifT3NHpMAAAAaofCrQa4uzjTXbMNXbfPr7Zc1u1eo3xbyw8mk4TpC4uOlnN7srCaMktqxOXx8UHk76kbRmdOnB82b2i4uMxD57j4DwAAAACWER+ii0pgGcXVOMyKblsp39ZWgr3dyM1F9xIYhVsAANACFG414m9joileP2Rqe1oxbTuhG2ZlbslZ1s23lYT7Kgu3jpM39cdRQ0zC7CTzxyRI5g3T5dyy1YfyLHY/AAAAAI4uTtFxm16sO0Hv6DalqqNwyw0NUf661x3ZpbVi9xsAAICaoXCrERxZ8I85g+T3n1+TapGFhpRvy0bHWLFwq49KYPmVjlO4XaePSbBUvq1kQnwQBem3pG1ILaA6/URfAAAAADCvBGXhFlEJ1NjcQn/qm04CvVxpRLT1XmN0lnNb3dBMFXW6AcEAAABqhcKthpw/IooGhfvIkQZcgDOnpuYWOnBaV7jlTF1lfIGlhSkLtw4SlVBW00B7MnQdzv1CvKlfqO57a6nC/5wkXVxCTUMzbVZsVwMAAAAA84kK8BCzC1g6ohJob0YpVdbrCqTTBoaSs/7Y2IpyQFluOXJuAQBA3VC41RBe5Nyj6Lp9Yc0xauFpXmZyNK9STL9lY+Ksl2/LwhRRCYUO0nHLWV/N+u+fJbttJfMVcQm/H0ZcAgAAAIClTpjHBOkizjKKaxx+O75a8m1NFW6RcwsAAGqHwq3GzBsaQcP6+onLh3MqaLUZC3DJWbaJSWDhDjicbL0yJsGC+baSKQOCycfdRVxedyRfbFsDAAAAAPOTZlPUNjZTQaVjrG27Urg9WwWF274Bhtcd2WWO0TACAADahcKtxvTp04f+OXew/P6La4/JXZu9lZxpm8Fk0oRXaduUIwwn41iKjfqoC18PFxofH2Tx+3R3cZY7eznPa0dascXvEwAAAMDRB5Rx162jKqisE80mjJtPQn0N8Wi2go5bAADQEhRuNWjGoFAaq48yOF5QRT/tzzbL7e7TDyZzc3aiIVG6rl5rTngN0y/kHKHjlrNtpWEIvGXM1dk6v4oLFHEJvx1CXAIAAACAJTtuHT3ndvMx3VAyNmOQ5XeYdUWkP6ISAABAO1C41WjX7b2KrtuX1x3v9bb30uoGStNPvR3a1090Z1qbVLgtrq4XHan27I+jhpiE2VaISZBMHxxK7i66X/s1h/PN1q0NAAAAAAbxIYaO23QH7rg1yrcdbPuYBGl4nAQZtwAAoHYo3GrU5P7BNHVAsLz96rs9p3t1e/tOK/NtrTuYTBKmz7ltbSUqqmoge7YuJV/8n9MhrNl94OXmIg+FKKqqp72KeAwAAAAAMI94RCWIBoEtxwvlaDBrz9DobD0c6OUqLucg4xYAAFQOhVsNU2bdvrr+ONU3Nff4tpL1MQm2yLeVhPsZMq/sOec2vaiaThbqups58iLQ282q9z9fEZfwO+ISAAAAAMyub6CnPL8hw0GjEvafLqOymkZxedrAEHKxUjRYd3Ju8yrqsAMNAABUzeZ/Pd98801KSEggDw8PGjt2LG3ZsqXD637//fc0Z84cCg0NJT8/P5o8eTKtXr263fW+++47GjJkCLm7u4v///DDD2SPxsQG0mz9sKmc8jpasTNTk4PJJOG+Hg5RuFXGJMxKDLf6/c9OCicX/QsJLty2coszAAAAAJgNzy+ICfSUoxIccb21KVURk6Df8aW2wi13BfMANQAAALWyaeH2q6++omXLltFDDz1EycnJNG3aNFqwYAFlZpouQG7evFkUbletWkV79uyhmTNn0gUXXCC+VrJ9+3ZatGgRXXvttbR//37x/8svv5x27txJ9ugfcwbJl1/fcJJqG7rfddvS0ioPJuNJr331CxlrC9dHJbD8SvsdULb+qC4mwdr5thJ/T1eaMiBEXM4uq6VD2bpJvwAAAABgPnH6uISahmYqqdENpXUkGxX5tmerrHCrfL2DnFsAAFAzmxZuX3zxRVqyZAndeOONlJSURC+//DLFxMTQW2+9ZfL6/Pn77ruPxo8fTwMHDqSnnnpK/P/nn382ug4Xdx944AFKTEwU/589e7b4uD0a1tefzh0eIWeWfrI9vdu3cbKwiirrdYtJzp7i4We2EKqISiiw047byrpG2plWIi5HB3rSwDAfmzyO+UMVcQmHc23yGAAAAADsWXywl3w5q8x+mxJMKaluoAP6GRqJEb4U6W+bxpCuDCjLRs4tAAComIut7rihoUF0zd5///1GH587dy5t27atS7fR0tJClZWVFBQUZNRx+49//MPoevPmzeu0cFtfXy/eJBUVFfLt85ul8X3w9qme3tfdswbQb2LLO9FbG0/SFeOjyddDF7jfFXsydIVENirG3yr/ZlPCfAxZr3nldb0+Lmq0KbWAmlp0W+U45oL/fT3ZOtfbYzM7MZS4Ps93zXEJ/1R0bmuZPf7MmAOOC44Lfl7we2RPzy94jgetiA/Rddyy0w5WHOShZNISV20xCUxZSEbHLQAAqJnNCrdFRUXU3NxM4eHGGZ/8fl5eXpdu44UXXqDq6moRhSDhr+3ubT799NP02GOPtft4YWEh1dXVWeUFSHl5uXjh4+TU/SZo/z5E8xOD6LeUEiqrbaTX1xymJZOiuvz1248Zjk2CL1FBgSGD1Zqc6nXDC9jp4grxOHpzXNRo1b4s+fKYCLceH+ve/sywUVE+lJxdJQal7TyaQQlB6uqEsNVxsUc4Ljgu+HnB75E9Pb/wSXsALYjXRyU4YsetmvNtlRm3DIVbAABQM5sVbiVtt+Xzwr8rW/VXrFhBjz76KK1cuZLCwsJ6dZscp3DPPfcYddxyZIM0BM0aL3r48fH99fRFz33netOa1C0iYH9FciHdds4QCvAydLB25mjRMfF/nnw7bVgcebnZ5scipKWVXJ0PUmNzK5XVt4rva2+Pi5rw92ZHxgFx2dvNmeaOTiB3F2eb/cycP6qGkrNTxOW/chppYmIcaZ05jos9wnHBccHPC36P7On5hQfaAmhBnCIq4bQDFW55fsbm47rCrZebM42LN+yOVAtk3AIAgFbYrHAbEhJCzs7O7TphuQOxbcesqaFmnI37zTff0DnnnGP0uYiIiG7fpru7u3hri1+AWOtFCL/o6c39JYT60uXjomnFriyqqm+i97em033zE8/4dXzdY/mVcv6Uj0fXir2WwP/0MF8PMTCroKJeHIveHhc1Sc4qpZIaXVfxtIGh5OnW9TgLU3p7bOYPj6QnftUVblcfyae7zrGPuAR7+pkxJxwXHBf8vOD3yF6eX/D8DloRHeglGiP45H2WA0UlHMmtoKKqBnF5Sv8QcnNR35qMBzK7OPUREWY5DvS9AQAA7bHZX1E3NzcaO3YsrV271ujj/P6UKVM67bS9/vrr6YsvvqDzzjuv3ecnT57c7jbXrFnT6W3aiztnDSQ3Z9239KM/06mw8sxn9g9klcn5U6NjA8jWwvQDyoqrG6ihyb5ySv84mi9fnpVk3CVuq06DEdH+4vLhnArKKqmx9UMCAAAAsBtcsJQ6O0+X1/doroEWbUw1RIFNH6y+mATGBfUIf133fk55ra0fDgAAQIdsevqT4wnef/99+vDDDyklJUUMFcvMzKRbb71VjjBYvHixUdGW3+ds20mTJonOWn7jbDXJ3XffLQq1zz77LB09elT8f926dbRs2TKyd5zVdNXEWHG5trFZDCo7k+Qs3bRXNjomkGwtzNfQ+VxYZV9bytanGBaxMwfbvnDL5g2NkC+vPty1bGkAAAAA6N6AspqGFrkL1d5tOmbIt52hwnzbtjm3ZTWNVF3fZOuHAwAAoL7C7aJFi+jll1+mxx9/nEaNGkWbN2+mVatWUVycLmszNzdXFHIl77zzDjU1NdHtt99OkZGR8hsXayXcWfvll1/SRx99RCNGjKDly5eLaIWJEyeSI1g6sz95uOq+rZ/tzKDcM5xBTs4slS+roeM23M+QW9eVjmGtOF1aQ0fzdJEUI2MCxPYsNVgwzFC4/e0QCrcAAAAA5hSvyLnNcIDdTeW1jbQ3U9cY0i/Um2KCDP9+Nefcnuk1EwAAgMMOJ1u6dKl4M4WLrkobN27s0m1eeuml4s0RcUbsdVPi6Z1NaSJq4LU/TtBTFw83eV3erpWsX1j5e7pSgr4jQC2F2/yKOooKVV8mVk9sOGrotj0nUR3dtqxfqA8NCvehY/lVtCejlAoq6ihM8T0AAAAAgJ6LCzasrzOKq2lCQrBdH84/TxSJTF82XcXdtixSH5XAssvqaECYr00fDwAAgCn2URUDI7ee3Z983HU1+a//yqLMYtNn97NKakWWrNRty8NF1BSVkF9hPx236xWFWzXk2yrNV8YlHDHk8AIAAABA7ySEGDpO04vsv+N2U6oiJkEl0WBnikpgOWXouAUAAHVC4dYOBXq70ZKzEsRlnpT6yvrjJq+3VxmToIJ827YdtwV2EpVQ09BE204Wy2f2h0T6kZrMU8QlrEZcAgAAQI+8+eablJCQQB4eHmIA75YtWzq87tatW2nq1KkUHBxMnp6elJiYSC+99FK763333Xc0ZMgQcnd3F///4Ycf8N3RdMetfRdueTeflG/r7uJEExOCSM2UUQko3AIAgFqhcGunlkxLEPEH7Ifk03SioEr1+bYszE/ZcVtH9mDr8SIRW8FmJYaporNZiQvJsfr8se1pxVRW4xiDMwAAAMyF5ynwINyHHnqIkpOTadq0abRgwQKjWQ1K3t7edMcdd4j5Djyg9z//+Y94e/fdd+XrbN++XcyDuPbaa2n//v3i/5dffjnt3LkT3zgNiQn0Iif90i+9pJrsWWp+JeXp1++T+gWTh6szaaXjNhsdtwAAoFIo3NopPw9XunV6f3GZY6ZeWnes3XWSs3T5tlxHHKWSwm24r/113P6hiEmYrbKYBMaF5Pn6rlvOJFuLuAQAAIBuefHFF2nJkiV04403UlJSkhi+GxMTQ2+99ZbJ648ePZquvPJKGjp0KMXHx9M111xD8+bNM+rS5duYM2cOPfDAA6Ijl/8/e/Zs8XHQDjcXJ7mzk6MSuCvVMWIS1J1vy6ICDK87csvso2EEAHSySmrooR8P0eaTupoH9A43onEM54403U5isC4Ubu3YdVPiKMTHTVz+9UAuHcmpkD9X19gsvz8g1EcUetUgwMuV3Jyd7KZw29LSKufberg60ZT+IaRG85Q5t4fzbPpYAAAAtKShoYH27NlDc+fONfo4v79t27Yu3QZ36fJ1p0+fbtRx2/Y2ubjb1dsE9YgL1u1sqqpvohL9fAl7JMUkaGEwGfP1cCVfD91ckJxyZNyCYymtbqBPd2SIAqc9evCHg7RiVxY9vCqNKmobbf1wNI9/Vu777gBd8/5OOpZfaeuH43B0f6nALnm5udDSGQPo8V+OiPdfXHuM3r9unLh8KLtc5N+qKSZB6v7kuITTpbVUYAdRCYdyyqlQX4Ce2j9EtVvGRscEULifuxgIt/l4kXhhIQ24AwAAgI4VFRVRc3MzhYeHG32c38/L6/xkaHR0NBUWFlJTUxM9+uijomNXwl/b3dusr68Xb5KKCt1J+paWFvFmaXwf3FFqjfvSEl0kla5L6VRRFQV6qaNhwpx47fhXeom4HBvkSXFBnmf8OVDDzwvHJaTmVVJuWS01NTWTk5RrYUNqOC5qhONivmNTUddIl7y1nU4VVVP/UG9affc0VfzsmwvXEbaeKBKX65tbadvJIpo/LNLWD0vTv0vbT+qOJ9eQvtiZQf89fwjZmxYrP/d2535QmbFzV02Mpfe2pFFueR2tS8kXubajYwMpOdOwZYDfVxMeUMaF29KaRjkbVqvWpyhjEoxffKkJ/6HmrttPtmeIY74xtYDOHxFl64cFAACgGW0z7Hnxf6Zce45GqKqqoh07dtD9999PAwYMEBEKPb3Np59+mh577LF2H+ficF1dnVVehJSXl4vH6eSEjX2SEHfDevZAWh5Fe9hf9xdvR25s1jWFjI/2ET9zWvh5CfF0olTunG9updSMHAr2tn1RXQ3HRY1wXMxzbPg69/+SJoq27GRhNa3Zl0Zjon3JXnyVnE/KVJq1B0/TmDB1NlBp5XfpcLahfvT93tN0w5ggEQVkT1qs/NxbWdn1zmUUbu0cd3jeOWug2Cogdd1+umQiJWepbzCZhDs/JUXVjRRN9pFvy4PJ1Gy+vnDLfjuUh8ItAABAF4SEhJCzs3O7TtiCgoJ2HbNtJSQkiP8PHz6c8vPzRdetVLiNiIjo9m1yDu4999xj1HHLWbuhoaHk5+dnlRc9XFjm+0PByWBoXAvRlmxxubTRmcLC1L0m7In92w2F2vkjY7r0b1TDz0tcaAH9eapcXG5w8aawMNu/LlLDcVEjHBfzHJu3N52kTW1yXzdn1NL8Mbr5OPbgj5MnjN7fm1Njl8+71vpd4g7t3ApDzE9FXTPtK2ql80fY1zFtsfJzr4eHIWf9TFC4dQCXjYsWT9CZJTW05XiRCJSWOm693ZxpYJi6zq6FKQaUceFWq/Ir6uhgtm4hODTKjyL8u/6LaQsTEoJExnBZTSNtOFogcpDVGu0AAACgFm5ubjR27Fhau3YtXXzxxfLH+f2FCxd2+Xa4w0MZczB58mRxG//4xz/kj61Zs4amTJnS4W24u7uLt7b4BYi1CkD8osea96cFCSE+8uWMklq7Ozb8syvl2/KsiikDuv6i19Y/L30DdfnDLLeinkar5Htj6+OiVjguvTs2f54ooufXGIaW8+9rQ3MLrTqYS48tHEruLtp/7ZdeVE37T+teg0syimsou6yOYkRsDXT3d+lEga47W+mbPafpwlF97e5g9rHic2937gN/CRyAq7MT3T17oPz+f1ceEtEJbGRMADmrLM+GM27toXCr7LadrfJuW+bi7ERz9HEONQ3NtPW4LscGAAAAOsddru+//z59+OGHlJKSIoqtmZmZdOutt8qdsIsXL5av/8Ybb9DPP/9Mx48fF28fffQRPf/883TNNdfI17n77rtFofbZZ5+lo0ePiv+vW7eOli1bhm+HxsQEeZK02k4vbv8CWOvSiqpFzBkbnxBI3hqak9A3wFO+nFOGAWVgv/jn+64VyaQfcyPqA+cO1w2orqhroo2pZ4430YKf9+eY3MkrZd5C96Xktd/Szw2B9jrYTo1QuHUQF43uK4LH2bH8KtXGJLBwO+m41Uq+rdL8Ybo/3uz3w50PVAEAAACdRYsW0csvv0yPP/44jRo1ijZv3kyrVq2iuLg48fnc3FxRyFVux+NiLl933Lhx9Nprr9Ezzzwjvl7CnbVffvmlKOqOGDGCli9fTl999RVNnDgRh11juIst3NdNXOZcSe5QtSebFAWf6YNCSUt4OJkkp0z7g5FbpKocgEJ9UzMt/XwvFVc3yL+nXLhdONrQMfnTPkPBU6v4uXWlonD7n3OT5MtoSuq5o7m6QadsxuBQo65bsA7tnA6FXuGu2nvmDKbbv9hr9PHRMeoaTCYNJ5MUVWmzcMsxA1tP6BaxIT7uNLyvP2nB1AEh5OPuIiYD8zC7xuYW0bENAAAAnVu6dKl4M4WLrkp33nmneDuTSy+9VLyB9kUHuFNeZQNV1jWJWKpAb10h1x5s1McksBmD1b/LTCkqwMMuOm65YHXHimRRnHr1ytGaK6CDZT3xyxHal6WLSowO9KRXrhglhlNPGxBCwd5uoqDLr/0q6xrJ18P2A/p6KiW3kk4U6JrUJsQH0byh4eTj5kxVDc3058kicWKD/93QPUcVHbf/OS+JNh8rFJ3b3+zOEicA1LaD2x6hIuNAFgyLoKRI48EUo9TYcWsUlWAIwdaS7SeLqa5RN0F4ViLnfGnjyYwzbWfqYx34RcXOtBJbPyQAAAAAzYsJMKxvT9lRXAI3K+xMKxaXI/09aGCYIc9XC7hhRFqm55Rrt3DLndy/Hsil8tpGen9Lmq0fDqjId3tO02c7dDs+3Fyc6O1rxlKAl5sclXf+iEhxub6phX4/pO0dlyv364ZAsgtGRYl/39gYX/m17eEcQ+codA0Xu1P1hVuOlhkQ5iufoOP4zS3H7SNiQ+1QuHUgXDy8d+4g+f3YIC/RDao2yuFkhRqNSlh/NF9zMQmS+UOVcQm5Nn0sAAAAAPYgWtHZmWFHhVseeswFH8ZdnjzYRUt4Z5m020/LHbcnCw0/UwdOl9tdHAf0zOGccnrwh4Py+08uHEbD2uwEVcYlrNRwXAIXGH/WP34Xpz503nBdQXpCrKFxbYt+Ryx0XXZZrdiNy5IidUXwReNj5M9/vTsLh9MKULh1MLMSw2jhqChxZvnms/uRGvl5upC7i5NmoxJ4ofSHPt+WJ3WeNSCEtIRza6Tjv/pwPrKyAAAAAMzYcZteZD8DXZQDjZTZh1rCncKsqKpBdBBr0akiwwwT7rrNKLafnzHomfKaRrrts73yiZUrJ8TQ5YqCm2R0TADFBXuJy9tOFlFBhTaznvdkllKOfgD7WQNDKEgfRzMhTldsZMi57b4URb5tYoSfXFOSGgDXHsmn4qr6Xn734ExQuHUwfBb85UWj6OgTC+iaSbqBGWp8jNKZ72INdtxyto70R2NS/2BNTdZl/HjP1udiFVbWU3JWqa0fEgAAAID9FG7tqOOWsw4ZZxxO0VizgqkBZbz1V4vSFB23bP9pXZ4pOCbuPr3n632UWaIr4I+I9qdHLhja4WvvhSOjdF/XSvSTYriXlqzcZ4hJ4EY1SbS/u9jiz3anl1JtgzZPzqgh3zZR33HLOxX+NlbXqd3Y3Eo/JBuOPVgGCrcOiJ+cOd9GzaSc24r6Zs2d+f5DGZOgz4vVGmVcwm8HtZ11BAAAAGBrUf7uJKUIpNtJN2RmcQ2lFekKhmNjA8lPo0ONpKKOluMSpO+DMi4BHNcbG07Q+qO6HaABXq705tVjxCyTjlw4SttxCTxQe5X+NauHqxPNGRJhVPs4a0CwuNzQ3EK70jHDpTuO5rXvuGWXjzN0b3/5VxbiWSxM3dU7cFhh+o5bVlCprdZ76Y+ktI1Ai2YnhYlsIPb74Tw8EQMAAAD0AsdQSVvy7SXjdtMxw5p3ukZjEtp23Gq1cMvDyZQOoOPWYW06VkgvrjsmLvPJolevGE3RgboohI4MCPOhYX11RbmD2eV0stAQvaEFW08UUYl+qDnPl/Fps+NVGV3454kiqz8+LTuaWyn/DYvXR2qw/qE+ND4+UFw+UVBFezPR5W9JKNyCKoX5GraT5WsoZ6eoqp72ZemetAaH+1JMUOd/JNWKJ41O7q87M3m6tBYTOAEAAAB6KS7IW55uXlajKzJovUAk4cFk9lG41c7rDkllXaOIN1M6lF1BTc26bFNwHKdLa+juL5NJmk33zzmD5Ai8M7lI2XWrsa3vPym6hKXYB6UpA4LlHQ9bjqNw21UcK3FKf6JxULgvuTgblw8XjY+VL3/9F4aUWRIKt6BKUsYtK6jQTsfthqMF8h/KWUna7LaVzB9m2GKy+jDiEgAAAAB6Q9mtpPW4hPqmZtp2slhc5iE1QyINW2i1JirAQ9Mdt227bVltYzOd0FjXJPQODyFb+kWyODHEzkkKo6UzBnT56y8YGSUXN3/cl6OZHZdcXFyjf63q5+Fisvs/0MuNhkX5y8O22p7oANOO5VfKtY3ECMOQN8m5wyPk7uafD+RQVX0TDqWFoHALqs641VpUwh+KmAT+Y6llc4aEy3+8fz+Ewi0AAABAb8SHKAq3JoptWsJDfmr0Q36429ZJH7Gl+Yzbcm0XbkMVuxYPZCHn1pG8sDFLdFqzuGAveuHyUd36veTGqSn6HZc81CxZv4tU7dYfzadq/XPRgmGR5O5iOsv3rIGGuIRtJ9F12+18WxMn57zcXOhC/SA4/nvw6wHt5SNrBQq3oErhvoYz3/mV2tiy1NDUIk/WDfRypVExuswXrQrz9aBxcbp/w/GCKpFdAwAAAAA9Exesi0pg6RrPuTWKSdBwvi3z93QlT/3gpmwNdtyeLDT8LF0wwrBNfD9ybh3GV7uz6KdDRfJwrreuHit+rrtroQbjEoxiEvRFRFOmKXJuEZfQNSn6fFuWZKLjli1qM6QMLAOFW1D/cDKNRCXsPFUsn+2bOTiMnDXceSCZNxRxCQAAAADmEKeYfZCh8aiEjam6XWa83FUWRLSIp85LcQkclaCVLeKmOm65+03aMXfgNDpuHcHB0+X0yE9H5Pefung4DYny63FUnpuLrkT0y4FcalR5TnJ5TSNtTC2UZ+RM7KfrGDZlTFygGLDFth4v0tzvua07bgd3ULgdEe0vxygkZ5bR8XxDsRfMB4VbUH1UQr5GCrfrUwwxCVrPtzVVuEVcAgAAAEDP8fblznJJtYKLm8fydTuxRsYEUKC3G2mdNKCsrrGFSvUZoVpxqqhKLqJz1jBPe5eKLpxFDPartLqBbv1sj9j5ya6ZGEuXjInu8e35ebjKcX/F1Q209YS6IwV+P5xLDfri8vkjojptnPJwdaYJCUHicl5FHZ1EBnSnuLB9NK9SjmAJ9jHUZ9qe+Fo03tB1+xW6bi0ChVtQJQ65lrYsFWggKoGf2Dhfh7k49eny9E61iwnyomF9dWdsD2aXi7OaAAAAANB9XDiI9Nd1dmZoOCpBigaT8m3tgVHOrYbiEvg1yCl9VAKv27lbkjvgWGNzq9FWZ7AvzS2tdPdX++R4j2ER3vSf85J6fbtaikv4ab8hJkHKWu3MNEXOLXfdQse4eU4adGdqMJnSRaP6kpuzrrT4fXK2fCIBzAeFW1AlPnMTpu+61cJwMs5/zSrR/dHkM3l8ttJeDO+rW/xJQfUAAAAA0LuuW+7q1OoJcWlrMpsx2D52mUkdt1or3PLrJCmqrV+ILkN5ZHSA/PkDyLm1W6+sPy6fRAn2dqOnzusnxxz0xozBoeTn4SIurzmSTzUNTaRGBRV1tO1ksfy8OlJ/wqIzZw0wnGhSezexraUoYhKSTAwmU+JdF/OG6XbqllQ30LoUXUMbmA8Kt6Ba4fqpqJV1Tar9gyFZf1QRk5BoHwtYCZ+9l2SUaLc7BAAAAMDWEvTFNa0OKOPMyz/1BQ8exqs8wa9lWi3cpikGkyWE6CISpI5bti+rzCaPCyzrj6P59Or64+IypwO8csUoCvM1T2SJu4sznTciUlyuaWimtUfUWYTjDF4ppnbhSM52PvN8Ge4cDfHRHacdaSWqz/C1paOKbv0zddy2HVKGuATzQ+EWVEtLA8r+UOTbzk4KJ3sSF2R4gYGOWwAAAIBerKuCtV245eEzlfW6hoppA0PtYhgvk4aTsZxy9ce0SdL0+bYsIdRb7o7j6DaGAWX2J7O4hpZ9uU9+/775iTSlf8dDuXobl/CjSuMSVnYzJoE5OfWhqfphilX1TTix0cXBZIkRZx52xz+D0YG6E2CbjxfKER5gHijcgkYGlKl3AVVW00C7M0rE5X6h3kadFPYgVtFxywsFAAAAAOiZeMWAsgwNrqs2phYYbam2F1H+ho5bLRUcpHxb1l//GoSzlBMjdR1yPICJC1RgH2obmumWz/ZQRZ3uezpvaDjdcnY/s9/PhPggitLncW8+XkTFVepqokovqqb9+m5yHsg3IOzMHaESqXDLtiDn9owdt3wSqH+Yd5eK4pfru265E/rb3ae7/D2BM0PhFlQrTB+VwPJVnHPLOV8t+m0as+0sJoHFKl5goOMWAAAAoOfilVEJRdrruN2kGEzGHbf2IkJfpNJaVMIpxc+Q1HHLRuhzbrmAcvB0uU0eG5h/EN1/fjxEKbkVcqbx85eN7FJEQHdxEe4CfRcrD0H79WAuqcnPPei2NT2gzPB8BgY8XIxP+rD+oT4iPqMrLh0bTdKP49e7s6hFKpJAr6FwC6oV5quMSqjTSL6tfcUkMH9PV/Gm1c4QAAAAADXuZNJaVEJBZR0dztEVjYb19aNQRZOF1nGXaoiPu+YKt2n6wq2nqzOFK147KQc1YUCZffhiVyZ9t/e0/P1++9qx5GvBgdgXKeISVu4zFErVUMBWxiRcMLJ7hdtIf0/qrz/Jsf90OVXUaXNIpCVx0bZJX3SVuve7mhV+tv6EHu9c+PMkBsCZCwq3oImoBJ6Yqkb8h2O7fpqlr7sLjYsPJHuegJxbXivOwAEAAABA93m5uchrXK2dEN98zPAifMYg+9tl1lefc8uvO7QwtIgfo7QbjqPauEuybcctQ86t9iVnltKjPx2W33/20hE0KLzrBbWe4Kzkwfr72JNRSln6nzVbS8mtpBMFVXKkQ1/FYMGuknYLcDfxDv1reeh5vq3SFeMxpMwSULgFTQwnU2vGLQ8vKNJn/oyKDSBXZ/v8lYrRd4fwiTct5X4BAAAAqE28fkBZcXWDprq9lDEJ0+0o31bZLSbFC+RpYEAZF9K48NQ2JoENDPMRXZls/2ldFihoE+fLLv18LzU2677Xf58aTxd2s8u0pxaONtzPyn3qGFK2cr/hcUhxDt11liLndusJdIV2lG/b3Y5baVB7sLebuLzmcD6VVjf06HsExuyzygT2l3Gr0sKtFIrORsUYzmzbmzjlgDKVnG0FAAAA0HLhlmUUaWNdxQXCLfo8SF8PFxpth+teqXCrlbiENMVgMs47VXJxdhJxFux0aa3qhktB13/v7voymXL1JxLGxQXSg+cmWe3wKQvEP+7LEbtNbYkzU3/Wxzbw0Kzzhkf26HYm9Q8WX8+2YkBZOyl5hsJtUjc7bt1cnOiSMbqYjYbmFvohWR0Ff4cr3JaXl9Py5ctpyZIlNHv2bJo8eTJdeOGF9Mgjj9C2bdss8yjBIfm4u5CXm+5HtKCiXvWF25GKLUn2nMeWqbE8NgAAAAA1iQvRXs4td22W1TTKw324MGjXhdvyWk0NJuvXpuO2XVxCNgaUadELa1LpzxO6rfycKf3m1WOsusMzOtBLxBEwjieQMq5tZU9mqdjxys4aGEJB+s7OntQZRscGyDnR2FFq7Kh+AF6Al6tRfGVXLWoTl2Drgr896PJvfW5uLt10000UGRlJjz/+OFVXV9OoUaNE8TY6Opo2bNhAc+bMoSFDhtBXX31l2UcNDiPE21XVHbf7FIXbETGGIQD2JlafccvQcQsAAADQcwmKjtt0RfFNzTalKmISBtlfTIIy45bllKnztYepwWQsIcSn3edHKAeUZaFwqzVrDufRmxtPisvOTn3ojavGGEUJWsuFo9QTl6C8/4U9jEmQTFXGJeh3E4AumkOaL5QY4Ut9+hiys7tqQJgvjdEXxlPzK8UQOOgdl65eceTIkbR48WLatWsXDRs2zOR1amtr6ccff6QXX3yRsrKy6N577+3lwwNHx4XbzNJ6qm5opqr6JnF2TE1bVw7qz15zKHqYYpKrvYlTbunT2CANAAAAALWuq9I1sq5S5tuebaeFW542L9FCB15aoW5AkzScrC3lbsADyLnVFO6m/ufX++X3H1iQSBMSdJ2v1sZxBDwYramllX7an0P3L0gShWRbDONbdTBPXPZwdaI5QyJ6dXu8c+DldcfF5S3Hi2jR+FizPE6tS1XEJHR3MJnSFeNjaW9mmdx1a8+xkqrquD18+DA9//zzHRZtmaenJ1155ZW0c+dOuu6668z1GMGBhSi2PxSorOv2eEEl1TQ0i8sj7bjblkX4eZCrs+4PNDpuAQAAAHouXhGVkKGBqISS6gZ5wBV3YCkLnPZEaxm3UlRCiI8b+XvqdikqxQV7yR/njjdsV9aGmoYmuvXTPVRZ3yTeP29EJC05K8FmjyfQ241m6IcR5lfU0840XXSDtfEQMX4ukgZg9bahi09s+OpvY9vJYpGfC23ybbs5mEyJf2693XQDEn/enyN+rsEKhdvQ0O6dWe3u9QFM/hz5GBYh/IdCTRxlMBnjs6oxgV5y4RYLPwD7xYvXHw8WUkNTi60fCgCAXfJyc5GH8Goh45aHkkkRhfYak8B4EjoP1tFC4bayrlHezmyq25bxFmcpLqGoql4ecAXqxa+xHvj+oNhezgaE+dD//jaiR9vVzWnhKN2wKfajjeISftIPJROPRzE0rac4p5uHlDEuCB/R57o6Oinftrcdt97uLnSB/vvEO6d/PZBrlsfnqLqVbL106VKqqjJsyfj000+N3i8rK6Nzzz3XvI8QHJqUccsKKtW12NinyIqy58Fkkhj9gDLuMi6q0p3tBAD7wlmL13/0Fz2zPpM+2Z5h64cDAGC34vVxCbym4iKcVmIS7Llw6+TUh6L8ddFnuSrPuE0vMkRsdFS4bZdzi7gE1eO110p9gZK7Fd++ZqwogNnaOUnhcvfkbwfzqK5Rt+vUWmobmkXmL/PzcKHp+g7g3uK4BGVHLxAd1Xfc8rmCQeE977hll7cZUgZWKty+8847VFNj+CNx++23U0FBgfx+fX09rV69uhcPB6Djwq3aBpRJHbcc8TOsr31HJUjbrSSISwCwTxtSC0SGGVuXkm/rhwMA4CBxCerNueXtw5v1hVsvN2cap58wb6+kuATepl6h4oJ6WpGheapfaPvBZJIRiuYSDAhStz0ZJfTEL0fk95+/bKTouFUDTzdnmjcsQv7d2HDUUAOyhvVH88XMG7ZgWCS5u+iKyL11ltGAMhRum5pb6Ji+25uHaPL3vTdGxwTQQP3P8O6MUjpRYHjeAgsWbttuj8Z2abBu4VY9UQl81k/awsJnotRwJtTSYvUdtyyzRP3b+gCg+3Yocsv2ZZVZvaMCAMAxB5Spd13F24elnVZT+ofIUQL2Sis5t2mF1V3quMWAMu0UzHgYmXTy/Oaz+9GC4ZGkJhfZMC7BKCZhVO9jEpS/OzxknO1KL3H4dS8Py6zXR6Ul9iLfVsIRH4sUXbff7EbXbU/Z919e0LwQRcatlOOkBodyyqlZ/4fVEWIS2hVui9W7kAWAnndV7TxVIr/f0NxKezNKcTgBACwYlaD2jlujmAQzbU9WM60UbqXBZKxfJ4XbCH8POU/5wOlyDGBSqR/35YiiGRsTG0D3zRtMajOlfzCF+Oh+ljYcLaTyGut0pPP9bEzVPQ/xz/LEfrpcWnPgwuLUAbrb49kOf6Ub1sGO6GieefJtlS4ZEy0POf9u72lqbMYMjZ5A4RZUTa1RCcrBZCPtfDCZJFYRlZCBjlsAu5OSV0FlbRbh2200ORgAwJGiEpRFOLXZmGrYEj3DjvNtJVLGLctWcc6t9DPDkW3KNXpncQmVdU2q7u525G7b1/84Lr9//4IkMThLbfgxXTBS1wXc0NxCvx2yzrCp3w/nivtj54+IEkOzzemsgYbnNUePSziaq9tRzBIjet9xy4K83WjuEF3MBu/eWJ9i3ZgNe9Ht/d3//e9/yctL98ehoaGB/u///o/8/XX5nsr8WwBz8HR1Jl8PF7HQKFBR4Za3EEtGxThex21WCX7XAezN9pPFnUYnAACAZaISMlRaTCuvbaS9mbo1b79Qb3lQrT3TQsctxxWmFeqyIqMDvc6Y9zky2l/Oreeu284yccH6fj5g6Lad3C+YJiSoN0ea4xI++jNdjku4YkKsxe/zp/2GmIQLzRiTIJna39DB6+gDypQdt0mR5um4lYaU/XpQV+j/6q9Mmq/PSwYLFW7PPvtsSk1Nld+fMmUKpaWltbsOgDmF+7qLwi1n3PJChbc02Np+/VRWD1cnGhTuGIsfLzcXsT2mqKpe1Vv6AKBndqQZtod5uTpRTWOLOEnFmd69HU4AAADGfNwN6yqpaKM2204UydFgMwaFkSPQQuG2sLJeHtTUWb6tZISiyYRfw1w02pBVCrbFv1+v/XFCfv+u2QNJzUZE+4ufOe745nit3PJaivQ3/M6YGzdubdM3FvCgbD4JYW7BPu40NMqPDudUiLfiqnrxMUeUou+45b9PUvavuYbA8W6GnPI6Eb+TV14nYlzAQoXbjRs3dufqAGYR6utBJwqrqbaxWUyx9PMwxCfYAj+ZZ5XoFnLD+/qrciuLpfAfTH6BwXnDKOYA2NcLh52ndAvjIC9XOqufP/10qIgam1tpT0YpnTXQMHUXAADMIyFEt67iQlxVfZN4sawmUq6ko+TbsqgAQzEhV6VRCWnKfNvQLhRu+xqKXdxxC+rxy4EcedAcd9pOVnR/qhE3UPFwsJfXHSeeW89Dw26Z3t9i9/fLgVxxP2zhyCiLNXDxOpeLtuzPk8V04Ujzd/aqXUVdI2XrT1YNjvAlJzNGUnC8xWXjYuiV9ceJzwV+uyeL7pil7pMUamOWilNTUxNVVem2awCYW7if4YxXQYXtB5QpFzyOMpjMZFxCqTq7QwCg+47kVIidDYyHPoyLNuRabU9z7G1jAACOGJfAu9ykwWTuLk40UcXbt829wyzQS9ckIhUx1EYq9J1pMJkk0NtNXsMfzikXmaqgvm7bZSrvtlXGJSiHqlnSSgvHJEimDVDm3BpOWDmS1Dzz59sqXTYumqS6+1e7szAo0ZKF21WrVtGnn35q9DHOuPXx8aGAgACaO3culZZiAjWYV5hR4db2Z76THXAwmanCbaZKt/UBQPcpi7OT+gXRmBhfkxEKAABgPvHKwa8qW1cdy6+iPP26m7sAPVwdJzJHikvgf78UFaEmp4oMDVNdzavlLe6srrFFfG/B9lYdzKUTBbrvxbi4QNV320riQ7zl18ApuRV0LN9Q8DOn9KJqeSD4kEg/GhBm/mKiZFx8oDhBJQ0o4xNXjuZoriHfNtGM+bYSzuPmyATGu5cxR8OChdvnn3+eKioM39Bt27aJYWUPP/wwff3115SVlUVPPPFENx8CQOfCfQ1blvIrbV+4lf6AONJgMmVUgiQDA8oA7IayODspIYhCvF3lLh5+zquu13XjAgCAeQsgEs6MVJONqYbJ39MHOUZMQtvCLRdtC1Tw2qMt5c9KVzJu2+4SPKCf1QG20yK6bY/L7999zkBVzHHpqosU3a8r92Vb5D5+tlK3LeMTU+PjdbsKOIdVGUfiKFIUHbdJFui4ZYvGx8iXv/wryyL3Ya+6Vbg9dOiQGEgm+fbbb2nOnDn00EMP0SWXXEIvvPAC/fzzz5Z4nODAlFEJPKDMlvjsmzSYLNjbjaIDLRfGrv6OW8f7gwZgj3jL5K5TusItD8oZEOYjd96Kz7focm4BAMC84lUclSDFJDhk4VYxNEeNA8qkqAQekhzh59Gtjlu2Hzm3Nvf74Ty583lMbIDciagV54+IErmlbOW+HLN3qPLtKWMSLrBC5qxyngN33Tpyx+0gCxVu5wwJl6No+HegvKbRIvdDjl64rayspOBgQwv/1q1badasWfL7Q4cOpZwcy+acgOMJ9VUWbm171juzpIbK9E8wvEVES2dGzSFW0XHLxwIAtO9QToUYiiMVa6XntUn9DH/vt6fpBpcBAIBldjKlqygqgXdZ/JVeIp+072pXp7113LJslQ0oa2xukdfgCSE+XR4gNKyvP0lXVe4eBNt027663tBte9dsbXXbSq/Pp+qLzadLa81+gj8lt1KOkZgQH0R9Fb+TlqIsnm89UeRwP5NSxi03pllqGLy7izNdPDpaXG5oaqEfLdStTY5euI2KiqKUlBRxmYeR7d+/n6ZOnSp/vri4mLy8DAsQAHMIV5xJtvVwsn3KfFsHG0zGQn3cyVOfcYaoBAD7sP2koSirzFdTDqJBDhUAgPn5erhSiI+bnOeoFttOFlNjc6vcbau1opI5C7dq67jlIhnvhOnqYDKJt7uLvKMmNb+S6hqbLfYYoXNrjuTRUX2RjBuBtNrRroxLMHcBbuV+w+1dYOGYBAnn6PKOWrbjZLFDDfHj55XqBt1zQmKE+fNtO4tLcMQ8YYsXbi+99FJatmyZGFB20003UUREBE2aNEn+/O7du2nw4ME9eiAAHQlTdNzaOmfKqHAbY9hy5Ch44S7FJZwuqcU0SAA7oOymVXbZcjeF9CLvwOlyuSsXAADMJ04fl1BQWU81Dep4nt10zHHzbdsWbnNVVrhNKzQMFutuJ/QIfdMJZ/cezjFsiwbr4SLVK+tPyO8v02C3rWTu0AgR18F+PZArusHN1f358z7dLm4Xpz503vBIsgbuXp+i77qtrG+S4xEdQUqe4fkgKdJyQ+DY4Ahfo+F2h7LxXGT2wu0jjzxC48aNo7vuuov27dtHn332GTk7GyaMrlixgi644ILu3CRAl8LC/T1dVZFxu9/BO25ZjL5w29DcIk8bBgBt4kX2bv12WD5J1rZ7Z7K+kMsv8qTrAQCAhQa/qiAugQtLG1N1+bZuzk6amXRvTn1VHJWgHEzWL7R7hduRipxbDCizjbVH8kWxSsodnjFYuydGfNxd6JykcHG5tKaRNitysXtjT2apGBAm5c4G6btgrWGaIi5hiwPl3B7NNQwms3THLbtC0XX71e5Mi9+fPehW4ZZjELjbtrS0VEQmTJs2zejzGzZsoH//+9/mfowA8oAyzri1VTs9Fzg4C5LFB3tRoBX/iKj1BQZybgG0jTtpa/Rbo/jFeduuD+TcAgBYVoJiQJka4hJ4mjpvm2XjEwLFFntHwztOuNNPjVEJymn3Pe24lf7+gy26bRXZtrO0220ruWhUX/nyj/ou2d5aqYhdWGilmATJVAcdUHZU0XGbaOGOW3b+iEg5fnFlcg7V6l+LgJkKt5bw5ptvUkJCAnl4eNDYsWNpy5YtHV43NzeXrrrqKhHH4OTkJGIb2lq+fLl4Amz7VlenrrOl0D1hvrqc2/qmFqqotc02Mg7s5hBtJrX3OyIpKoFlqqAzBAB6TpldK3XXKk3sp8y5RcctAIC5xSmKb2oYULZJ323rqDEJzNmpD0X461575JSrNyqhX4guzqiruCDj6qwrFDrSNnC1+ONogRxRMayvH81OCiOtO3tQKAV46XbGrj2S1+tYLW6UWnUwT1zmGIY5QyLI2t320u6z5KwyqqzTDSW3d1LmsruLE8UrTiZaMt+di7dSLMVvh3Itfp8OVbidNWtWl9666quvvhLF14ceeoiSk5NFB++CBQsoM9N0u3R9fT2FhoaK648cObLD2/Xz8xNFXuUbF4ZBu8L0Hbcs30Y5t44+mEwSi45bALscTKbsrpWE+LjToHDdC8ND2eUOs4AF+7dr1y5qbjZ0eLTdzcNrzq+//tpizQjff/89zZkzR6xred06efJkWr16tdF10IzgeB23GcW277jdpNjuPGOw9gtLvc25LatppGoVZbxLUQk8RMlfXzDrzkT3pEjdNui0wmqqwN90q7HHblvm5uIkZ9DWNbbQmsO6omtPbT1RRCXVDeLy7KRwEcdgbRzPIMWE7XSApgXOVk/X/+3h/Fk+cWUNbYeUgRkLtxs3bqRTp07RkCFDROG0o7euevHFF2nJkiV04403UlJSEr388ssUExNDb731lsnrx8fH0yuvvEKLFy8mf/+OB0PxkyAPTlO+gbaF+xkK7wU2yrk1yrdFx62QUWL7zhAA6BneQbA7Q7cgjfT3MIpB6TjnthSHG+wCF0qLiw0nLnhdmZaWJr9fVlZGV155pcWaETZv3iwKt6tWraI9e/bQzJkzxZwI/lolNCM41glxZX6pLdQ1Nss7MfjvwkD9gEpHFKXvuGW5Kum65QKyNO+juzEJEs5VlRxCXILVcG60FE/BxfM5Q3TZsPbgotHmi0v4SfH1C0daNyZBcpYi55YLyfbuWH4VSeeuEyMsH5MgGRsXKOd07zpVYvO/f2rXrVMYzzzzjDj7/80339DVV19NN9xwAw0bNqxHd9zQ0CAWqvfff7/Rx+fOnUvbtm2j3qiqqqK4uDjRSTFq1Ch64oknaPTo0R1en7sq+E1SUaHbwtDS0iLeLI3vg8/CWeO+tER5XMJ8DHmyeeW1NjlWUsctZ14lRfjY9Ptly5+ZKH934hPE/ASfWVytqp9b/C7huODnpeuSM0tEdwSb1C9IPKdIzyvK55cJCUH08fYMcXnbySKaPsiwoHUkeH5Rz3Exx3217bA1lZ/fnUx9ZTMC42YE7qDlZoSnn3663fX580pPPfUUrVy5kn7++WejNavUjAD2iwfw8vAd7jKz9XAyLtpyLJkUk2APHYG97biVBpQNCLNeQaMjysJGTwu3vGvwM9KdUNp/upymKIpUYJ1u27tnD7Cr362xsYEiYiC7rJa2Hi+kwsp6kRPdXZxzKnXs+nm40HQbDW6b1D9YdJ1yw8KW4+YZuKZmR/XD8qw1mEzCvwM8pOypVUfF+1/vzqJ/z0+02v3bdeH2vvvuE2/bt2+nDz/8kKZOnSryZrmAy9mz3BXQVUVFRaKwGh5ufLaJ38/L63mLfWJioiguDx8+XBRguUOXH+f+/ftp4MCBJr+GF9SPPfZYu48XFhZaJRuXX4CUl5eLJ3XO7oX2x8W91VBYT8stpoKC7m0N6q3q+mY6UaDLlOof4kkVpcVkeIqzPlv/zIT5uFJ+ZSOlF1VRQUEBqYWtj4ta4bjguJiy/qAhT2poiKv8u9z256W/r6FItvVYPhWMNeTeOhL8HqnnuFRWGqYfW1JXX1iboxmBjyP/u4KCgnrVjADaxENvuXCbV1EniheebrqhLbaNSXDMfFtThdtclQwoUw4m6xfas25o5a7BA8i5tYrNx4vkBiDuaJxr5dxWS3Ny6iOGiL258SS1tBL9ciCH/j41odu3s/5oPlXrh1QtGBYpoj1swc/DlUbFBNCejFI6WVgtOu4j/Q3PB/aab2utwWRKl4yJpv/9nkpNLa307Z7T9M85g8jFGa/hTXHp6fYyfuOiKHffvvHGG3TvvfdSTk5Ot4q3phbFvPDvzRmoSZMmiTcJF23HjBlDr732Gr366qsmv+aBBx6ge+65R36fC74c2SDljlkaL9b538z3h2KT6eMyqIHP2um2MFa3uFBYWJjVcyClvptxCSFWv3+1/cwkhPhSfmUJldc1k4dfoPgDpwa2Pi5qheNi3uPCsSm8nXSiiUxYLTmYf0q+PHdUPIUFepk8LvxsNzgiTQxoTC2oUdXvvDXh90g9x0VtcwvM0YzwwgsvUHV1NV1++eW9akbALjJtdqZzVM3eTF1h51RRlVW3q7bdzs2424x3Yli6k17NOxki/Q0dg9mlNVbfVWDquJwsMBRY4oM9e/SYEoK9yMvNmWoamsWAMjUeey3+vHTabbvumPz+HTP780ephSucdnRsLhwZKQq37MfkbLpuclyvYhIuGBlpln9LT4/L1P7BonDLNh8rpMvGRpM9UR6XFEXH7aAw6+4qDvJyFUP6Vh/OF53afxzNp3OSbBcj0mLl36Pu3E+v0p737t1LmzZtopSUFBGZ4Ora9RdyISEh5Ozs3G5Byx0/bRe+vcEvIsaPH0/Hjxu2J7Tl7u4u3kx9rbVehPCLHmven1ZIxyXcz3CWq6Cy3urH6UC24QmNz8Cp4ftky5+ZuGBv2nFKl415urSOhvXt/nYYS8HvEo6LJX9edqYV01Xv7xTbpz64bpwYnKBFXHiWigS8vS022KfT48I5t1y45dcZezLKNPvv7i08v6jjuJjrfo4cOSKvQ3mhfvToUdHhKhVju6unzQgrVqygRx99VEQlKE8M96QZAbvItNmZHuJuKOIcSMuhIKdAKz9CoszSOnkr/vBIb6qrKKW6CsfdyeDRbOiyPZlXZtUdZh0dl5TThkFJ/k71PX5Mg0M9KTm7inLK6uhoerYonmiBmn9eOrIrs0Jeb/UL9qAxYU4W+Vmy9bEJ6EM0MMSTjhfVigiO3amZFBvY9ZOsFXVNtCFVd1xCvF0pwbvJLMepp8dlSLCh23f9odM0PcYQ22gPpOOiK9yWy8e9qbqMCqwcNTtvgK8o3LJP/jxJI4JtFyPSYuXfo+7sIOt24Za7avnsP7/x2f9rrrmGdu7cKQaWdYebm5uYuLt27Vq6+OKL5Y/z+wsXLiRz4YO+b98+0a0A2hXm525UuLXlYDIu3Do65SCNzJIaGta342GBAPbk9Q0nRNFWmoCq1QImb9mTcgwn9z9z5/CkfsG0fFu6vANBq/9uAKXZs2cb5dief/754v9cbO3ODrDeNCPwUDPOxuUdbOecc06vmxGwi0ybnelD45qIdujia0qbXK2+s6u+qZme+X6X/P6cYVFWeQxq3sng6dfIp3fE5dL6Vqt+Tzo6LrlVJ8T/+alp9MDoHm8lH5tQIgq3LKfOlRLjbbuT0B5+XkzhvyOf/GAYerlsTiJFmLFBTW3H5m/jquiZ31PF5T9P19O4wbFd/toNu7OosVn39/iCUX0pMiLcpsdlZnAI+fx0gqrqm2nP6WoKCeGvt59cYum4NLv7UkWdLp5iSJS/TXYVXxASSv/bkEV5FfW0Pb2CyMOPwhSD6a2pxcq/R93ZQdatwu25555LGzZsEJldzz33HJ133nnk4tLzpl2OJ7j22mtp3LhxInrh3XffFdN3b731VnnxmZ2dTZ988on8NVyEZdwRwRm0/D4XgaXCMWfVcncCbyHjwjJ3JPB1OM4BtIsXJoFerlRa00j5FZbPHW6LtxIxH3eXHmdK2ZPYIOPCLYAjOJRdTluOG7rweOtUTUMTebn1avOKTXDxVcLdtGfCW2aloYQ7Thm+FkCrTp0yRIX0Vk+bEbjTludE8P95TW2OZgTsItNmZ3pCiI/RusrahZfHfzksdwVG+XvQVRPiHH7Xob+XO/l6uFBlXRPllNdZ/XvS9ueFf/+ljujoQE/ydOt5l6wy5/ZgdgWdo6HMVS3tfNl2ooh267fb9w/1pvNGRFm0+GfrY7NwdF96dnWqWCv+tD+Xlp0zqMsnQH85YJi7sHBUX7P+G3pyXNydnETTwrqUAiqubqBjBdU0JMp6g7usgY/LsXxDe21SpJ9Nfnb4Li8bF0Ov/aFrjvl+Xw4tnTGAbKWPFX+PunMf3Xq1+fvvv1NkZKQornKB1NRALylCoSsWLVpExcXF9Pjjj1Nubq6IW1i1apUYwsD4Y3xfSsqBDDwI4osvvhDXT0/XdQKVlZXRzTffLLoe/P39xfU3b95MEyZM6M4/FVQo3M9DFG4LKup7nYXcHVwozi3XFYuH9/UXuV+OTlm4tfUEZABreXezoWuCccfqptRCWjA8UnPfhO1pxUbTc88kwMtNTJrlHKzDORVUXtNI/hrZWglgirTW7AwXSbtyvZ40I3CxdvHixSK3lhsOpG5dT09PsX5laEZwHPHB3vLl9CLrrqs+35lBK3bpXm+5uzjRO9eOo0Bv+9oW3FNR/p6UWldJuWV1IpPUlh13hVX1VFXf1K7Q3xMjozGgzBpeWW/YHXHX7IF2/xqSB3hNTAiiHWkl4iTDgdPlRicJOlJQUUfb9A0FnPc9MlodOznPGhAiCrds64lCuyvcsqN5FTYbTKZ02Vhd4ZZ9/VcW3Ta9v9VqPVrRrcLtI488YvYHsHTpUvFmCscxtKXc0mbKSy+9JN7A/nDLPE89bGhuobKaRqstKqUpoKwrf3wcAf9RlWSh4xYcAP+c/3pQ1w3AC28pLuH3w3maK9xyvu0+fWcVn4ThjNuu4M5cLtzyn+Fd6SU0ZwjiEsD+cLbZ559/Tu+//74YAsZDxyzRjPDOO+9QU1MT3X777eJNct1118nrXzQjOA4+ESbtLEsvtl7A4O70Enr0p8Py+8/8bTgNV0nRRA2iAjwoNV/32qOoup7CfG03GPFUoeHnol+IodDfEzFBnvLPGxfXrNkQ4yh2pBXTTv08EP5+nT8iihzBRaP6isIt+3FfdpdeO3O3rVTiWTgySjU/i2cNDJUv8467m8/mwXL2hWsrEm7QsGUM49QBwfTniWJKL64Rvzvc8QwqKtwCdFWYryHnNr+yzmqFW+Tbtufv6SpvH8sosXKCOYANfLD1lFysXTqjP328LV0MUvgjpUBkA/Y0Z84W9maUihehXY1JUMYlfPjnKTlqAYVbsCd//PEHffjhh/T999+LYuvf/vY3+uCDDyzWjLBx48Yz3h6aERwLD34trSkTu7z4BJuHq2X/ruSV19Gtn+2VcyWXnJVAF4+2r8npvRWlOLHJg7xsWbhN08cksH6hvSvccmFseHSAiHzibeDZZbUUHWhoyoDee2Wdodv2jlkD7L7bVsLNDP9deVisM3/en0sPnZtELs6dbwdfuT9HvnzhKPUUuDneItLfQzwn7zpVYpXnZVsVbl2c+lB/G8dBXj4uRhRu2Vd/ZaFw24b6w2EA9MIVA8ryK+qtnm/LMJjMsOCTum55IduoLwIB2KPS6gaxgGCers50w9QEOkc/nKuyvkne3qXFmISuDCaTTEwIFjm3UicJgNadPn2annzySerXrx9deeWVFBgYSI2NjfTdd9+JjyvjuQAsLb7N4FdL4gLELZ/toaIq3Xp6Sv9gemBBokXvU+uF29yyWps+FinfliX0suOWKbejc9ctmA8X+aS1Fv9eXzhSPcVIazT3zEzUdary88uZ1sjpRdVyk9SQSD8aEGa77fqmXu9yXIIUj7ZHn1dsLxqaWihN38k/IMyH3FxsWxqcNzRC/PywVQdzqbyWB0SCpMvfnfnz59O2bdvOeL3Kykp69tlnMQwMLJJxq8zCsQbOszqQVS4XjiP8bXemXa05t9yFmGPjxSyAJX26I4NqG3XbpReNjxHd/nOHGgZ5rD5kPEleS4PJurMNibfy8qKapeRVUFlNg0UeH4A18MBdHmx75MgReu211ygnJ0f8H8BW4hXFOGWRztx4W/x/fjwkF0t40NXrV405Y1ecI1JGCXFXqi1JBRZmjkHJIxQ5t8omFei9VxXZtnfMGuhwv1sclyBZuc/QTWvKzyrttpWcNVBXuGXKAcX2IKO0jpr0uwkTI2xfMOdu5otH95UL5T8pfjagG4Xbyy67jC6//HJKSkqif//73/TNN9/Qn3/+KQaErVu3jl599VXxeR5elpycTBdeeCGOL5iVcntSQWW91bYlcUdd2yB/4MKtt9U6QwBshbuSlm/TDb/kbW68lZRNHxRKHq66P6Frj+TLMQpqV9PQJL9A446d7p6MkqIVOItMym4D0KI1a9bQjTfeKAaAnXfeeeTsbF/bH0HbA8oyLJhz+8n2DPp2z2lxmf+OvXvtOArCMLIuRSXYUlpRlfw9i1Q0s5il41bfpAK9tyejhLaeKJKbXC5SYTHS0mYmhpGvuy6Rc/XhPLGW7ugkkjIm4QIVdiZP1XfcSgPK7MmJIsPJqER9Y4atcVyC5Ku/DHMBoBuF2yVLllBaWho9/PDDdPToUbrlllto2rRpNH78eJo3bx699957FBsbKwq5X375JcXEGA46gPmjEqyzeMJgsjN33LKMYhRuwT59s+c0lVTrOkvPGx5JMfqfe083Z5oxKExc5nw4HvCiBbzNS8oz7Enov/JrlJ27AFqzZcsWsUts3LhxNHHiRHr99depsNC+XpSBdge/8nAWS+CYmyd+OSK//79LR9rlpHRzDieT2HJ3WVNzC2Xqfya4wO9khrxUHvocoS8AH8ouF7sMofdeWX9CvnzHzAEO120rdU7OH6bbmVZV30TrUvJNXi8lt5JOFOhOSEyID+rysFxrCvFxpyR9UfNwToX8msDuCrcq6Lhl/PdoeF/dSaVD2RXiuQl0uvVM4ubmRldddRWtXLmSSkpKqLS0VGwtq6uro4MHD9Lzzz9PgwcP7s5NAvQoKsFahVvlYLLRXZiK6agvMLLQcQt2iLto39+SJr9/89n9jD4vLUrZ74e1EZegLLZ2J99WMj4hiKTXi8i5BS2bPHmyaDrIzc0VzQjcdNC3b19qaWmhtWvXiqIugDUpc0s599HceKv/7Z/vlbfG3jK9n0Nlb/b0tYeU7Z5TbrvC7enSWvn71tvBZEoj9F23vLtQOfwMeiY5s1QMfJMiSC4eY4gMcDQX6be8sx+TTW95X7k/W758gYo7k6fp4xJ4t9m2k/YTl3Ci0PCcJhWn1YBj6SRf79bNGIFeDifz9/eniIgIcnXVhQgDWPqMl7WHk0lbinnRNkyxpQjQcQv2j7d3Sd3kPJxgmP4MsHIrmKuz7hXdmsP5YsuXlgaTTeoX1O2v56EBQ6P85Um09tR5AI7Jy8uLbrjhBtq6datoQvjnP/9JzzzzDIWFhSH2C6wqwMtNHsxi7p1MYhjZp7vFDhGpEHHfPAwjOxNXZycK10e12bLjVopJMNdgMslIRVPKAeTc9torimzb22cOED8/jop3aIX56l67bzpW0G4uAnd4/6zPv3Vx6iN2tamVNKCMbbWjnNsTRbq/M4FervL3Sg0461iKo/sxObvDqA1H47jPJqA5POkwWJ/BVWiFjFt+kkjJrRCX+4f6kJ8HTlAoRfp7iD+0DBm3YG+4CPvOppPy+9yZ1Ba/wJ7cP0TuZOItPWpWXd8kT47uH+ptlBveHcpO3V2nEJcA9oN3jf3vf/+j06dPiw5cnigNYE08gV7q7jTXi1X+e/bA9wflv1G8Y+q1K0eL3HboelxCUVWDzQoIRoPJQno/mKxtxy2T1gfQ812aG1N13ba85f9vY6Id+lDy84vU0c8RXb8ezDX6/J7MUsopr5MHgKk5Z3tCQpCoQ0gDyrTQqHEmRVX1VFyjm+OTGOGnqvUO11zO1RfyK+qaRCMNEOlSowE0gvOYuFugoLJOnKkzR8ZTR7hoK2VBYjBZe5zZxNuAOIeNC7f8R0xNT/pdxWeA39uSJvJ05g9T79lesK4daSW0X/8iZkikn9HZdqX5QyPkbXG/H86l4SruzP8rvUQeotaTmARlp+67m9Pk6AX83oAWcZftmQQH9/z3BKAn4kO8xd8ergtwDNXA8N7nDn6w9RT9kKzbkuzl5iyGkXF3L3R9QNneTN0OvLzyOvE9srZTihiDBHNGJfQNaLfLEHrmVUW37dKZ/eVCnyPjuIT3t54Sl1cm59DVE+Pkz63cZ4hJWKjimAQps3d8fCD9eaJYNGrwa19zdr7bQmqeIQ4qMVId+bZKi8bF0Pd7dT8jX+7KooWjHDd2RIJnFNDkgDIuqJa22XJhyXzbUTHqLcbYkjSoiYPntbpl+q2NJ+mNDSfp9i+S6XQphqyBzjubjbttOzopMWdIuJx/9/uhPM3EJEzuZ7oQ3RXj45U5t9oYygbQ1vLly2nDhg1UVlYmZjaYeuPPAVhTXLAi59YMcQl/niiip1alyO+/cNlIGqySITRaoRyYZKu4BOOOW/MVjPy9XOUubx681NDUYrbbdiQHT5fT+qMF4nKUvwddOtaxu20lQ6P8xA4vtiu9RH6d1djcQqsO6tbMvCV+zhDDzAi1mmoUl6D9QaYcdyZJilBPvq2yy1kqjvPrlxT9LmhHhsItaIqUM2WNnNt9isKtMgMKTA8o02pcwu6MUvF/7kTcna67DI7taF6F0Xa3znK3Qn3daXycLiv2ZGE1nShQ70CjHYrBZBN7kG8r8fVwlSe+puZXUnGVdTLHAczp1ltvpfLyckpLS6OZM2fSBx98QD/88IPR2/fff4+DDlaVEGJYV2UU925YFHfs3vHFXtJvtBAT7heoOEdSzR23Eu62swWp45a3k5u7W3pEtO41Dhdtj+Wrdw2jZq/+Yei2vW1Gf3J3cbbp41ELbnq4SNEp+dN+Xabt1hNFcsPP7KRw8nFX/ybwaQNC5cv8+O2pcKvGjlv+2blCMaRs2Zf7HD7rtkeF26ysLJH/Jdm1axctW7aM3n33XfN8pwA6EKbvuGX5lbpcHEuRtknzVhfOfoH2YvUdt1ot3HLchnKriLJYD45LigFgN05LELEgnZk3zNApoNau24q6RjqYrXtOGxTuYzTssScmKaIWdp5C1y1oz5tvvkm5ubn073//m37++WeKiYmhyy+/nFavXm0X+XWg/Y5b5fb47qppaKKbP91DpTWN4v1ZiWH0jzmDzPIYHblwm1Nm2dceHeXT51Xo7tcS27OVObeIS+i+wznltPZIvrgc4edBlyuKTcAxCIbCLcclsJ/0Q8nYQn0Orha6h3mIF9t2spiamrXdnS69/uUddAPD1Fe4ZddNiadE/Q6R1PxKeua3o+TIelS4veqqq8T2MpaXl0dz5swRxdsHH3yQHn/8cXM/RgCjjFtJgX4RY6ncU2nBzE/UyCkyLTbIsIDMNPMEZGs4XVorYh4kKNwCb4OUFpQBXq60qAsL8LlDwuXLqw/rFu9qszu9RO66mtwv2CzTgiWccwugRe7u7nTllVfS2rVr6ciRIzR06FBaunQpxcXFUVWVYYo7gLXEKwq3GT1cV/GJh/u+PSBvLeWt9S8tGoVhZL0cTmarqASjfFsLFG6VuwoPZGFAWW+ybdFt215ssBeNiQ2Qi2/JmaW0Rj9sys/DhaYPNnSyqhnP1Zmij0uorGuiA/pmCC3iovOxgir5b46nm7Nqs4VfuWK0XIdZvi2dNqTqIkkcUY8Kt4cOHaIJEyaIy19//TUNGzaMtm3bRl988YXIDAOwlHBfQ5dYgQWjEpSTVTGYrGsdtxka7LhNyTPOyzmCfC+H9+HWU9Skr3AunhRHXm4uXcp6HtZX15XPXa1qzEpWFld7M5hMmXMrTSTfocjOBdAq3pbHb1z0amnRdicNaBd3dHExg6X3MCrhnc1p9MsB3QR33oL87uKx5O+p6xSD7ovyV3Tcltu2cNvPjIPJJNygIuXWo+O2e/jkiHTCPszXvUsn+x11SJnkX98eoOqGZnF5wbBITcVKTDPKudVuXAL/bZHyrKWOVrXiTPaHzk2S3//XN/upsNIxI9p6VLhtbGwUXQps3bp1dOGFF4rLiYmJYtsZgKWEKzpuLRmVYDyYDPm2nZ1F1XJUwtFc4yyvhuYWkW8Kjqm8tpFW7MoUl91dnGjxlPguf+38oRGq7rqVBpPxILWJCb0v3HIxQMq5PV5QRUXIuQUNqq+vpxUrVoidY4MHD6aDBw/S66+/TpmZmeTj42PrhwcOiE8exOu7Krm7s75JV+Doqk3HCunZ3w3bSbnTdoBKt8FqBe++8XR1tlnGrVHh1gIdt3yCelC4r/z3vFZfVFOjXw/k0r9/PkmrDuaqItLmNUW27a3T+4sOQWiPZ0VIJ/tP6Ds92cJR2ohJkJw10D4KtymK179qL9yyxZPjaKa+M7uoqoHu+3a/Kn7/NVG45a1kb7/9Nm3ZskVsL5s/f774eE5ODgUH9/4FIUCXCrcW7LhVnnHGYLLOizfB3m6ajUowVaRFXILj+nxnhtwFcNm46G7lwM5X5NyuVlnObXlNo5gWzTivO1D/O2vOuAR03YLWcCRCZGQkPfvss3T++eeL2Q3ffPMNnXvuueTkhNm9YPucW978kVXS9UJhelE13fnFXpJezy47ZyDNUUT5QM+L6VJcQm5ZndULBmmFhkJXQohlTihJObc8qJczW9WooLKO/vnNftp0sozuWLGPLn9nOx1QvF6zRUboqoO69R6vF6+aGGuzx6J2wT7udLai6Cl1KE80Q3SXNUUHeslxJXszS43i9rT6+leNg8lMPQc/d9lICvHRvX7ZkFpIn2zPIEfTo5UpL3LfeecdmjFjhsgGGzlypPj4Tz/9JEcoAFgC/8Jyx5glM255QSYV73hrWbyiqxQ67rrlwQl1jeo9S3+miZoSFG4dE//sfvRnurjMzzE3ntWvW1/PHU399VsY/8ooUdU2nl3pJfIL+Un9gsx2u8rIBRRuQWu4AcHPz48SEhJo06ZNdNNNN9Ell1zS7g3A2hIU604uxnZ1gNXNn+6mijpdIYELtnfNGmixx+ioA8pqG5upTD/wzdodt7w2ibPQa5IR0QHthjOrzec7Mqmh2VA0/yu9lC58/U+65+t9lFdeZ+Nu237otu1GXAI7f0SUJnO3pw7QrX05Vm2nRqPCjmqs41Y6OfLcZbqaI/u/VSlGA8YdQY8Kt1ywLSoqEm8ffvih/PGbb75ZLIQBLIWnuwd7u1u045a3QXEbvtRty2d5oGs5t2rM9uxs4rKUH8d/tNycndrFZIDj+DE5Wy62LhgWIW9V7Y55+rgELpKuS8lXZ76tGbsbxsUFkot+0Y0BZaA1ixcvppkzZ1JAQAD5+/t3+AZgq47brubccsPBP7/eT8fydZ2ZA8J86MXLR4phOmAeffWFW2vHJfD3Nq2wWn4MltqKr5znYcsu1o5wZMjnO3VRVs59eKCS4bXH93uzaebzG+nldcfE2t4ajudX0q8Hc+WmoqsnxlnlfrWMTyZ5KYZgXaixmATJWQMMw9S2ntBmXILUuOTl5mT03KZ2MweH0fX6GDvO6L1rRbLmmsZ648xTV0yora0Vf0gCAwPF+xkZGfTDDz9QUlISzZs3z9yPEcBIuJ+7yFMsrKqnlpZWsy9M9ysmqo7Sbx2CjsUFGefcaiVLjV/gSF2IvEXM3dVZFG1PFlaLrFMM8nAc/Dzy7pY0+f1bzu7fo9vhuIQ3N54Ul38/lEdXToi1y3xbibe7i/jd2Zup+73hbYxhvoY4GwA1wzBdUKv4EMXg1y7EUL2x4QT9rp/S7uvhQu9eO5Z8PTCMzBIdt1L28DB9xrulcSNJpX47trRF21IDgLiBgWc9KAc0qwVn2kpZ+jMGBNKbiyfQ5zuz6JX1x8WanTuhX153nL7clUX3zR9MF43qa9ETF6/9cUJ+DXHz2f3IU1GQhI6zlK+eGEvvbTlFY+MCaaRGX2PzbjP+0eIoGy3m3PLvi3TyaUCIp+Ya1O5fkCh2+XHxOTW/kp757Sg9euFQcgQ96rhduHAhffLJJ+JyWVkZTZw4kV544QW66KKL6K233jL3YwQwmXPLOUzF1brOWHNCvm33xAR17wWGWhzNVeT7RPgZFekPqnDRCpaz/miB3NHCUQI9zbXmYV1R/rrnp20ni8TiyNZKqxvE1GNpcrS/l3lfzBvn3JaY9bYBABxRfDc6bv84mk8vrD0mLvPr71evGE39QjFYz9KFW1sMJutvwe+rm4sTDYnyk+9TDesXCTeLSVFW7LJRYeTq7EQ3nJVAm/41Q3TgSbt/OLbtnq/308Vv/km70y2zJuHhWj8fyBGXg7zd6JpJ6LbtqgcWJNHqZWfTFzdN1FzBUMKNPdLrBB7mZ4uYjt5QxgsMUJwk1AoPV2d65YrR4jmLLd+WThtSC8gR9Khwu3fvXpo2bZq4/O2331J4eLjouuVi7quvvmruxwjQruNWkm+BnFtlxqky8wnOvKWPO261QipmsaRIP6NinbJ4D/bv3c2KbtvpPeu2ZbwInacfUtbY3Eobjtp+IbHzlOGFyyQzdttKkHMLAGBeXAzydXc5Y+H2ZGEV3b1in9z5d+/cwTQzMQzfDguQTsqyHCsWapSFW0t23LKRKm1g4F09Uhcwn4AeGWU4DgFebqLb7vdlZ9Msxc8+5/Re+vZ2uv2LvZRl5tcm3OEu/c7dNK2f6CSFruEuaO7udnfRdofytAEhmo1LUA4m445bLRoc4UsPnZskv/+vb/araraIqgq3NTU15Our2w69Zs0aMbyBJ/BOmjRJFHABLEm5FZe35ppTU3OLvFjhzJdQ365PlXdUykEJmRrquE1RnHHkjNtRisJtciYKt45if04V7dF/vweH+9KMQYbsqp6Qcm6luARbUw4NUxZZzYW3u7ly4BzflyJLFwAAen4SME7fCZVdWiuy/NqqrGukmz/ZLW+jP3d4BC2d0fMTj9D1jltrZtxas3BrPKBMPetg7qiTXDc5zmSnJuc6f3j9ePp0yQSxlpP8eiCXZr+4if73+1Gq0v+u9EZaYRWt3JctLgd6udLiyei2dURnDVTk3B4vJC1JUQwm02rhlvHv3szBoXKkzH3f7hfd+fasR4XbAQMG0I8//khZWVm0evVqmjt3rvh4QUGBmNALYElhRh235j27wlseOCeJjYpFt21XhPq4k7t+u0KGRjpu+YldikqI8POgQG83sTXRz8NF7rq29yd/0Plst6G4yjllvd26NT4+iIK93cTlTccKqbbBtqH50tAw3kU4PiHI7LfPnSbSUJO0omqL7IIAAHDUuATOUcxqM/iVc9n/8dV+kS3OuFD13KUjNbv1WAsiFB23uTYq3PYLtXDHbYy/6gaU8Tb03/RDwHhtdcGIyE6vP21gKP1611n05EXDROc64xMfPH9gxnMb6ctdmSJqr6fe2HBS/E6yG6f1E1n/4HhGxwaQtz7XeOuJYk29ZlR23PYP1m7htk+fPvTcZSPFcEC2IbWQPlac5LFHPSrc/ve//6V7772X4uPjacKECTR58mS5+3b06NHmfowARsIVHbfmLhLwcCrJKMQkdHnbS6w+55a3I/ELCrXLLa+jijrdmffESF/53yHFJfAABGtuhQPb4JyyLWm6DvtIfw+6YGTvJ9w6O/URk3MZnwTabMMz8cVV9SK4X8rf9bPQsBrjnFt03QIAmDPnNqNNXAIPZFqXki/nLb67eCwKSFbIVQzx0TWO5JRZb33IJ0QZ5zlG+Vu2yNIvxId89IVItQwo+3xnBjXpX1dcNTFWDBI+ExdnJ5E7u/FfM+iWs/vJu4J4bX//9wfp/Ne2ijkE3cW/hz/qu2359w7dto6LM5Yn6te+/HPFg7K0gF+jSxm3MYGe5O2u7ciKEB93UbyVPPXbUaPCtL3pUeH20ksvpczMTNq9e7fouJXMnj2bXnrpJXM+PoAOh5OxAjPnmWAwWc9Ihdv6phazf08sQfmkzoPJJMq4BGURH+zT+1tPyZeXnJUgB933lpRzy1bbMC7BKN9WUVw1N+TcAgBYLoYqvcjQcbv6cJ4o3Eo7KV67crTRrAGwnL4Butcf+ZV11NjcPr7C3LhgKc2OSAj2Fg0GlsS3P6yvn9zgYO44uu6qa2ymL3Zmiss8fOzqid2LJeCT1Q+cm0Tr7plO8xUxVjzj4qr3dtJNn+w26mg+k9f/OCF36954VgL5WuhkOGjDWYqc2z81knPLuzdq9DsBOSbQHswcHCYGFErd9Zz7zs8d9qjHr1IjIiJEd21OTg5lZ+vOPnH3bWJiojkfH0Cnw8kKzNxxuy9Ld4aZ10bS4gXOLFaZc6uBuARlvk+SvuOWSVu+GQq39o279X9M1v3t8vVwoSsmxJrttqf0D5YHy3BXlDVe4HUWk8AmWSDfVjIm1pBzq7xPAADoGWWeqTSg7Hh+Jd3z1T754/+en0hn9zKXHbqfc8u7oq0xST6vokEMOrVGTIKpdfAB/WsiW/l5fw4VVzeIywuGRxrFVXQHn9h4+9qx9OXNk8RwM8naI/k096VN9OQvR6i8trHT2+Adhd/r14wcq3bdVF2hCBzXtIGGwu2W49oo3Cpf/9pL4ZbdvyBR/vfwTsNnfjtK9qhHhduWlhZ6/PHHyd/fn+Li4ig2NpYCAgLoiSeeEJ8DsKRgH3dRWDV3xm1NQxMd028rHhTuiymhPei4NbWlT42UW1qUHbdSVAJLRsetXfvoz3Rq0L8gunpirLw90Bx4Wq402ZsjOWwVH7Bdf78c38DZu5bi6eZMo2MCxeX04hrKLbde/h8AgD1SdtHy8yoXlm7+dA9V67ulONqHc9nBNgPKcqyQc5tZWme1wWSmBpTZMueWM0OVQ8n+boZCKe88+vmOs+i5S0fIw6e5MM67r2Y8t4E+3Z4uhlSb8sYGQ7ftDWclWCx6CrSDB+JJzWQ7TxVTfVOzpnacDrajwq2HqzO9csVoeeckP3dsSC0ge9Ojwu1DDz1Er7/+Oj3zzDOUnJxMe/fupaeeeopee+01evjhh83/KAEUuAgh5UyZM+P2UHaF/EdZuWUeurelj89Kq500mMzN2cmoi4EXcn31C/ODp8s7XMCBtvE07s93ZIjL3Cl6vQWmAs9XxCX8boO4BN7iyBm+bES0v1kL06ZM6mcoDCPnFgCgd3jgijT8hifZL/syWd7WPSTSj/73txEYRmZlnIUvySm3buG2X6gPWQOvFyT7bZhzuzujlA7n6NbqI6P9abSZXpdxHMRl42Jo470z6M5ZA+ThyqU1jfTwysO04JUttLFNwYdf13y757S4zLup/j41wSyPBbSNh2OdNUC346GusYX2ZJSS2h1VdtxG2tfO4sERvvTQuUny+//6Zj8VaiC+0eKF248//pjef/99uu2222jEiBE0cuRIWrp0Kb333nu0fPly8z9KgA5ybjkQvDfTQTscTIbCbc87blVeuOXcG2nYA58t5YB5Jel7z4OlThTqCl9gX1bsyqTKet1wugVJwRSmyM02l+mDQuUXBKsP55vteaqrdqZZJ9/WVBTDjpOG+wYAgJ4VBeL1XZanS2vFxGwW6OVK71w7Vux0AOuSTuxba0BZZlm91TtuowM9KcjbTe645c5XW/joT8MMguunxpv9JIW3uwv9c+5g+uPeGXShYjDt8YIquv6jv+j6j3bRiQJdkeutTSflAWnc+cuDyQDaxiVs1UBcgtRx6+HqRHGK1+72YvHkOJo5WFdML6pqoPu+3W+z5zDVFG5LSkpMZtnyx/hzAJYmbU3gv6M8Od0c9im2BCm3zMOZRQdqJ+OWuxClIlqiIt/WVNF+XyYGlNkbDq7/cKtu+x2/Drh6TLhF7odfFEjZg3yCKTmz1CYxCWyyFQq3nHPLHext7xsAAHomvs3QMd5x9sZVYyjGDl9wa4EtoxL6WalwywVSqeuWu1D5pIG1ZZfVihPe0k6484YbCquWKMa/euVo+n7pFKP1/8bUQpr38ha6/7sD9M3uLPEx3rnEMQkAkqmKAWVbVT6gjCMhpeaqweG+4u+JvenTpw89d9lIsWOF8QnPjxWRKw5ZuOUOW45KaIs/xp8DsDRlh5y5cm6ljltPV2caGGadLUn2lC0Tof+eZBaru3DL02QlSYp8W1NF+/02zPcCy/hpfw7l6SNWzkkMo7gg83fbSpRTjK0dl7BDPySMoyDGxevyZy39HDA6NkA+ecMvvAAAoOfiQ4wLtA+em0RTFIUCcIzCLXdZB+q7YK2dc2uLdfBnOzLkBgueQSDlVlr65PMPS6fQK1eMoih9JAY/hi//ypIHxPHk+gAv630fQP34xII0FOtgdjmV1eiG6anRsfwqMVix7XwXexPi4y6Kt5KnfjtqlO2rZT16Jvzf//5HH374IQ0ZMoSWLFlCN954o7jMMQnPPfec+R8lQBvhvsrCbe+3K3FHnHRWeXhff3Jps30ezixWn3PLE2Cr9NvQVT+YzETH7bC+fvJZyH02nqhrzi7T+ibk9ba0tNK7m0/Kx8XSg11mJ4XJP0urj+RZbbsOPydKcSA8IdrLzbL5tqYiGaTCMQAA9MzQKEPe6CWj+9INmGRvU8HebnIR0dJRCdwdV1DVaNWYBAlnykoOWDnntrahWcRZSSeer5oYa9VuvYWj+tL6f86gf84ZRF6KOBLOm16Cblsw4Sz9yTRe4m9T8dpXmu/S0etfezJzcJg40SK9Br57xT4Rlah1PapOTZ8+nY4dO0YXX3wxlZWViXiESy65hFJTU2natGnmf5QAHUQlsPzK3i+elJNTR8YYFizQs5xbNXfdKs+6mTrjyEWuQeG6P2ipeRVi8axlh7LLacTja+nqz47YXUh7d208ViDOOLNxcYE0Ns6ynajcmSHFFGSV1NIRxaLJkpTDwSYrsmctTXlfGFAGAND7XRvLzhlId88eSE9dMhzDyGyMB1tJ3ZiW7rhNLzKsoxNCrLsL0KjjVjH/wxpW7sumshpdwfr8EVEUpmjUsRbOj75z9kDacO8MWjQuRszD+N+lI63a9QzacZYi53aLinNujRqX7LjjVnL/gkS5Gzo1v5Ke+e0oaV2P2wqjoqLo//7v/+i7776j77//np588klqbm6mG264wbyPEMCEMGXh1gxRCcosU+Tb9owy5FytObfc8Ziin6jJ+Te8xcWUUfriPe/UOpSt7e0VnO3DZxtPl9XTe1sMwx4c0dub0uTLt0zvb5X7nDfMEJew2kpxCdsVZ/ytMZhMwvlwUjcScm4BAHpfKFx2ziD6x5xBIo4G1BOXwANOK+p0BUZLOKXfNcP6hVq345bXxlKBmk/+W2u4Kq/RlyvyKKWOOVsOwn720hG07p7pdN6ISJs+FlCviQnB8oyHrSd0QyTVHhUoFTTtmYerM71yxWj5dQk/t2xILSAtM+t+cO68/fjjj815kwAmKc/AFpqh43afYiuQMpweuh+VwDJLDAtONSmsqqeS6oYznm3k7eW26jYw9yJYuW2Ht5+V6zsZHA0PB9t1Sjc8s3+oN81ODLPK/c4bEi6GoLHfD1upcKvvuOWFpKW7itsuksbG6u6Po2eyVHoCBwAAQM05t0aFWytHJSi7bqsbmulkoW6nkqXtSCuRuwLHxAagkQY0gTu0pbU2767LKK5W5etB6XeLdy07Svf44AhfeujcJPn9f32zX9O7TxHkCZrEZ0HN1XHLT2ZScY67MHnCKPQuKiFDpVEJUrftmc42jtIPWWL7NFy4bTskihfgn+6wn+ma3fHu5jSjbFvuZLLWIEUeesE4piHNwi+A+IWk9PvHP8fW7tIyyrlVRDYAAABondSJaunCrZRTzxKs3HHLRihi46zVwPDRn4ZdYddPTbDKfQI4QlwCD2Uur210mJgEpcWT42jm4FBxuaiqge77dr/VZo6YGwq3oNkBAdLQn94OJ+Mih/Rkxp2WHE4P3RcX7K36qARlMHtSZMd/uAaG+cpDCbRcuDUVkv/Rn+l2EdDe3c4VqduVtwBeNLqvVe9/3tBw+fLqw/lWi0mQ8nWtyTjnVtfhDAAAYG8dt9kWHFAmddzyS5J4xfraWpQ7z6wxoIx36KxLyZc7AhcoYqYAtDKgjG1VYeH2qLJxyc4Hk7XFdZ3nLhspmvPYhtRCESOoRSjcgiZxt1yYPp+0tx23+40GkyEmoacCvVzJx91F3YXbvK794eKTAsP66roNuGNVq9sqlIXb+CBdl0hxdQN9szuLHMl7W9LEtFd2w9QEcnexbhfqvKGGFyCWjktQdrlaM99WOdzRXZ8nxY9Fq2e1AQAAOivc5lqo45b/bkqF2yh/T5vkG0tr4LYDnC3l0x0ZYq4Eu3ZSHLnqM0MBtIB/X/w9XcXlbSeLrJYL3VUpisHcSQ7WcctCfNxF8Vby1G9HjYaVa4WuytJFl1xySaefLyvTbmcaaA8XbnPL66i4up4am1t6/Ede2VGJwm3vzmhxXMKR3ArKLq2lpuYWclHZwksKZufCLE+J7czomAA5E5W3iZ0zxNA1qQW88N9+UnfW18fdmf47N55u+FI3UfPdLWl05YRY1X1/LIGL7t/uOS0u84mFqybG2qQbnTu8+eePf5Z4e6XyxZ9F8m1dnGi0IvLDWrgoPi4+kP48USxOenDWbYwiRgUAAECrrJFxyyfYK+qaxOWEENv8/eQiFGfrcmQDx4zxkFtpyI+51TQ00Ze7MsVlvg9enwJoCb+unDogmFYdzBO/uwezy1U1M8eRO24lMweHiYGHPKSMn8/uXrGPVt4xVVODP7v1DOzv79/pW1xcHC1evNhyjxagTXYk44auoqqed0QaFW6jDWeYoec5t00traKorib8JC0NWODhVGfqulQW8ZVd2VpxvKBKZPmw8fFBNCTCm6bpM5g4PP/Xg7nkCD7ZrvsDzbhoK50Rt7b5iq7bNRbquuWthlwoZTwkzFaLkUkJwSajGwAAALQsKkCZcVtnhcFknTcZWNII/WuihuYWi3anfb83Wy5UXzgyioJ9dDsqAbTkrAG6HFW29XghqYn0++vq3Memzym2dv+CRHnGTWp+JT3zm66hyS47bj/66CPLPRKAbuIMJElBRT1F+ne/g40LOodzdE9mCSHeFODlGFMWLSUu2NAZwHEJauq0Syuqosbm1i4HsyvPlGox53bbiaJ2uaO3nN1PDs1/e1OaWCDbc6ZzdX0TfbI9Q1x2cepDf58ab7PHMn9YBL207picc2uJwRtSt23brFlrE/e9luS4hMvHx9jssQAAAJiLl5uLiAYrrWk0Gv5qTsohprbquGUjogPox3054vL+0+XifUvsDuMOOAl3xAFokdQcw/i11h2zBpIa1Dc108lC3cmg/qE+Fuuc1wIPV2d65YrRdMHrW0UNiJ97pg8KpZmJYaQFjvudA80L9zWc9e7pgLLUPN32H4Zu295TFmqlyfZa3SYS6e8hBlkx3t7eorK8ou7k207RZ51O7hck/5zztv3NKgzQN6ev/sqSBw8uHNW3Ryd3zGVQuA/F609s7DxVTCXVum5oe8q3lfCLO099ty8Xk5FzCwAA9haXwJPaLZFlyfEEEm4qsRXOrJccsFADA8cqnSjQFaonxAcZZesCaO01sNTAtDez1CLr/J7g3y/peaqzwdyOYnCELz10bpL8/r++3a+ZWTYo3IJmheujElh+D3/h9mEwmUU7brUczM6dqNJUXd7ClV5sWEirHf+Blop43BkibQvhf9Ot0/vL13tr4wmyV5x7/cHWU/L7N5/dz6aPh4/9PP2UZF4/rTuim55sLlwc3aEv1nu4Ohm94LI2PpvPObeMI1PU9lxgTfx9uf+7AzTysTX0+yHLDqYDAADLk04C81qroNL8cQmn9N1xrF+o7Qq3QyL9RXYnO3C63CL3sXybYZ12vQ13RcH/t3cf8G3V5/74H++9914Zzh5OyCIJM4OWUmYobaAQoGlKS+DeC+FS/i1wb7l0hJ0wCgRaRtpCSvtrIISSvYAsMpxpx3YcOx7x3rb0fz3fo3N0ZEu2JGscSZ/366WX1pEsHR8dffWc5/s84AhXGTI3eYbnmi1ntJe4ZPg96OvunJWj/K+4rOAjfzvsEUkmCNyCx0oyKZVg38CJMyllaEzmuBq3rPyStgKd3FzB1sLs6uZOnlQu4fiFZqVeGE9b9zcMvNmCcalKBsfekkse9b5s8a9vq5RpjPzlzEdY3U1d5/YzB9e55eDoBUNd6Wk58UPWcHY2dcavL9e55braHxoyv5/45KiYsgYAAJ4rw6TObYfTMm6DA/zcOlMoLDiARqVIY6fTNS2iiZgjldW30b9P1IjL6TGhtMDDmgAD9PeTeQUUYihFwKXazje4P3FBXZ+6EBm3SjLNb2+ZSImRUonMLSdr6R1VyRatQuAWfLpUghy45WLdY7Ezc8j0MfnovNay7E5USV9cseFBlKrK1h6MnHHbP8ivdbvPquvbGmsuMf7/cK1b2atbz5K34aOmr20vUa6r36878fYkb3s7T9dRS6dUxsER1MFRd9a3NRe4VZdw8DVbTxobVPBUrE8M9QIBAMCzSyU4o0EZZ/FyQJNlxoYoY2p3kctr8Uyho5WObVD2zu4y0WCaLZ2VS4EBCEuAZ0uNCaV7Ls9Tmvqt3iz1tnCnE9XGxKUxGkhi0YrEyBD63a2TlOu/+fSEU5swOgL2kOAdzcnsKJXAQZMzhgYAXPPFXR3YvUlQgD9lGAa0XONWK9MO6lu7lG2Ep4lY25BrgmHAyg45aZqY0+vbmgni3Tg1g5IN9Xs3Ha8WWYHehJsCcA1fOZP+srx40gLOfF4wLkUZ0KmDeo6tb+v+98vdqMODUed22ynT//GbO0o1s18EAIDhBm4dm3Fb2dChNNLNjrMuycCZ1LMRv1WVlxuu1q5e+us3FeIyZyjejiam4CW4JF1MWJC4vOFgpfJ7xN0zTuMjgpXeLSC5cnSy0hCRex49+MEh6uzR7sw4BG7BY8WFB4tMWXax2fbA7ZHzTcqRXnVmJTimXEJLZ6/SGMrduAmdrNCK+rYy/uItMNQXK77Q7BHTnPmL56vSS8rBjXwzjS14Gr18RJg/A69vM2aneoPXthuziJfPy7c6UO+p5RI4EMhNwBgHS53R+dmegzjTcuOV/fM5jTUrdAWeVrqvRPosyk5ebPH6poAAAN7MmYHbs3XGA+nZqpIM7jwIKzvswASGjw+cp5YuqfTCjVMyKC5CmrIM4On4t+MDV45QfmP99rMTbnstPNOrrtX2xCVfsmpxoVL7l8foz352krQKgVvwWJy9lmwol2BPjVs0JnOObFWDMs661YJi9TQRK+vb9s824AxJdZ1crTp8vpE6DEcLZxckWvyS/uGMbIoKDRSXPz54nqoN9VE9HR+Q4S7FLDchXNT01RLO/uVyHWzLiRqHHNktrWtTDl5xsJSDplqgzvz1xTq3nAXN+43+9b/fUJXxAO+yZs0aysvLo9DQUCoqKqIdO3ZYXPbjjz+ma6+9lpKSkig6OppmzZpFmzZtGrDcRx99RGPHjqWQkBBxvmHDBie/CwAYjDyzjFU6uFSCujFZdpz7s+O4xq1cs9NRGbc6nZ7W7TLWk0RTMvA2S2fliLrNcv1Ud42B7U1c8iWhQQH0wu1TRGNl9s6eMtpdqs1Zttr4dQdgp2RDuYT6tm6RaWgLdc3SyW7swO7dDcraNVXf1p4vrslZnlXndrchaDlUrdOo0CD60cwccZmn5b21y9jZ11uybe+bl+/2+nD9cQ23a8dI5RLau/tErdvhkrNt2SxVbVl38/U6t9tUpTAeW1xIOYaDWjvP1IkGguBd1q9fTytXrqTHH3+cDh48SHPnzqXFixdTeXm52eW3b98uArcbN26k/fv305VXXknXX3+9eKxsz549tGTJElq6dCkdPnxYnN922220b98+F74zAFDj6caBhrGFozNu+UCsTAulEvhA8Lj0aCUZo7G9e9jPuf10rdKAjccsCCiBNwYDH7p2lHL9/z474ZYyWaaNyVDf1hJuYP34dWOU609vPieylbUGgVvwaHKdTlZrmApgrcMV0tGUyJBAyk+MdPhr81U5WgzcGo44cvKp3CHXnsDtIU8I3Koak5mrb6t295xc5Qjj+/vKNVPawl4Vl9pp45EqcZk7hd48NZO0aNF4x5ZL2Kuajq+F+rayCRkxFOHDdW7l+rb8A//ykYl0r6E8CfvjDmTdepvVq1fTsmXL6N5776UxY8bQ888/T1lZWbR27Vqzy/P9jzzyCE2fPp1GjhxJv/nNb8T5P//5T5NlOLj72GOPUWFhoTi/+uqrxe0A4B58QDjF0Gj0QpNjA7cl6lIJGgjcMnX5pW8dUC5hnap7O7JtwVvdNDWTRqVEKok/nx11THk0W6hnio5Bxu2g7pyVQ1cVJovLDe29olmZ1kjzZAE8lDxwYhebO02mLw2Gp4VXG8orcP0mLrsAjpGlCtzKnXHdqbdPR6cuSl9ceQkRFGYIJFmLMwGCA/zFlGetZ9x2dPfRwfJGJfM5M874vzCHS43cUpQpgrbcKOLPe8voZ4a6TJ6Ig2Hc+ZjdNStXsw0H54xIFAHNtu4++qL4othG7e2mLOrbGqZg8UEoDpZqhVznlgOYfOSaM2wKknzjINm5ujalrm9RTpzIcL+lKIv+sPkUNbb30D8OX6BHFhWKDsTg+bq7u0XW7KpVq0xuX7BgAe3evduq59DpdNTS0kLx8aoSI3v20EMPPWSy3MKFCwcN3HZ1dYmTrLm5WXl+Pjkb/w3eL7nib3kSrBfvWi/psaFU2dgh9uetnd0UHuyYn9QlhlIJsWFBFBMaoIn1MjHDOFPtcEUDXT7C/pk9JbWtSmNW/s121egkm96jp24vroB1o631wpGF/1o4mu57d7+4/ttNJ+nqwiS7x/vDybjlMEdBUrjJOsD2MtD/3TSeFr+wk0YkhNCjC0e5bMxkLQRuwWsCtzU2NChTZ06qMyrBsTVutZBxe66+jboMZTTsmSbCGalj06PFNsOBp6b2Hoox1CjVmv1lDUpNzaGybWX3z82nD78qFwHPt3eV0rLL8zQb8BzMpbZuWm/oUBwWFCDqS2kVr98rCpPpX99WiR993Exu9ohEu57rbG2r0nhgem6cSweE1uByHXLmKQeYfSVwK79ndsVo6Qg+HzT60YwcennLGerlGn+7z4mmCOD56urqqK+vj1JSpDIoMr5eXW1dls0f/vAHamtrE6UQZPxYW5/zmWeeoSeffHLA7bW1tdTZ2emSHyFNTdz8VU/+/traH7kT1ot3rZf4UGPCx9GSC5QbP/yDcJ09Oqoy9BvIiAmixsZGTayXjDBjLf6vz9ZQzTj7a2W+usVYOuamCfFUX2f8rvTm7cUVsG60t17Gx+lpckYkHapsFWVQ3tpaTN+fkOSSv83jTDlxKSs2lJob6kldpAvbi3mv3TKCwvQdRB1NVNPl/N42fMDeWgjcgteUSqhp6bSpgVP/5lPgGNGhQRQXHkQN7T1UroHmZI6YJsLBfTnYz9vOvFGu+dIdTpmEwerbquUmRtDiCWkiiFjX2k1/239eqX3rSd7dc0786GG3X5ZFseHa7lC8aFyqWOdyuQR7A7fqhgfW/s/dWefWE7cte2w9WaNcnq/aX9w5O4de314iDrC8t6+MHrhqhMiUBu/Qvxkk/1C0povzBx98QL/+9a/pk08+oeTk5GE9J5dTePjhh00ybrlkg9wEzdn4xyC/Pv57CKxgvXjr9pKf0kB0QipT1BUQRsnJwx8XFqv6MYxKjaXY2FhNrJfERD1FhpwUM7NO1nUO2EdZq7mzhz4tPqQcYL/nijEUExbkE9uLK2DdaHO9/PL6YLrl1b3i8ltfXaQfzR3tsAz9wZy+2CJ6mLDxmbEDPrfuXi9alZioEwe6XbVeuJmttfBrAbyqVIJ9jckQuHW07IQIamhvpKrmTurq7aOQQPdlcJoWZrc/cKvedrQbuDUG8WYXWB8I/On8AiWIyEGl26dnaS5zc6gSEe8YaqZx7TnOGta6KwuTlRIcm45V06+vH2dXyRZ1fdtZ+fYFf51pfHq0CEzyDz5+rdYGsjxZZ0+f0jCODy6OUWX6c3mS709Jp798c55aOnvpL19X0D0esL3C4BITEykgIGBAJmxNTc2AjFlzTc24Nu5f//pXuuaaa0zuS01Ntfk5Q0JCxKk//gHiqh9n/Bl35d/zFFgv3rNeMlSlqKqauhzy2s/VG+vl5idHama98J/nsnI8xrzY3EW1rd0mv7+s9fGBC6JEFLtpagbFRQzcT1lDK+tFi7ButLdepuUm0MJxKbTp2EWqaemid/aUu6Qs3ckaY7nCMWnRZt87thfzXLlebPkb2OOBR0uONn7p82DCGjqdXimunxodatfgAwbH9VUZ9yI63+DYxg22OqHKuC1Mta+jpjorW52trSWcyfCt4bVxMXzuemyt8RkxdLkh45PLW3zqhgL6w/G3/RUiw5tdPzFtyNq+WsDBzLkjE5V91yE7tisOgnIWK4sKDRQlPbSGDwBwCQfGJR24tIO349IXcvY3Z9v2D1TfOzdfufzmzlJR4xg8W3BwMBUVFdHmzZtNbufrs2fPHjTT9sc//jG9//779J3vfGfA/bNmzRrwnJ9//vmgzwkAzqfuqXGh0THj3FJVY7I8VdkxrTUos6ffQ59OT+/sUTUlm53rsNcGoHX/tbBQ1Jllr249K8q7OdsJVQY/92sBz4fALXi0lCjbM265Yytnf7FJWdpp5ONNcuK1U+f2RHWLEijLjLOueV1/uQnhynQuLpnAATOt+br0ktKYy5ZsW9lPryhQLr+67awm36M5HPR6Y0epcv3+ecb3oXULx6Uqlznr1lanLrZSvWHwNyMvXmQba5G6hIO6tIMv1LedP3pgdv6olCi6wnA7N7fhUhng+bg8wR//+Ed66623qLi4WDQVKy8vp+XLlyslDO68806ToC1f59q2M2fOFJm1fOJafLIHH3xQBGqfffZZOnHihDj/4osvaOXKlW55jwAgSVcFbisbOx3amIzlJUZoalVPyjT+XpKTX2wtH1RmKJ/GB61HptiXSAHgiUYkR9KS6VnicktXL72y5YzLfv/a2+MFtMftgds1a9ZQXl6eqO/A2Qo7duywuGxVVRXdcccdNHr0aJFWbGng+tFHH9HYsWPFVDE+37BhgxPfAbhTbHiQmG7MuGu5NQ6Wq8skSJlg4JyMW+bOOrdNHT0iMCJn29o7RZsfJ2fdch1Y+Tm1WibBnlqn3MxsQoY0MD92oZl2njHWy9Wyd/eUKQcH+MeAFrNOLblmbIpyBH7T0Wqbg+V7VDWN1bVktV3n1ljawdvr2/L/du4I82VV7lNl3b6xvcRjDpSAZUuWLKHnn3+ennrqKZo8eTJt376dNm7cSDk5OcoYlgO5stdee416e3vpZz/7GaWlpSknDtbKOLP2ww8/pLfffpsmTpxI69atE6UVZsyYgX8FgBulx4Y6POOWG+BqNXA7cZgzz7gZpwzZtuCLHrx6FIUGSTGLP+0powonJzbJGbdRIYEmMwTAc7k1cMuDTw6+Pv7443Tw4EGaO3cuLV682GRgq9bV1SUKBfPykyZNMrvMnj17xOB56dKldPjwYXHOHXr37dvn5HcD7sABNblcgrUZt6aNyZBx6wzZCdrIuD3pwKONpnVubc82cLZdhkArx6Zn5iXY9VlaPt+Yrbp261nSuv1lDfSbjcXKdVfUjHKk+IhgmmH4X52rb6eThu6vdtW31WBjMtm49BgxcGRc2sGbg5Q8ED9ryJqakh1HMeFBFg+UjDXU3D58vom+Ptfg0tcJzrFixQo6d+6cGK/u37+f5s2bp9zHQdetW7cq1/kyfxb6n3g5tVtuuUVk23Z3d4tM3ptuugn/PgA3iwoNUr7XLjQNP3DLn/0SQykhDrKEBrmvN4Q56TGhlBgpNX09Utlk0/c4N0nacVoao+YkhNOVo+1rbgbgyVJjQumeOVJPA+5v8dzmU077W03tPXShqVP5/evtvSV8hVsDt6tXrxYNGe69914aM2aMyFTgzrdr1641u3xubi698MILYmpZTIz5gBs/x7XXXiumpBUWForzq6++WtwO3kmuUcs1LrkR1lDkoBvvw+QMQ3AsHpjJ5KlRbm9MNsz6PpNVQf5DFdoKstS3dilTYsanx1gMFg1l0fhUURZCzuC1p46ZK9/zA+8foF5DfYifzMvXdNbpYOtc9pkNtYW5VvfeUinLmst4jNFw/Sou4XBZXry4zKUdTtd4b53b7aeNZRKuGKSJIQ+i75tnbEr2xo4Sp782AABwfLmEqqZO8Z08HFzzsrmzV5PZtvJ3llzntrG9x6akDHW27Z2zcu1qxArgDX4yv0ApvbfhUCUVq+rQavX3L2iH2wK3nDnA2QgLFiwwuZ2v79692+7n5Yzb/s+5cOHCYT0naFuKqkFZzRANyrjbt7yTHJEUKY6YgxP+J1GhFBwo7V6cPRVkMOovRHVnd3tMytRuxq0685Iz+YYTYFPXiOVat1rETS4e/PCQ+LHEOCj4XwtHkydaMM7YHZ47zlqLA/X840mub6v1H0K+Uud268nB69uqfXdiumiQyb4ovqhkWwEAgOeUS+ju1Sn15u1VqiqTkJ+kvcAtm6iqc8v9HqzN/Pv4QKW4HBEcQLdOy3Ta6wPQOg7aPmCYHchJ67/97IRT/g7q23onaY6HG9TV1VFfXx+lpBh/tDK+zs0Z7MWPtfU5eUobn2TNzVKwR6fTiZOz8d/gKSeu+FuexNr1khRpDNxWN3VQhqruVH/HKhuVDD0egHjqOveEbSYrLkxMGeaj8vxZd8U0jf7rRR24HZkcOaz1FRceJN5TRUOHmCbW3dNLgYb6yu6264wxWDQzP37A+7Rle7lxchqt3nxS1PLlpklnalooX2PZH89vPqXU4OWpey8umSTqidr6/9XC5yglKkQ0/eDp8ry9lta2UE7C0Ot799nB/+fD4Yz1cllunElt3qUzs8nTDLVe+Mf7bsN2mRARTGNTowZdhwF+XOsvh/7vs5NiAP/HHSX0P98fT57GHZ8jLX/3AYDvNSjjOrdJUcbfI97UmMxcAgM3KLthcsaQj/nLNxXU0SPNhrylKJOikTADPm7prBx6e1epKGWw5WStSGZwdLkzZNx6J7cFbmX9gzk8+B9ugMfW53zmmWfoySefHHB7bW0tdXY6plPoUD9AuIswv05uuga2rZcIf2lqETt9voaywqQsNHN2FktNY1h+TADV1BivexJP2GZSIgKIY0s8YDtx7gIlRAS5dL1wLYwTVVL5gIyYYGpvukTDzf0dnRQqArf8nvadKKeRScaSEO6087S0HXMcOSe8d8B2bev2ctukJFqzq1IEk176/Dg9do3UXEcLdpc20UtbpExgDtY+uTCXqLOZajqbPfZzNCcnUgRu2cdfnaUfFhnLJ1iyrbhKuTwq1s+h+zJnrJeEAD1FhQRQS1efCNxWX7xI/h5Wc2uo9bK/ooXauqUfqNOzIqmuzhhct+Tq3FB6Mcif2nt09NH+87R0cpw4SORJ3PE5ammxrR40AICzA7dyE1tva0xmLuP2WysalPHsqHf2qMokzM512msD8BRcv/rhBaPpP/96WFz/v89O0N9XzHZoglOx4fcvG506vBmnoB1uC9wmJiZSQEDAgExY/vHZP2PWFqmpqTY/J9fBffjhh00ybrnWLjdCi46OdsmPHv6w8t/TahDOHaxdL/lpHKiVpuF0+YVQcrLlovdnGy8ol+eOzaTkZM+scesJ28zItDrafU4KprX5h9OYZGPGnSvWS3lDB3X2SllZ4zLiBt0urHXZiDb64pRU37aiPYDmOOA5h6uqqYPKG6QZA5Oz4ig3M23Y28v9V8fRu99cpNauXvq0uJ4e++4ESjZM6XanyoYOeurzb5Xr/7lgFC0uMpZ28NTP0U0zIkSgnO0qa6OHFicP+WPo8AVpwMdBvpmF2Q4tleCs9TIjP4G+KK6hps4+atSHU2GKZw0mh1ovhw8YS5YsmMjfL0PvH3iJ2y9rord2naOuPj1tOttOv7h6JHkSd3yOQkPdvz8CAN+m7tRe2Ti8BmWldcZSOQVJkaRFCZEh4j3zez1a2Uy9fbpBZ55xCaDzDdJ6mT8qSbPvC8DVbpySQW9sLxFNibmfCPe4WDxh4O83e3C97VOGZsfZ8eEUaWiiCJ7Pbf/J4OBgKioqos2bN9ONN96o3M7Xb7jhBrufd9asWeI5HnroIeW2zz//nGbPnm3xMSEhIeLUH/8AcdWPEP7R48q/5ymsWS+pMcaBU01r96DL8tQexvVXx6THePT61vo2k62a7l1xqYMuy0tw6Xo5ddE4CC5Mi3bIepqaHWdS5/aOGe7PRN1XamyUNqcgweL7tGV7iQ0PoR/NzBE1brv79PT2njJ6bPEYciduPPjABwepsUPKqL9mTAr99IoRDpmh4e7P0YjkKBqdEiUGcAfKG6m2tVtpumjO8aompYkJN2QLDHR892lnrJdZBYkicMv2lV6isemed+BssPWy/ZRUJoE3yfmjkq1ed/dcnkfv7CkTAfk/7S2n5VeM0FxHca19jrT6vQcAvppxO7wZmnKphOAAf8PzDq/ZmbNMyooRgVueeXamtnXQxkfrdhmzbe+eg2xbAHVPkUcXj6Z71n0jrv9u00m6ZmwKBTmgBF9FQzu1G2Z/FSLb1qu4deTLWa5//OMf6a233qLi4mIRbC0vL6fly5crmbB33nmnyWMOHTokTq2traKUAV8+fvy4cv+DDz4oArXPPvssnThxQpx/8cUXtHLlSpe/P3B9c7KLzZYHTo3t3XSuXposPz492iE7R7AsJ95YRsCW7rPOmCYyxkFfXOPSY8SXLTtsxTQxV9itavTEgTFHuWdOrvgBwd7fW07NnZZLkLjC//y/YqWcAB9B/sNtk1xSN9lVFqqalH1+fPAmZermXo6ui+VMXItXtrfEuxqUVTd1Ks0gJmbEiMwka2XGhdPi8VJ5DG5ws+GglH0NAADalRYTalIqwV580K7M8PskJyFcGWdq0UR1ndtBGvVyjc09hu957pMwb+TgzToBfM2Vo5NFc2W5VArXg3b0719OXALv4dbI1ZIlS+j555+np556iiZPnkzbt2+njRs3Uk6OlMVWVVUlArlqU6ZMEaf9+/fT+++/Ly5fd911yv2cWfvhhx/S22+/TRMnTqR169bR+vXracaMGS5/f+AayVHGgVNNs7HJXH9y0IcNpw4VWCc7wb2BW5PC7A764goLDhCZkYynobR1GesruwPXlJSDeCGB/jQ1x3HbNZdGuLlIajzR0tVLf95bRu7yyaFK+pPh73O2/JofThWdWb3JQkPgjm06OniDTvnHEJuV7zmB2zGp0cr/jTNueTqXt9h2ylhjeP5o20uo3D8vX7nMTcq8ad0AAHij1JhQMcNCLltlLw76dvdJpb3yk7RZ39ZcndvBEhje2W3Mtr1rdq5DyzkBeANOPlm1uFC5/vwXp6m9u9ehv38dlbgE2uD2lMMVK1bQuXPnqKurSwRj582bp9zHQdetW7cOCFT0P/Hj1W655RaRbdvd3S0yeW+66SaXvR9wveiwQBG0GirjlmvIyCYjcOt0WXHuDtxKRxzDggJEhqajTM6WgqMcVzlSaTnbwBV4vcp11abnxlOIg6fM3z+vQPlR8tbOc9Rp6AzsShwgX/XREeX60zeMo/EZnjfFfihj06IpKz5MCczyDAFzuKbc16VSLdXEyGAakew5NeP4h9sMQ3ZBY3uP8hn1BttOGRuRcS0/e7KY5MyLs7VttOWkZzbOBADwFTxzL8WQPFI5jFIJZ2uNpb3yErX9nT4hI0YZF8rl5/praOumjw9IM0eiQgLp5qJMV75EAI/BJfgWjZMSN2pbuuitnaXDfk65MTdDxq13cXvgFsARR6zkepA1LV1WBW4nqab6gHNwdmpylDRdWJ4C5ircVEv+m6NSoxw67WyyattRb1PusOuMc6fMc2djeQp3XWuXMhB35f9x+Z/3i1pq7NaiTFoyPZu8dT8mD9542qRcC7a/YxeaRQa03OzL08pFqLdTdeawJ+Ng+o7TUn1bzii298Dg/XONWbdv7Chx2OsDAADnSI8NVcZI9h7cLq2T6tvKZQW0LCo0SHmNnNnH/Qf6+/DrCuoyNAe+dVoWmiMBDOK/Fo1Wfqe+uq2ELrWZT9ywNePW0YlL4H4I3IJX1blt6ugxO3DizOxDhiBbbHiQqCEFzievZx7QOmL6h7XkbppsbJpjp4moy2y4u87t7rNSsIjNdlKt0+XzC5TLr28/K4KKrsCf2Uc/+lZp2MEF9p+6YTx5s0WqcgncYdabyiTIuJmat9W5PVjRSC2GZnFzRybafaDoqsJkZZrs3pJLdMRCNhMAAGivQRnXOh924FbjpRLUyS89fXqTeprygcw/7ZFmwvJx5Ttnub+JL4CWFSRF0m3TMpWElVe2nLH7ubiEX9kl5yQugfshcAtegetxDlbn9nxDh2j6Ig84PC1LzVNlualBmck0kUE63tqDp6ZHBEslCQ6VN2qivm1kSKCYvuYMPIV7zggp2MbN/SwFFB2N66P969sqZardqz8qElnc3mxKVhwlGbLUd5yuNVtD2VMbk8m4RnRcuKHObUm9yw4EONO2k8YyCVfYUd9WXUpi2eV5ynVk3QIAaFuGKnBrb4My+QC1PNNJ69R1br/tl8DAzVUvGALYV41OplwPeD8A7vbg1aMoNEgKy/1pTxlV2PmbmROX9IZhNerbeh8EbsEryFPy2cWWgUe81ZmRaEzmOjnxxgFbuQvLJahrZ3KmpiPx0csJhkErD05rBqmr7EynLrYqByO4bmhggPN25+qs21e3nRVBY2c6UN5A/7uxWLn+u1sn+cTgnwN3C8amiMs8zVBdN5X19Onom3NSfVsO8Gp9SqXlOrdSwLm5s5eKq4xNFDzVVlVjsnkjE4f1XDdPzaT4iGBx+V9HqpQa1gAAoO2MW3v313LGbXRooLL/17KJ6plnFaYzQ9btMvaduXuO8UAkAAze6PAew+eFGxU+t/mU5n7/gvshcAteQa5xa6lBmWljMu9rbKRV6pIULs24rXZexu3AcglNbi+T4OzMy8tHJNK4dGk9ckM2dW1dR6tv7aKfvXdATMFj98/LNykh4O0GK5fA676tu08pk+CpMwfU26unl0vgZhJHK5uVBnPq2R/2CA0KoKUzpamlnI38tgMaVQAAgHOkxRj3+RfsaFDG5d3kgG9+UqRHfK/zd12gYQq2OuP2aGUTfWU4uMyz0+TZWgAwtJ/MLxDlHNmGQ5V0/ILtiQ0nVMkQaEzmfRC4Ba+qcWupVIL6iDAak3l3qQTOBpUDt+kxoRRj+BJ0pCmqwO2higZyh92qKfOzC4aX5TcU/iHx0ytMs26dgQNVK9cfoirDNLvLcuPpkYWjyZdwDVjOumFfnqgxafzh6WUSvLHO7XZVVvQVo5Mc8pxLZ+VQSKC/0uSlubPHIc8LAADOy7i1p1SCJzUmUx9gLDT0jzhT2yrqcsolrmQ/np3rEUFoAK3g5rYPXDlCXOaJjb/ddMLm5yhGxq1XQ+AWvEJKVKjFUglcKJ8z1VhWfBglRBqDvOC6jNsyF5VKqG7pVgaRzjraOGmQaWKuwAFOOeDF9UJdMR1m8fg05f+580ydUxonvfDv07TjtJRJnBgZQi/fMcWpJSC0KCjAn64xlEvg7VgdoN/r4Y3JZKNSIpXpoPtKL3l0nVt1OYv5oxwTuOVt/6apxkYVH35V7pDnBQAAJ9a4berw+sZk6v4HcoCJM215ttQnhy+I2/jg801TM9z8CgE8z49m5ij7lK0na01mV1qVuGTIuE2NDqXYcO2XXQHb+NYvYvDJ5mRcC7SjR8paQ7atayVEBFO4oaGUvYXWbXWmzjhwdlZAMy0mTMny5vrJOhcHno5daFK62HPmJdcNdTau7ctlC5yVdbv1ZA299OVpcZnfzks/mDLsaeeeauE4Y7mETYZyCd29XN+2QZmaqT4o4mk4C2dmfry4zNuxPdPBtIADzttP1yoN9KbmxDnsudVNyt7edU7UNwYAAG3hqc1hQQEOybjNS4wkTzGpX4OyD74qF+MUdvtl2RQeLM0cAgDbstkfvnaUcv3ZT09Y3VeEZyty7wgmZ8SDd0HgFryuVEL/GrfqxmSTVZmS4JoATbahXEJFQ7tLMutO16oCt07KuFUfBODAU4lq4O0K6izMWU4uk9C/cRJnA7JPj1aZ/OAYjvMN7aJEgjw2+c+Foz26FMBwzRuZpPwQ5A7N/LnhH0byASguNeDpUxDVGcN7SqzPKNAS/p80tktlDOaMSBTZ0o7C9QGvGZOsDMY3Hqly2HMDAIBj8HdxemyoUuPW1uatZ2tblct5HlIqQZ1xy/aXNdCf9pYpB97lOu0AYLvvT8lQEo+4j8qn/fpdWHKiutmp/V3A/RC4Ba8QGRKoBDoGBG5VjcnUU9zBNeTALTebqrJjGpmtzqoybsc68YijabkE4zbm6sDtHBcGOPlI8N1zcsVljsG/vr1k2M/JNVx/9v5BJQDGwarl84z1dH1RWHCAUi/1Uls3fX3ukml9Ww8uk2C+zq3UzMTT8DQ2R9e3Vbt3rjHDnT9rtgYEAADAdXVu+eCqPJaxL+PWcwK3I5MjKTTIXznAfNEw2/GaMSkm/S0AwPYZjo8uKlSu/27TSatmXRVXGRtzj0HGrVdC4Ba85oi3nHXbv1TCIUNQjXeE49JxBMrV1FO6XdGg7Eyd9DeCA/0pN8F5g2B1gzJ1Vrez8VS0r0svKTWMXD3Q5/pLfKCEfXTgPNX0qyltq//9V7ES+OYa1H+4dbJLSj9o3aLxxnIJnx2tpj3q+rZekI3MGaWJkVL9ra9KL4la5B5d39YJgdsZefE00TAd9diFZpNtAAAAtFfnttLGcgly4Jab6fJBW0/B/QfGp0vfT+pjinfPMZb5AQD7cDLAZXnxyj7iL99UDPkYuTE3Q8atd0LgFryGXA+zpauX2rulGi98fuqitCMblRKFmktuzLhl5U5uUNbR3UcVjV1KAyRnNrYanxlD8mx1+eCAK/DfkqfMzy5w/ZR57nr6wxnZShCZ62/a65NDlfTunjIl0L72h0UUEx7ksNfqya4sTKagAD8lcMtTEeUfiN6QzcLb7QxD1i034OLApCdpaOtWDtiMTokSda+dsY7UWbdvOCDDHQAAnJNxa2udW55RI2fo5nlQYzJz5RIYT++W69cDwPDGf6sWG7Nun//itBLbsERuTMa/HTyp0SFYD4Fb8BopZhqUHa1sFlO6Gerbuke2KuvV2Rm3p2talf+3s482RocGUUGS1EiiuKqZOg3BVGdTdxh1V+blPZfnUbAhKP7nPWXU3Gnb1EB2+mILrfroiHL9qe+No/EZxmYXvo63r9mG+sXVzZ3UZWj6oS4x4OlM69x6VjYpNyWTs4yckW0ru258qpLNteVkrfjcAACAdnDDUHsCt6V1xvq2+R7UmEw2Kct0zPbj2bkeX38fQCumZsfRIkOz4tqWLnprZ6nFZfk3qNxvZURylEN7LoB24L8KXiMlamCDskMVUpYam9xvgAGuz7gtc3Lg1rQwu/M7asoHA7h+73HDkU7XNiZLcNtBkpumZigZ7u/vK7fp8ZxhufzP+5XM4VuKMmnJ9CynvFZvKZfgTWUSzNe5rffYMglXjHJe4JZnDch1pdkfd1geuAMAgHtLJXAzSWuV1HpmfVtzGbex4UF0w2RpXAgAjvFfi0aLUo/s1W0lIkvfnDM1rUoD8DEu+P0L7oHALXiNZEONW3axRcq4PVzRpNyGxmTuG9DKJUsrnB64VRdmd349Y1c3KONSEAfLG5TawZlx7psyf/+8fKVUxJs7S63OOOYGS6s++pbOGn6wcID96RvGI0vDjGvHpijr2BsDtwVJEZRkOODGdZutab6gBTqdnrYbArfhwQFUlBvn1L/HBzWiDHWlNxysFJkXAACgvVIJttS4lTPkPLVUQm5COM0ZIY1JVl490qNq9AJ4Ap7Zedu0LCXp5eUvzwxd3xaNybwWArfgpaUS5IzbRuXH9chkHIFyB65dKtd/LHNyjdsTqo6aLsm4zXRt4PabMg5u6ZX6tu6UnxRJC8cap/BwQMka7+w+R//v2ypxmYNRa39UhMG+BYmRITQ9N94ke12d2ePpeEqlnHXb1t1HRyuNB9q0jLPr61q7lc9hSKBzf6xGhQbRHXJd6T4d/WmP/XWlAQDAsVLtLZWgyrgt8MBSCfwd/qd7ZtDBJ66lH6MpGYBTrLxmJIUGSSG7P+09ZzYJSq5vy9CYzHshcAteIzlKFbht6RLBJPnIN9fOlKcagOtxdihr6uihJkMjBkfjTE75iCNn8SVEGjOwnYWPanJg2lUNykzLJEj1T91p+RUFyuXXt5co03QsOVDeQP+7sVi5/rtbJ3rk9EBXkutbMW9s+qF+T+rt21PKJMwfneySv/njObkUaPgO+9PeMpF9DwAA7hcaFCAOtLILjTaUSjDUuOVmQhlxnnlQ1t/fj+Iigt39MgC8OjFt2eV54jIn76zefGrAMsi49Q0I3ILXSFGXSmjupG8NHb8ZGpNpI3DrzAZlF5u7qLGjx6X1fbj4+/h0qSTDufp2amw3X3vIKYFbDTSp4s+V/DpK69ro82PVFpflukwPvHdAyRi+b24eLRqf5rLX6qm+PyVD7Nv4AMHtl0lZl97k8hHGAxAffFXuEeUStp2qc0l9WzWetfDdidLnpaG9h/524LxL/i4AAAwtI1ZKHrnY0mnV9xgf6OZxI8tJiEByCQBY9JP5BaKONPv7oUo6dqHJbI+XhIhgSnJB4hK4BwK34DWSVaUSOHCrzoBE4Na9suKdH7gtdnFjMrN1bs87b6p3c2cPHTEcjBiVEqnUBnW3n6qybtduOysyn839QHnww4N0wdC0Y3puHD2yqNClr9NTxUcE045HrqJvfnmN6DDrbfgH63xD8PN8Qwd9cugCaVlLZy8dNHy35CdFmOzbnO3eufnK5Td3DJ3hDgAArq1zy0OgaisalHFJhe5eKcCbj5lHADCI6NAgeuDKEco+5refnVTu4xnGcvkungnKJUzAOyFwC14jMiRQnFhNc5dJ4BaNydwrJ944Hb7skrGmlyfXtzV3UOBQufPKJXxVconkOM1sDZRJkM0dmUjjDFnH355voj1mpru/+O/TtOO0lKXI0wlfvmOqyFYG63C2LQ/avNUDV0mDUbZm6xlNByS/rmhRXp8ccHYVLvkj17bmTK0vii+69O8DAIB5ci8Ha+vcenpjMgBwraWzcpQ+F1yya/fZOpNsW4b6tt4Nv5zBqyQbshCrRamEJiVQlK5qHACux02VZOaKqjuC+otrtJsCt4dV5TmcWSbB3Y3J1PjILk/hUWfdqm09WUMvfnlaXOYSnS/+YLJJI0EAbsA2I0+qdVtS20afHbVccsPd9pwzZtVf4aL6tmr3zTNm3b6xvcTlfx8AAAZKN5RKYFVWZNyW1kr1bRkybgFgKNwI9+FrRynXn/30hNTfxU2JS+B6CNyCV0k21Llt7+4TjbDY5KwYTBtws2xVjdsyQ00vR5O/uDiRsyAp0qVB6ThD3aHDFY1mSwU4gnxklYOfMzRQ31btuvGpSnCeM2uPVkrBLW4OuHL9ITGth/3HgtGayhYGbWbdvrzljNM+R8PBr2lvmXSAKCTQXwk2uxLX1B2ZLO3fvilroIPlDS5/DQAAYErOhGNyY+TBcF8AWb4Lx6wA4Nl9L+TgLJfn+/RotUmpwDFp0gxI8E4I3IJXMZfJNynTmBEJ7hETFiROzgrcdvX20VlD9kJufJiYWu7KjFO5FEd9W7eo0+loda1dSsdQni4tr0utCAzwN8kEfHXbWfE/WfHeAWpslw6gXF2YTD9VZeYC9G9SNikzRlwurmqmL0/UaG4FnbzYSrWt0vY8qyBBdBJ3Nd7f3DtX6i7M/rij1OWvAQAAzNe4tatUAmrcAoAVAvz96FFVj5DfbTpJxyqblcSeEYYD++CdELgFrw/cTs5G4FYLcgxZt1VNxoYMjnKmppV6DXUnRyQaB8+uoj44oK6t7Ch7S4xlEjhgpEW3FmVSYmSwuLzxSBWt/PCQyEBmWfFhtPq2yeTPowoACwHJB64aqVx/6UvtZd1yTTGZq+vbqt0wOUOUAGKfHq1yWvkZAABwUuC2VgrcRoUGik7wAADWuGJ0kjLjizP3T15sUTL33ZFQAK6DwC14ZY1btYkZCNxqgdx9neOr1kwjs4W6vs9INwRu1QcH5GCl8+rbarPUAA8W7p6Tp/yPefoO4+zntT8sohhDOQkASzgrW54CxgdA1Nu9FmzXSOCWP2t3zcpRPmtv7kTWLQCAO3HwVZ7tdaFx8Bq3nT19dKGpQwm2oAs8AFiL9xerFhuzbmWob+v9ELgFr5LcL+OWC/4jYKQNOaoGZeUOzhBTNybzxozbPYYAVqC/H03PjSOt+tGMHIoINj3a++T3xonyDgBD4YzsFVeqat1+eUYzK621q1fUlGXZ8WFun9r6o5k5FBokDeH+8k0FNRlKkgAAgHu+v+RGyENl3J6rb1Nq/6MxGQDYakp2HC0en2pyG+rbej8EbsGrpPTLuJVrj4L7yc2rWHm9sbaXI8j1X9mIJOPfcZX4iGDl/R290EQ9fY4rBcE/AOQmFlOyYyk8OJC0ig+S3DEjW7l+89RMun16lltfE3iW70xIU4Kie0rqaX/ZJdKC3WfqqKdP+qU9b2SS2zOk4iKC6daiLKUZ53tflbn19QAA+Lq0GClxoKWrl5o7LR9MKzWUSWDuPggIAJ7pPxeOFjVvZci49X4I3IJX17iVm92A+2Ubatw6I+O22FAqIT48iBLC3RPYnGw4SNDZo6NThnpDjsy2ZbM0WiZB7cFrRtEtRZm0dGYO/c/3x7s9wAWehQehP72iQHNZt1vVZRJGu69Mgtqyy/NI/nit23XO4bXDAQDAvjq3VYOUS1A3JstPQuAWAGxXkBRJd1wmJcuEBPojWc0HIHALXiU5Ghm3npBxW1bvuMBtbUsX1bV2icujU6PdFihUZ3c7slyCaX1bbTYmU4sMCaTf3zqJnv7+eArrVzYBwBo3TsmgDMMP4C0na+loZZNbVxw3Sdt2UgrcBgX40ax8qSmEu+UmRtCCsSnick1LF/3j8AV3vyQAAJ+VEWtMHhmsXILcmIwh4xYA7PXEd8fS/944nt6/b6bStBa8FwK34FV4Gjl3aJV/YI9Nj3b3SwLVFDL+nzg64/akqkxCYZrU2MgdJmfFOLxBGQeM9pytU46mcqkEAG8XFOBPy+fnK9fXbHVv1u3Z2laloeLkjEhNlSu5b65xPf1xR4nYZ7hafWsXbT55iXacNmYlAwD4csbtYE14S+talcsI3AKAvbgh4g9n5FBRjnb7n4DjIHALXufK0cnifNH4NAoJRMaflqZAZ8WFK4FbRwUY1I3J3FnfZ1x6jGgexg5XOCZDkDOTLzRJ0+2m58Zjewafceu0LEoy1Cz/9Gg1nalxXPkRW201ZNuymTnaKr/Dg3X5gA7X+t5xWjrQ40wd3X207VQt/WZjMV33wg6a/psv6YlPS+nNneec/rcBADwhcDtYxq3ctyAtJlRTBwIBAEC78G0BXue5JZPpJ/PzaVSK+4J4YF5WfLio7cXNdOrbuh0yreN4Vf/ArVQ2wdVCgwJExu/RymY6VdMiutBz2QCHlUkYof0yCQCO/DzdNzePfrPxhOi+vWbLWVq9ZLJbVjAHKWWzc7U1i4NLw3DW7Yr3Dojrb+wooXmjHFuDt7dPR0cqm2jXmTraeaaODpQ1UreZBoxfnbtEXb19OMAEAD7JmsBtQ1s3NbRLjcuQbQsAANZC4Ba8MrOTsx9Be3JUDco4m9QRgdsThsZknOw6KjmSmhrcE7hlkzJjReCWA01HzjfRrGHWpN1tKJPAZntAYzIAR+LpX2u2nqXG9h765PAFWnnNKJMmh67A2aX7Si8p2VG58aYNMLVg4bhUyooPo4pLHSLjtriqmcak2R9g5tkQnBHGgVp+vj0l9dTS2Wt2WS4pPi49mqakhdG1E7MpAM0IAcBHpZvUuDXfnAyNyQAAwB4I3AKAWxqUVVxqH3ZNnp4+HZ2pkWqF5SdFUkiQe0tjTM6Kpff2lSsNyoYTuNXpuL6tlHEbFRJI41GvGXxMREgg3TMnj1ZvPkV9Oj2t3XaWnrlpgktfw96SeurulbJL549Kclvzw6EOVi6bk0e//udxcf2PO0rpD7dNsrnJIx8o2nm6TgRs5RItlvbjc0Yk0uUjEsU+LjYskGpqaig5OZH8/VGBCwB8E5c9iAsPEhm1lmrcymUSWF5ipAtfHQAAeDIEbgHALYFbzrgdLh4Ay1N23VnfVh24dVSDMi63wOUk2Iz8eAoMQEAEfM9ds3Lp9e0lovTIR/vP04NXj6TUGNdlvW49WaNcnj8qUdM1gTnA3dzZS/84XEmPLBpNKdGW11NbVy99VXpJlD7gQC3Xx7WEAxGzDYHaOQWJA7KedbqBZRMAAHy1ES8Hbi82d4oDjnxgTa2k1tiYLD8xwg2vEAAAPBECtwDgMuof/GWXjFkH9uIpwbLhTA12FM765bq2HGQ6fH54gdvdZ4z1bWehTAL4qJjwILpzllQygQ/ScBD3/7t+rMvr23LjwdkFCdTR3EBazU7+0UxpPfX06Wnd7nP06KJCkzq1h88b6tSerqMD5Q3UqzPfIDIk0J8uy4uXArUjEmlsWjT59ws+AACA+Tq33HuB9688k6H/gUZ1xm1+EgK3AABgHaRwAYDbSiUMlzpLTAsZt5xZMTFTqq9c1dQpMi4c0phsmLVyATzZssvzKDRIGq68/1UZ1be6po71ubo2OmeYGcBlXaJCg0jL7pqdS0EBUoD1vb1ldLSyidbtKqV73/mGJj+1mW5eu1tk5XITMXXQlqs/TMqMoRVXFND7986gw79aQH9aNoN+Mr+AxmfEIGhrgzVr1lBeXh6FhoZSUVER7dixw+KyVVVVdMcdd9Do0aNFiYmVK1cOWGbdunWiPEf/U2en/d8tAOA8Gao6t+bKJciBW95XZ6iamQEAAAwGGbcA4NL6X9yQrK61yyGlEk6oMm4LNZBxyyZlxSpBV65zy42DbMXZcftKpOeIjwim0SnuD0oDuEtCZAj94LJsenvXOers0dGbO0vpEVU2qbOzbdn80UmkdVwa4XuTMuijA+dFyYTvvrTT4rLczXzOiASRVTszP4Fiw4Nd+lq90fr160XwlYO3c+bModdee40WL15Mx48fp+zs7AHLd3V1UVJSEj3++OP03HPPWXze6OhoOnnypMltHBgGAG1m3MouNHaY9HLg3gVy4JYTGVACCwAArIXALQC4VE5CuAjc1rR0iY7tYcEBw864jQoNpPSYUNEN3d0mZZrWubUncHvsQjO1dEld3GflJyDjDXze/fPy6b295aJcwp/2lIls0JiwIJfVt71iVLJH/A/um5cnArf9JUQEG+rUJojyB5lxpnVqYfhWr15Ny5Yto3vvvVdcf/7552nTpk20du1aeuaZZwYsn5ubSy+88IK4/NZbb1l8Xs6wTU21/XsEANwfuFW70NRBXYZml1xaCwAAwFoI3AKAS3GWwf4yqU5kRUM7jbIzm7SxvVuUI2BjUqPFj1stBG6nZBsDt5xxO9wyCdy1HcDXccOXm4sy6YOvysVBjXd3n6OfXz3SaX+vs6eP9hiy3pOjQmhMWpQm9i9DKUyNpl9cNYL+tv88jUyJUurUcikZ1Kl1nu7ubtq/fz+tWrXK5PYFCxbQ7t27h/Xcra2tlJOTQ319fTR58mR6+umnacqUKRaX50xePsmam5uVJnKuaCTHf4M/K2hah/Xii9tLWkyIcrmyocPkfZ2tMZb3yksIH/Q9e9t6cRSsF6wbbDP4LHnTPsaWv4PALQC4rc5teb39gdviKuMAmIMqWpqunBodStXNnfTt+SYxNc7WgMnus3XKZdS3BZD8dH4B/eWbCtGp+81dpXTP5XmiKZczfH3ukijLwOaPStLMgSFrPLxgtDiB69TV1YnAakpKisntfL26utru5y0sLBR1bidMmCACsJyhy2UYDh8+TCNHmj9wwdm9Tz755IDba2trXVIbl3+ENDU1ic8L1+4FrBdf2l6Ce7uVy6U1jVRTY5y58W2p8XJCiM7kPm9fL46C9YJ1g20GnyVv2se0tBjjGUNB4BYA3Ba4LRtGg7IT1dqrbyubnBVLnx2rptauXiqpa6URydYHlrt7dSJoxDgAzLUoAYAoOyGcvjcpnTYcrKTG9h56f1853Tcv3ymrZutJz6pvC9rAAX41Hvj3v80WM2fOFCcZB22nTp1KL730Er344otmH/PYY4/Rww8/rFzngG9WVpaop8v1cl3xo4ffM/89BJywXnxte0lI1FOg/1HRALK+Q0fJycYyO3VdxoPyk/JSKTk53mfWi6NgvWDdYJvBZ8mb9jG29CxA4BYAXF7jVlYxnMCtKuOWpwFrySRD4JYdLG+0KXDL5RXkTL/ZIxKG9aMfwNusuKKA/n6okjj59fUdJbR0Vg6FBtlfJ3uoxmScLM/lBgAGk5iYSAEBAQOyazmjrn8W7nDwj4jp06fT6dOnLS4TEhIiTuYe66oAEH9vufLveQqsF+9fL/wWeOZVZWOHKOelfk8lhsZkrCA5asj3603rxZGwXrBusM3gs+Qt+xhb/ga+CQDA5VlzsrJ64yDW3oxbjmvaW27BWSZlxSiXD5+3rc7trjPqMgkIGAGocd3WRYaGf7UtXfTXbyocvoLON7TTmZpWcXlKdhzFhgfjnwCDCg4OpqKiItq8ebPJ7Xx99uzZDlt7nMF76NAhSktLw38EQKMyDA3KGtp7qL1bajTLSg2B26iQQEqMxPcKAABYD4FbAHCppMgQCjNkyJXbmXHLNS5PXpQybnPiw51W59JeEzNjRUCZHa5osumxe9CYDGBQP7tyhHL51W0l1NOnc0q2rVzfFsAaXJ7gj3/8I7311ltUXFxMDz30EJWXl9Py5cuVEgZ33nmnyWM4CMsnbkDGNWj58vHjx5X7uVbtpk2bqKSkRNy3bNkycS4/JwBoT3qscerrhcZOpeElZ+Gy/KQIzKYCAACbaCvaAQA+Mf2A69xy4LVCdNy1vXkXZ+rK5QS4i7rWRIYE0sjkSDp1sZWKq5rFgN2a6dycmXGwokFczk0IV7I2AMBofEYMXTk6ibacrBU/hP9+sJJunZbllPq2V6C+LVhpyZIlVF9fT0899RRVVVXR+PHjaePGjZSTkyPu59s4kKs2ZcoU5fL+/fvp/fffF8ufO3dO3NbY2Ej333+/KMEQExMjlt++fTtddtll+L8AaFS6aux2obGDRiRHUll9uyjxw9C7AAAAbIXALQC4XJYhcMuNuC62dFJajG0ByhPVqvq2adoqkyCblBkrArfcoOLYhWYqyokb8jHfnGugnj5pZD8LZRIALHrgqhEicMvWbD1LN03NpAAbDwCZw/uk3YZyJQkRwTQ+3Vj2BGAoK1asECdz1q1bZ7b0wWCee+45cQIAzw3cstI6qfwOy0uMdMvrAgAAz4VSCQDg1gZlnIVgK85ilWkx45ZNzo5VLh+usK7O7W5VmYTZBQlOeV0A3qAoJ55m5scrdQM3HqlyyPN+U3aJ2rr7xOV5o7ijLJoDAgCA9TLMBG7Vjcm4VAIAAIAtELgFAJfjUgmycrsCt8aM27Fp0ZrNuJUdsjJwu+essTHZzHwEbgEG8/OrRiqXX9lyRpRdGS7UtwUAgOFIU9W4rTTUuC2pNQZuUSoBAABshcAtALhctirj1p4GZSeqpYzbiOAAyozTZh3Y0alRFBIo7WIPnx86cNvU0UNHKqVGZqNToigpKsTprxHAk3FW+uSsWKV8yr9P1Az7ObcZyi9wc8G5IxOH/XwAAOC7pRKqmuRSCQjcAgCA/RC4BQC3ZtyW2Ri4be7sofMNHUpwVKtTmYMC/GlCRoxSDuJSW/egy39VeonkhMFZKJMAYFWjwweuHKFcf3nLmSFrhg6muqlTqZ89MSOGEiJx8AQAAGwTHRpEUSGB/WrcSoHb1OhQijDcBwAAYC0EbgHA5ThLljPa7Mm4PWXSmEybZRJkkwzZgNZk3e5WlUlAfVsA61w9JpnGGPYDXEt61xljnWhbbT8lZduy+aOT8S8AAIBhZd1eaOqkhrZu5eA9yiQAAIA9ELgFAJcLCQygtGipBlh5vXH6mDWKVYHbMalR5DGB2yHq3O4xNCbjBOIZqG8LYHXW7c+uLFCuv/TlabvX3NZTxlIL80cl4T8AAAB2STfUue3u1dHX5y4pt6MxGQAA2AOBWwBwa53bhvYeUf7AWieqpPq2npBxOyXLugZlda1dyhRtLq8QExbkktcH4A0Wj09TfgzvK71E36h+JFurt09HO05LWe/8+ZNr5wIAAAynzu2uM8YZVci4BYt0fURdrURt9UTdbUQ6HVYWAChQZAcA3CInPoL2lkgBlvL6dhpvqAc7FDnAKde41XpJiPiIYDFFjjNuuf4mZwhayrZlswrQEAnAFgH+frTiihH0n389rNS6XXf3ZTY9x8GKRmrp7BWXuSkZPycAAMBwA7c7VIFbZNx6KA6i9nYQdbcT9fCpg6inzXDOp/Z+96nvl+/rGPyxfV0D/25QBFFwOFFwhOGyfD2SKCjc9HJQOIV36YgSUg3LRZp/LF8OQAgIwNPgUwsAbs24ZRWXrAvc6nR6JeM2IzZMNIDQMg7STsqMoS0na0VmccWlDpP3LdutCtyivi2A7W6YnE7Pf3FKNC7cerKWjpxvogmZ1h0MYttOqurbokwCAAAMA49RZSW1xpJg+YmRWK/Ows1J+7qlbFURDG0znsT1VilAKq7L97WbXuZllMeqrvd2uuf/JgK8bURtxjHKYNOorZ6HGBBiCOQaTmFxROEJROHx0nmY4Vw58fV4opAYIn9M2AZwBwRuAcAtsuONAcwyKxuUcVCmrbtPXJYbEmnd5Kw4EbhlBysazAZu9xgakwUF+NG03DiXv0YATxcU4E8/mV9AT/z9qLj+ypYz9OrSIqsfj/q2AADgKGkxUo1btUB/PzETC6zU00nUXEnUdF45+TVVUFxdGfn59fQLsBoCnDpp5ozmBQQTBYUZMmX5PMJwHkYUGCIFivu/Nz53VACZs3s7+GRjaSm/ACmAqwR2+58bTuJ+w22hMZzJ4pjXDeDD3B64XbNmDf3ud7+jqqoqGjduHD3//PM0d+5ci8tv27aNHn74YTp27Bilp6fTI488QsuXL1fuX7duHd19990DHtfR0UGhoQO/RAHA/YHbcisDt8XVxvq2Y9K0XSZBNinLmPV3uKKJbpicYXJ/ZWMHnauX3v+UrDgKD3b7bhnAI91alEkv/fs01bR00WfHqunUxRYalTL0fqK2pYuOVkr7lrFp0ZRsaJwIAAAw3FIJMj5wHxiAbEUlO5azSJsqiJrUwdkK4+U2Y8NQGYf/Qpy+SfoZygsYygzIl9WBVlFyQH1b//vlQKyFZewtVcB1cM1mFLeRrquNmuuqKDosgPzl8gsmGcTq7GPVdXkZa+j7pP+bFRnAA4K9SlA3jigkWpXxG2ma/Wtyvd9llHgAH+bWCMH69etp5cqVIng7Z84ceu2112jx4sV0/Phxys7OHrB8aWkpXXfddXTffffRn//8Z9q1axetWLGCkpKS6Oabb1aWi46OppMnT5o8FkFbAG3JUWWeco1ba5yoMta3LUz1lIxbY5Ojw+cbh6hvm+Cy1wXgbUKDAuj+efn0P/8qFtfXbDlDz98+ZcjHbT9l/AFyxegkp75GAADwfqkxoSLJkOOTPlkmgYOGIltWFYg1CcxWmq/pagsOCJrUcTXUex20JqwqQGhpeQ6uajVD1D+AKDRaOvWn01FnTQ1FJyfbXs6As5s5+7adT/XGU0eD6fV21TKcBeysYK8lgaFWBHj7XQ8Mo5C2LqKGROnxAUFSVjOfc+azOFm47B/onm2BdxycPd7XQ6TrIerrla6Lyz2m9/FlP3/ptfrzaw+SthPlcqDxJF/X6vYN2g3crl69mpYtW0b33nuvuM7Ztps2baK1a9fSM888M2D5V199VQR0eTk2ZswY+uabb+j3v/+9SeCW60qmpqa68J0AgK24c3tUaKBoCGRtxu0JVcZtoYdk3MaGB1NuQrjIqj1a2UQ9fToxrVu221AmgaG+LcDw3DEjW5RJ4JrS/zh8gR66dhTlJEQM+phtqsAt6tsCAMBw8TgvJSqUqps7vbMxWVcrUUMp0aVSosaygYFZDuzZzY8oKo0oJlN1yhLnuugMqu0KoqSMPPIPCkUAylF4XQalE0Wn2xHstRDYFYFf+bIc7LUys9cSLhXBJxu2L/7FNawidAMCuuqgr7mAbxCRXmcMsA4IwKoDrxbuc3bJD78A8gsIomTDuRTQNQR1OavZ7GVVEJgPdoRESTWPxXmUdDBBvswZ1SGq6xxIR21kzw3cdnd30/79+2nVqlUmty9YsIB2795t9jF79uwR96stXLiQ3nzzTerp6aGgIKlRUWtrK+Xk5FBfXx9NnjyZnn76aZoyxXLWTVdXlzjJmpul4JBOpxMnZ+O/wd3m2IWnUQAANG9JREFUXfG3PAnWi/evm5z4cDp6oVmUC+jq6TUJaJpTbGhMFhLoT9lxYQPev1bXy8TMGBG47erVUfGFJqURG79WOeM2NMifJmZGO+W1a3W9uBvWi/etl9BAf7pnTi79YfNp0umJ1m49S7+5cbzF5ft0etpxWgrcRoYE0uSsGIvv25PXizO5Y73gfwAAWpceaxq4zUuM8LxSBhyYlQO06vPhZE8GR/ULyhoDs+LEwUMOEpnD3zc1NVLGJLIGPTDY2yEFceUSDepyDSblG1oGuU91fbiBYGtwwzs+eRN9H/n19onSI9Tjij/opwrqyoFd1XWug2z2PkN2OZ+HxUrZ8D7MbYHburo6EVhNSUkxuZ2vV1dXm30M325u+d7eXvF8aWlpVFhYKOrcTpgwQQRgX3jhBVGG4fDhwzRy5Eizz8vZvU8++eSA22tra6mzs9MlP0CamprEDx9/HI3AevGhbSY5wl8Jnhw5W0mZsZYrV3X09FGZoaRCfkIo1dfVesx6KYg17mp3Fp+n5CDpQFF5QydVNUn7mIlpEdR0aTgZCpZpdb24G9aLd66XRQXh9Oo2f2rr1tHf9p+nOybGUnJUsNllj1a1iexcNi0rkhrqjRnw3rZenMUd66WlxVg2BwBAq3VuD5QbS2Tlay1wyxl+nCE7IDB7TjpxgMye8gUcyBssMMtBGvBNHHiLMe31MSxc89ekZu/AYLCuq5VaG+spMiyY/EWGqyEQy5muJuf9L3dbv6w1RDmDfuUL5ExXObN1wH3qZcyUQJDPRWkFcyUV+kzLK6gyffW6Hurr7qQAPyK/AY9VXXZI9q+eqKtZOg1HQIi0/+Agbmis4TxGddnCbXJg2MMP9ri9Cw6XNVDjgX//24ZaXn37zJkzxUnGQdupU6fSSy+9RC+++KLZ53zsscdEwzMZB3yzsrJE7Vyul+uKHz38+vnv4ccg1osvbTMj0xroy9PSoLbNL4ySkxMtLnuoopF3+8L4zHhK5hpOHrJeLh8TRM9tqxCXzzb2Ka/9i9JyZZn5Y9LMvidH0Op6cTesF+9cL/wpumt2K63ZepZ6dXr6+Hgz/X/XjzW77JEjp5XLCyZkDvoZ9PT14izuWC/oWwAAWpfRr0FZnjtKJXCtWQ7CXioZGKDloK09QRkuYxCXRxSfJ53H5RLFGgKzkaloIAWuw4FMOTvTEp2O2mtqKNKe2r821aNVBXTlmrNKIJbPtTVu1Ot0VFdTI8a9foO9NvH++gWAOTDe1WI4GQKyfLnTcK6cmkyvy/dbWx+5v74uqWmhmcaFVh1UUoK+gwR7Q2MomHOqwmcRRaeRlrgtcJuYmEgBAQEDsmtramoGZNXKuG6tueUDAwMpIcF8Ux/+ETF9+nQ6fdr446y/kJAQcTL3WFf9COEfPa78e54C68W714269mRFQ8eg7+XkReOR/zFp0RaX1eJ6GZcRS0EBftTTp6dvzzcpr21P6SVlmTkjnBv00OJ60QKsF+9cL8suz6O3d50TmfofflNBD1w9khIjB37PbztlzLC9YnTykO/X09eLs7h6vWD9A4DWpcWEKpe5FE+Sme8gh+GASvURovK90rkcnG01P4t1UBxois02Dc6qg7Rc3xIAJJw8KNeJJY1l1Tvs/Rnq3cqlCsLjh/ecnNHL5TAGBHXVgV9VMLizyXBqJOpolM5tnRHATfK45jKfBsGjWH53uu+9QjT1R6QlbgvcBgcHU1FREW3evJluvPFG5Xa+fsMNN5h9zKxZs+if//ynyW2ff/45TZs2Talv2x9n5B46dEiUTgAAbclJMA7+KoZoUHbCUN9WDtx6Wrd7fs0ctD1T20otnT0UERxIew31bblJ2/h0z3pPAFqWEBkiGpW9ubOUOnt04vzRRYUmyzS0ddPh81LG/6iUSDGtFQAAwBHU3yncmGywGaU242DG+a+JKvYRle8hOv+NbfU+uVmQCMjmDgzQRmciaxYAnIeDwGFx0mk4wd9OdTC3QbouB3bl8wG3GYLAyjxeCzgLV2PcWiqByxMsXbpUBF45KPv6669TeXk5LV++XClhUFlZSe+++664zre//PLL4nH33XefaFbGjck++OAD5Tm5Vi2XSuB6tlzygMsjcOD2lVdecdv7BADzsuONgVu5fq0lxdXGmoaFqYNMidGoSZmxInDLM06OnG+iuIhgqm+T6iLNyEugwCEaswGAbe6fl09/2lNG3X06cb58XgHFhBsP8m4/XSs+j3K2LQAAgKNkxoU7rr5t8wUpQFtuCNRePCp1rh9MRNLAoGx8vnQ5ItHj6z0CgI8HfyMSpJOtuJkuZ/SaBHOly7qOBmqvv0DhiaNJa9wauF2yZAnV19fTU089RVVVVTR+/HjauHEj5eTkiPv5Ng7kyvLy8sT9Dz30kAjEpqeni8DszTffrCzT2NhI999/vyipEBMTQ1OmTKHt27fTZZdd5pb3CACDTyML9PcTdSjLB8m45cx5OeM2NTpUBD09zaSsWPrT3jJx+dD5RgoJDFDum11gx5cOAAwqJTqUbpmWSe/vK6fWrl5at/scPXiNsUnptlPGBofzRyVhbQIAgMOMSYui70xIo4PlDfTjOXm2BRVqjlPYsc3kt+uYlFXbaPw9bFZ0BlH2TKLsWUSZ04gSRgxe9xMAwFf5+0sZtXzqn/Sr01FrTQ2FJ2gvocPtzclWrFghTuasW7duwG3z58+nAwcOWHy+5557TpwAQPs4yzQzLozO1beLwK2l5oRVTZ3U3Ck1UChM88yB6OQs45SLwxWN1KczTtGYPQKBWwBn+On8Alr/dYX4vL29u5SWzc0TtQZ1Oj1tNwRuw4MDaFruMKZrAQAA9MPj2Vd+OHXIxtvU00l04YAho3avCNT6dzZRjMUH+BGljCPKmiEFajlgy83BAADAa7k9cAsAvi0rPlwEbjkjrqG9h+LNZNOeqDbWty1M9cxasDxNLiokkFq6eulAeSN1dveJ2xMigmlUsmcGowE8Yf9yw+R0+vhAJTW299B7e8voJ/ML6HhVM9W1disZ7+oMeAAAAEcZELRtqzfWpuVA7YWDUsd2SwJDiTKmGTJqZxJlTtdk/UUAAHAeBG4BwO0Nynacli6X1beZDdwWV7WYTD3zRP7+fjQxK4Z2namn2pYu5faZBQniPgBwjhVXjKANBytFPds3dpTSXbNzTcskoL4tAAA4A3/xXCoxDdTWnRr8MeGJpM+aQS3x4ylyzDXknz6ZKNDzSoQBAIDjIHALAJppUMblEqZkD5yyXGyob+vJGbdyuQQO3Kqhvi2Ac41IjqTrxqfRv45UUV1rF/3lmwraerJGuX/+SNS3BQAAOzubt1QRNVUQNVYQNZUTNZ03XObTeaKewZvvinq0WYZsWi59kFAgyiu019RQZHKyVI8RAAB8GgK3AOBW2fHGTrvl9eYHtyeqpYzb4AB/yk8aZmdeN5qUOXBq2+yCRLe8FgBfsuLKAhG4Za9sOaOUSeASJtkJxoNHAAAAip4OKfiqBGb7nTdXEuml0ldW8Q8kSptsLHvAAdvIJPOZugAAAAYI3AKApjJu++vs6aOS2lYlcy4owHMzD9QNylhaTCjlImgE4HTj0mPoqsJk+vJEDV1sNpYqmT8a2bYAAD6ro7FfMLbc9HqbsayOzQLDpKZhcXlEWdOlIG1GEVEwDhYCAIBtELgFALdSZ7uVmQncnqlpJZ0h8aDQQ+vbypKjQyk9JpQuNHWK67MKEgbvNAwADvOzK0eIwK3a/FEI3AIAeLXuNqKaE0Q1x4lqionqzxizaLuMpbhsFhZHFJNJFJMtBWhjslTn2UThCdyZzJHvBAAAfBQCtwDgVpEhgZQQEUz1bd1UYSZwq65vO8aD69vKJmXF0oWmanEZZRIAXKcoJ07UlN59VqozHRLoTzPzE/AvAADwBr3dUlBWBGgNQVo+bzhnx5P5EUWl9gvGZqmCtJlEIZ6dTAAAAJ4DgVsA0ETWLQduq5s7RWmE0KCAAfVtvSHjll0/KZ0+PVpNceFBYuo2ALjOA1eOUAK3nPGu3tcAAIAH0OmIGs9JgdmLqiBt/WkiXa91z+EfJAVfTYKxqiBtdAZRYLCz3wkAAIBVELgFAE3UuT1Y3ih6MZxvaKcRycYA7YlqY8ZtoRdk3F43IY2+eHgexUeEUHwEfhQAuBIHax++dhTtOVtPv/zOWKx8AACt4kFhS7Uqe5ZPx4hqTxL1mG9mO0BQBFFyIVHyWMNpDFHSaKLIVCJ/z+2ZAAAAvgWBWwBwu5x+DcrkwK1er6fiKinjNjEymJKiQsgbqAPTAOA6XFP6F1ePFCcAANBQk7A6VR1aucxBR4P1GbSJo6TAbIoqSMvZtAjQAgCAh0PgFgDcLksVuC2rN2ZR1LZ00aW2bq/JtgUAAADw6UZhnDFrCMz61RRTUvVR8m+7aOUT+BHF5xkDs3ImbUIBUUCQk188AACAeyBwCwBul5MQYZJxKytW17dNRZYqAAAAgGc1Civu1yhMryzmR0QWK41HpRuCs2NUZQ4KiYKNB/sBAAB8AQK3AOB2OQmqUgmqjNsTVcb6tmPSkHELAAAAoBm6PikYqw7O2tgoTBcSQ34pY8kvZZwxSMsB2vB4p798AAAAT4DALQC4XVJkCIUE+lNXr84k4/aEOuM2DRm3AAAAAG5pFNZ8wTQ4y+dc9qC3w7rnCAqXArJKmYMxpEsqpJp2f0pOSSE/1KIFAAAwC4FbAHA7f38/yo4Pp9M1rSJwq9PpxW3FhozbAH8/GpEc6e6XCQAAAODd2upNg7NyNm1Xk+2NwtRlDmJzBjYK0+mIOmqc8jYAAAC8BQK3AKAJcuCWs25rW7soLjyYzta2ivsKkiIoJNBiFTQAAAAAsEdPJ9G5HUSnPiM6/TlRY7kNjcLyTYOzaBQGAADgcAjcAoAmZKvq3JbVt1NDezf19EkNLApTUd8WAAAAwCGaq4hObyI6tYmoZCtRj7FMlVnRmWYahY0mCgrDPwQAAMDJELgFAM1k3Mq4XEKgP/calqC+LQAAAICduCTBhYOGYO1nRFWHLZc5yLqMKGW8KkhbSBQag1UPAADgJgjcAoAm5Kgybsvr20TJBNkYZNwCAAAAWK+rhejsFimrlksgtFmoJRuRTDRqAdGoRUT5VxCFoBksAACAliBwCwCazLi91N6jXEfGLQAAAMAQLpUQnfpcyqo9t5NIZxxLmUibJAVqRy0kSpsysGkYAAAAaAYCtwCgCZlxqhq3l9qpsqFDXI4ND6LU6FA3vjIAAAAADerrJarYK2XV8qnupPnlgsKJ8q+UMmtHLiCKTnf1KwUAAAA7IXALAJoQGhQgArTVzZ10oqqFOnr6xO2FqVHk52esdwsAAADgs9ovEZ35Qsqq5fPOJvPLxWRLGbWcWZt7OVEQDoIDAAB4IgRuAUAzshPCReBWDtqyQtS3BQAAAF+l1xPVnpACtZxVW7GPSG/sA6Dw8yfKvMwYrOXmYjjwDQAA4PEQuAUATdW5/ar0ksltY9LQJAMAAAB8iE4nBWiPbSA69SlRY7n55UJiiEZeIwVqR1xDFB7v6lcKAAAAToZK9ACgGTmqBmUyZNwCAIAnWLNmDeXl5VFoaCgVFRXRjh07LC5bVVVFd9xxB40ePZr8/f1p5cqVZpf76KOPaOzYsRQSEiLON2zY4MR3AO4P1n5F9OkqoufGEr29iOir1wYGbRNHEc3+OdGP/0X0yFmiW94imngbgrYAAABeChm3AKCpUglqPMNvVAoybgEAQNvWr18vgq8cvJ0zZw699tprtHjxYjp+/DhlZ2cPWL6rq4uSkpLo8ccfp+eee87sc+7Zs4eWLFlCTz/9NN14440iaHvbbbfRzp07acaMGS54V+CSMgiVB4iOfUx07O9EzecHLuMfJNWo5axabi4Wn49/DAAAgA9B4BYANFUqQS0vIYLCggPc9noAAACssXr1alq2bBnde++94vrzzz9PmzZtorVr19IzzzwzYPnc3Fx64YUXxOW33nrL7HPyc1x77bX02GOPiet8vm3bNnH7Bx98gH+MJwdrqw4RHTUEa5vKzQdrufTBuBuJRi8iCo1xxysFAAAADUDgFgA0IychwuT6mLRot70W0NiPXF0vUV8PUV+36lx1mQWGEAUE9zvnE77qAMB5uru7af/+/bRq1SqT2xcsWEC7d++2+3k54/ahhx4yuW3hwoUicAseRq+nwLrj5HdkLdHxvxM1nBu4jH8gUcFVhmDtdURhse54pQAAAKAx+DULAJoRFx5EkSGB1NrVK64XpqJMgksCor1dqiBol2lgtFcOkKrvVwVMxWPVgdR+AVWTyz2D3N5NpLN0vyEway/utM0B3MBgw7kU2PULDKYEvT/5hURYCPqqgr/KYw3nQaFEQRFEwXwKJwqOJAric/m2COl+f5SSB/B2dXV11NfXRykpKSa38/Xq6mq7n5cfa+tzcgkGPsmam5vFuU6nEydn47+h1+td8rc84ju25hj5Hfs7+R3/OyVeOjtwEb8AovwrSD/2+0SF3yEKizPe6QPrENsL1gu2F3yWsI/BvtdXv5N0NvwdBG4BQDP8/PxEuYTjVdIPzUJk3A78EdjTQdTZZDx1NRsuNxJ1Npu5vYn8OpspqbOV/KhvYIDVF+h1RL0d0knFj4iCnP23A8MMgV1DIFcd2BW3GYK+A5bpFwwOCjMfSA4IkopBA4AmvsPUePDf/zZnPyeXZXjyyScH3F5bW0udnZ3kih8hTU1N4nVy0zVfFHDpDIWd3UihZz+lwMaSAffr/fypO30mdRYsps68a0gfFi/d0dJD1FJDvgTbC9YLthd8lrCPwb7XV7+TWlparF4WgVsA0JQRyZFK4HZserT3BV6724g6GgYNtA44qe/jDFkb8U987VYK9pMCkuIUZOZyUL/LZpbl6aVMyQCWz7sMGcPmzrtIb1jOT9/nvLcnB4zb6533N1RZxMq5uGyaYTx4FrHqsn8whbV3Ep2Pk9azf4C0jjlzmc/FiW8LIOJsMUfcxs/N/wcOsusM5+qTcltfv9v0Fh5nuM/S40gv/U0/1WsR76/fufp+XtXNDUQhXYaAufp+f9Xj+t2GwLrXS0xMpICAgAGZsDU1NQMyZm2Rmppq83NyHdyHH37YJOM2KytLNEKLjo52yY8eDizz3/OpwG3daaJjG8jv+Abyqz1hPlibNp0CJ91KfmO/R0ERSeLAoa/PK/LZ7WUIWC9YL9hm8FnCPsb7972hoaFWL4vALQBoyoorC6iutYsuH5lIGbFhpPkArDhdMl5uly83DryPT27IctUHR5IuIJT8g0LITwncqYOgqpMSxJPvVy1r8XFBqoCh+nGBQwRlOUjovpCyXqcTQZDkxATyF2UazAd4BwaEu6XM5552aTuQTz3yZb691cz97dLJ0UT5CuPU6OHiYQra4JhfL0n2rFA54B0YKn1OhjwPs3I5PueSHaGD3MeZ2k7PK/d5wcHBVFRURJs3b6Ybb7xRWR98/YYbbrB7/cyaNUs8h7rO7eeff06zZ8+2+JiQkBBx6o9/gLgqMMY/elz599ym/izRMUODsYtHzSzgR5QzW9Ss1Rd+lxra/Sg5Odn714uNfGZ7sRHWC9YLthl8lrCP8e59r78NfwOBWwDQlMLUaHr/vpmu+4N9vUStF6WMyP5BVhGEdXMAloM+IdFSR+n+J5Pbo83fFxItMn1qOUCZnEx++GE0EAePAzm4Fe78/yfXMpIDutYEevl2vp8DxeYCyUodYgtBZg5Ig3txlq/8v3JcfN16nAHMAVw+cVBYDvSK63webrgtzPTcZHn1ufxccmA4hPzbeTsNl/ZDPoqzXJcuXUrTpk0TAdfXX3+dysvLafny5UombGVlJb377rvKYw4dOiTOW1tbRSkDvs5B4LFjx4rbH3zwQZo3bx49++yzIgD8ySef0BdffEE7d+5007sE0VTsKAdrNxBVf2t+hWTNlBqMjb2BKDrNuO9v960yCAAAAOAYCNwCgPfizFgOyDadJ2qulM5NLlcStVRJ06idiQMjXMOOm45wl2j5XAmy9g/KqoKwXOd0uFOtfaDBicfgwHlIpHRyBZ0cNDQ0kbNYQsIY7NX1dlJLQz1FRUaQPxlKC4hTr3Tiz4vdt+kMl/vf1mem5IChFIFym1x6wNxy5q4HWH4cf6aU8gpyqQVDSQV1eQVV+QW9rpc6O9opNDiI/EzKNahLNfBjVOUalNu4CSCv305pXYsSGnzu/Jqj4u+LAwCtTnl6zhVI5j8Tl0v04GHyVUuWLKH6+np66qmnqKqqisaPH08bN26knJwccT/fxoFctSlTpiiX9+/fT++//75Y/ty5c+I2zqz98MMP6Ze//CU98cQTVFBQQOvXr6cZM2a4+N35OC5TxIHawx8Sle8xv0zmdKJxN0nB2pgMV79CAAAA8GII3AKA5+pqkYKvIhh7nvwaz1PMxTPk110vBWf55MjAiAjAxhmCsIYAbLgckJVPqut8X2islKkG4A4ctPQ3TKe3lk5HHTU1FJWcLD0elNIaTTU1FOLIzHU+uNSnDuiaOe/hy52DL9M/GCw/hjO1+XZxvcP0dkdnY3P2rY9bsWKFOJmzbt26Abdx84uh3HLLLeIELsazcUq2EB16n+jkRvNjifSpROMNwdrYbPyLAAAAwCkQuAUAbeIARPMFC9myhutdTSYP4bxUm0IH4QlE0RlEMZlEEUmDB2H5hAAsADgSZ/6KmrQDa5K6JDA1IKhrOOcyHUrgt995v9v0Pe3U1dZEIUkFrn8PAI5WfZTo8AdER/4qlVHqL6mQaOISKWDLWeYAAAAATobALQA4FmcQcdCVs2G7mg3n6lOzhdtVy3c2E7XXDe91cIkBOSjL0xajM00vR6cTBbugpikAgBaJ5oFRRCFRw85EbpRraDvsxQG4UGuNFKjlgG31EfMHeSfcSjTpdqK0ycMvXwQAAABgAwRuAWBgFlZno6Exl6oplxxQHSroyidnN0QKCJYCryIYawjORmeQLiqdLvWFU3zeRPLnUgb4cQUAAAD9cWb5qU+JDn1AdOaLgbXu/YOIRi8imnQH0YhriAKDsQ4BAADALRC4BfBW3CCHSwlw0LW9wRiE7R+QFdflyw0Dyg+4FDcP4sZcwVFEkcmGDFkpKGuSLctlDczVmNTpqLemRmrqhaAtAAAAqGcEVXwlZdYe+1hqOtZfxjQps3b8zVL5JAAAAAA3Q+AWwBMyYDmblQOrnAnbwacGCqspJzphyI41F5DlE3c2dwXOgA2JlqbcipP6ctQQtxtu44BtYCgCrgAAAOA4DWVE366XAraXSgbezweHuW7tpB8QJY3CmgcAAABNQeAWwBV6u41BV+W8ycxthtvVt3W3DHg6zjWNcegL9CPi0gJyMy7RpEt9OU7KYrUUdHVHYx0AAAAAc7hs0/FPpFIIZTsH3h8UQTT2e1J2be4887N4AAAAADQAgVsAezJg22qJWqqkjsPivMaQ5WohIMudul2Fg6lyEFYOug4WkBVB2Vj8aAEAAADPpesjKtlKdPhDouJ/mhl7+RHlzZXq1o65nigk0k0vFAAAAMB6CNwCyPp6pABsazVRi+qkvs6BWl6G9M5db9wUg4OvHFAV5zGqy7GkC4mmlt5AikrJIX/udqwOwgYE4X8KAAAAvqHmBNHh94m+/Yt0ML2/hBFSGQQuhxCb5Y5XCAAAAGA3BG7BRwKynBkrZ8daCMy21Tk2IBsYNmjwddDbgsIHr/Wq01FHTQ1FJScjUxYAAAB8p8FY03miin1So7Gy3UQXjwxcjsdUE26RArYZRaifDwAAAB4LgVvw3Olw7fVS9msbn+qMl1trpXM5MNvOAVkH8Asgikwhiko1niL5PEU656xXdfAVdV8BAAAA7NfbRVT1LdH5r4zBWnNZtcw/kGjkAilYO2ohxmEAAADgFRC4BW018GqXA7BcQ/YiRVwsIT/qIGrnYGytMSjLQVu9zjF/lwf66gDsgMCs4cQlCfwDHPM3AQAAAMAUz45SB2kvHCLq6xp8LaVNloK1nGEbkYg1CgAAAF4FgVtwblYsN+oSTbsajAFZdVascl4jNfJS4f6+UcOtEyuCr+ayZNOkQC2fc7MudBMGAAAAcG2z15pjUoBWnPYRNZYN/pjgSKLMaUSZlxFlzSDKLJLq+wMAAAB4KQRuYehaYj0dxuArB1fF5cahb+OgraMFBBNFJBNFJvU7TyaK4MtJhsvJ0kAeAVkAAAAA92u/RHT+a2OQtvIAUU/b4I+Jy5MCtFkcqL2MKHksZj8BAACAT0Hg1huzXLkeGE8r49IDfYaTfBs36uLLvZ3WBV/5nB/vTEER/QKwieKyLiKRmnpDKCZ9BPmLTNkkopBoNJgAAAAA0DIuZ1VzyljygMsf1J0a/DGBoUTpU4myphuyaS+Txn4AAAAAPgyBW3fraiW/nc9TZEsD+YUESoFVJehqIfg62G36Pve+Hz9/Q4OuOMPJcJlvG5AVazgPjjD/XDodddXUECUnI3MWAAAAQMvK9xKVbKO4szvIr/bboWdeRWcag7ScTZsygSgw2FWvFgAAAMAjIHDrbn3d5LfjdxRJGsNZsOrAK58rAVlVYLb/bcFRCLICAAAA+Jo9L5N/8T8pxFIj2LRJhkxaDtZeRhST6frXCAAAAOBhELh1t0Czw1vL/AKkx3CtV/lcfdnibUFEASGq20L7BWP7Zcci4wEAAAAArMVB2eJ/iov6iCTyEw3EDE3E0icTBYVhXQIAAADYCIFbdwsMI90PP6LG5jaKTUwh/6DQwQOy/gHufsUAAAAAAKZGX0e68ESqDyughBFF5BeAMSsAAADAcCFw627+/kQFV1E3arkCAAAAgKdKKCCKy6M+HtP6+bn71QAAAAB4BX93vwAAAAAAAAAAAAAAMIXALQAAAAAAAAAAAIDGuD1wu2bNGsrLy6PQ0FAqKiqiHTt2DLr8tm3bxHK8fH5+Pr366qsDlvnoo49o7NixFBISIs43bNjgxHcAAAAAAAAAAAAA4EWB2/Xr19PKlSvp8ccfp4MHD9LcuXNp8eLFVF5ebnb50tJSuu6668RyvPx///d/0y9+8QsRqJXt2bOHlixZQkuXLqXDhw+L89tuu4327dvnwncGAAAAAAAAAAAA4KGB29WrV9OyZcvo3nvvpTFjxtDzzz9PWVlZtHbtWrPLc3Ztdna2WI6X58fdc8899Pvf/15Zhu+79tpr6bHHHqPCwkJxfvXVV4vbAQAAAAAAAAAAADxBoLv+cHd3N+3fv59WrVplcvuCBQto9+7dZh/D2bR8v9rChQvpzTffpJ6eHgoKChLLPPTQQwOWGSxw29XVJU6y5uZmca7T6cTJ2fhv6PV6l/wtT4L1gnWDbQafJexjsO/VCnwnaWe9YLwEAAAAAL7CbYHburo66uvro5SUFJPb+Xp1dbXZx/Dt5pbv7e0Vz5eWlmZxGUvPyZ555hl68sknB9xeW1tLnZ2d5IofIE1NTeKHj7+/28sOawbWC9YNthl8lrCPwb5XK/CdpJ310tLS4pK/AwAAAADgs4FbmZ+fn8l1Hvj3v22o5fvfbutzcjmFhx9+2CTjlks2JCUlUXR0NLniRw+/Pv57CNxivWCbwWcJ+xjXwL4X6wXbi2d+jrhBLQAAAACAL3Bb4DYxMZECAgIGZMLW1NQMyJiVpaamml0+MDCQEhISBl3G0nOykJAQceqPf4C46kcI/+hx5d/zFFgvWDfYZvBZwj4G+16twHeSNtYLxkoAAAAA4CvcFiUMDg6moqIi2rx5s8ntfH327NlmHzNr1qwBy3/++ec0bdo0Ud92sGUsPScAAAAAAAAAAACA1ri1VAKXJ1i6dKkIvHLA9fXXX6fy8nJavny5UsKgsrKS3n33XXGdb3/55ZfF4+677z7RiIwbk33wwQfKcz744IM0b948evbZZ+mGG26gTz75hL744gvauXOn294nAAAAAAAAAAAAgMcEbpcsWUL19fX01FNPUVVVFY0fP542btxIOTk54n6+jQO5sry8PHH/Qw89RK+88gqlp6fTiy++SDfffLOyDGfWfvjhh/TLX/6SnnjiCSooKKD169fTjBkz3PIeAQAAAAAAAAAAADyuOdmKFSvEyZx169YNuG3+/Pl04MCBQZ/zlltuEScAAAAAAAAAAAAAT4ROWAAAAAAAAAAAAAAa4/aMWy3S6/XivLm52SV/T6fTUUtLC4WGhqJTMtYLthl8lrCPcRHse7FesL145udIHp/J4zWwDGNabcD3DdYLthd8jrCPwb5XK/CdpI31Yst4FoFbM/ifxbKyshz9vwEAAAAAB43XYmJisC6HWEcMY1oAAAAAzxzP+umRrmA20n7hwgWKiooiPz8/ckWknQfUFRUVFB0d7fS/5ymwXrBusM3gs4R9DPa9WoHvJO2sFx668iCXm9S6KsvXU2FMqw3Yf2C9YHvB5wj7GOx7tQLfSdpYL7aMZ5FxawavtMzMTHI13jgQuMV6wTaDzxL2Mdj3agG+k7BetLy9INPWOhjTagv2q1gv2F7wOcI+BvtercB3kvvXi7XjWaQpAAAAAAAAAAAAAGgMArcAAAAAAAAAAAAAGoPArQaEhITQr371K3EOWC/YZvBZwj4G+153wncS1gu2F8D+A/tVfN+4D76HsV6wzeCzhH0M9r1qaE4GAAAAAAAAAAAAoDHIuAUAAAAAAAAAAADQGARuAQAAAAAAAAAAADQGgVsAAAAAAAAAAAAAjUHgFgAAAAAAAAAAAEBjELh1kTVr1lBeXh6FhoZSUVER7dixY9Dlt23bJpbj5fPz8+nVV18lb/LMM8/Q9OnTKSoqipKTk+n73/8+nTx5ctDHbN26lfz8/AacTpw4Qd7k17/+9YD3mJqa6tPbC8vNzTX7///Zz37mU9vL9u3b6frrr6f09HTxfv7+97+b3K/X68U2xPeHhYXRFVdcQceOHRvyeT/66CMaO3as6GTM5xs2bCBvWS89PT306KOP0oQJEygiIkIsc+edd9KFCxcGfc5169aZ3YY6OzvJW7aXH//4xwPe38yZM316e2Hm/u98+t3vfufV24s1382+uo8BI4xpTWFMax7Gs+ZhPCvBeNYyjGltXy8MY1qMab15PIvArQusX7+eVq5cSY8//jgdPHiQ5s6dS4sXL6by8nKzy5eWltJ1110nluPl//u//5t+8YtfiI3EW3CgkQNue/fupc2bN1Nvby8tWLCA2trahnwsf+iqqqqU08iRI8nbjBs3zuQ9HjlyxOKyvrC9sK+//tpknfB2w2699Vaf2l74MzJp0iR6+eWXzd7/29/+llavXi3u53XGQf9rr72WWlpaLD7nnj17aMmSJbR06VI6fPiwOL/tttto37595A3rpb29nQ4cOEBPPPGEOP/444/p1KlT9L3vfW/I542OjjbZfvjEB0i8ZXthixYtMnl/GzduHPQ5vX17Yf3/52+99Zb4kXDzzTd79fZizXezr+5jQIIx7UAY01qG8exAGM9KMJ61DGNa29eLDGPagXxxTLvNG8ezenC6yy67TL98+XKT2woLC/WrVq0yu/wjjzwi7lf7yU9+op85c6beW9XU1Oh5c9y2bZvFZbZs2SKWaWho0HuzX/3qV/pJkyZZvbwvbi/swQcf1BcUFOh1Op3Pbi/8/jZs2KBc53WRmpqq/7//+z/lts7OTn1MTIz+1Vdftfg8t912m37RokUmty1cuFB/++23671hvZjz1VdfieXKysosLvP222+LdectzK2Xu+66S3/DDTfY9Dy+uL3wOrrqqqsGXcbbthdz383YxwDGtLZ/bnx1jILxrHUwnsV4djAY01q/XjCmxZjWm8ezyLh1su7ubtq/f7+I8Kvx9d27d1uM5PdffuHChfTNN9+IKb/eqKmpSZzHx8cPueyUKVMoLS2Nrr76atqyZQt5o9OnT4u0fS6vcfvtt1NJSYnFZX1xe+HP1Z///Ge65557xBFDX99e1NnX1dXVJtsDT+OYP3++xf3NYNvQYI/xhn0ObzuxsbGDLtfa2ko5OTmUmZlJ3/3ud0VWu7fhsiI8jWjUqFF03333UU1NzaDL+9r2cvHiRfrXv/5Fy5YtG3JZb9te+n83Yx/j2zCmtQ7GtEYYzw79mcJ4diB819gGY1ojjGkH56tj2iYvGM8icOtkdXV11NfXRykpKSa383XeWMzh280tzyne/Hzehg8OPfzww3T55ZfT+PHjLS7HwbfXX39dlADgqc6jR48WwTiud+NNZsyYQe+++y5t2rSJ3njjDbE9zJ49m+rr680u72vbC+OaRo2NjaKWka9vL2ryPsWW/Y38OFsf48m45uiqVavojjvuENOALCksLBR1S//xj3/QBx98IKYHzZkzR/wQ9RZctue9996jL7/8kv7whz+IqUJXXXUVdXV1WXyMr20v77zzjqiRddNNNw26nLdtL+a+m7GP8W0Y0w4NY1ojjGeHhvGsefiusR7GtEYY0w7NF8e0ei8ZzwY6/S+A0D8rkDegwTIFzS1v7nZv8MADD9C3335LO3fuHHQ5DrzxSTZr1iyqqKig3//+9zRv3jzypi8dGTdT4vdZUFAgdrS80/H17YW9+eabYj1xVrKvby+O2N/Y+xhPxFnonMWu0+lEg53BcJMudaMuHrBMnTqVXnrpJXrxxRfJG3CdJhkPZqZNmyaOrvPR+MEGdb6yvTCuBfbDH/5wyLpe3ra9DPbdjH2Mb8OY1jKMaY0wnh0axrOO3dfY+xhPhTGtKYxph+aLY9oHvGQ8i4xbJ0tMTKSAgIABUXieito/Wi/jwsjmlg8MDKSEhATyJj//+c/FkRyews5p+LbiHYonHvmxRUREhAjgWnqfvrS9sLKyMvriiy/o3nvvtfmx3r698LbAbNnfyI+z9TGeOsDlAvI8PYYL1Q+WbWuOv7+/6FDqzdsQZ6pz4Haw9+gr2wvbsWOHaHBoz/7Gk7cXS9/N2Mf4NoxpB4cx7eAwnjWF8axl+K4ZGsa0Q8OY1pQvjml/7kXjWQRunSw4OJiKiopEkECNr/P0d3M4M7D/8p9//rnIhAoKCiJvwEcm+OgHT2HnKbpcy9UeXGuFd8rejKcsFxcXW3yfvrC9qL399tuiHud3vvMdmx/r7dsLf474C0W9PXD9NO6saWl/M9g2NNhjPHWAywMODvzbc1CD91uHDh3y6m2IS7JwZvpg79EXthd1NhR/h3MXY1/YXob6bsY+xrdhTGsexrTWwXjWFMazluG7ZnAY01oHY1rfHdPqvXE86/T2Z6D/8MMP9UFBQfo333xTf/z4cf3KlSv1ERER+nPnzom1s2rVKv3SpUuVNVVSUqIPDw/XP/TQQ2J5fhw//m9/+5vXrM2f/vSnomvf1q1b9VVVVcqpvb1dWab/ennuuedE98hTp07pjx49Ku7nTfijjz7Se5P/+I//EOuFt4O9e/fqv/vd7+qjoqJ8enuR9fX16bOzs/WPPvrogPt8ZXtpaWnRHzx4UJz4/axevVpcLisrE/dzd0z+bH388cf6I0eO6H/wgx/o09LS9M3Nzcpz8Hri9SHbtWuXPiAgQDy2uLhYnAcGBortzxvWS09Pj/573/uePjMzU3/o0CGTfU5XV5fF9fLrX/9a/9lnn+nPnj0rnuvuu+8W62Xfvn16b1gvfB/vb3bv3q0vLS0VXc5nzZqlz8jI8OntRdbU1CT2rWvXrjX7HN64vVjz3eyr+xiQYEw7EMa05mE8axnGsxjPDgZjWtvXC8a0GNN6+3gWgVsXeeWVV/Q5OTn64OBg/dSpU/Xbtm1T7rvrrrv08+fPN1meN7IpU6aI5XNzcy3+cPRUvLM1d3r77bctrpdnn31WX1BQoA8NDdXHxcXpL7/8cv2//vUvvbdZsmSJ2Glw8DU9PV1/00036Y8dO+bT24ts06ZNYjs5efLkgPt8ZXvh4Jq5zw6/f6bT6fS/+tWv9KmpqfqQkBD9vHnzxJeRGq8neXnZX//6V/3o0aPFdldYWOhxAe7B1gsHJS3tc/hxltYLH2TjAwX8uUpKStIvWLBABDm9Zb3w4IXfE783/r/ze+Xby8vLfXp7kb322mv6sLAwfWNjo9nn8MbtxZrvZl/dx4ARxrSmMKY1D+NZyzCexXh2MBjT2r5eMKbFmNbbx7N+hjcGAAAAAAAAAAAAABqBGrcAAAAAAAAAAAAAGoPALQAAAAAAAAAAAIDGIHALAAAAAAAAAAAAoDEI3AIAAAAAAAAAAABoDAK3AAAAAAAAAAAAABqDwC0AAAAAAAAAAACAxiBwCwAAAAAAAAAAAKAxCNwCAGhUb28vPfvss3T27Fl3vxQAAAAAALtgTAsAYD8EbgEANCowMJBSUlLorrvuIp1O5+6XAwAAAABgM4xpAQDsFziMxwIAgJP9+Mc/pp6eHiopKaERI0ZgfQMAAACAx8GYFgDAPn56vV5v52MBAAAAAAAAAAAAwAlQKgEAQKNZCX5+fgNOixYtcvdLAwAAAACwCsa0AADDg1IJAAAaxUHat99+2+S2kJAQt70eAAAAAABbYUwLAGA/ZNwCAGgUB2lTU1NNTnFxceI+zr5du3YtLV68mMLCwigvL4/++te/mjz+yJEjdNVVV4n7ExIS6P7776fW1laTZd566y0aN26c+FtpaWn0wAMPKPetXr2aJkyYQBEREZSVlUUrVqwY8HgAAAAAAIxpAQCcA4FbAAAP9cQTT9DNN99Mhw8fph/96Ef0gx/8gIqLi8V97e3tIruBA71ff/21COp+8cUXJoFZDvz+7Gc/EwFdDvL+4x//MGmA5u/vTy+++CIdPXqU3nnnHfryyy/pkUcecct7BQAAAADvhDEtAIBlaE4GAKDRemB//vOfKTQ01OT2Rx99VAxuOeN2+fLlIvgqmzlzJk2dOpXWrFlDb7zxhli2oqJCZMyyjRs30vXXX08XLlyglJQUysjIoLvvvpv+53/+x6rXxMHfn/70p1RXV+fgdwsAAAAA3ghjWgCA4UGNWwAAjbryyitNArMsPj5euTxr1iyT+/j6oUOHxGXOvJ00aZIStGVz5swhnU5HJ0+eFIFfDuBeffXVFv/+li1b6De/+Q0dP36cmpubqbe3lzo7O6mtrc3keQEAAAAAMKYFAHA8BG4BADSKg6Pq0gXW4IAs0+v1ymVzy3Dd28GUlZXRddddJ7J6n376aREw3rlzJy1btox6enpsek0AAAAA4LswpgUAsB9q3AIAeKi9e/cOuF5YWCgujx07VmTfcnasbNeuXaJu7ahRoygqKopyc3Pp3//+t9nn/uabb0SG7R/+8AdRgoEfwxm6AAAAAACOhDEtAIBlyLgFANCorq4uqq6uNrktMDCQEhMTlZqz06ZNo8svv5zee+89+uqrr+jNN98U9/3whz+kX/3qV3TXXXfRr3/9a6qtraWf//zntHTpUlHflvHtnFGbnJxMixcvppaWFhHc5eUKCgpE4Pall14SdXH59ldffdUNawEAAAAAPBnGtAAA9kPGLQCARn322WeUlpZmcuIgrezJJ5+kDz/8kCZOnEjvvPOOCN5ypi0LDw+nTZs20aVLl2j69Ol0yy23iHq2L7/8svJ4Duo+//zzopnZuHHj6Lvf/S6dPn1a3Dd58mRavXo1PfvsszR+/Hjx3M8884wb1gIAAAAAeDKMaQEA7Oen50KIAADgUbhO7YYNG+j73/++u18KAAAAAIBdMKYFABgcMm4BAAAAAAAAAAAANAaBWwAAAAAAAAAAAACNQakEAAAAAAAAAAAAAI1Bxi0AAAAAAAAAAACAxiBwCwAAAAAAAAAAAKAxCNwCAAAAAAAAAAAAaAwCtwAAAAAAAAAAAAAag8AtAAAAAAAAAAAAgMYgcAsAAAAAAAAAAACgMQjcAgAAAAAAAAAAAGgMArcAAAAAAAAAAAAAGoPALQAAAAAAAAAAAABpy/8P/qVUYzUhJfsAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1400x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "print(\"\\n=== CARREGANT EL MILLOR MODEL ===\")\n",
    "print(f\"Checkpoint: {millor_config['checkpoint_path']}\")\n",
    "\n",
    "# Carregar el millor model\n",
    "millor_model = keras.models.load_model(millor_config['checkpoint_path'])\n",
    "\n",
    "print(\"\\n=== ARQUITECTURA DEL MILLOR MODEL ===\")\n",
    "millor_model.summary()\n",
    "\n",
    "# Re-entrenar breument per obtenir l'historial (opcional, per visualització)\n",
    "print(\"\\n=== ENTRENAMENT FINAL AMB LA MILLOR CONFIGURACIÓ ===\")\n",
    "print(\"(Això és només per generar gràfics d'entrenament)\\n\")\n",
    "\n",
    "callbacks_final = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=20,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=10,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "history = millor_model.fit(\n",
    "    X_train_scaled, y_train_scaled,\n",
    "    validation_data=(X_val_scaled, y_val_scaled),\n",
    "    epochs=200,\n",
    "    batch_size=millor_config['config'].get('batch_size', 16),\n",
    "    callbacks=callbacks_final,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n=== ENTRENAMENT COMPLETAT ===\")\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "# Loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Train Loss', linewidth=2)\n",
    "plt.plot(history.history['val_loss'], label='Val Loss', linewidth=2)\n",
    "plt.xlabel('Època')\n",
    "plt.ylabel('Loss (MSE)')\n",
    "plt.title('Evolució del Loss')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "# MAE\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['mae'], label='Train MAE', linewidth=2)\n",
    "plt.plot(history.history['val_mae'], label='Val MAE', linewidth=2)\n",
    "plt.xlabel('Època')\n",
    "plt.ylabel('MAE')\n",
    "plt.title('Evolució del Mean Absolute Error')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb49013f",
   "metadata": {},
   "source": [
    "## 8. VISUALITZACIÓ DEL PROCÉS D'ENTRENAMENT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "745b680d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABW4AAAHqCAYAAACUWtfDAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOzdBXhcZdYH8NO4uzdaTequlBo1rMACRQtL0WJdlmWRZdEPWdwdihaHIoUaVWq0TT1NJY007u7J95x35t65k0zSyMi9M//f8wQmyWRmepNM3jn3vP/Tp7W1tZUAAAAAAAAAAAAAQDWcbP0AAAAAAAAAAAAAAMAYCrcAAAAAAAAAAAAAKoPCLQAAAAAAAAAAAIDKoHALAAAAAAAAAAAAoDIo3AIAAAAAAAAAAACoDAq3AAAAAAAAAAAAACqDwi0AAAAAAAAAAACAyqBwCwAAAAAAAAAAAKAyKNwCANiRe+65h/r27UtZWVm2figAAAAA0A1YxwEAQFso3AKAXVm+fDn16dOnw7eNGzda7L7j4+Pp+uuvt9jtP/roo+Lf0JEffviBPvzwQ/rtt98oJibGYvfTGf7383HoyvV8fHx6dB8AAABgn7CO0846ju/D19eXqqqq2n0+IyODnJycxHX48WhBUVERubu7i8e8e/duk9eZMWMGDRs2zKqPKz09XTwm/t3oiaeeeop+/PFHsz8uPhYdvd7qys8QAHSdSzeuCwCgGR999BElJia2+/iQIUNIq2688UaaP3++yc+lpaXRLbfcQt999x2NGDHC6o8NAAAAwFywjlM/V1dXampqoq+++oqWLFnS7vvHRd2KigrSik8//ZQaGhrE5Q8++IDGjRtH9oALt5deeilddNFFZr/tfv360eeff97u41wABwDzQeEWAOwSnw23lwWXJDo6Wrx1tHAqKCiw+mMCAAAAMDes49TPzc2NLrjgArHbS1m4bW1tFd2hixYtovfee4+0gv8dYWFhFBcXRytWrKAXX3yRPD09bf2wVI2Pz6RJk7r9dbW1teTh4WGyM7ympoa8vLx6/Jiam5vFCQUUj8GeICoBABzS6NGjadq0aSb/2HNG7CWXXCJ/rKSkhJYuXSo+zotULpI+9NBDVF9f36XtfrzFSYnjGkzFNvz+++80e/Zs8vf3FwuWpKQkevrppzvd+tbS0kL/+9//RHcxL1B4wbl48WI6ffp0l47Dr7/+SqNGjRJfm5CQQM8//7zJ6/Ei/M033xTX5UVaYGCgOHvPnb6WXkSPHDlSLO6CgoLo4osvppSUFKPr8GO44oorKCoqSvw7wsPDxXHct2+ffJ0//vhDbOkKDg4Wjz82Npb+9re/icUhAAAAaAvWcepYx91www20bds2Sk1NlT+2bt06EZXw97//3eTX5OXliV1i3IzA62p+3I899pgotinxxyZOnCjWf35+fjRmzBjRCcv/FiXeln/++eeLdTRfh/99vC7mNWRX7dy5kw4dOkTXXnst3XTTTVReXi52sXVky5YtomDJ98WvDx5++GHxGkLprbfeEmtYjgbj7mN+TA8++KDRdfg+Fy5cKL4fvNbl78/HH3/c40iLtq8V+HJ1dbW4TSnGgNfD3f1e9Ib0emjNmjXi5yU0NFS8zuHXUVL0xObNm2nKlCni43wdlpmZSddcc414bcM/3/y66IUXXhCvfdrGSPBroSeffFI8fr7uhg0bzPb4AdQAHbcAYJeks61K/Ifd2dlZXObF5N13303Hjx+ngQMHytfhRUVOTo682Kyrq6OZM2fSyZMnxUKGYwh4scYFVS4M8oLZHHghygvF6dOn09tvvy0WKceOHRMLus7cdttt9O6779Idd9whFq28gOHFIxeF9+7dSyEhIR1+7fr168VicfLkyfTll1+KY8YLn/z8/HbX5UUdL7zuuusuevbZZ0Ux+/HHHxeLrP3794tiqbnxMeYF7pVXXikuFxcXiwUpP96//vpL/r6de+658mPngixnlPGLiLKyMvF5PibnnXeeKNTzIj4gIICys7PFAp+3xPXmrD4AAACYH9Zx2ljHnXPOOaJDlddXfLvSmvbss882Wl8rC4UTJkwQ+bf//e9/qX///rR9+3ZRdOP1GkcsSPh9fty8tmM7duygO++8U6zh+GuV+N/wz3/+k+6//37xb3n//fdFF/CAAQPEYzkTfsyMi4acL7xs2TLxMS4cmvo3cMMA3xcfQ34twI+/tLSUXn/9dXEd/n5w0wc/Xi6m87/3xIkTdOTIEfl2uNjNx5/X/K+++qpoLvjss89EUZa/h/fddx/1Fh/bWbNmidcy/PqAcRG8u9+Lzpgq8vJt8psSH1tej3MkBReTOWqD5ebmiuPM/16OdeCvKywsFMeG1+lPPPGEKFL/8ssvdO+994rXZHwSQomP36BBg8Sx5n+fqZ89AE1rBQCwIx999BGfhjf55uzsLF+vqKio1c3NrfXBBx80+vrLL7+8NTw8vLWxsVG8//bbb4uv/frrr42u9+yzz4qPr1mzRv5YXFxc63XXXdfusZw6dcroazds2CA+zv9nlZWVrX5+fq1nnXVWa0tLS4f/tkceeUR8nSQlJUW8v3TpUqPr7dy5U3y87b+trYkTJ7ZGRUW11tbWyh+rqKhoDQoKMrqf7du3i/dfeOEFo6/Pyspq9fT0bL3vvvvkj/G/n4/DmfD1vL29O/x8aWmpuO1zzz3X6OOZmZmt7u7urVdddZX8feTH9vLLL3d4W99++624zr59+874uAAAAMB2sI7T3jqO16cRERFi7VxcXCzWacuXL28tLCwU98ufl9xyyy2tPj4+rRkZGUa39/zzz4vrHj582OT9NTc3i9t//PHHW4ODg43Wy/x4PTw8jG6TjwkfB76/M6murhbr8EmTJhn9+/r06dN64sQJo+tOnz5dPM6VK1caffymm25qdXJykh/DHXfc0RoQENDp/V5xxRXiWPHaVmnBggWtXl5erWVlZeJ9fh3B98m/G2f6PrV9rcD4+6R8fdLb70XbY2HqbcmSJe1+pxcvXtzhbaxfv97o4/fff7/4OP8uKN12223i+5Kammp0bPr379/a0NDQ6eMF0DJEJQCAXfrkk09EV6byjbdBSfisNudy8dYhacsNnylfuXKliBpwcXGRt9h7e3uL7WRKfDZc6nboLe4O5eENfGa+O1OApW1A0mOR8Nlz3k7U2WPjM918TDgSgrdmSXgrFx8XJT7DzY+Lz4bzWXXpLSIiQmwBaxv5YA58xp/zr9r+27gLgjsHpH8bb5/jDoHnnntOZJElJycbbaFivO2Mt3/dfPPN4vtt6XgHAAAA6B2s47SzjuNdatwh+ttvv4lBVbzmuuyyy0xelx8Ld39yvJXysSxYsEB8ftOmTfJ1eQ3OHb0cIcY75rhDkztDeQdW27kOvNaTOnMZHxPuwOTIhjP5+uuvxTpc2qLP+DJHMpjqOuVjfOGFFxp97KqrrhLrT97yL63FeecX7xrj1xa8G6wt/vdxtBevbZV47ctRXrwWtqTufC86wmvwtq+3+E3q7lXiiDJTOCaC1/Ztjw0PlObj2PbY8PeFP6/E3w+pgxfAHqFwCwB2iQuXPJxM+TZ27Fij6/CijLdbrV27VrzPgwg4b0lZLOTFIS9s2xZUeVsTF3f5873F24FYR4PHOiLdd2RkZLvP8SKss8fGRWpeYPK/ra22H+PFOC+SeOsZL4qUb7xtzdRitLe6+m/j7wu/sJk3b57YHsjZZpydxVsBKysr5UUl563x9+z2228X7/PbK6+8YvbHDQAAAL2HdZx21nEclcAFSI5L4DeOEegohoofy88//9zucQwdOlR8Xnosu3btorlz54rLPODszz//FAVBnjHB+OS+EjdktMVZp22vZwpHInChd/78+aLYym8cjcbb8zleom12ralYCemYS98zzsrlY8GFYy5Y8hqU83ql1xzSdTta5ypvy1K6+r3oDB+3tq+3+I1/Jtoy9W/t6OPdPTYd3TaAvUDGLQA4LC728QKAz6bzZf4/L6r4DK9yIcidurzgVRZv+Uw/n5XuLHtM6oBoO8Ss7UKIC42sqwPFlI9NyoZqW/TlnN7OHhuf3eZ/D+dbtdX2Y3w7fF3O9jU1odUSU1uV/7a22v7beHEoZZNxLjB3TnAWLudicV4w43xbfuPF9+7du+m1114T+WW8+OYXGAAAAKAtWMepZx3HzRDc0cvFZB7K1RF+LFwU/b//+z+Tn5cKc5wRy0VE7gpVdhT/+OOPZE68bty6dau4rOzYVVq9erWYpyAxlSEsHXNlAZk7kfmNu6O5E/eRRx4R8yj4PnntytftaJ3LzvQaw9SQ5O4U4bv6vTCXjnYVmvp4d49Nd3YsAmgROm4BwGHxtis+I86LQF7MckFPuU2KcQdBVVVVu4Uib+GTPt8RadrrgQMHjD7+008/Gb3P4fu8DYyLjG0n5XZG2lbEgwyUuCMhJSWl08fG8Q+8/ej7778XA9gk3KXKZ9+VeJHJj4u7k02dVR8+fDiZGw/a4Em9bf9tXNyWtpaZwtvi/vOf/4jHxEM9TH3PuTj/xhtviPdNXQcAAADUD+s49azjLr74YvHG6+hJkyZ1eD1+LDx4l3c+mXosUrGQC3G8s00aKsy4e5YHW5mTdOKfu3o5gkz5tmrVKlE85s5ZJT7GbdfyX3zxhRiqZWoQGq+5OX6Au4W5qeDw4cPi47yW5TWtVIxUvsbgjuXOjiO/xuAmEmURmW+bi8xd7Tzu6vfCFvjY8CC3tut0Pjb8s8ERDwCOBB23AGCXeCFiasopL06kDlfGC0yegsvZVFwoXLRokdH1Oe+Wi3zXXXedmLDKi1s+M89TT/nsO2dvdWT8+PE0ePBgMQGVHwt3uf7www/ymX2Jj48PvfDCC3TjjTeK27vppptEJyhPn+UpudKE2rb4tjm3lbtHebHIi0J+jJwrxXlZ//jHPzo9RjyllbeFzZkzR0zi5W5UPha8wORpw5KpU6eK++GuAS5u86KUr8Nnwvnfwsfktttuo+7i+/v22287XODyv+PBBx8U3wPOCONtUY899pjoMuCuBakofscdd4gsNZ4gy7lqvAjmj/O0X8YFcf4YT7Llbgp+gSMtwjv7/gEAAIBtYB2n/nWcEq/NTK3p2nr88cdFXAA3LXCsFa9leV3G61culPKajXeR8ZqNZxfw+pwfO68Bn3/+ebPu8uK1ORcCOZaD1+CmcF4wF2k51kx6/cDdoHy8MjMzRcMAP24u/PLHpK5dXsvz6wo+9ryNnztyn376adGowa8PGK9lpZxZzu7luQ2cEfzrr7+K+C++bkf49Qp/De8a+9e//iWO4auvvtou1oHx95dzjLmgz4+FM3r5uHf1e9EZLghz3IYpnRWez4R/9vl7wz8H/Di5Q5mPy5tvvimOMx93AIdi6+loAADWmkbMb++99167r5kyZYr43NVXX23yNnlC7q233toaGRnZ6uLiIqa4PvDAA611dXVG1+OPt53aeuzYsda5c+eKabWhoaGtd955Z+uvv/4q7m/Dhg1G1121apWYrsrTX3ma7JAhQ1qfffbZTifF8pRdvs6gQYNaXV1dW0NCQlqvueYaMSm4K3766afWESNGtLq5ubXGxsa2PvPMMybvh3344YdigjE/Pp5CzBNceULs7t27ezSNuKPvkfLr33//ffnx+fv7ty5cuNBoym1+fn7r9ddf35qYmCgeF0/H5eu/9NJLrU1NTfI05YsvvljcLk/v5WnEfJz53w4AAADqgXWcdtZxfDudKSwsFI+DH0/bj991112tCQkJYu0aFBTUOnbs2NaHHnqotaqqyujxDh48WKzd+vXr1/r000+3fvDBB+I2T506JV+PH+95553X7v55rcdvHfnxxx/Fbb388ssdXuf3338X13nhhRfk2xw6dGjrxo0bW8eNGyceG78+ePDBB1sbGxvlr/v4449bZ86c2RoeHi6+N1FRUa2XX35564EDB4xu/+DBg60XXHCBWOPy9UaOHCl+B5T438qPoe3H+XXDqFGjxPeSj8/rr79u8nu/b9++1qlTp4rXFvw55THp6vfCFL6dzl5zScdD+p3+66+/TN4GH09TMjIyWq+66iqxbufHxj8Lzz33nHjt0/bY8McB7Fkf/o+ti8cAAAAAAAAAAAAAYICMWwAAAAAAAAAAAACVQeEWAAAAAAAAAAAAQGVQuAUAAAAAAAAAAABQGRRuAQAAAAAAAAAAAFQGhVsAAAAAAAAAAAAAlUHhFgAAAAAAAAAAAEBlXGz9ANSopaWFcnJyyNfXl/r06WPrhwMAAAAAeq2trVRZWUlRUVHk5IQehM5gTQsAAACg7fUsCrcmcNE2JibGUt8fAAAAAOilrKwsio6OxnHsBNa0AAAAANpez6JwawJ32koH0M/Pj6zRDVFYWEihoaHoHMFxwc8MfpfwHGMleO7FccHPizZ/jyoqKsQJdmm9Bh3DmlYd8PcGxwU/L/g9wnMMnnvVAn+T1HFcurOeReHWBCkegYu21irc1tXVifvClj8cF/zM4HcJzzHWgedeHBf8vGj79whxVl0/RljT2hb+3uC44OcFv0d4jsFzr1rgb5K6jktX1rMIBgMAAAAAAAAAAABQGRRuAQAAAAAAAAAAAFQGhVsAAAAAAAAAAAAAlUHGLQAAAGhec3MzNTY2WjT3im+fs6+QR2/Z4+Lq6krOzs5muS0AAAAALcGa1j7WtK5mXM+icAsAAACa1draSnl5eVRWVmbx++EFXWVlJYZiWeG4BAQEUEREBI41AAAAOASsae1vTRtgpvUsCrcAAACgWVLRNiwsjLy8vCxW6OPFXFNTE7m4uKCYaMHjwrdXU1NDBQUF4v3IyMhe3yYAAACA2mFNaz9r2lYzr2dRuAUAAADNbiWTirbBwcEWvS8Ubq13XDw9PcX/ebHL31vEJgAAAIA9w5rW/ta0nmZcz2I4GQAAAGiSlGnLnbZgX6TvqSVziwEAAADUAGta++RlpvUsCrcAAACgaZaKRwDbwfcUAAAAHA3WP/alj5leo6BwCwAAAAAAAAAAAKAyKNwCAAAA2IEZM2bQsmXLbP0wAAAAAAB6BOvZ9lC4BQAAALDytqnO3q6//voe3e73339PTzzxRK8eG9/3RRdd1KvbAAAAAAD7pvb1bJ8+fejWW29t97mlS5d2+Pi2b98uhpPNnz+/3efS09M7/Lfu2LGDLMnForcOAAAAAEZyc3Ply1999RX997//pdTU1HZTaCU80MDV1fWMRzEoKAhHGgAAAADI0dezMTEx9OWXX9JLL70kP5a6ujpasWIFxcbGmvya5cuX0x133EEffPABZWZmmrzeunXraOjQoUYfCw4OJktCxy0AAACAFUVERMhv/v7+4ky99D4vKAMCAujrr78WW8U8PDzos88+o+LiYrryyispOjpaTKgdPny4WHh2trUsPj6ennrqKbrhhhvI19dXLD7ffffdXj32TZs20YQJE8jd3Z0iIyPp/vvvp6amJvnz3377rXhsvEDmRew555xD1dXV4nMbN24UX+vt7S3+jVOnTqWMjIxePR5Ql7KaBmppbbX1wwAAAAAHX8+OGTNGXJc7eCV8mQu6o0ePbnd9Xq/yOva2226j888/XxRxTeH1rfLfzm9dKUj3Bgq3YHE70orp/u8O0OGcchxtAACALvj3v/9Nd911F6WkpNC8efPEAnjs2LH0yy+/0KFDh+jmm2+ma6+9lnbu3Nnp7bzwwgs0btw4Sk5OFlvDeDF69OjRHn0PsrOz6dxzz6Xx48fT/v376a233qIPP/xQLKalzgtejPPCmh83F2ovueQSam1tFcVdjmCYPn06HThwQGxF438Dpifbj4KKOrrsnR309LoMamlB8RYAAMDR2Xo9+/e//50++ugj+X1et/I61RTuGh40aBANHjyYrrnmGvF1vIZVA0QlgEXxwv3OFclUWFlPJwqq6NvbpuCIAwCARV3w2lbxd8fcWqmV+lCfDj8f6utOP995llnuizsNuOipdO+998qX77zzTvr999/pm2++oYkTJ3Z4O1xo5QWutHjm7WJcUE1MTOz2Y3rzzTdFl8Lrr78uCq58G1zM5a7bRx99VBRuuUDLjzsuLk58DXdSsJKSEiovLxcdDP379xcfS0pK6vZjAHVqbG6hq9/fSScLq8Wb70+H6f8uHo7CPAAAgMrWs2da09rTevbaa6+lBx54QM6n/fPPP0V8An9tW1zUveqqq8Rlzritqqqi9evXi91jSlOmTCEnJ+MeWF7jOjs7k6WgcAsWlVZUJT/ZnCyswtEGAACL4787eRV1mj7S3FWg1NzcTM8884zoBuBiaX19vXjj2IHOjBgxQr4sbWErKCjo0WPibonJkycbFeM47oAXtqdPn6aRI0fS7NmzRbGWuyrmzp1Ll156KQUGBoq8Mh4CwR+fM2eOWARffvnlIm4BtM/V2YnuPmcg3bUimbjZ9otdWeTm4kyPXDAExVsAAIAewHq29+vZkJAQOu+88+jjjz8W3bN8mT/WFmfz7tq1S6yzGQ8oW7RokSjmti3c8nXaNh9YsmgrHo9Fbx0c3t7MMvkYlNY0Un1TM7m7WPaHGgAAHBt3ClhCVzpuzaVtQZa3iHF3wcsvvywKo/x57mJoaGjo9HbaZm7xYrelpaVHj4kXvG2jDaQtZPxxXrSuXbuWtm3bRmvWrKHXXnuNHnroIbH9LSEhQWw54+1y3FnBi97//Oc/4vqTJk3q0eMBdTl/RBQ1NrXQPV/vJ/6pWL4tnVyc+tBD5yWheAsAAKCS9WxXOm7taT17ww03iIFj7I033jB5HR5GxrvGOE9Xucbl+y0tLRVNCBLefTZgwACyJhRuwaKSFYVbVlBRTzFBXjjqAABgMeba3qUk5bTyGXhb5LJu2bKFFi5cKDK3GC9Wjx8/btW4gSFDhtB3331nVMDlIi0Piujbt694nz/OXbj8xtOFOTLhhx9+oHvuuUd8nodB8BtvW+Pu3S+++AKFWzuycFQUlZSV05Nr04lr+u9vPUUuzk707/mDUbwFAACw8XrW1mtaW6xn58+fLxeGeedXW3wsPvnkE3r++edp1qxZRsflb3/7G33++edy4ddWMJwMLCo5s9To/YJKbW9dBQAAsAU+sy91s3JkwS233EJ5eXkWuS/O6dq3b5/RW2ZmpsgWy8rKEnlkPBBi5cqVItv27rvvFllf3FnLg8p2794trs+TewsLC8Vi/NSpU6JYy0PJMjIyREfusWPH7CrnljOAubOYJyfz4A1+cdIVnLfGLxJGjRrV7nNcKOeCubu7u/g/F8HV7rwhwfTUxcPk99/edJJeXHvMpo8JAAAAHGs9K+EdYXxf/GYq0oAHpXFX7ZIlS2jYsGFGbxz5xd24SsXFxeIxK9946JoloXALFlNV30TH8ivbddwCAABA9zz88MM0ZswY0SkwY8YMke110UUXWeQw8sAGqTNWeuPuWe6qXbVqlcgA4zzbW2+9VWw/e/DBB8XX+fn50ebNm8UACZ7Ky1EIvCVuwYIF5OXlJYq93LnAn+Mpwty9wAt2e8DRD7zVj6MheOLxtGnTxL+bC9hnKpIvXrxYZAO3xUVuzlfjwRr79+8X/+dc4DNNXlaDReNi6MmLDMXb1/44Qa+uP27TxwQAAACOs55V4jUqv5nChVnOsfX392/3OV63cgPD3r175Y/xdXlGg/Ltxx9/JEvq0yqFk4GsoqJCfNN4Md3RN9ecuD2cg5XDwsLaTafTsm0ni+iq94xfXDx6wRC6fmqCQx8Xc8CxwXHBzwt+j/D8QuLsNndySl2OlmTrqAS1stRx6ex7a+11WlfwJGR+IfLWW2/JH+NuYn4x8vTTT3f4dVdccQUNHDhQdIDwop9fHEi4aMv/1t9++81oux/nrK1YsUITa9rlf56iR38+In/+vvmDaekM6+bCqQHWbTgu+HnB7xGeY/Dc2xmsae1zTVtnpvUsMm7Bavm2LL8SHbcAAABgPzg3bc+ePXT//fcbfXzu3LliK2BHeFjbyZMn6bPPPqMnn3zSZMftP/7xD6OPcYcKD/ToSH19vXhTviiQCoc9HUrXHXwf/MJHuq/Fk+OoobmFnlp1VLz/v99TyaVPH7pxWtdO4tuLtscFcFzw84LfIzzH4LnX1N8J6c3SpPtAH6dlj4v0/TS1DuvOmgCFW7Bu4bYCGbcAAABgP4qKiqi5uZnCw8ONPs7vd5TbxoM4uNDLObjc2WEKf213bpNxd+9jjz3W7uOcNWzp/DXpRQh3jvCLFGm31IWDvKmsvC+9+We2eP+p345SbU0VLRpt/G+zZ6aOC+C44OcFv0d4jsFzr6SxsVH8reCOT36zJP5bxOsWhl1klj0u/L3k7yvn4rq6uhp9rrLSOFa0MyjcgsV+6Pdl6QaTebg6UV2j7mwCMm4BAADAHrVd5PNayNTCn18UXHXVVaLAynm/5rhNCQ+Au+eee4w6bmNiYig0NNRqUQn8+Pj+lAXKe88LIw9PL3pxnS7n9qVNpynA34+unRRHjqCj4+LocFxwXPDzgt8lPMfo8MlVLuTxydyOTuiaW9tCIpj/uPD3kv/uBwcHt4tK6E7MGwq3YBGnS2upqKpBXJ6QEEw704qpvqmFCirRcQsAAAD2IyQkRGTUtu2E5azXth2zjF+Y7d69Wwwx4wFtyi2SvMBfs2YNzZo1Swzs6OptStzd3cVbW/yiwVoFQy5Qmrq/u84ZRE0trfTqHyfE+4/8dITcXJzpygmx5Ag6Oi6ODscFxwU/L/hdwnOM7u80Px9Kb5akPAmMjlvLHhfp+2nq73931gNYOYBF7M3UdduyMbEBFO6nO5uQX4GMWwAAALAfbm5uNHbsWFq7dq3Rx/n9KVOmtLs+d74ePHhQDCKT3m699VYaPHiwuMyDztjkyZPb3SYXdU3dplb8Y84gum1Gf/n9B384SN/szrLpYwIAAABQM3TcgsXzbUfHBtKfJ4oos6SGymsbqa6xmTxcnXHkAQAAwC5wPMG1115L48aNEwXXd999lzIzM0VBVoowyM7Opk8++UR0WAwbNszo68PCwsSWOeXH7777bjr77LPp2WefpYULF9LKlStp3bp1tHXrVtIq7jq5b95gampuofe2nCKe/XHfdwfIxbkPXTw62tYPDwAAAEB1ULgFi0hWdNyOig6gMH3HrZRzGxvshSMPAAAAdmHRokVi8MTjjz9Oubm5ogC7atUqiovTZbjyx7iQ2x3cWfvll1/Sf/7zH3r44Yepf//+9NVXX8kduVou3j54bhI1NrfS8m3ponj7z6/3k4uTE10wMsrWDw8AAABAVVC4BbPjjtrDORXicv9Qb/L3cqUwX0PeWn5lHQq3AAAAYFeWLl0q3kxZvnx5p1/76KOPire2Lr30UvFmb7h4+8gFQ6ippYU+25FJLa1Ey77aRy5OfWjB8EhSo4zialqxK4v8PV3p1un9kAsIAAAAVoHCLZjd4ZxyMXxCiklgUsYty6/AgDIAAAAAR8bF28cvHEZNza305V9Z1NzSSneuSKY3nfrQ3KERpBYnCirpjQ0naeW+bFFgZsP6+tG0gaG2fmgAAADgADCcDCycbxsg/h/u524UlQAAAAC9M2PGDFq2bBkOI2iWk1Mfeuri4XTpWF2+LZ/4v/2LvbThaIEqGhGWfr6H5ry0mX5INhRt2RH9zjIAAADoHaxnzwyFW7Bs4TZG33Hrq+i4rUTHLQAAOK4LLriAzjnnHJOf2759u+hE3Lt3b6/vh7fnBwToTqACqLl4++zfRtBFo3T5tpx9e8tne2jzsUKbzWm48eO/6LxXt9Kqg3kig5d5uBpeNqUX19jksQEAADjierZPnz6UlJTU7nNff/21+Fx8fHy7z9XW1lJgYCAFBQWJy23x1/DXSm88PNbNzY2eeeYZUhsUbsFig8m83JxpULiPuNx2OBkAAICjWrJkCf3xxx+UkZHR7nMffvghjRo1isaMGWOTxwZgC85Ofej5y0bS+SN0+bYNTS100ye76c8TRVZ7DDvTiunaD3bSxW9uo3Upho7fEB93eujcJPrjnzPkj6UXVVvtcQEAADj6etbb25sKCgpEQbjt/cTGxpr8mu+++04Mix0yZAh9//33Jq8jDZXlt5ycHDFI9s477yS1QeEWzCqvvI5yynUdtSOi/cnF2aldVAIybgEAwJGdf/75FBYW1m5gVU1NDX311VdiIVxcXExXXnklRUdHk5eXFw0fPpxWrFhh1sfBi9OFCxeSj48P+fn50eWXX075+fny5/fv308zZ84kX19f8fmxY8fS7t27xed4kc6dFtzFwF29vDBetWqVWR8fOBZeM760aBQtGKbLt61vaqElH/9FO9KKLXafra2ttOV4IV3+9nZa9O4O2nLcUCiO9Pegxy4cSlv/PZNuOrsfRQV4UoCXqzyoDAAAwJFZcz3r4uJCV111lSjUSk6fPk0bN24UHzflgw8+oGuuuUa88WVTeI0bERFh9MZFYrVB4RbMal+WrttWOZiM+bi7kKers7iMwi0AADgyXnwuXrxYLHS5cCT55ptvqKGhga6++mqqq6sThdJffvmFDh06RDfffDNde+21tHPnTrM8Br7fiy66iEpKSmjTpk20du1aOnnyJC1atEi+Dj8OXmj/9ddftGfPHrr//vvJ1VVXuLr99tupvr5efC1vg+NtZVwABugNV2cneuWK0XROUrh4v66xhW5Y/hftTi8x64Hln/91R/Lpoje30bUf7KJdituPDfKiZy4ZTpv+NZOumxJPHvr1K4sL1r2Y4yaFusZmsz4mAAAALbH2enbJkiWiIMyFYcb3O3/+fAoP160ZlHhNy9253JTAb9u2baO0tDTSKhdbPwCw33zbMYrCLWeGcNctZ4IVVCIqAQAALOid6URV5h9u5EK8KO3T8RV8wohu2dSl27rhhhvoueeeE50C3NXKuIvgkksuEXlc/HbvvffK1+dtW7///rtYDE+cOLHX/5Z169bRgQMH6NSpUxQTEyM+9umnn9LQoUNFoXb8+PGiI/df//oXJSYmis8PHDhQ/nr+3N/+9jfROdHU1ESDBg0Sf+sBesvNxYneuHo03frpHtqQWkg1Dc10/Ud/0SdLJhitLXuipaWVfjuUR69vOEEpucYDxvqHetPtMwfQhSOj5B1jbSUEe9H+LN1aN7OkhgaF+/bq8QAAAFh7PXvGNa1K17OjRo2i/v3707fffiuKv1y4ffHFF00WZPkxLFiwQNw/4wIvf+zJJ580ut6///1v+s9//mP0sZ9//ln+t6gFCrdgscLtqBjjgSicc8uF28q6JqppaCIvN/z4AQCABfAitzLHrDdp7pIkF0OnTJkiFpG8OOTOgC1bttCaNWvE55ubm0UXK3cWZGdni+5WfjPX9q2UlBRRsJWKtowzwDj2gD/Hhdt77rmHbrzxRlHQ5eETl112mVgws7vuuotuu+028Xj58fPnRo4caZbHBuDu4kxvXTNW5NxyfEFVfRNd98Eu+vymiTQiuvsD95qaW+jnAzn0xoaTdKKgyuhziRG+dOesgTR/WITI2u2M1HEr5dyicAsAAFpaz5p7TWvt9ewNN9xAH330kci1raqqonPPPZdef/11o+vwfX788cf0yiuvyB/juIR//OMf9Nhjj5Gzs2EnDTcoXH/99eIydw1zM0JcXBypDSpnYDaNzS10IFtXuI0J8qRQX0OuLQtvM6AsPgQ/fgAAYAHcKWBmug1guu6EPma6X97ydccdd9Abb7whFqG8UJw9e7b43AsvvEAvvfQSvfzyy6KrlRe4y5YtE1vPzIEXp6Y6ZJUff/TRR0Vu2K+//kq//fYbPfLII/Tll1/SxRdfLAq68+bNE1vfVq9eTf/73//EY1bjQAfQJo4oeG/xOBGVsO1kMVXWN9E17++kL26aRMP6+nfpNnjI2fd7T9ObG0+KDlmlkdH+dMesgTQ7MYyczlCwlcSHeMmXM4qNbw8AAEDt69kurWlVvJ69+uqr6b777hNrVI5p4LiGtnhdykViZfyXVNDlgjJ34kpCQkJowIABRoVbU7dpa+p7RKBZR3MrRRYZGx3TfitbuKKQyzm38SHqC30GAAA70MXtXd2iXMyZKRKAM7fuvvtu+uKLL0RnwE033SQXTblbgQeHcYcAa2lpoePHj1NSUpJZ7pu7aznuICsrS+66PXLkCJWXlxvdB0cg8Bt3KfBwCV6Qc+GW8dfdeuutooj78MMP03vvvYfCLZi9ePv+deNEVMKuUyVUUddE13ywk1bcNImSIv06/DrOn/16dxa9vfGkPDRXMj4+UHTYThsY0u14j3hFx+0pDCgDAACtrWctsKa15no2KCiILrzwQvr666/p7bffNnkdHkR2xRVX0EMPPWT0ce785c8pC7dagcItmE2y0WCy9tvYwvwUhVvk3AIAgIPjYV7cDfDggw+Kgqm0VYvx2f/vvvtODFPgfC7O8MrLy+v2Qpe7C/bt22f0MTc3NxF9MGLECNG5wF0QvIBfunQpTZ8+ncaNG0e1tbVi+9ill15KCQkJYnIvZ99yri3jbgle+HLubVFREW3YsMFsRWUAJY7W+vD68XTdh7toT0YpldU0is7bL2+eRAPbZMxW1zfRFzsz6d0taVTYZq151oAQunPWAJrYL7jHB1hZuM1A4RYAAMAq61klzrZ98803KTi4/d/zwsJCkVH7008/0bBhw4w+d91119F5550nrhMaGio+VllZKR6PsuPWz8+P/P27trPHWkwn7wP0Mt92tInhEcZRCcbdDwAAAI6It5eVlpaKQirndUm4g3XMmDEijmDGjBkUERFBF110Ubdvn/O/Ro8ebfTGeWDcCfHjjz+KRfTZZ58t7r9fv34ig4xx/ldxcbHYhsYdt9xNwYVazgaTCsK333676Nw9//zzafDgwWIRDWAJPu4utPzv4+X5CcXVDXTlezvlvNqKukZ6/Y/jdNazf9D/rUoxKtpyFML3S6fQZzdO7FXRlgV4uZKfh67vJb0IUQkAAADWWM8qeXp6mizask8++UTEMUhRDUqcwevr6ytmN0j++9//UmRkpHiLiooSj52jGNSmTyuXlcFIRUWFqLDz2QKutlsat4sXFBRQWBhnbGm3lj7juQ1i+BhPAz706Dzxf6XtJ4vpyvd2iMs3n92PHjw3ySGOiyXg2OC44OcFv0d4fiGqq6ujU6dOiY5QDw/DyUFLUOZedXd7tT2z1HHp7Htr7XWaltnbmra8tpGu/WAnHThdLt4P83Wni8f0FV22PPxWacGwCLp95oAu5+F21cLXt9L+0+Vid2nK4/NFnMOZYN2G49Id+HnBceku/Mxo/7hgTWufa9o6M61n1f3TC5pRUt0girZsWJRfu6ItC1dGJaDjFgAAAAC6wd/TlT65YQIN0efbFlTW0zub0uSiLc8Yu2hUFK35x9n01jVjzV60ZXH6uARufTldiq5bAAAAsCwUbsEs9hnl27aPSWBhiqgEFG4BAAAAoLsCvNxE7EFihCHf1sWpD10+Lpr++OcMevmK0TSoTfatOcUHe8mXTyEuAQAAACwMw8nAAvm27QeTSflk/FZV30QFFcYDIwAAAAAAuiLI240+v3EivbTumBhetnhyHEUHGgqqlhQfggFlAAAAYD0o3IJVBpNJOIuMC7fouAUAAACAngr2cacnLxpu9QMoRSWw9OJqq98/AAAAOBZEJUCvNbe00r6sMjnHNsq/4wExYfqc2+qGZlHABQAAAADQigRFx206ohIAAADAwlC4hV47WVglF2FHxwR2OoEvXJFzW4ABZQAAYKapwWBf8D0FtQr0ciVfD92mRXTcAgCAOWH9Y19azPQaBVEJ0GvJmaVnzLc1VbjNr6infqE++A4AAECPuLm5kZOTE+Xk5FBoaKh4v7OTh73R2tpKTU1N5OLiYrH70CJzHxe+vYaGBiosLBTfW/6eAqgJ/5zHB3vTwexyyimrpfqmZnJ3cbb1wwIAAA3Dmta+1rStZl7PonALvbY3o2v5tlLGraSgsg5HHwAAeowXQgkJCZSbmyuKt5bECzA+a873icKt5Y+Ll5cXxcbGitsFUBseUMaF25ZWoqySWhoQhkYEAADoOaxp7XNN62Wm9azNC7dvvvkmPffcc+JF19ChQ+nll1+madOmmbzu999/T2+99Rbt27eP6uvrxfUfffRRmjdvnnyd5cuX09///vd2X1tbW0seHh1nr0LPJWfpOm6dnfrQ8L7+nV43zKjjFoVbAADoHT6DzQsiPkPe3NxsscPJC7ni4mIKDg5GMdHCx8XZ2RmdzaBq8cFe8uWM4moUbgEAoNewprWvNa2zGdezNi3cfvXVV7Rs2TJRvJ06dSq98847tGDBAjpy5Ih4EdbW5s2bac6cOfTUU09RQEAAffTRR3TBBRfQzp07afTo0fL1/Pz8KDU11ehrUbS1jIq6RjpeUCUuJ0X6kqdb51vFwpUdtxX1FnpUAADgSHhB5OrqKt4suZjj2+f1BLpAcVzAscUFKwaUFdfY9LEAAID9wJrWdlpUvNa3aeH2xRdfpCVLltCNN94o3udu29WrV4uu2qeffrrd9fnzSlzAXblyJf38889GhVv+YY+IiLDCvwAOZJVTayvJg8nOxCjjthKFWwAAAADQloQQQ8dtelG1TR8LAAAA2DeblZE5qHfPnj00d+5co4/z+9u2betyRbyyspKCgoKMPl5VVUVxcXEUHR1N559/PiUnJ5v1sUPPBpOxMD9Dxy2iEgAAAABA2x23KNwCAACAHXbcFhUViSy68PBwo4/z+3l5eV26jRdeeIGqq6vp8ssvlz+WmJgocm6HDx9OFRUV9Morr4gYhv3799PAgQNN3g7n5fKbhL9OKgzzm6XxfUhByFqzV1G4HRntf8Z/g4eLE/l6uFBlXZMo3HZ2fS0fF0vDscFxwc8Lfo/w/ILnXUf9e4R1AdhasLcb+bi7UFV9E2UgKgEAAAAsyObDydoG9fLivyvhvStWrBCDyTgqISwsTP74pEmTxJuEi7Zjxoyh1157jV599VWTt8WxDI899li7jxcWFlJdXZ1VXoCUl3PkQKvqsjQ6w493b0aJuOzn4UxezVVUUHDmroMgT33htryO8vPzO/x+a/W4WAOODY4Lfl7we4TnFzzvOurfI95tBWBLvHaND/GiQ9kVdLq0hhqaWsjNBWtVAAAAsKPCbUhIiJiy1ra7tqCgoF0XrqmhZpyN+80339A555zT6XX5RcT48ePp+PHjHV7ngQceoHvuuceo4zYmJoZCQ0PFoDNrvOjhBSDfn5YKlLw1rLxON8F7TFzQGb9vkqjAdMooraO6phby9A8iPw9Xuzou1oBjg+OCnxf8HuH5Bc+7jvr3CANnQS1xCVy4bWklUbztF+pj64cEAAAAdshmhVs3NzcaO3YsrV27li6++GL54/z+woULO+20veGGG8T/zzvvvDPeD3eA7Nu3T0QndMTd3V28tcUvQKz1IoRf9Fjz/sxh/+ly+fLY2MAuP/YIf8OAsqKqRgrwan/stXxcrAXHBscFPy/4PcLzC553HfHvEdYEoAbxwYYBZRyXgMItAAAA2F1UAne5XnvttTRu3DiaPHkyvfvuu5SZmUm33nqr3AmbnZ1Nn3zyiXifi7WLFy8WubUchyB163p6epK/v7+4zJEH/DnOs+XOWY5H4MLtG2+8YcN/qX1KziyTL4+ODezy1ykHlBVU1NGAMHQoAAAAAIB2xCsGlJ0qqqaZNn00AAAAYK9sWrhdtGgRFRcX0+OPP065ubk0bNgwWrVqFcXFxYnP88e4kCt55513qKmpiW6//XbxJrnuuuvEQDJWVlZGN998syjqcjF39OjRtHnzZpowYYIN/oWOUbjliNoRMbrCeVeE+xo6bvMrLZ8hDAAAAABgTvEhhsJtRvGZZzwAAAAAaHI42dKlS8WbKVIxVrJx48Yz3t5LL70k3sCyahuaKSW3QlweGObTYU6tKeF+isJtRb1FHh8AAAAAgKXEKaIS0otrcKABAADAIhAcCj1yMLucmngaA8ckxHQ9JqFtVEJ+BTpuAQAAAEBbQn3cydvNWR7YCwAAAGAJKNxCjyRnlsqXR8cGdOtrlVEJBZXouAUAAAAA7Q3li9Pn3J4uraXG5hZbPyQAAACwQyjcglUHk5kaTgYAAAAAoDXxIbq4hOaWVlG8BQAAADA3FG6h21pbW2mvvuPWx92FBoT5dOvrPVydyd9Tl4mLjNueHX/ekidFVQAAAACA9cXrO24Z4hIAAADAElC4hW7LLa+TIw5GxviTs1Ofbt9GuL7rljNuuRAJXff8mlSa9cJmuvv74zh2AAAAACoo3GYUIecWAAAAzA+FW+hdTEI3B5NJwvQ5t/VNLVRR24TvQhc1NbfQ5zszxeU9pyspNb8Kxw4AAADABuJDlB23NfgeAAAAgNmhcAu9Gkw2Jq57g8lM5dzmVyLntqv2ZpZRWU2j/P7qw3k9Ov4AAAAA0DvxwbqMW4aoBAAAALAEFG6h25KzDB23o3rYcRvup+u4ZQUVutgFOLP1R/ON3l992Ph9AAAAALCOUF938nJzFpcz0HELAAAAFoDCLXRLQ1MLHcwul7sMgrzdenQEw30VHbcV6Ljtqj9SCozeP5pXSenIVAMAAACwuj59+lCcPuc2q6RGRFoBAAAAmBMKt9AtKbkVonjLRsf2rNu2bcctohK6JrO4ho4XtM+0/R1xCQAAAAA2jUtoamml7LJafBcAAADArFC4hR7n246O7Vm+LQtDVEKvYhIuHxctX/79EHJuAQAAAGxB6rhlGFAGAAAA5obCLXR7OJZkdA/zbVkYohK67Y+jhpiEv0+JpwEhnuLyvqwyyi1HhwcAAACAtSWEKAaUIb4KAAAAzAyFW+iW5Cxdx627ixMlRvr2+OiF+RkybgsqMZzsTKrqm2hHWrG43DfAkwaF+9CMAYaO5zUYUgYAAABg447banwHAAAAwKxQuIUuK6ysp6wSXWfniGh/cnXu+Y+Pu4szBXq5issYTnZmW44VUmNzq7h8TlKYGIYxY4Ch4/m3Q7k9/l4AAABA77355puUkJBAHh4eNHbsWNqyZUuH1926dStNnTqVgoODydPTkxITE+mll14yus7y5cvF3/u2b3V1GOqqJvGKwm1GcY1NHwsAAADYHxdbPwDQDt6SL+nNYDLlgLLSmkYqqKin1tZW8WIETFuviEmYlRQu/t8/2EMMxOA8tV2nSqi4qp6CfQydzAAAAGAdX331FS1btkwUb7kg+84779CCBQvoyJEjFBsb2+763t7edMcdd9CIESPEZS7k3nLLLeLyzTffLF/Pz8+PUlNTjb6WC8OgHuF+7uTh6kR1jS2ISgAAAACzQ8ct9GwwWUzPB5O1HVDW0NxCZTWN+E50oKWllTboC7debs40MSFIXOZC97yhEbrrtBKtSzEMLwMAAADrefHFF2nJkiV04403UlJSEr388ssUExNDb731lsnrjx49mq688koaOnQoxcfH0zXXXEPz5s1r16XLf+sjIiKM3kBd+Hskdd1mldZQU3OLrR8SAAAA2BF03EKXJWeat+PWaEBZZR0Fervhu2HCvtNlVFzdIC5PGxhCHq7O1NKie1Ewf2g4vbM5TVz+/VAeLRrfvqsHAAAALKehoYH27NlD999/v9HH586dS9u2bevSbSQnJ4vrPvnkk0Yfr6qqori4OGpubqZRo0bRE088IYq+HamvrxdvkoqKCvF/XjdIawdL4vvgXVTWuC81iQ3yoqN5lSLWKru0hmKCDAPLHPm4nAmOC44Lfl7wu4TnGDz3OurfpJZu3A8Kt9AlzS2ttP+0rnAb5e9BEf4eZtlaJuG4hEQ0kZj0R4ohJmF2oi4mQTK8rz9F+ntQbnkdbT1RRBV1jeTnocsOBgAAAMsrKioShdXwcOO/0fx+Xl5ep18bHR1NhYWF1NTURI8++qjo2JVw7i3n3A4fPlwUYF955RURw7B//34aOHCgydt7+umn6bHHHmv3cb4Pa2Tj8ouQ8vJy8cLHyclxNvaFeRou7zuZQ+5Nfkafd9TjciY4Ljgu+HnB7xKeY/Dc66h/kyorK7t8XRRuoUuO5VdSTUOz2bptpYxbCQaUdS3fdkZiqNHnnJx0cQnLt6WLLg+OVFg4qq9Zvj8AAADQdW2z+ruS38/RCNxVu2PHDtGxO2DAABGhwCZNmiTeJFy0HTNmDL322mv06quvmry9Bx54gO655x75fS74cmRDaGioyMu1xose/jfz/TlSgXJIbD3RHl1kVVmzK4WFhRl93lGPy5nguOC44OcFv0t4jsFzr6P+TfLoxswCFG6hBzEJvc+3ZWG+hh/UgkrDtj4wyCmrpZRc3TbHkdH+RsdMMn+YrnArxSWgcAsAAGA9ISEh5Ozs3K67tqCgoF0XblsJCQni/9xVm5+fL7pupcJtW/wiYvz48XT8+PEOb8/d3V28mfpaaxUM+UWPNe9PDeJDdBm3LLOk1uS/3RGPS1fguOC44OcFv0t4jsFzryP+TXLqxn1g5QDdH0xmpsKtMioBHbdn7radnWT6xd/4+CAK1ucDb0wtpFp9ZzQAAABYnpubG40dO5bWrl1r9HF+f8qUKV2+He7QVebTmvr8vn37KDIyslePF8wvQVG4TS+qxiEGAAAAs0HHLXRJcpau49bVuQ8NjfI3y1FDVMKZ/ZGi23bHZiUab7uTODv1oTlDwunLv7KotrGZNh8vFPEJAAAAYB0cT3DttdfSuHHjaPLkyfTuu+9SZmYm3XrrrXKEQXZ2Nn3yySfi/TfeeINiY2NFji3bunUrPf/883TnnXfKt8lZtRyVwHm2HHnA8QhcuOWvBXUJ9/Ugdxcnqm9qofRiFG4BAADAfFC4hTMqr22kEwVV4vKQSD/ycHU2y1EL8VF23CIqoa2ahib682SxuBzh50FDozrOpuO4BC7cSnEJKNwCAABYz6JFi6i4uJgef/xxys3NpWHDhtGqVasoLi5OfJ4/xoVcZY4aF3NPnTpFLi4u1L9/f3rmmWfolltuka9TVlZGN998s4hg8Pf3p9GjR9PmzZtpwoQJ+NaqDM8ciAv2omP5VZRVUiuG+vKJdQAAAIDeQuEWzmifvtvWnIPJmJuLk9jiX1zdQIXIuG3nzxPF1NDUIi7PSgrrdMDJlP4h5OvuQpX1TbQuJV98HR9fAAAAsI6lS5eKN1OWL19u9D531iq7a0156aWXxBtoQ3ywtyjcNjS3iBkFMUFetn5IAAAAYAdQ2QGb5NtKwvx0w7YKKuuopaUV3w2FP44aYhJmdxCTIOEi7ewk3XUq65poe5quUxcAAAAArDugLKO4BoccAAAAzAKFW5VIya+WuyvVJjlT0XEbY76OW+WAssbmViqtaTDrbWsZDyBZn6IbTMaZadxReyYclyDhuAQAAAAAsF7HreQUcm5Vp66xmQ6eLhfD43idDQAAoBWISrCxk4VV9PSqFFqXUkBPLHSmayfHk5pwF6wUlcCxBjFBnmYf5qDMuQ1W5N46ssM5FVSgj4+YOiCEPN3OnCt89qBQ8nB1orrGFlp7JI+evGgY8tUAAAAArCA+2BCNkFGEAWW2wkXZ7LJaOppbSUfzKiglr5KO5lbQqaJqkjb3fXDdOJqdFG6zxwgAANAdKNzaWFUdZ5LqOitf33CCLhsXY7bhX+bAHQM8nEyKSegsZ7UnwvQdtyy/so6GUMcDuBwJ59RKpAiEM/Fyc6EZg8Lo98N5VFTVQLvTS2hiv2ALPkoAAAAAYHGKqIR0RCVYRXV9E6Xmc2G2klJyK0Sh9mhepYgN68yaw/ko3AIAgGagcGtjI2MCaE5SGK1NKRAdp5/tyKAbp/UjVcYkmHEwWduMW1ZYoeswBc631RXz2awz5Nu2jUvgwi3j/6NwCwAAAGB5kX4eYuYAR5+lIyrB7DsAM0tqdB20+k5aLtB2NUvYzdmJ+of5iOIuyymvNe8DBAAAsCAUblVg2TkDRdct7955a+NJunJCLHm7u9j9YDIW7qvouK2oM/vta1FBRR0dOF0uLg+J9KNI/67HU8xMDCNX5z4iM3j1oTz67/lDzN4lDQAAAADGnJz6UFyQFx0vqKLM4hpqbmlFZFUP8E6/VI43EEVaXaH2WH4l1TQ0d+nro/w9KDHSjxIjfMX/kyJ8KSHEW3wvhj6yWtwORykAAABohTqqgw4uKdKPzhkUSGuPlVJxdQMt35ZOt88cQGrquHXqQzQi2gKFW0XHLUclgHG3bVdjEiT+nq5ikNmmY4WUU64rAHNXNwAAAABYVlywtyjcNjS3UF5FHfUNMO9sCHtTVFVPa1NLKHdfmb5YW9nloqqnqzMNivAVhdkkqVAb4Uf+Xq4dfk1UgCedKKiinLJakYWL5gYAANACFG5V4sZJUbT+eKkIzX9n00m6ZlKcKMLZUk1DkzjbzQaF+5KPBbqAjQq3iEoQ1hsVbrs/OGHBsAhRuJXiElC4BQAAALC8hBDDgLL0omoUbjuRV15H57y4marqO8+jZbFBXkYdtPx//hh30XZHpL+HKNzyIN/SmkYK8nbr1tcDAADYAgq3KhEX5EEXj+5L3+3Npoq6JvpgSxrdM3ewTR8Td2tK01ctkW/LQnzciHfyt7bqIgIcXV1jM209XiQfmxF9/bt9G+cMCSenHw6K793vh/LovnmD0VEAAAAAYIWOWwnn3E4dEIJj3oFfD+a2K9pyk4iuQKvrnk2K9KXBEX5max5RdkBz1y0KtwAAoAUo3KrIXbMG0E/7c0Q+6QdbT9H1UxNsuqAwHkxmme32Ls5OFOztLrZKoeOWaEdaMdU26jK8Zg4OE3lp3RXi407j44No56kSOlVULbbsccc0AAAAAFhOvKJw29XBWY5K2h3Gnv3bcBH1FR3oadFmA45KkHAkw7AeNEgAAABYm5PV7xE6FBPkRYvGx4jL1Q3NIjLBlvYqBpONsVDhloX76QaUFVbVi6mxjmx9Su9iEiTzh0XIl7nrFgAAAAAsK14RlcAnz6HjHWY704rF5TAfV7p0TF/xOsjSmbNRbTpuAQAAtACFW5W5Y+ZAcnPRfVs+3p5us/gADuyXOm59PVyoX4iPxe5Lyrnl6bs8nM1R8TGXBpO5OTvRWQN7vr1u3lBD4fY3FG4BAAAALC7S31Os4VhGMQq3HdmeVkz1TS3i8qR4f6tFekUFGGZr5JYjog0AALQBhVuVifD3oGsnxYnLHJz/xoYTNnkcp0trRXwBGxUT0KMt+93tuGX5Dpxzm5pvmKQ7sV9Qr/K8uKNAGkqWkluBFw8AAAAAFsbDsmKCPOWoBEffSdaRTamGmITJ8X5Wu19lxq205gYAAFA7FG5V6LYZ/cnLzVlc/mJXJp0utX5GVnKWMt/WMoPJJGG+hrPfBZWOW7g1iklIDOv17c1XdN2uPoy4BAAAAABLSwjR5dxyR2meAzckdGazPt+WC93jY/ys2iAjQVQCAABoBQq3KsTDpf4+NV5c5kFlr/9h/a7bZEW+raUGk0nCjDpudV2+jmh9Sr5Z8m0l84YabgM5twAAAACWF6cYUJaOuIR2MotrKE2f/8szNHzcdc0q1uDu4ixeZzEUbgEAQCtQuFWpm6f1F9my7Js9p60+4EDKt2Wj9VvuLSVc2XHroIXb4qp6uct5ULiPGNDQW/1CfWhwuK+4vDezjPKQ5QUAAABgUfHBhjUcxyWAsU3HDDvMpg8Ktfrh6avPuS2orKcGfc4uAACAmqFwq1L+Xq5007R+8tCuV9Yds9p91zc105GcCnG5X6g3BXi5WfT+pOFkLN9BoxI2phZSqz4GbVZi77ttJfOHGeIS1hxBXAIAAACAJcXroxJYupUbL7Sy5pVMH9TzQby9mQPBeN3tyLM1AABAO1C4VbEbzkqgQC9XcXnl/hw6ll9plfs9nFNBDc26M9CjYyybb9t2OFmBgy6g1h81xCSck9T7fFtThVvEJQAAAABYVjyiEjptDtl2slhc5siCpAjr5du2LdwyDCgDAAAtQOFWxXzcXcSgMums8Itrjlk/JsHC+bYs2MednPo4bsYtb9PafKxIXA7wcjXrMLjECF+K02/Z23mqhEqqG8x22wAAAABgLNLfg1yddQtbRCUY251eSrWNzXJMgpP0AsBGhdvc8lqr3z8AAEB3oXCrctdOiqdQX11H6u+H8+jg6XK7GkwmTZSVBgU44palv9JLqKq+SVyeOThMHA9z6dOnD80fGiFHbqxTDEADAAAAAPNycXaSZxXwcLKWFn0WFtDGVEW+7WDr59sqM25ZTpnjve4AAADtQeFW5TzdnOnOWQPk919cm2q1jltPV2d5uJWlSTm3RVX1osDoSJTF1FmJ5otJkCAuAQAAAMD6cQl1jS1iCBbobDqmy7flHoVpA6yfb8sQlQAAAFqDwq0GLBofQ33123o2pBbSnowSi90XZ8xKeU8jov1F14A1SDm3XLMtrnKcBW5rayutT9F1H7g49aGzLTBdd2R0AEXoC+NbjxdRZV2j2e8DAAAAANrn3J7CgDIhp6yWjuVX6damMQEU6G3Z4ccdifT3NHpMAAAAaofCrQa4uzjTXbMNXbfPr7Zc1u1eo3xbyw8mk4TpC4uOlnN7srCaMktqxOXx8UHk76kbRmdOnB82b2i4uMxD57j4DwAAAACWER+ii0pgGcXVOMyKblsp39ZWgr3dyM1F9xIYhVsAANACFG414m9joileP2Rqe1oxbTuhG2ZlbslZ1s23lYT7Kgu3jpM39cdRQ0zC7CTzxyRI5g3T5dyy1YfyLHY/AAAAAI4uTtFxm16sO0Hv6DalqqNwyw0NUf661x3ZpbVi9xsAAICaoXCrERxZ8I85g+T3n1+TapGFhpRvy0bHWLFwq49KYPmVjlO4XaePSbBUvq1kQnwQBem3pG1ILaA6/URfAAAAADCvBGXhFlEJ1NjcQn/qm04CvVxpRLT1XmN0lnNb3dBMFXW6AcEAAABqhcKthpw/IooGhfvIkQZcgDOnpuYWOnBaV7jlTF1lfIGlhSkLtw4SlVBW00B7MnQdzv1CvKlfqO57a6nC/5wkXVxCTUMzbVZsVwMAAAAA84kK8BCzC1g6ohJob0YpVdbrCqTTBoaSs/7Y2IpyQFluOXJuAQBA3VC41RBe5Nyj6Lp9Yc0xauFpXmZyNK9STL9lY+Ksl2/LwhRRCYUO0nHLWV/N+u+fJbttJfMVcQm/H0ZcAgAAAIClTpjHBOkizjKKaxx+O75a8m1NFW6RcwsAAGqHwq3GzBsaQcP6+onLh3MqaLUZC3DJWbaJSWDhDjicbL0yJsGC+baSKQOCycfdRVxedyRfbFsDAAAAAPOTZlPUNjZTQaVjrG27Urg9WwWF274Bhtcd2WWO0TACAADahcKtxvTp04f+OXew/P6La4/JXZu9lZxpm8Fk0oRXaduUIwwn41iKjfqoC18PFxofH2Tx+3R3cZY7eznPa0dascXvEwAAAMDRB5Rx162jKqisE80mjJtPQn0N8Wi2go5bAADQEhRuNWjGoFAaq48yOF5QRT/tzzbL7e7TDyZzc3aiIVG6rl5rTngN0y/kHKHjlrNtpWEIvGXM1dk6v4oLFHEJvx1CXAIAAACAJTtuHT3ndvMx3VAyNmOQ5XeYdUWkP6ISAABAO1C41WjX7b2KrtuX1x3v9bb30uoGStNPvR3a1090Z1qbVLgtrq4XHan27I+jhpiE2VaISZBMHxxK7i66X/s1h/PN1q0NAAAAAAbxIYaO23QH7rg1yrcdbPuYBGl4nAQZtwAAoHYo3GrU5P7BNHVAsLz96rs9p3t1e/tOK/NtrTuYTBKmz7ltbSUqqmoge7YuJV/8n9MhrNl94OXmIg+FKKqqp72KeAwAAAAAMI94RCWIBoEtxwvlaDBrz9DobD0c6OUqLucg4xYAAFQOhVsNU2bdvrr+ONU3Nff4tpL1MQm2yLeVhPsZMq/sOec2vaiaThbqups58iLQ282q9z9fEZfwO+ISAAAAAMyub6CnPL8hw0GjEvafLqOymkZxedrAEHKxUjRYd3Ju8yrqsAMNAABUzeZ/Pd98801KSEggDw8PGjt2LG3ZsqXD637//fc0Z84cCg0NJT8/P5o8eTKtXr263fW+++47GjJkCLm7u4v///DDD2SPxsQG0mz9sKmc8jpasTNTk4PJJOG+Hg5RuFXGJMxKDLf6/c9OCicX/QsJLty2coszAAAAAJgNzy+ICfSUoxIccb21KVURk6Df8aW2wi13BfMANQAAALWyaeH2q6++omXLltFDDz1EycnJNG3aNFqwYAFlZpouQG7evFkUbletWkV79uyhmTNn0gUXXCC+VrJ9+3ZatGgRXXvttbR//37x/8svv5x27txJ9ugfcwbJl1/fcJJqG7rfddvS0ioPJuNJr331CxlrC9dHJbD8SvsdULb+qC4mwdr5thJ/T1eaMiBEXM4uq6VD2bpJvwAAAABgPnH6uISahmYqqdENpXUkGxX5tmerrHCrfL2DnFsAAFAzmxZuX3zxRVqyZAndeOONlJSURC+//DLFxMTQW2+9ZfL6/Pn77ruPxo8fTwMHDqSnnnpK/P/nn382ug4Xdx944AFKTEwU/589e7b4uD0a1tefzh0eIWeWfrI9vdu3cbKwiirrdYtJzp7i4We2EKqISiiw047byrpG2plWIi5HB3rSwDAfmzyO+UMVcQmHc23yGAAAAADsWXywl3w5q8x+mxJMKaluoAP6GRqJEb4U6W+bxpCuDCjLRs4tAAComIut7rihoUF0zd5///1GH587dy5t27atS7fR0tJClZWVFBQUZNRx+49//MPoevPmzeu0cFtfXy/eJBUVFfLt85ul8X3w9qme3tfdswbQb2LLO9FbG0/SFeOjyddDF7jfFXsydIVENirG3yr/ZlPCfAxZr3nldb0+Lmq0KbWAmlp0W+U45oL/fT3ZOtfbYzM7MZS4Ps93zXEJ/1R0bmuZPf7MmAOOC44Lfl7we2RPzy94jgetiA/Rddyy0w5WHOShZNISV20xCUxZSEbHLQAAqJnNCrdFRUXU3NxM4eHGGZ/8fl5eXpdu44UXXqDq6moRhSDhr+3ubT799NP02GOPtft4YWEh1dXVWeUFSHl5uXjh4+TU/SZo/z5E8xOD6LeUEiqrbaTX1xymJZOiuvz1248Zjk2CL1FBgSGD1Zqc6nXDC9jp4grxOHpzXNRo1b4s+fKYCLceH+ve/sywUVE+lJxdJQal7TyaQQlB6uqEsNVxsUc4Ljgu+HnB75E9Pb/wSXsALYjXRyU4YsetmvNtlRm3DIVbAABQM5sVbiVtt+Xzwr8rW/VXrFhBjz76KK1cuZLCwsJ6dZscp3DPPfcYddxyZIM0BM0aL3r48fH99fRFz33netOa1C0iYH9FciHdds4QCvAydLB25mjRMfF/nnw7bVgcebnZ5scipKWVXJ0PUmNzK5XVt4rva2+Pi5rw92ZHxgFx2dvNmeaOTiB3F2eb/cycP6qGkrNTxOW/chppYmIcaZ05jos9wnHBccHPC36P7On5hQfaAmhBnCIq4bQDFW55fsbm47rCrZebM42LN+yOVAtk3AIAgFbYrHAbEhJCzs7O7TphuQOxbcesqaFmnI37zTff0DnnnGP0uYiIiG7fpru7u3hri1+AWOtFCL/o6c39JYT60uXjomnFriyqqm+i97em033zE8/4dXzdY/mVcv6Uj0fXir2WwP/0MF8PMTCroKJeHIveHhc1Sc4qpZIaXVfxtIGh5OnW9TgLU3p7bOYPj6QnftUVblcfyae7zrGPuAR7+pkxJxwXHBf8vOD3yF6eX/D8DloRHeglGiP45H2WA0UlHMmtoKKqBnF5Sv8QcnNR35qMBzK7OPUREWY5DvS9AQAA7bHZX1E3NzcaO3YsrV271ujj/P6UKVM67bS9/vrr6YsvvqDzzjuv3ecnT57c7jbXrFnT6W3aiztnDSQ3Z9239KM/06mw8sxn9g9klcn5U6NjA8jWwvQDyoqrG6ihyb5ySv84mi9fnpVk3CVuq06DEdH+4vLhnArKKqmx9UMCAAAAsBtcsJQ6O0+X1/doroEWbUw1RIFNH6y+mATGBfUIf133fk55ra0fDgAAQIdsevqT4wnef/99+vDDDyklJUUMFcvMzKRbb71VjjBYvHixUdGW3+ds20mTJonOWn7jbDXJ3XffLQq1zz77LB09elT8f926dbRs2TKyd5zVdNXEWHG5trFZDCo7k+Qs3bRXNjomkGwtzNfQ+VxYZV9bytanGBaxMwfbvnDL5g2NkC+vPty1bGkAAAAA6N6AspqGFrkL1d5tOmbIt52hwnzbtjm3ZTWNVF3fZOuHAwAAoL7C7aJFi+jll1+mxx9/nEaNGkWbN2+mVatWUVycLmszNzdXFHIl77zzDjU1NdHtt99OkZGR8hsXayXcWfvll1/SRx99RCNGjKDly5eLaIWJEyeSI1g6sz95uOq+rZ/tzKDcM5xBTs4slS+roeM23M+QW9eVjmGtOF1aQ0fzdJEUI2MCxPYsNVgwzFC4/e0QCrcAAAAA5hSvyLnNcIDdTeW1jbQ3U9cY0i/Um2KCDP9+Nefcnuk1EwAAgMMOJ1u6dKl4M4WLrkobN27s0m1eeuml4s0RcUbsdVPi6Z1NaSJq4LU/TtBTFw83eV3erpWsX1j5e7pSgr4jQC2F2/yKOooKVV8mVk9sOGrotj0nUR3dtqxfqA8NCvehY/lVtCejlAoq6ihM8T0AAAAAgJ6LCzasrzOKq2lCQrBdH84/TxSJTF82XcXdtixSH5XAssvqaECYr00fDwAAgCn2URUDI7ee3Z983HU1+a//yqLMYtNn97NKakWWrNRty8NF1BSVkF9hPx236xWFWzXk2yrNV8YlHDHk8AIAAABA7ySEGDpO04vsv+N2U6oiJkEl0WBnikpgOWXouAUAAHVC4dYOBXq70ZKzEsRlnpT6yvrjJq+3VxmToIJ827YdtwV2EpVQ09BE204Wy2f2h0T6kZrMU8QlrEZcAgAAQI+8+eablJCQQB4eHmIA75YtWzq87tatW2nq1KkUHBxMnp6elJiYSC+99FK763333Xc0ZMgQcnd3F///4Ycf8N3RdMetfRdueTeflG/r7uJEExOCSM2UUQko3AIAgFqhcGunlkxLEPEH7Ifk03SioEr1+bYszE/ZcVtH9mDr8SIRW8FmJYaporNZiQvJsfr8se1pxVRW4xiDMwAAAMyF5ynwINyHHnqIkpOTadq0abRgwQKjWQ1K3t7edMcdd4j5Djyg9z//+Y94e/fdd+XrbN++XcyDuPbaa2n//v3i/5dffjnt3LkT3zgNiQn0Iif90i+9pJrsWWp+JeXp1++T+gWTh6szaaXjNhsdtwAAoFIo3NopPw9XunV6f3GZY6ZeWnes3XWSs3T5tlxHHKWSwm24r/113P6hiEmYrbKYBMaF5Pn6rlvOJFuLuAQAAIBuefHFF2nJkiV04403UlJSkhi+GxMTQ2+99ZbJ648ePZquvPJKGjp0KMXHx9M111xD8+bNM+rS5duYM2cOPfDAA6Ijl/8/e/Zs8XHQDjcXJ7mzk6MSuCvVMWIS1J1vy6ICDK87csvso2EEAHSySmrooR8P0eaTupoH9A43onEM54403U5isC4Ubu3YdVPiKMTHTVz+9UAuHcmpkD9X19gsvz8g1EcUetUgwMuV3Jyd7KZw29LSKufberg60ZT+IaRG85Q5t4fzbPpYAAAAtKShoYH27NlDc+fONfo4v79t27Yu3QZ36fJ1p0+fbtRx2/Y2ubjb1dsE9YgL1u1sqqpvohL9fAl7JMUkaGEwGfP1cCVfD91ckJxyZNyCYymtbqBPd2SIAqc9evCHg7RiVxY9vCqNKmobbf1wNI9/Vu777gBd8/5OOpZfaeuH43B0f6nALnm5udDSGQPo8V+OiPdfXHuM3r9unLh8KLtc5N+qKSZB6v7kuITTpbVUYAdRCYdyyqlQX4Ce2j9EtVvGRscEULifuxgIt/l4kXhhIQ24AwAAgI4VFRVRc3MzhYeHG32c38/L6/xkaHR0NBUWFlJTUxM9+uijomNXwl/b3dusr68Xb5KKCt1J+paWFvFmaXwf3FFqjfvSEl0kla5L6VRRFQV6qaNhwpx47fhXeom4HBvkSXFBnmf8OVDDzwvHJaTmVVJuWS01NTWTk5RrYUNqOC5qhONivmNTUddIl7y1nU4VVVP/UG9affc0VfzsmwvXEbaeKBKX65tbadvJIpo/LNLWD0vTv0vbT+qOJ9eQvtiZQf89fwjZmxYrP/d2535QmbFzV02Mpfe2pFFueR2tS8kXubajYwMpOdOwZYDfVxMeUMaF29KaRjkbVqvWpyhjEoxffKkJ/6HmrttPtmeIY74xtYDOHxFl64cFAACgGW0z7Hnxf6Zce45GqKqqoh07dtD9999PAwYMEBEKPb3Np59+mh577LF2H+ficF1dnVVehJSXl4vH6eSEjX2SEHfDevZAWh5Fe9hf9xdvR25s1jWFjI/2ET9zWvh5CfF0olTunG9updSMHAr2tn1RXQ3HRY1wXMxzbPg69/+SJoq27GRhNa3Zl0Zjon3JXnyVnE/KVJq1B0/TmDB1NlBp5XfpcLahfvT93tN0w5ggEQVkT1qs/NxbWdn1zmUUbu0cd3jeOWug2Cogdd1+umQiJWepbzCZhDs/JUXVjRRN9pFvy4PJ1Gy+vnDLfjuUh8ItAABAF4SEhJCzs3O7TtiCgoJ2HbNtJSQkiP8PHz6c8vPzRdetVLiNiIjo9m1yDu4999xj1HHLWbuhoaHk5+dnlRc9XFjm+0PByWBoXAvRlmxxubTRmcLC1L0m7In92w2F2vkjY7r0b1TDz0tcaAH9eapcXG5w8aawMNu/LlLDcVEjHBfzHJu3N52kTW1yXzdn1NL8Mbr5OPbgj5MnjN7fm1Njl8+71vpd4g7t3ApDzE9FXTPtK2ql80fY1zFtsfJzr4eHIWf9TFC4dQCXjYsWT9CZJTW05XiRCJSWOm693ZxpYJi6zq6FKQaUceFWq/Ir6uhgtm4hODTKjyL8u/6LaQsTEoJExnBZTSNtOFogcpDVGu0AAACgFm5ubjR27Fhau3YtXXzxxfLH+f2FCxd2+Xa4w0MZczB58mRxG//4xz/kj61Zs4amTJnS4W24u7uLt7b4BYi1CkD8osea96cFCSE+8uWMklq7Ozb8syvl2/KsiikDuv6i19Y/L30DdfnDLLeinkar5Htj6+OiVjguvTs2f54ooufXGIaW8+9rQ3MLrTqYS48tHEruLtp/7ZdeVE37T+teg0syimsou6yOYkRsDXT3d+lEga47W+mbPafpwlF97e5g9rHic2937gN/CRyAq7MT3T17oPz+f1ceEtEJbGRMADmrLM+GM27toXCr7LadrfJuW+bi7ERz9HEONQ3NtPW4LscGAAAAOsddru+//z59+OGHlJKSIoqtmZmZdOutt8qdsIsXL5av/8Ybb9DPP/9Mx48fF28fffQRPf/883TNNdfI17n77rtFofbZZ5+lo0ePiv+vW7eOli1bhm+HxsQEeZK02k4vbv8CWOvSiqpFzBkbnxBI3hqak9A3wFO+nFOGAWVgv/jn+64VyaQfcyPqA+cO1w2orqhroo2pZ4430YKf9+eY3MkrZd5C96Xktd/Szw2B9jrYTo1QuHUQF43uK4LH2bH8KtXGJLBwO+m41Uq+rdL8Ybo/3uz3w50PVAEAAACdRYsW0csvv0yPP/44jRo1ijZv3kyrVq2iuLg48fnc3FxRyFVux+NiLl933Lhx9Nprr9Ezzzwjvl7CnbVffvmlKOqOGDGCli9fTl999RVNnDgRh11juIst3NdNXOZcSe5QtSebFAWf6YNCSUt4OJkkp0z7g5FbpKocgEJ9UzMt/XwvFVc3yL+nXLhdONrQMfnTPkPBU6v4uXWlonD7n3OT5MtoSuq5o7m6QadsxuBQo65bsA7tnA6FXuGu2nvmDKbbv9hr9PHRMeoaTCYNJ5MUVWmzcMsxA1tP6BaxIT7uNLyvP2nB1AEh5OPuIiYD8zC7xuYW0bENAAAAnVu6dKl4M4WLrkp33nmneDuTSy+9VLyB9kUHuFNeZQNV1jWJWKpAb10h1x5s1McksBmD1b/LTCkqwMMuOm65YHXHimRRnHr1ytGaK6CDZT3xyxHal6WLSowO9KRXrhglhlNPGxBCwd5uoqDLr/0q6xrJ18P2A/p6KiW3kk4U6JrUJsQH0byh4eTj5kxVDc3058kicWKD/93QPUcVHbf/OS+JNh8rFJ3b3+zOEicA1LaD2x6hIuNAFgyLoKRI48EUo9TYcWsUlWAIwdaS7SeLqa5RN0F4ViLnfGnjyYwzbWfqYx34RcXOtBJbPyQAAAAAzYsJMKxvT9lRXAI3K+xMKxaXI/09aGCYIc9XC7hhRFqm55Rrt3DLndy/Hsil8tpGen9Lmq0fDqjId3tO02c7dDs+3Fyc6O1rxlKAl5sclXf+iEhxub6phX4/pO0dlyv364ZAsgtGRYl/39gYX/m17eEcQ+codA0Xu1P1hVuOlhkQ5iufoOP4zS3H7SNiQ+1QuHUgXDy8d+4g+f3YIC/RDao2yuFkhRqNSlh/NF9zMQmS+UOVcQm5Nn0sAAAAAPYgWtHZmWFHhVseeswFH8ZdnjzYRUt4Z5m020/LHbcnCw0/UwdOl9tdHAf0zOGccnrwh4Py+08uHEbD2uwEVcYlrNRwXAIXGH/WP34Xpz503nBdQXpCrKFxbYt+Ryx0XXZZrdiNy5IidUXwReNj5M9/vTsLh9MKULh1MLMSw2jhqChxZvnms/uRGvl5upC7i5NmoxJ4ofSHPt+WJ3WeNSCEtIRza6Tjv/pwPrKyAAAAAMzYcZteZD8DXZQDjZTZh1rCncKsqKpBdBBr0akiwwwT7rrNKLafnzHomfKaRrrts73yiZUrJ8TQ5YqCm2R0TADFBXuJy9tOFlFBhTaznvdkllKOfgD7WQNDKEgfRzMhTldsZMi57b4URb5tYoSfXFOSGgDXHsmn4qr6Xn734ExQuHUwfBb85UWj6OgTC+iaSbqBGWp8jNKZ72INdtxyto70R2NS/2BNTdZl/HjP1udiFVbWU3JWqa0fEgAAAID9FG7tqOOWsw4ZZxxO0VizgqkBZbz1V4vSFB23bP9pXZ4pOCbuPr3n632UWaIr4I+I9qdHLhja4WvvhSOjdF/XSvSTYriXlqzcZ4hJ4EY1SbS/u9jiz3anl1JtgzZPzqgh3zZR33HLOxX+NlbXqd3Y3Eo/JBuOPVgGCrcOiJ+cOd9GzaSc24r6Zs2d+f5DGZOgz4vVGmVcwm8HtZ11BAAAAGBrUf7uJKUIpNtJN2RmcQ2lFekKhmNjA8lPo0ONpKKOluMSpO+DMi4BHNcbG07Q+qO6HaABXq705tVjxCyTjlw4SttxCTxQe5X+NauHqxPNGRJhVPs4a0CwuNzQ3EK70jHDpTuO5rXvuGWXjzN0b3/5VxbiWSxM3dU7cFhh+o5bVlCprdZ76Y+ktI1Ai2YnhYlsIPb74Tw8EQMAAAD0AsdQSVvy7SXjdtMxw5p3ukZjEtp23Gq1cMvDyZQOoOPWYW06VkgvrjsmLvPJolevGE3RgboohI4MCPOhYX11RbmD2eV0stAQvaEFW08UUYl+qDnPl/Fps+NVGV3454kiqz8+LTuaWyn/DYvXR2qw/qE+ND4+UFw+UVBFezPR5W9JKNyCKoX5GraT5WsoZ6eoqp72ZemetAaH+1JMUOd/JNWKJ41O7q87M3m6tBYTOAEAAAB6KS7IW55uXlajKzJovUAk4cFk9lG41c7rDkllXaOIN1M6lF1BTc26bFNwHKdLa+juL5NJmk33zzmD5Ai8M7lI2XWrsa3vPym6hKXYB6UpA4LlHQ9bjqNw21UcK3FKf6JxULgvuTgblw8XjY+VL3/9F4aUWRIKt6BKUsYtK6jQTsfthqMF8h/KWUna7LaVzB9m2GKy+jDiEgAAAAB6Q9mtpPW4hPqmZtp2slhc5iE1QyINW2i1JirAQ9Mdt227bVltYzOd0FjXJPQODyFb+kWyODHEzkkKo6UzBnT56y8YGSUXN3/cl6OZHZdcXFyjf63q5+Fisvs/0MuNhkX5y8O22p7oANOO5VfKtY3ECMOQN8m5wyPk7uafD+RQVX0TDqWFoHALqs641VpUwh+KmAT+Y6llc4aEy3+8fz+Ewi0AAABAb8SHKAq3JoptWsJDfmr0Q36429ZJH7Gl+Yzbcm0XbkMVuxYPZCHn1pG8sDFLdFqzuGAveuHyUd36veTGqSn6HZc81CxZv4tU7dYfzadq/XPRgmGR5O5iOsv3rIGGuIRtJ9F12+18WxMn57zcXOhC/SA4/nvw6wHt5SNrBQq3oErhvoYz3/mV2tiy1NDUIk/WDfRypVExuswXrQrz9aBxcbp/w/GCKpFdAwAAAAA9Exesi0pg6RrPuTWKSdBwvi3z93QlT/3gpmwNdtyeLDT8LF0wwrBNfD9ybh3GV7uz6KdDRfJwrreuHit+rrtroQbjEoxiEvRFRFOmKXJuEZfQNSn6fFuWZKLjli1qM6QMLAOFW1D/cDKNRCXsPFUsn+2bOTiMnDXceSCZNxRxCQAAAADmEKeYfZCh8aiEjam6XWa83FUWRLSIp85LcQkclaCVLeKmOm65+03aMXfgNDpuHcHB0+X0yE9H5Pefung4DYny63FUnpuLrkT0y4FcalR5TnJ5TSNtTC2UZ+RM7KfrGDZlTFygGLDFth4v0tzvua07bgd3ULgdEe0vxygkZ5bR8XxDsRfMB4VbUH1UQr5GCrfrUwwxCVrPtzVVuEVcAgAAAEDP8fblznJJtYKLm8fydTuxRsYEUKC3G2mdNKCsrrGFSvUZoVpxqqhKLqJz1jBPe5eKLpxFDPartLqBbv1sj9j5ya6ZGEuXjInu8e35ebjKcX/F1Q209YS6IwV+P5xLDfri8vkjojptnPJwdaYJCUHicl5FHZ1EBnSnuLB9NK9SjmAJ9jHUZ9qe+Fo03tB1+xW6bi0ChVtQJQ65lrYsFWggKoGf2Dhfh7k49eny9E61iwnyomF9dWdsD2aXi7OaAAAAANB9XDiI9Nd1dmZoOCpBigaT8m3tgVHOrYbiEvg1yCl9VAKv27lbkjvgWGNzq9FWZ7AvzS2tdPdX++R4j2ER3vSf85J6fbtaikv4ab8hJkHKWu3MNEXOLXfdQse4eU4adGdqMJnSRaP6kpuzrrT4fXK2fCIBzAeFW1AlPnMTpu+61cJwMs5/zSrR/dHkM3l8ttJeDO+rW/xJQfUAAAAA0LuuW+7q1OoJcWlrMpsx2D52mUkdt1or3PLrJCmqrV+ILkN5ZHSA/PkDyLm1W6+sPy6fRAn2dqOnzusnxxz0xozBoeTn4SIurzmSTzUNTaRGBRV1tO1ksfy8OlJ/wqIzZw0wnGhSezexraUoYhKSTAwmU+JdF/OG6XbqllQ30LoUXUMbmA8Kt6Ba4fqpqJV1Tar9gyFZf1QRk5BoHwtYCZ+9l2SUaLc7BAAAAMDWEvTFNa0OKOPMyz/1BQ8exqs8wa9lWi3cpikGkyWE6CISpI5bti+rzCaPCyzrj6P59Or64+IypwO8csUoCvM1T2SJu4sznTciUlyuaWimtUfUWYTjDF4ppnbhSM52PvN8Ge4cDfHRHacdaSWqz/C1paOKbv0zddy2HVKGuATzQ+EWVEtLA8r+UOTbzk4KJ3sSF2R4gYGOWwAAAIBerKuCtV245eEzlfW6hoppA0PtYhgvk4aTsZxy9ce0SdL0+bYsIdRb7o7j6DaGAWX2J7O4hpZ9uU9+/775iTSlf8dDuXobl/CjSuMSVnYzJoE5OfWhqfphilX1TTix0cXBZIkRZx52xz+D0YG6E2CbjxfKER5gHijcgkYGlKl3AVVW00C7M0rE5X6h3kadFPYgVtFxywsFAAAAAOiZeMWAsgwNrqs2phYYbam2F1H+ho5bLRUcpHxb1l//GoSzlBMjdR1yPICJC1RgH2obmumWz/ZQRZ3uezpvaDjdcnY/s9/PhPggitLncW8+XkTFVepqokovqqb9+m5yHsg3IOzMHaESqXDLtiDn9owdt3wSqH+Yd5eK4pfru265E/rb3ae7/D2BM0PhFlQrTB+VwPJVnHPLOV8t+m0as+0sJoHFKl5goOMWAAAAoOfilVEJRdrruN2kGEzGHbf2IkJfpNJaVMIpxc+Q1HHLRuhzbrmAcvB0uU0eG5h/EN1/fjxEKbkVcqbx85eN7FJEQHdxEe4CfRcrD0H79WAuqcnPPei2NT2gzPB8BgY8XIxP+rD+oT4iPqMrLh0bTdKP49e7s6hFKpJAr6FwC6oV5quMSqjTSL6tfcUkMH9PV/Gm1c4QAAAAADXuZNJaVEJBZR0dztEVjYb19aNQRZOF1nGXaoiPu+YKt2n6wq2nqzOFK147KQc1YUCZffhiVyZ9t/e0/P1++9qx5GvBgdgXKeISVu4zFErVUMBWxiRcMLJ7hdtIf0/qrz/Jsf90OVXUaXNIpCVx0bZJX3SVuve7mhV+tv6EHu9c+PMkBsCZCwq3oImoBJ6Yqkb8h2O7fpqlr7sLjYsPJHuegJxbXivOwAEAAABA93m5uchrXK2dEN98zPAifMYg+9tl1lefc8uvO7QwtIgfo7QbjqPauEuybcctQ86t9iVnltKjPx2W33/20hE0KLzrBbWe4Kzkwfr72JNRSln6nzVbS8mtpBMFVXKkQ1/FYMGuknYLcDfxDv1reeh5vq3SFeMxpMwSULgFTQwnU2vGLQ8vKNJn/oyKDSBXZ/v8lYrRd4fwiTct5X4BAAAAqE28fkBZcXWDprq9lDEJ0+0o31bZLSbFC+RpYEAZF9K48NQ2JoENDPMRXZls/2ldFihoE+fLLv18LzU2677Xf58aTxd2s8u0pxaONtzPyn3qGFK2cr/hcUhxDt11liLndusJdIV2lG/b3Y5baVB7sLebuLzmcD6VVjf06HsExuyzygT2l3Gr0sKtFIrORsUYzmzbmzjlgDKVnG0FAAAA0HLhlmUUaWNdxQXCLfo8SF8PFxpth+teqXCrlbiENMVgMs47VXJxdhJxFux0aa3qhktB13/v7voymXL1JxLGxQXSg+cmWe3wKQvEP+7LEbtNbYkzU3/Wxzbw0Kzzhkf26HYm9Q8WX8+2YkBZOyl5hsJtUjc7bt1cnOiSMbqYjYbmFvohWR0Ff4cr3JaXl9Py5ctpyZIlNHv2bJo8eTJdeOGF9Mgjj9C2bdss8yjBIfm4u5CXm+5HtKCiXvWF25GKLUn2nMeWqbE8NgAAAAA1iQvRXs4td22W1TTKw324MGjXhdvyWk0NJuvXpuO2XVxCNgaUadELa1LpzxO6rfycKf3m1WOsusMzOtBLxBEwjieQMq5tZU9mqdjxys4aGEJB+s7OntQZRscGyDnR2FFq7Kh+AF6Al6tRfGVXLWoTl2Drgr896PJvfW5uLt10000UGRlJjz/+OFVXV9OoUaNE8TY6Opo2bNhAc+bMoSFDhtBXX31l2UcNDiPE21XVHbf7FIXbETGGIQD2JlafccvQcQsAAADQcwmKjtt0RfFNzTalKmISBtlfTIIy45bllKnztYepwWQsIcSn3edHKAeUZaFwqzVrDufRmxtPisvOTn3ojavGGEUJWsuFo9QTl6C8/4U9jEmQTFXGJeh3E4AumkOaL5QY4Ut9+hiys7tqQJgvjdEXxlPzK8UQOOgdl65eceTIkbR48WLatWsXDRs2zOR1amtr6ccff6QXX3yRsrKy6N577+3lwwNHx4XbzNJ6qm5opqr6JnF2TE1bVw7qz15zKHqYYpKrvYlTbunT2CANAAAAALWuq9I1sq5S5tuebaeFW542L9FCB15aoW5AkzScrC3lbsADyLnVFO6m/ufX++X3H1iQSBMSdJ2v1sZxBDwYramllX7an0P3L0gShWRbDONbdTBPXPZwdaI5QyJ6dXu8c+DldcfF5S3Hi2jR+FizPE6tS1XEJHR3MJnSFeNjaW9mmdx1a8+xkqrquD18+DA9//zzHRZtmaenJ1155ZW0c+dOuu6668z1GMGBhSi2PxSorOv2eEEl1TQ0i8sj7bjblkX4eZCrs+4PNDpuAQAAAHouXhGVkKGBqISS6gZ5wBV3YCkLnPZEaxm3UlRCiI8b+XvqdikqxQV7yR/njjdsV9aGmoYmuvXTPVRZ3yTeP29EJC05K8FmjyfQ241m6IcR5lfU0840XXSDtfEQMX4ukgZg9bahi09s+OpvY9vJYpGfC23ybbs5mEyJf2693XQDEn/enyN+rsEKhdvQ0O6dWe3u9QFM/hz5GBYh/IdCTRxlMBnjs6oxgV5y4RYLPwD7xYvXHw8WUkNTi60fCgCAXfJyc5GH8Goh45aHkkkRhfYak8B4EjoP1tFC4bayrlHezmyq25bxFmcpLqGoql4ecAXqxa+xHvj+oNhezgaE+dD//jaiR9vVzWnhKN2wKfajjeISftIPJROPRzE0rac4p5uHlDEuCB/R57o6Oinftrcdt97uLnSB/vvEO6d/PZBrlsfnqLqVbL106VKqqjJsyfj000+N3i8rK6Nzzz3XvI8QHJqUccsKKtW12NinyIqy58Fkkhj9gDLuMi6q0p3tBAD7wlmL13/0Fz2zPpM+2Z5h64cDAGC34vVxCbym4iKcVmIS7Llw6+TUh6L8ddFnuSrPuE0vMkRsdFS4bZdzi7gE1eO110p9gZK7Fd++ZqwogNnaOUnhcvfkbwfzqK5Rt+vUWmobmkXmL/PzcKHp+g7g3uK4BGVHLxAd1Xfc8rmCQeE977hll7cZUgZWKty+8847VFNj+CNx++23U0FBgfx+fX09rV69uhcPB6Djwq3aBpRJHbcc8TOsr31HJUjbrSSISwCwTxtSC0SGGVuXkm/rhwMA4CBxCerNueXtw5v1hVsvN2cap58wb6+kuATepl6h4oJ6WpGheapfaPvBZJIRiuYSDAhStz0ZJfTEL0fk95+/bKTouFUDTzdnmjcsQv7d2HDUUAOyhvVH88XMG7ZgWCS5u+iKyL11ltGAMhRum5pb6Ji+25uHaPL3vTdGxwTQQP3P8O6MUjpRYHjeAgsWbttuj8Z2abBu4VY9UQl81k/awsJnotRwJtTSYvUdtyyzRP3b+gCg+3Yocsv2ZZVZvaMCAMAxB5Spd13F24elnVZT+ofIUQL2Sis5t2mF1V3quMWAMu0UzHgYmXTy/Oaz+9GC4ZGkJhfZMC7BKCZhVO9jEpS/OzxknO1KL3H4dS8Py6zXR6Ul9iLfVsIRH4sUXbff7EbXbU/Z919e0LwQRcatlOOkBodyyqlZ/4fVEWIS2hVui9W7kAWAnndV7TxVIr/f0NxKezNKcTgBACwYlaD2jlujmAQzbU9WM60UbqXBZKxfJ4XbCH8POU/5wOlyDGBSqR/35YiiGRsTG0D3zRtMajOlfzCF+Oh+ljYcLaTyGut0pPP9bEzVPQ/xz/LEfrpcWnPgwuLUAbrb49kOf6Ub1sGO6GieefJtlS4ZEy0POf9u72lqbMYMjZ5A4RZUTa1RCcrBZCPtfDCZJFYRlZCBjlsAu5OSV0FlbRbh2200ORgAwJGiEpRFOLXZmGrYEj3DjvNtJVLGLctWcc6t9DPDkW3KNXpncQmVdU2q7u525G7b1/84Lr9//4IkMThLbfgxXTBS1wXc0NxCvx2yzrCp3w/nivtj54+IEkOzzemsgYbnNUePSziaq9tRzBIjet9xy4K83WjuEF3MBu/eWJ9i3ZgNe9Ht/d3//e9/yctL98ehoaGB/u///o/8/XX5nsr8WwBz8HR1Jl8PF7HQKFBR4Za3EEtGxThex21WCX7XAezN9pPFnUYnAACAZaISMlRaTCuvbaS9mbo1b79Qb3lQrT3TQsctxxWmFeqyIqMDvc6Y9zky2l/Oreeu284yccH6fj5g6Lad3C+YJiSoN0ea4xI++jNdjku4YkKsxe/zp/2GmIQLzRiTIJna39DB6+gDypQdt0mR5um4lYaU/XpQV+j/6q9Mmq/PSwYLFW7PPvtsSk1Nld+fMmUKpaWltbsOgDmF+7qLwi1n3PJChbc02Np+/VRWD1cnGhTuGIsfLzcXsT2mqKpe1Vv6AKBndqQZtod5uTpRTWOLOEnFmd69HU4AAADGfNwN6yqpaKM2204UydFgMwaFkSPQQuG2sLJeHtTUWb6tZISiyYRfw1w02pBVCrbFv1+v/XFCfv+u2QNJzUZE+4ufOe745nit3PJaivQ3/M6YGzdubdM3FvCgbD4JYW7BPu40NMqPDudUiLfiqnrxMUeUou+45b9PUvavuYbA8W6GnPI6Eb+TV14nYlzAQoXbjRs3dufqAGYR6utBJwqrqbaxWUyx9PMwxCfYAj+ZZ5XoFnLD+/qrciuLpfAfTH6BwXnDKOYA2NcLh52ndAvjIC9XOqufP/10qIgam1tpT0YpnTXQMHUXAADMIyFEt67iQlxVfZN4sawmUq6ko+TbsqgAQzEhV6VRCWnKfNvQLhRu+xqKXdxxC+rxy4EcedAcd9pOVnR/qhE3UPFwsJfXHSeeW89Dw26Z3t9i9/fLgVxxP2zhyCiLNXDxOpeLtuzPk8V04Ujzd/aqXUVdI2XrT1YNjvAlJzNGUnC8xWXjYuiV9ceJzwV+uyeL7pil7pMUamOWilNTUxNVVem2awCYW7if4YxXQYXtB5QpFzyOMpjMZFxCqTq7QwCg+47kVIidDYyHPoyLNuRabU9z7G1jAACOGJfAu9ykwWTuLk40UcXbt829wyzQS9ckIhUx1EYq9J1pMJkk0NtNXsMfzikXmaqgvm7bZSrvtlXGJSiHqlnSSgvHJEimDVDm3BpOWDmS1Dzz59sqXTYumqS6+1e7szAo0ZKF21WrVtGnn35q9DHOuPXx8aGAgACaO3culZZiAjWYV5hR4db2Z76THXAwmanCbaZKt/UBQPcpi7OT+gXRmBhfkxEKAABgPvHKwa8qW1cdy6+iPP26m7sAPVwdJzJHikvgf78UFaEmp4oMDVNdzavlLe6srrFFfG/B9lYdzKUTBbrvxbi4QNV320riQ7zl18ApuRV0LN9Q8DOn9KJqeSD4kEg/GhBm/mKiZFx8oDhBJQ0o4xNXjuZoriHfNtGM+bYSzuPmyATGu5cxR8OChdvnn3+eKioM39Bt27aJYWUPP/wwff3115SVlUVPPPFENx8CQOfCfQ1blvIrbV+4lf6AONJgMmVUgiQDA8oA7IayODspIYhCvF3lLh5+zquu13XjAgCAeQsgEs6MVJONqYbJ39MHOUZMQtvCLRdtC1Tw2qMt5c9KVzJu2+4SPKCf1QG20yK6bY/L7999zkBVzHHpqosU3a8r92Vb5D5+tlK3LeMTU+PjdbsKOIdVGUfiKFIUHbdJFui4ZYvGx8iXv/wryyL3Ya+6Vbg9dOiQGEgm+fbbb2nOnDn00EMP0SWXXEIvvPAC/fzzz5Z4nODAlFEJPKDMlvjsmzSYLNjbjaIDLRfGrv6OW8f7gwZgj3jL5K5TusItD8oZEOYjd96Kz7focm4BAMC84lUclSDFJDhk4VYxNEeNA8qkqAQekhzh59Gtjlu2Hzm3Nvf74Ty583lMbIDciagV54+IErmlbOW+HLN3qPLtKWMSLrBC5qxyngN33Tpyx+0gCxVu5wwJl6No+HegvKbRIvdDjl64rayspOBgQwv/1q1badasWfL7Q4cOpZwcy+acgOMJ9VUWbm171juzpIbK9E8wvEVES2dGzSFW0XHLxwIAtO9QToUYiiMVa6XntUn9DH/vt6fpBpcBAIBldjKlqygqgXdZ/JVeIp+072pXp7113LJslQ0oa2xukdfgCSE+XR4gNKyvP0lXVe4eBNt027663tBte9dsbXXbSq/Pp+qLzadLa81+gj8lt1KOkZgQH0R9Fb+TlqIsnm89UeRwP5NSxi03pllqGLy7izNdPDpaXG5oaqEfLdStTY5euI2KiqKUlBRxmYeR7d+/n6ZOnSp/vri4mLy8DAsQAHMIV5xJtvVwsn3KfFsHG0zGQn3cyVOfcYaoBAD7sP2koSirzFdTDqJBDhUAgPn5erhSiI+bnOeoFttOFlNjc6vcbau1opI5C7dq67jlIhnvhOnqYDKJt7uLvKMmNb+S6hqbLfYYoXNrjuTRUX2RjBuBtNrRroxLMHcBbuV+w+1dYOGYBAnn6PKOWrbjZLFDDfHj55XqBt1zQmKE+fNtO4tLcMQ8YYsXbi+99FJatmyZGFB20003UUREBE2aNEn+/O7du2nw4ME9eiAAHQlTdNzaOmfKqHAbY9hy5Ch44S7FJZwuqcU0SAA7oOymVXbZcjeF9CLvwOlyuSsXAADMJ04fl1BQWU81Dep4nt10zHHzbdsWbnNVVrhNKzQMFutuJ/QIfdMJZ/cezjFsiwbr4SLVK+tPyO8v02C3rWTu0AgR18F+PZArusHN1f358z7dLm4Xpz503vBIsgbuXp+i77qtrG+S4xEdQUqe4fkgKdJyQ+DY4Ahfo+F2h7LxXGT2wu0jjzxC48aNo7vuuov27dtHn332GTk7GyaMrlixgi644ILu3CRAl8LC/T1dVZFxu9/BO25ZjL5w29DcIk8bBgBt4kX2bv12WD5J1rZ7Z7K+kMsv8qTrAQCAhQa/qiAugQtLG1N1+bZuzk6amXRvTn1VHJWgHEzWL7R7hduRipxbDCizjbVH8kWxSsodnjFYuydGfNxd6JykcHG5tKaRNitysXtjT2apGBAm5c4G6btgrWGaIi5hiwPl3B7NNQwms3THLbtC0XX71e5Mi9+fPehW4ZZjELjbtrS0VEQmTJs2zejzGzZsoH//+9/mfowA8oAyzri1VTs9Fzg4C5LFB3tRoBX/iKj1BQZybgG0jTtpa/Rbo/jFeduuD+TcAgBYVoJiQJka4hJ4mjpvm2XjEwLFFntHwztOuNNPjVEJymn3Pe24lf7+gy26bRXZtrO0220ruWhUX/nyj/ou2d5aqYhdWGilmATJVAcdUHZU0XGbaOGOW3b+iEg5fnFlcg7V6l+LgJkKt5bw5ptvUkJCAnl4eNDYsWNpy5YtHV43NzeXrrrqKhHH4OTkJGIb2lq+fLl4Amz7VlenrrOl0D1hvrqc2/qmFqqotc02Mg7s5hBtJrX3OyIpKoFlqqAzBAB6TpldK3XXKk3sp8y5RcctAIC5xSmKb2oYULZJ323rqDEJzNmpD0X461575JSrNyqhX4guzqiruCDj6qwrFDrSNnC1+ONogRxRMayvH81OCiOtO3tQKAV46XbGrj2S1+tYLW6UWnUwT1zmGIY5QyLI2t320u6z5KwyqqzTDSW3d1LmsruLE8UrTiZaMt+di7dSLMVvh3Itfp8OVbidNWtWl9666quvvhLF14ceeoiSk5NFB++CBQsoM9N0u3R9fT2FhoaK648cObLD2/Xz8xNFXuUbF4ZBu8L0Hbcs30Y5t44+mEwSi45bALscTKbsrpWE+LjToHDdC8ND2eUOs4AF+7dr1y5qbjZ0eLTdzcNrzq+//tpizQjff/89zZkzR6xred06efJkWr16tdF10IzgeB23GcW277jdpNjuPGOw9gtLvc25LatppGoVZbxLUQk8RMlfXzDrzkT3pEjdNui0wmqqwN90q7HHblvm5uIkZ9DWNbbQmsO6omtPbT1RRCXVDeLy7KRwEcdgbRzPIMWE7XSApgXOVk/X/+3h/Fk+cWUNbYeUgRkLtxs3bqRTp07RkCFDROG0o7euevHFF2nJkiV04403UlJSEr388ssUExNDb731lsnrx8fH0yuvvEKLFy8mf/+OB0PxkyAPTlO+gbaF+xkK7wU2yrk1yrdFx62QUWL7zhAA6BneQbA7Q7cgjfT3MIpB6TjnthSHG+wCF0qLiw0nLnhdmZaWJr9fVlZGV155pcWaETZv3iwKt6tWraI9e/bQzJkzxZwI/lolNCM41glxZX6pLdQ1Nss7MfjvwkD9gEpHFKXvuGW5Kum65QKyNO+juzEJEs5VlRxCXILVcG60FE/BxfM5Q3TZsPbgotHmi0v4SfH1C0daNyZBcpYi55YLyfbuWH4VSeeuEyMsH5MgGRsXKOd07zpVYvO/f2rXrVMYzzzzjDj7/80339DVV19NN9xwAw0bNqxHd9zQ0CAWqvfff7/Rx+fOnUvbtm2j3qiqqqK4uDjRSTFq1Ch64oknaPTo0R1en7sq+E1SUaHbwtDS0iLeLI3vg8/CWeO+tER5XMJ8DHmyeeW1NjlWUsctZ14lRfjY9Ptly5+ZKH934hPE/ASfWVytqp9b/C7huODnpeuSM0tEdwSb1C9IPKdIzyvK55cJCUH08fYMcXnbySKaPsiwoHUkeH5Rz3Exx3217bA1lZ/fnUx9ZTMC42YE7qDlZoSnn3663fX580pPPfUUrVy5kn7++WejNavUjAD2iwfw8vAd7jKz9XAyLtpyLJkUk2APHYG97biVBpQNCLNeQaMjysJGTwu3vGvwM9KdUNp/upymKIpUYJ1u27tnD7Cr362xsYEiYiC7rJa2Hi+kwsp6kRPdXZxzKnXs+nm40HQbDW6b1D9YdJ1yw8KW4+YZuKZmR/XD8qw1mEzCvwM8pOypVUfF+1/vzqJ/z0+02v3bdeH2vvvuE2/bt2+nDz/8kKZOnSryZrmAy9mz3BXQVUVFRaKwGh5ufLaJ38/L63mLfWJioiguDx8+XBRguUOXH+f+/ftp4MCBJr+GF9SPPfZYu48XFhZaJRuXX4CUl5eLJ3XO7oX2x8W91VBYT8stpoKC7m0N6q3q+mY6UaDLlOof4kkVpcVkeIqzPlv/zIT5uFJ+ZSOlF1VRQUEBqYWtj4ta4bjguJiy/qAhT2poiKv8u9z256W/r6FItvVYPhWMNeTeOhL8HqnnuFRWGqYfW1JXX1iboxmBjyP/u4KCgnrVjADaxENvuXCbV1EniheebrqhLbaNSXDMfFtThdtclQwoUw4m6xfas25o5a7BA8i5tYrNx4vkBiDuaJxr5dxWS3Ny6iOGiL258SS1tBL9ciCH/j41odu3s/5oPlXrh1QtGBYpoj1swc/DlUbFBNCejFI6WVgtOu4j/Q3PB/aab2utwWRKl4yJpv/9nkpNLa307Z7T9M85g8jFGa/hTXHp6fYyfuOiKHffvvHGG3TvvfdSTk5Ot4q3phbFvPDvzRmoSZMmiTcJF23HjBlDr732Gr366qsmv+aBBx6ge+65R36fC74c2SDljlkaL9b538z3h2KT6eMyqIHP2um2MFa3uFBYWJjVcyClvptxCSFWv3+1/cwkhPhSfmUJldc1k4dfoPgDpwa2Pi5qheNi3uPCsSm8nXSiiUxYLTmYf0q+PHdUPIUFepk8LvxsNzgiTQxoTC2oUdXvvDXh90g9x0VtcwvM0YzwwgsvUHV1NV1++eW9akbALjJtdqZzVM3eTF1h51RRlVW3q7bdzs2424x3Yli6k17NOxki/Q0dg9mlNVbfVWDquJwsMBRY4oM9e/SYEoK9yMvNmWoamsWAMjUeey3+vHTabbvumPz+HTP780ephSucdnRsLhwZKQq37MfkbLpuclyvYhIuGBlpln9LT4/L1P7BonDLNh8rpMvGRpM9UR6XFEXH7aAw6+4qDvJyFUP6Vh/OF53afxzNp3OSbBcj0mLl36Pu3E+v0p737t1LmzZtopSUFBGZ4Ora9RdyISEh5Ozs3G5Byx0/bRe+vcEvIsaPH0/Hjxu2J7Tl7u4u3kx9rbVehPCLHmven1ZIxyXcz3CWq6Cy3urH6UC24QmNz8Cp4ftky5+ZuGBv2nFKl415urSOhvXt/nYYS8HvEo6LJX9edqYV01Xv7xTbpz64bpwYnKBFXHiWigS8vS022KfT48I5t1y45dcZezLKNPvv7i08v6jjuJjrfo4cOSKvQ3mhfvToUdHhKhVju6unzQgrVqygRx99VEQlKE8M96QZAbvItNmZHuJuKOIcSMuhIKdAKz9CoszSOnkr/vBIb6qrKKW6CsfdyeDRbOiyPZlXZtUdZh0dl5TThkFJ/k71PX5Mg0M9KTm7inLK6uhoerYonmiBmn9eOrIrs0Jeb/UL9qAxYU4W+Vmy9bEJ6EM0MMSTjhfVigiO3amZFBvY9ZOsFXVNtCFVd1xCvF0pwbvJLMepp8dlSLCh23f9odM0PcYQ22gPpOOiK9yWy8e9qbqMCqwcNTtvgK8o3LJP/jxJI4JtFyPSYuXfo+7sIOt24Za7avnsP7/x2f9rrrmGdu7cKQaWdYebm5uYuLt27Vq6+OKL5Y/z+wsXLiRz4YO+b98+0a0A2hXm525UuLXlYDIu3Do65SCNzJIaGta342GBAPbk9Q0nRNFWmoCq1QImb9mTcgwn9z9z5/CkfsG0fFu6vANBq/9uAKXZs2cb5dief/754v9cbO3ODrDeNCPwUDPOxuUdbOecc06vmxGwi0ybnelD45qIdujia0qbXK2+s6u+qZme+X6X/P6cYVFWeQxq3sng6dfIp3fE5dL6Vqt+Tzo6LrlVJ8T/+alp9MDoHm8lH5tQIgq3LKfOlRLjbbuT0B5+XkzhvyOf/GAYerlsTiJFmLFBTW3H5m/jquiZ31PF5T9P19O4wbFd/toNu7OosVn39/iCUX0pMiLcpsdlZnAI+fx0gqrqm2nP6WoKCeGvt59cYum4NLv7UkWdLp5iSJS/TXYVXxASSv/bkEV5FfW0Pb2CyMOPwhSD6a2pxcq/R93ZQdatwu25555LGzZsEJldzz33HJ133nnk4tLzpl2OJ7j22mtp3LhxInrh3XffFdN3b731VnnxmZ2dTZ988on8NVyEZdwRwRm0/D4XgaXCMWfVcncCbyHjwjJ3JPB1OM4BtIsXJoFerlRa00j5FZbPHW6LtxIxH3eXHmdK2ZPYIOPCLYAjOJRdTluOG7rweOtUTUMTebn1avOKTXDxVcLdtGfCW2aloYQ7Thm+FkCrTp0yRIX0Vk+bEbjTludE8P95TW2OZgTsItNmZ3pCiI/RusrahZfHfzksdwVG+XvQVRPiHH7Xob+XO/l6uFBlXRPllNdZ/XvS9ueFf/+ljujoQE/ydOt5l6wy5/ZgdgWdo6HMVS3tfNl2ooh267fb9w/1pvNGRFm0+GfrY7NwdF96dnWqWCv+tD+Xlp0zqMsnQH85YJi7sHBUX7P+G3pyXNydnETTwrqUAiqubqBjBdU0JMp6g7usgY/LsXxDe21SpJ9Nfnb4Li8bF0Ov/aFrjvl+Xw4tnTGAbKWPFX+PunMf3Xq1+fvvv1NkZKQornKB1NRALylCoSsWLVpExcXF9Pjjj1Nubq6IW1i1apUYwsD4Y3xfSsqBDDwI4osvvhDXT0/XdQKVlZXRzTffLLoe/P39xfU3b95MEyZM6M4/FVQo3M9DFG4LKup7nYXcHVwozi3XFYuH9/UXuV+OTlm4tfUEZABreXezoWuCccfqptRCWjA8UnPfhO1pxUbTc88kwMtNTJrlHKzDORVUXtNI/hrZWglgirTW7AwXSbtyvZ40I3CxdvHixSK3lhsOpG5dT09PsX5laEZwHPHB3vLl9CLrrqs+35lBK3bpXm+5uzjRO9eOo0Bv+9oW3FNR/p6UWldJuWV1IpPUlh13hVX1VFXf1K7Q3xMjozGgzBpeWW/YHXHX7IF2/xqSB3hNTAiiHWkl4iTDgdPlRicJOlJQUUfb9A0FnPc9MlodOznPGhAiCrds64lCuyvcsqN5FTYbTKZ02Vhd4ZZ9/VcW3Ta9v9VqPVrRrcLtI488YvYHsHTpUvFmCscxtKXc0mbKSy+9JN7A/nDLPE89bGhuobKaRqstKqUpoKwrf3wcAf9RlWSh4xYcAP+c/3pQ1w3AC28pLuH3w3maK9xyvu0+fWcVn4ThjNuu4M5cLtzyn+Fd6SU0ZwjiEsD+cLbZ559/Tu+//74YAsZDxyzRjPDOO+9QU1MT3X777eJNct1118nrXzQjOA4+ESbtLEsvtl7A4O70Enr0p8Py+8/8bTgNV0nRRA2iAjwoNV/32qOoup7CfG03GPFUoeHnol+IodDfEzFBnvLPGxfXrNkQ4yh2pBXTTv08EP5+nT8iihzBRaP6isIt+3FfdpdeO3O3rVTiWTgySjU/i2cNDJUv8467m8/mwXL2hWsrEm7QsGUM49QBwfTniWJKL64Rvzvc8QwqKtwCdFWYryHnNr+yzmqFW+Tbtufv6SpvH8sosXKCOYANfLD1lFysXTqjP328LV0MUvgjpUBkA/Y0Z84W9maUihehXY1JUMYlfPjnKTlqAYVbsCd//PEHffjhh/T999+LYuvf/vY3+uCDDyzWjLBx48Yz3h6aERwLD34trSkTu7z4BJuHq2X/ruSV19Gtn+2VcyWXnJVAF4+2r8npvRWlOLHJg7xsWbhN08cksH6hvSvccmFseHSAiHzibeDZZbUUHWhoyoDee2Wdodv2jlkD7L7bVsLNDP9deVisM3/en0sPnZtELs6dbwdfuT9HvnzhKPUUuDneItLfQzwn7zpVYpXnZVsVbl2c+lB/G8dBXj4uRhRu2Vd/ZaFw24b6w2EA9MIVA8ryK+qtnm/LMJjMsOCTum55IduoLwIB2KPS6gaxgGCers50w9QEOkc/nKuyvkne3qXFmISuDCaTTEwIFjm3UicJgNadPn2annzySerXrx9deeWVFBgYSI2NjfTdd9+JjyvjuQAsLb7N4FdL4gLELZ/toaIq3Xp6Sv9gemBBokXvU+uF29yyWps+FinfliX0suOWKbejc9ctmA8X+aS1Fv9eXzhSPcVIazT3zEzUdary88uZ1sjpRdVyk9SQSD8aEGa77fqmXu9yXIIUj7ZHn1dsLxqaWihN38k/IMyH3FxsWxqcNzRC/PywVQdzqbyWB0SCpMvfnfnz59O2bdvOeL3Kykp69tlnMQwMLJJxq8zCsQbOszqQVS4XjiP8bXemXa05t9yFmGPjxSyAJX26I4NqG3XbpReNjxHd/nOHGgZ5rD5kPEleS4PJurMNibfy8qKapeRVUFlNg0UeH4A18MBdHmx75MgReu211ygnJ0f8H8BW4hXFOGWRztx4W/x/fjwkF0t40NXrV405Y1ecI1JGCXFXqi1JBRZmjkHJIxQ5t8omFei9VxXZtnfMGuhwv1sclyBZuc/QTWvKzyrttpWcNVBXuGXKAcX2IKO0jpr0uwkTI2xfMOdu5otH95UL5T8pfjagG4Xbyy67jC6//HJKSkqif//73/TNN9/Qn3/+KQaErVu3jl599VXxeR5elpycTBdeeCGOL5iVcntSQWW91bYlcUdd2yB/4MKtt9U6QwBshbuSlm/TDb/kbW68lZRNHxRKHq66P6Frj+TLMQpqV9PQJL9A446d7p6MkqIVOItMym4D0KI1a9bQjTfeKAaAnXfeeeTsbF/bH0HbA8oyLJhz+8n2DPp2z2lxmf+OvXvtOArCMLIuRSXYUlpRlfw9i1Q0s5il41bfpAK9tyejhLaeKJKbXC5SYTHS0mYmhpGvuy6Rc/XhPLGW7ugkkjIm4QIVdiZP1XfcSgPK7MmJIsPJqER9Y4atcVyC5Ku/DHMBoBuF2yVLllBaWho9/PDDdPToUbrlllto2rRpNH78eJo3bx699957FBsbKwq5X375JcXEGA46gPmjEqyzeMJgsjN33LKMYhRuwT59s+c0lVTrOkvPGx5JMfqfe083Z5oxKExc5nw4HvCiBbzNS8oz7Enov/JrlJ27AFqzZcsWsUts3LhxNHHiRHr99depsNC+XpSBdge/8nAWS+CYmyd+OSK//79LR9rlpHRzDieT2HJ3WVNzC2Xqfya4wO9khrxUHvocoS8AH8ouF7sMofdeWX9CvnzHzAEO120rdU7OH6bbmVZV30TrUvJNXi8lt5JOFOhOSEyID+rysFxrCvFxpyR9UfNwToX8msDuCrcq6Lhl/PdoeF/dSaVD2RXiuQl0uvVM4ubmRldddRWtXLmSSkpKqLS0VGwtq6uro4MHD9Lzzz9PgwcP7s5NAvQoKsFahVvlYLLRXZiK6agvMLLQcQt2iLto39+SJr9/89n9jD4vLUrZ74e1EZegLLZ2J99WMj4hiKTXi8i5BS2bPHmyaDrIzc0VzQjcdNC3b19qaWmhtWvXiqIugDUpc0s599HceKv/7Z/vlbfG3jK9n0Nlb/b0tYeU7Z5TbrvC7enSWvn71tvBZEoj9F23vLtQOfwMeiY5s1QMfJMiSC4eY4gMcDQX6be8sx+TTW95X7k/W758gYo7k6fp4xJ4t9m2k/YTl3Ci0PCcJhWn1YBj6SRf79bNGIFeDifz9/eniIgIcnXVhQgDWPqMl7WHk0lbinnRNkyxpQjQcQv2j7d3Sd3kPJxgmP4MsHIrmKuz7hXdmsP5YsuXlgaTTeoX1O2v56EBQ6P85Um09tR5AI7Jy8uLbrjhBtq6datoQvjnP/9JzzzzDIWFhSH2C6wqwMtNHsxi7p1MYhjZp7vFDhGpEHHfPAwjOxNXZycK10e12bLjVopJMNdgMslIRVPKAeTc9torimzb22cOED8/jop3aIX56l67bzpW0G4uAnd4/6zPv3Vx6iN2tamVNKCMbbWjnNsTRbq/M4FervL3Sg0461iKo/sxObvDqA1H47jPJqA5POkwWJ/BVWiFjFt+kkjJrRCX+4f6kJ8HTlAoRfp7iD+0DBm3YG+4CPvOppPy+9yZ1Ba/wJ7cP0TuZOItPWpWXd8kT47uH+ptlBveHcpO3V2nEJcA9oN3jf3vf/+j06dPiw5cnigNYE08gV7q7jTXi1X+e/bA9wflv1G8Y+q1K0eL3HboelxCUVWDzQoIRoPJQno/mKxtxy2T1gfQ812aG1N13ba85f9vY6Id+lDy84vU0c8RXb8ezDX6/J7MUsopr5MHgKk5Z3tCQpCoQ0gDyrTQqHEmRVX1VFyjm+OTGOGnqvUO11zO1RfyK+qaRCMNEOlSowE0gvOYuFugoLJOnKkzR8ZTR7hoK2VBYjBZe5zZxNuAOIeNC7f8R0xNT/pdxWeA39uSJvJ05g9T79lesK4daSW0X/8iZkikn9HZdqX5QyPkbXG/H86l4SruzP8rvUQeotaTmARlp+67m9Pk6AX83oAWcZftmQQH9/z3BKAn4kO8xd8ergtwDNXA8N7nDn6w9RT9kKzbkuzl5iyGkXF3L3R9QNneTN0OvLzyOvE9srZTihiDBHNGJfQNaLfLEHrmVUW37dKZ/eVCnyPjuIT3t54Sl1cm59DVE+Pkz63cZ4hJWKjimAQps3d8fCD9eaJYNGrwa19zdr7bQmqeIQ4qMVId+bZKi8bF0Pd7dT8jX+7KooWjHDd2RIJnFNDkgDIuqJa22XJhyXzbUTHqLcbYkjSoiYPntbpl+q2NJ+mNDSfp9i+S6XQphqyBzjubjbttOzopMWdIuJx/9/uhPM3EJEzuZ7oQ3RXj45U5t9oYygbQ1vLly2nDhg1UVlYmZjaYeuPPAVhTXLAi59YMcQl/niiip1alyO+/cNlIGqySITRaoRyYZKu4BOOOW/MVjPy9XOUubx681NDUYrbbdiQHT5fT+qMF4nKUvwddOtaxu20lQ6P8xA4vtiu9RH6d1djcQqsO6tbMvCV+zhDDzAi1mmoUl6D9QaYcdyZJilBPvq2yy1kqjvPrlxT9LmhHhsItaIqUM2WNnNt9isKtMgMKTA8o02pcwu6MUvF/7kTcna67DI7taF6F0Xa3znK3Qn3daXycLiv2ZGE1nShQ70CjHYrBZBN7kG8r8fVwlSe+puZXUnGVdTLHAczp1ltvpfLyckpLS6OZM2fSBx98QD/88IPR2/fff4+DDlaVEGJYV2UU925YFHfs3vHFXtJvtBAT7heoOEdSzR23Eu62swWp45a3k5u7W3pEtO41Dhdtj+Wrdw2jZq/+Yei2vW1Gf3J3cbbp41ELbnq4SNEp+dN+Xabt1hNFcsPP7KRw8nFX/ybwaQNC5cv8+O2pcKvGjlv+2blCMaRs2Zf7HD7rtkeF26ysLJH/Jdm1axctW7aM3n33XfN8pwA6EKbvuGX5lbpcHEuRtknzVhfOfoH2YvUdt1ot3HLchnKriLJYD45LigFgN05LELEgnZk3zNApoNau24q6RjqYrXtOGxTuYzTssScmKaIWdp5C1y1oz5tvvkm5ubn073//m37++WeKiYmhyy+/nFavXm0X+XWg/Y5b5fb47qppaKKbP91DpTWN4v1ZiWH0jzmDzPIYHblwm1Nm2dceHeXT51Xo7tcS27OVObeIS+i+wznltPZIvrgc4edBlyuKTcAxCIbCLcclsJ/0Q8nYQn0Orha6h3mIF9t2spiamrXdnS69/uUddAPD1Fe4ZddNiadE/Q6R1PxKeua3o+TIelS4veqqq8T2MpaXl0dz5swRxdsHH3yQHn/8cXM/RgCjjFtJgX4RY6ncU2nBzE/UyCkyLTbIsIDMNPMEZGs4XVorYh4kKNwCb4OUFpQBXq60qAsL8LlDwuXLqw/rFu9qszu9RO66mtwv2CzTgiWccwugRe7u7nTllVfS2rVr6ciRIzR06FBaunQpxcXFUVWVYYo7gLXEKwq3GT1cV/GJh/u+PSBvLeWt9S8tGoVhZL0cTmarqASjfFsLFG6VuwoPZGFAWW+ybdFt215ssBeNiQ2Qi2/JmaW0Rj9sys/DhaYPNnSyqhnP1Zmij0uorGuiA/pmCC3iovOxgir5b46nm7Nqs4VfuWK0XIdZvi2dNqTqIkkcUY8Kt4cOHaIJEyaIy19//TUNGzaMtm3bRl988YXIDAOwlHBfQ5dYgQWjEpSTVTGYrGsdtxka7LhNyTPOyzmCfC+H9+HWU9Skr3AunhRHXm4uXcp6HtZX15XPXa1qzEpWFld7M5hMmXMrTSTfocjOBdAq3pbHb1z0amnRdicNaBd3dHExg6X3MCrhnc1p9MsB3QR33oL87uKx5O+p6xSD7ovyV3Tcltu2cNvPjIPJJNygIuXWo+O2e/jkiHTCPszXvUsn+x11SJnkX98eoOqGZnF5wbBITcVKTDPKudVuXAL/bZHyrKWOVrXiTPaHzk2S3//XN/upsNIxI9p6VLhtbGwUXQps3bp1dOGFF4rLiYmJYtsZgKWEKzpuLRmVYDyYDPm2nZ1F1XJUwtFc4yyvhuYWkW8Kjqm8tpFW7MoUl91dnGjxlPguf+38oRGq7rqVBpPxILWJCb0v3HIxQMq5PV5QRUXIuQUNqq+vpxUrVoidY4MHD6aDBw/S66+/TpmZmeTj42PrhwcOiE8exOu7Krm7s75JV+Doqk3HCunZ3w3bSbnTdoBKt8FqBe++8XR1tlnGrVHh1gIdt3yCelC4r/z3vFZfVFOjXw/k0r9/PkmrDuaqItLmNUW27a3T+4sOQWiPZ0VIJ/tP6Ds92cJR2ohJkJw10D4KtymK179qL9yyxZPjaKa+M7uoqoHu+3a/Kn7/NVG45a1kb7/9Nm3ZskVsL5s/f774eE5ODgUH9/4FIUCXCrcW7LhVnnHGYLLOizfB3m6ajUowVaRFXILj+nxnhtwFcNm46G7lwM5X5NyuVlnObXlNo5gWzTivO1D/O2vOuAR03YLWcCRCZGQkPfvss3T++eeL2Q3ffPMNnXvuueTkhNm9YPucW978kVXS9UJhelE13fnFXpJezy47ZyDNUUT5QM+L6VJcQm5ZndULBmmFhkJXQohlTihJObc8qJczW9WooLKO/vnNftp0sozuWLGPLn9nOx1QvF6zRUboqoO69R6vF6+aGGuzx6J2wT7udLai6Cl1KE80Q3SXNUUHeslxJXszS43i9rT6+leNg8lMPQc/d9lICvHRvX7ZkFpIn2zPIEfTo5UpL3LfeecdmjFjhsgGGzlypPj4Tz/9JEcoAFgC/8Jyx5glM255QSYV73hrWbyiqxQ67rrlwQl1jeo9S3+miZoSFG4dE//sfvRnurjMzzE3ntWvW1/PHU399VsY/8ooUdU2nl3pJfIL+Un9gsx2u8rIBRRuQWu4AcHPz48SEhJo06ZNdNNNN9Ell1zS7g3A2hIU604uxnZ1gNXNn+6mijpdIYELtnfNGmixx+ioA8pqG5upTD/wzdodt7w2ibPQa5IR0QHthjOrzec7Mqmh2VA0/yu9lC58/U+65+t9lFdeZ+Nu237otu1GXAI7f0SUJnO3pw7QrX05Vm2nRqPCjmqs41Y6OfLcZbqaI/u/VSlGA8YdQY8Kt1ywLSoqEm8ffvih/PGbb75ZLIQBLIWnuwd7u1u045a3QXEbvtRty2d5oGs5t2rM9uxs4rKUH8d/tNycndrFZIDj+DE5Wy62LhgWIW9V7Y55+rgELpKuS8lXZ76tGbsbxsUFkot+0Y0BZaA1ixcvppkzZ1JAQAD5+/t3+AZgq47brubccsPBP7/eT8fydZ2ZA8J86MXLR4phOmAeffWFW2vHJfD3Nq2wWn4MltqKr5znYcsu1o5wZMjnO3VRVs59eKCS4bXH93uzaebzG+nldcfE2t4ajudX0q8Hc+WmoqsnxlnlfrWMTyZ5KYZgXaixmATJWQMMw9S2ntBmXILUuOTl5mT03KZ2MweH0fX6GDvO6L1rRbLmmsZ648xTV0yora0Vf0gCAwPF+xkZGfTDDz9QUlISzZs3z9yPEcBIuJ+7yFMsrKqnlpZWsy9M9ysmqo7Sbx2CjsUFGefcaiVLjV/gSF2IvEXM3dVZFG1PFlaLrFMM8nAc/Dzy7pY0+f1bzu7fo9vhuIQ3N54Ul38/lEdXToi1y3xbibe7i/jd2Zup+73hbYxhvoY4GwA1wzBdUKv4EMXg1y7EUL2x4QT9rp/S7uvhQu9eO5Z8PTCMzBIdt1L28DB9xrulcSNJpX47trRF21IDgLiBgWc9KAc0qwVn2kpZ+jMGBNKbiyfQ5zuz6JX1x8WanTuhX153nL7clUX3zR9MF43qa9ETF6/9cUJ+DXHz2f3IU1GQhI6zlK+eGEvvbTlFY+MCaaRGX2PzbjP+0eIoGy3m3PLvi3TyaUCIp+Ya1O5fkCh2+XHxOTW/kp757Sg9euFQcgQ96rhduHAhffLJJ+JyWVkZTZw4kV544QW66KKL6K233jL3YwQwmXPLOUzF1brOWHNCvm33xAR17wWGWhzNVeT7RPgZFekPqnDRCpaz/miB3NHCUQI9zbXmYV1R/rrnp20ni8TiyNZKqxvE1GNpcrS/l3lfzBvn3JaY9bYBABxRfDc6bv84mk8vrD0mLvPr71evGE39QjFYz9KFW1sMJutvwe+rm4sTDYnyk+9TDesXCTeLSVFW7LJRYeTq7EQ3nJVAm/41Q3TgSbt/OLbtnq/308Vv/km70y2zJuHhWj8fyBGXg7zd6JpJ6LbtqgcWJNHqZWfTFzdN1FzBUMKNPdLrBB7mZ4uYjt5QxgsMUJwk1AoPV2d65YrR4jmLLd+WThtSC8gR9Khwu3fvXpo2bZq4/O2331J4eLjouuVi7quvvmruxwjQruNWkm+BnFtlxqky8wnOvKWPO261QipmsaRIP6NinbJ4D/bv3c2KbtvpPeu2ZbwInacfUtbY3Eobjtp+IbHzlOGFyyQzdttKkHMLAGBeXAzydXc5Y+H2ZGEV3b1in9z5d+/cwTQzMQzfDguQTsqyHCsWapSFW0t23LKRKm1g4F09Uhcwn4AeGWU4DgFebqLb7vdlZ9Msxc8+5/Re+vZ2uv2LvZRl5tcm3OEu/c7dNK2f6CSFruEuaO7udnfRdofytAEhmo1LUA4m445bLRoc4UsPnZskv/+vb/araraIqgq3NTU15Our2w69Zs0aMbyBJ/BOmjRJFHABLEm5FZe35ppTU3OLvFjhzJdQ365PlXdUykEJmRrquE1RnHHkjNtRisJtciYKt45if04V7dF/vweH+9KMQYbsqp6Qcm6luARbUw4NUxZZzYW3u7ly4BzflyJLFwAAen4SME7fCZVdWiuy/NqqrGukmz/ZLW+jP3d4BC2d0fMTj9D1jltrZtxas3BrPKBMPetg7qiTXDc5zmSnJuc6f3j9ePp0yQSxlpP8eiCXZr+4if73+1Gq0v+u9EZaYRWt3JctLgd6udLiyei2dURnDVTk3B4vJC1JUQwm02rhlvHv3szBoXKkzH3f7hfd+fasR4XbAQMG0I8//khZWVm0evVqmjt3rvh4QUGBmNALYElhRh235j27wlseOCeJjYpFt21XhPq4k7t+u0KGRjpu+YldikqI8POgQG83sTXRz8NF7rq29yd/0Plst6G4yjllvd26NT4+iIK93cTlTccKqbbBtqH50tAw3kU4PiHI7LfPnSbSUJO0omqL7IIAAHDUuATOUcxqM/iVc9n/8dV+kS3OuFD13KUjNbv1WAsiFB23uTYq3PYLtXDHbYy/6gaU8Tb03/RDwHhtdcGIyE6vP21gKP1611n05EXDROc64xMfPH9gxnMb6ctdmSJqr6fe2HBS/E6yG6f1E1n/4HhGxwaQtz7XeOuJYk29ZlR23PYP1m7htk+fPvTcZSPFcEC2IbWQPlac5LFHPSrc/ve//6V7772X4uPjacKECTR58mS5+3b06NHmfowARsIVHbfmLhLwcCrJKMQkdHnbS6w+55a3I/ELCrXLLa+jijrdmffESF/53yHFJfAABGtuhQPb4JyyLWm6DvtIfw+6YGTvJ9w6O/URk3MZnwTabMMz8cVV9SK4X8rf9bPQsBrjnFt03QIAmDPnNqNNXAIPZFqXki/nLb67eCwKSFbIVQzx0TWO5JRZb33IJ0QZ5zlG+Vu2yNIvxId89IVItQwo+3xnBjXpX1dcNTFWDBI+ExdnJ5E7u/FfM+iWs/vJu4J4bX//9wfp/Ne2ijkE3cW/hz/qu2359w7dto6LM5Yn6te+/HPFg7K0gF+jSxm3MYGe5O2u7ciKEB93UbyVPPXbUaPCtL3pUeH20ksvpczMTNq9e7fouJXMnj2bXnrpJXM+PoAOh5OxAjPnmWAwWc9Ihdv6phazf08sQfmkzoPJJMq4BGURH+zT+1tPyZeXnJUgB933lpRzy1bbMC7BKN9WUVw1N+TcAgBYLoYqvcjQcbv6cJ4o3Eo7KV67crTRrAGwnL4Butcf+ZV11NjcPr7C3LhgKc2OSAj2Fg0GlsS3P6yvn9zgYO44uu6qa2ymL3Zmiss8fOzqid2LJeCT1Q+cm0Tr7plO8xUxVjzj4qr3dtJNn+w26mg+k9f/OCF36954VgL5WuhkOGjDWYqc2z81knPLuzdq9DsBOSbQHswcHCYGFErd9Zz7zs8d9qjHr1IjIiJEd21OTg5lZ+vOPnH3bWJiojkfH0Cnw8kKzNxxuy9Ld4aZ10bS4gXOLFaZc6uBuARlvk+SvuOWSVu+GQq39o279X9M1v3t8vVwoSsmxJrttqf0D5YHy3BXlDVe4HUWk8AmWSDfVjIm1pBzq7xPAADoGWWeqTSg7Hh+Jd3z1T754/+en0hn9zKXHbqfc8u7oq0xST6vokEMOrVGTIKpdfAB/WsiW/l5fw4VVzeIywuGRxrFVXQHn9h4+9qx9OXNk8RwM8naI/k096VN9OQvR6i8trHT2+Adhd/r14wcq3bdVF2hCBzXtIGGwu2W49oo3Cpf/9pL4ZbdvyBR/vfwTsNnfjtK9qhHhduWlhZ6/PHHyd/fn+Li4ig2NpYCAgLoiSeeEJ8DsKRgH3dRWDV3xm1NQxMd028rHhTuiymhPei4NbWlT42UW1qUHbdSVAJLRsetXfvoz3Rq0L8gunpirLw90Bx4Wq402ZsjOWwVH7Bdf78c38DZu5bi6eZMo2MCxeX04hrKLbde/h8AgD1SdtHy8yoXlm7+dA9V67ulONqHc9nBNgPKcqyQc5tZWme1wWSmBpTZMueWM0OVQ8n+boZCKe88+vmOs+i5S0fIw6e5MM67r2Y8t4E+3Z4uhlSb8sYGQ7ftDWclWCx6CrSDB+JJzWQ7TxVTfVOzpnacDrajwq2HqzO9csVoeeckP3dsSC0ge9Ojwu1DDz1Er7/+Oj3zzDOUnJxMe/fupaeeeopee+01evjhh83/KAEUuAgh5UyZM+P2UHaF/EdZuWUeurelj89Kq500mMzN2cmoi4EXcn31C/ODp8s7XMCBtvE07s93ZIjL3Cl6vQWmAs9XxCX8boO4BN7iyBm+bES0v1kL06ZM6mcoDCPnFgCgd3jgijT8hifZL/syWd7WPSTSj/73txEYRmZlnIUvySm3buG2X6gPWQOvFyT7bZhzuzujlA7n6NbqI6P9abSZXpdxHMRl42Jo470z6M5ZA+ThyqU1jfTwysO04JUttLFNwYdf13y757S4zLup/j41wSyPBbSNh2OdNUC346GusYX2ZJSS2h1VdtxG2tfO4sERvvTQuUny+//6Zj8VaiC+0eKF248//pjef/99uu2222jEiBE0cuRIWrp0Kb333nu0fPly8z9KgA5ybjkQvDfTQTscTIbCbc87blVeuOXcG2nYA58t5YB5Jel7z4OlThTqCl9gX1bsyqTKet1wugVJwRSmyM02l+mDQuUXBKsP55vteaqrdqZZJ9/WVBTDjpOG+wYAgJ4VBeL1XZanS2vFxGwW6OVK71w7Vux0AOuSTuxba0BZZlm91TtuowM9KcjbTe645c5XW/joT8MMguunxpv9JIW3uwv9c+5g+uPeGXShYjDt8YIquv6jv+j6j3bRiQJdkeutTSflAWnc+cuDyQDaxiVs1UBcgtRx6+HqRHGK1+72YvHkOJo5WFdML6pqoPu+3W+z5zDVFG5LSkpMZtnyx/hzAJYmbU3gv6M8Od0c9im2BCm3zMOZRQdqJ+OWuxClIlqiIt/WVNF+XyYGlNkbDq7/cKtu+x2/Drh6TLhF7odfFEjZg3yCKTmz1CYxCWyyFQq3nHPLHext7xsAAHomvs3QMd5x9sZVYyjGDl9wa4EtoxL6WalwywVSqeuWu1D5pIG1ZZfVihPe0k6484YbCquWKMa/euVo+n7pFKP1/8bUQpr38ha6/7sD9M3uLPEx3rnEMQkAkqmKAWVbVT6gjCMhpeaqweG+4u+JvenTpw89d9lIsWOF8QnPjxWRKw5ZuOUOW45KaIs/xp8DsDRlh5y5cm6ljltPV2caGGadLUn2lC0Tof+eZBaru3DL02QlSYp8W1NF+/02zPcCy/hpfw7l6SNWzkkMo7gg83fbSpRTjK0dl7BDPySMoyDGxevyZy39HDA6NkA+ecMvvAAAoOfiQ4wLtA+em0RTFIUCcIzCLXdZB+q7YK2dc2uLdfBnOzLkBgueQSDlVlr65PMPS6fQK1eMoih9JAY/hi//ypIHxPHk+gAv630fQP34xII0FOtgdjmV1eiG6anRsfwqMVix7XwXexPi4y6Kt5KnfjtqlO2rZT16Jvzf//5HH374IQ0ZMoSWLFlCN954o7jMMQnPPfec+R8lQBvhvsrCbe+3K3FHnHRWeXhff3Jps30ezixWn3PLE2Cr9NvQVT+YzETH7bC+fvJZyH02nqhrzi7T+ibk9ba0tNK7m0/Kx8XSg11mJ4XJP0urj+RZbbsOPydKcSA8IdrLzbL5tqYiGaTCMQAA9MzQKEPe6CWj+9INmGRvU8HebnIR0dJRCdwdV1DVaNWYBAlnykoOWDnntrahWcRZSSeer5oYa9VuvYWj+tL6f86gf84ZRF6KOBLOm16Cblsw4Sz9yTRe4m9T8dpXmu/S0etfezJzcJg40SK9Br57xT4Rlah1PapOTZ8+nY4dO0YXX3wxlZWViXiESy65hFJTU2natGnmf5QAHUQlsPzK3i+elJNTR8YYFizQs5xbNXfdKs+6mTrjyEWuQeG6P2ipeRVi8axlh7LLacTja+nqz47YXUh7d208ViDOOLNxcYE0Ns6ynajcmSHFFGSV1NIRxaLJkpTDwSYrsmctTXlfGFAGAND7XRvLzhlId88eSE9dMhzDyGyMB1tJ3ZiW7rhNLzKsoxNCrLsL0KjjVjH/wxpW7sumshpdwfr8EVEUpmjUsRbOj75z9kDacO8MWjQuRszD+N+lI63a9QzacZYi53aLinNujRqX7LjjVnL/gkS5Gzo1v5Ke+e0oaV2P2wqjoqLo//7v/+i7776j77//np588klqbm6mG264wbyPEMCEMGXh1gxRCcosU+Tb9owy5FytObfc8Ziin6jJ+Te8xcWUUfriPe/UOpSt7e0VnO3DZxtPl9XTe1sMwx4c0dub0uTLt0zvb5X7nDfMEJew2kpxCdsVZ/ytMZhMwvlwUjcScm4BAHpfKFx2ziD6x5xBIo4G1BOXwANOK+p0BUZLOKXfNcP6hVq345bXxlKBmk/+W2u4Kq/RlyvyKKWOOVsOwn720hG07p7pdN6ISJs+FlCviQnB8oyHrSd0QyTVHhUoFTTtmYerM71yxWj5dQk/t2xILSAtM+t+cO68/fjjj815kwAmKc/AFpqh43afYiuQMpweuh+VwDJLDAtONSmsqqeS6oYznm3k7eW26jYw9yJYuW2Ht5+V6zsZHA0PB9t1Sjc8s3+oN81ODLPK/c4bEi6GoLHfD1upcKvvuOWFpKW7itsuksbG6u6Po2eyVHoCBwAAQM05t0aFWytHJSi7bqsbmulkoW6nkqXtSCuRuwLHxAagkQY0gTu0pbU2767LKK5W5etB6XeLdy07Svf44AhfeujcJPn9f32zX9O7TxHkCZrEZ0HN1XHLT2ZScY67MHnCKPQuKiFDpVEJUrftmc42jtIPWWL7NFy4bTskihfgn+6wn+ma3fHu5jSjbFvuZLLWIEUeesE4piHNwi+A+IWk9PvHP8fW7tIyyrlVRDYAAABondSJaunCrZRTzxKs3HHLRihi46zVwPDRn4ZdYddPTbDKfQI4QlwCD2Uur210mJgEpcWT42jm4FBxuaiqge77dr/VZo6YGwq3oNkBAdLQn94OJ+Mih/Rkxp2WHE4P3RcX7K36qARlMHtSZMd/uAaG+cpDCbRcuDUVkv/Rn+l2EdDe3c4VqduVtwBeNLqvVe9/3tBw+fLqw/lWi0mQ8nWtyTjnVtfhDAAAYG8dt9kWHFAmddzyS5J4xfraWpQ7z6wxoIx36KxLyZc7AhcoYqYAtDKgjG1VYeH2qLJxyc4Hk7XFdZ3nLhspmvPYhtRCESOoRSjcgiZxt1yYPp+0tx23+40GkyEmoacCvVzJx91F3YXbvK794eKTAsP66roNuGNVq9sqlIXb+CBdl0hxdQN9szuLHMl7W9LEtFd2w9QEcnexbhfqvKGGFyCWjktQdrlaM99WOdzRXZ8nxY9Fq2e1AQAAOivc5lqo45b/bkqF2yh/T5vkG0tr4LYDnC3l0x0ZYq4Eu3ZSHLnqM0MBtIB/X/w9XcXlbSeLrJYL3VUpisHcSQ7WcctCfNxF8Vby1G9HjYaVa4WuytJFl1xySaefLyvTbmcaaA8XbnPL66i4up4am1t6/Ede2VGJwm3vzmhxXMKR3ArKLq2lpuYWclHZwksKZufCLE+J7czomAA5E5W3iZ0zxNA1qQW88N9+UnfW18fdmf47N55u+FI3UfPdLWl05YRY1X1/LIGL7t/uOS0u84mFqybG2qQbnTu8+eePf5Z4e6XyxZ9F8m1dnGi0IvLDWrgoPi4+kP48USxOenDWbYwiRgUAAECrrJFxyyfYK+qaxOWEENv8/eQiFGfrcmQDx4zxkFtpyI+51TQ00Ze7MsVlvg9enwJoCb+unDogmFYdzBO/uwezy1U1M8eRO24lMweHiYGHPKSMn8/uXrGPVt4xVVODP7v1DOzv79/pW1xcHC1evNhyjxagTXYk44auoqqed0QaFW6jDWeYoec5t00traKorib8JC0NWODhVGfqulQW8ZVd2VpxvKBKZPmw8fFBNCTCm6bpM5g4PP/Xg7nkCD7ZrvsDzbhoK50Rt7b5iq7bNRbquuWthlwoZTwkzFaLkUkJwSajGwAAALQsKkCZcVtnhcFknTcZWNII/WuihuYWi3anfb83Wy5UXzgyioJ9dDsqAbTkrAG6HFW29XghqYn0++vq3Memzym2dv+CRHnGTWp+JT3zm66hyS47bj/66CPLPRKAbuIMJElBRT1F+ne/g40LOodzdE9mCSHeFODlGFMWLSUu2NAZwHEJauq0Syuqosbm1i4HsyvPlGox53bbiaJ2uaO3nN1PDs1/e1OaWCDbc6ZzdX0TfbI9Q1x2cepDf58ab7PHMn9YBL207picc2uJwRtSt23brFlrE/e9luS4hMvHx9jssQAAAJiLl5uLiAYrrWk0Gv5qTsohprbquGUjogPox3054vL+0+XifUvsDuMOOAl3xAFokdQcw/i11h2zBpIa1Dc108lC3cmg/qE+Fuuc1wIPV2d65YrRdMHrW0UNiJ97pg8KpZmJYaQFjvudA80L9zWc9e7pgLLUPN32H4Zu295TFmqlyfZa3SYS6e8hBlkx3t7eorK8ou7k207RZ51O7hck/5zztv3NKgzQN6ev/sqSBw8uHNW3Ryd3zGVQuA/F609s7DxVTCXVum5oe8q3lfCLO099ty8Xk5FzCwAA9haXwJPaLZFlyfEEEm4qsRXOrJccsFADA8cqnSjQFaonxAcZZesCaO01sNTAtDez1CLr/J7g3y/peaqzwdyOYnCELz10bpL8/r++3a+ZWTYo3IJmheujElh+D3/h9mEwmUU7brUczM6dqNJUXd7ClV5sWEirHf+Blop43BkibQvhf9Ot0/vL13tr4wmyV5x7/cHWU/L7N5/dz6aPh4/9PP2UZF4/rTuim55sLlwc3aEv1nu4Ohm94LI2PpvPObeMI1PU9lxgTfx9uf+7AzTysTX0+yHLDqYDAADLk04C81qroNL8cQmn9N1xrF+o7Qq3QyL9RXYnO3C63CL3sXybYZ12vQ13RcH/t3cf8G3V5/74H++9914Zzh5OyCIJM4OWUmYobaAQoGlKS+DeC+FS/i1wb7l0hJ0wCgRaRtpCSvtrIISSvYAsMpxpx3YcOx7x3rb0fz3fo3N0ZEu2JGscSZ/366WX1pEsHR8dffWc5/s84AhXGTI3eYbnmi1ntJe4ZPg96OvunJWj/K+4rOAjfzvsEUkmCNyCx0oyKZVg38CJMyllaEzmuBq3rPyStgKd3FzB1sLs6uZOnlQu4fiFZqVeGE9b9zcMvNmCcalKBsfekkse9b5s8a9vq5RpjPzlzEdY3U1d5/YzB9e55eDoBUNd6Wk58UPWcHY2dcavL9e55braHxoyv5/45KiYsgYAAJ4rw6TObYfTMm6DA/zcOlMoLDiARqVIY6fTNS2iiZgjldW30b9P1IjL6TGhtMDDmgAD9PeTeQUUYihFwKXazje4P3FBXZ+6EBm3SjLNb2+ZSImRUonMLSdr6R1VyRatQuAWfLpUghy45WLdY7Ezc8j0MfnovNay7E5USV9cseFBlKrK1h6MnHHbP8ivdbvPquvbGmsuMf7/cK1b2atbz5K34aOmr20vUa6r36878fYkb3s7T9dRS6dUxsER1MFRd9a3NRe4VZdw8DVbTxobVPBUrE8M9QIBAMCzSyU4o0EZZ/FyQJNlxoYoY2p3kctr8Uyho5WObVD2zu4y0WCaLZ2VS4EBCEuAZ0uNCaV7Ls9Tmvqt3iz1tnCnE9XGxKUxGkhi0YrEyBD63a2TlOu/+fSEU5swOgL2kOAdzcnsKJXAQZMzhgYAXPPFXR3YvUlQgD9lGAa0XONWK9MO6lu7lG2Ep4lY25BrgmHAyg45aZqY0+vbmgni3Tg1g5IN9Xs3Ha8WWYHehJsCcA1fOZP+srx40gLOfF4wLkUZ0KmDeo6tb+v+98vdqMODUed22ynT//GbO0o1s18EAIDhBm4dm3Fb2dChNNLNjrMuycCZ1LMRv1WVlxuu1q5e+us3FeIyZyjejiam4CW4JF1MWJC4vOFgpfJ7xN0zTuMjgpXeLSC5cnSy0hCRex49+MEh6uzR7sw4BG7BY8WFB4tMWXax2fbA7ZHzTcqRXnVmJTimXEJLZ6/SGMrduAmdrNCK+rYy/uItMNQXK77Q7BHTnPmL56vSS8rBjXwzjS14Gr18RJg/A69vM2aneoPXthuziJfPy7c6UO+p5RI4EMhNwBgHS53R+dmegzjTcuOV/fM5jTUrdAWeVrqvRPosyk5ebPH6poAAAN7MmYHbs3XGA+nZqpIM7jwIKzvswASGjw+cp5YuqfTCjVMyKC5CmrIM4On4t+MDV45QfmP99rMTbnstPNOrrtX2xCVfsmpxoVL7l8foz352krQKgVvwWJy9lmwol2BPjVs0JnOObFWDMs661YJi9TQRK+vb9s824AxJdZ1crTp8vpE6DEcLZxckWvyS/uGMbIoKDRSXPz54nqoN9VE9HR+Q4S7FLDchXNT01RLO/uVyHWzLiRqHHNktrWtTDl5xsJSDplqgzvz1xTq3nAXN+43+9b/fUJXxAO+yZs0aysvLo9DQUCoqKqIdO3ZYXPbjjz+ma6+9lpKSkig6OppmzZpFmzZtGrDcRx99RGPHjqWQkBBxvmHDBie/CwAYjDyzjFU6uFSCujFZdpz7s+O4xq1cs9NRGbc6nZ7W7TLWk0RTMvA2S2fliLrNcv1Ud42B7U1c8iWhQQH0wu1TRGNl9s6eMtpdqs1Zttr4dQdgp2RDuYT6tm6RaWgLdc3SyW7swO7dDcraNVXf1p4vrslZnlXndrchaDlUrdOo0CD60cwccZmn5b21y9jZ11uybe+bl+/2+nD9cQ23a8dI5RLau/tErdvhkrNt2SxVbVl38/U6t9tUpTAeW1xIOYaDWjvP1IkGguBd1q9fTytXrqTHH3+cDh48SHPnzqXFixdTeXm52eW3b98uArcbN26k/fv305VXXknXX3+9eKxsz549tGTJElq6dCkdPnxYnN922220b98+F74zAFDj6caBhrGFozNu+UCsTAulEvhA8Lj0aCUZo7G9e9jPuf10rdKAjccsCCiBNwYDH7p2lHL9/z474ZYyWaaNyVDf1hJuYP34dWOU609vPieylbUGgVvwaHKdTlZrmApgrcMV0tGUyJBAyk+MdPhr81U5WgzcGo44cvKp3CHXnsDtIU8I3Koak5mrb6t295xc5Qjj+/vKNVPawl4Vl9pp45EqcZk7hd48NZO0aNF4x5ZL2Kuajq+F+rayCRkxFOHDdW7l+rb8A//ykYl0r6E8CfvjDmTdepvVq1fTsmXL6N5776UxY8bQ888/T1lZWbR27Vqzy/P9jzzyCE2fPp1GjhxJv/nNb8T5P//5T5NlOLj72GOPUWFhoTi/+uqrxe0A4B58QDjF0Gj0QpNjA7cl6lIJGgjcMnX5pW8dUC5hnap7O7JtwVvdNDWTRqVEKok/nx11THk0W6hnio5Bxu2g7pyVQ1cVJovLDe29olmZ1kjzZAE8lDxwYhebO02mLw2Gp4VXG8orcP0mLrsAjpGlCtzKnXHdqbdPR6cuSl9ceQkRFGYIJFmLMwGCA/zFlGetZ9x2dPfRwfJGJfM5M874vzCHS43cUpQpgrbcKOLPe8voZ4a6TJ6Ig2Hc+ZjdNStXsw0H54xIFAHNtu4++qL4othG7e2mLOrbGqZg8UEoDpZqhVznlgOYfOSaM2wKknzjINm5ujalrm9RTpzIcL+lKIv+sPkUNbb30D8OX6BHFhWKDsTg+bq7u0XW7KpVq0xuX7BgAe3evduq59DpdNTS0kLx8aoSI3v20EMPPWSy3MKFCwcN3HZ1dYmTrLm5WXl+Pjkb/w3eL7nib3kSrBfvWi/psaFU2dgh9uetnd0UHuyYn9QlhlIJsWFBFBMaoIn1MjHDOFPtcEUDXT7C/pk9JbWtSmNW/s121egkm96jp24vroB1o631wpGF/1o4mu57d7+4/ttNJ+nqwiS7x/vDybjlMEdBUrjJOsD2MtD/3TSeFr+wk0YkhNCjC0e5bMxkLQRuwWsCtzU2NChTZ06qMyrBsTVutZBxe66+jboMZTTsmSbCGalj06PFNsOBp6b2Hoox1CjVmv1lDUpNzaGybWX3z82nD78qFwHPt3eV0rLL8zQb8BzMpbZuWm/oUBwWFCDqS2kVr98rCpPpX99WiR993Exu9ohEu57rbG2r0nhgem6cSweE1uByHXLmKQeYfSVwK79ndsVo6Qg+HzT60YwcennLGerlGn+7z4mmCOD56urqqK+vj1JSpDIoMr5eXW1dls0f/vAHamtrE6UQZPxYW5/zmWeeoSeffHLA7bW1tdTZ2emSHyFNTdz8VU/+/traH7kT1ot3rZf4UGPCx9GSC5QbP/yDcJ09Oqoy9BvIiAmixsZGTayXjDBjLf6vz9ZQzTj7a2W+usVYOuamCfFUX2f8rvTm7cUVsG60t17Gx+lpckYkHapsFWVQ3tpaTN+fkOSSv83jTDlxKSs2lJob6kldpAvbi3mv3TKCwvQdRB1NVNPl/N42fMDeWgjcgteUSqhp6bSpgVP/5lPgGNGhQRQXHkQN7T1UroHmZI6YJsLBfTnYz9vOvFGu+dIdTpmEwerbquUmRtDiCWkiiFjX2k1/239eqX3rSd7dc0786GG3X5ZFseHa7lC8aFyqWOdyuQR7A7fqhgfW/s/dWefWE7cte2w9WaNcnq/aX9w5O4de314iDrC8t6+MHrhqhMiUBu/Qvxkk/1C0povzBx98QL/+9a/pk08+oeTk5GE9J5dTePjhh00ybrlkg9wEzdn4xyC/Pv57CKxgvXjr9pKf0kB0QipT1BUQRsnJwx8XFqv6MYxKjaXY2FhNrJfERD1FhpwUM7NO1nUO2EdZq7mzhz4tPqQcYL/nijEUExbkE9uLK2DdaHO9/PL6YLrl1b3i8ltfXaQfzR3tsAz9wZy+2CJ6mLDxmbEDPrfuXi9alZioEwe6XbVeuJmttfBrAbyqVIJ9jckQuHW07IQIamhvpKrmTurq7aOQQPdlcJoWZrc/cKvedrQbuDUG8WYXWB8I/On8AiWIyEGl26dnaS5zc6gSEe8YaqZx7TnOGta6KwuTlRIcm45V06+vH2dXyRZ1fdtZ+fYFf51pfHq0CEzyDz5+rdYGsjxZZ0+f0jCODy6OUWX6c3mS709Jp798c55aOnvpL19X0D0esL3C4BITEykgIGBAJmxNTc2AjFlzTc24Nu5f//pXuuaaa0zuS01Ntfk5Q0JCxKk//gHiqh9n/Bl35d/zFFgv3rNeMlSlqKqauhzy2s/VG+vl5idHama98J/nsnI8xrzY3EW1rd0mv7+s9fGBC6JEFLtpagbFRQzcT1lDK+tFi7ButLdepuUm0MJxKbTp2EWqaemid/aUu6Qs3ckaY7nCMWnRZt87thfzXLlebPkb2OOBR0uONn7p82DCGjqdXimunxodatfgAwbH9VUZ9yI63+DYxg22OqHKuC1Mta+jpjorW52trSWcyfCt4bVxMXzuemyt8RkxdLkh45PLW3zqhgL6w/G3/RUiw5tdPzFtyNq+WsDBzLkjE5V91yE7tisOgnIWK4sKDRQlPbSGDwBwCQfGJR24tIO349IXcvY3Z9v2D1TfOzdfufzmzlJR4xg8W3BwMBUVFdHmzZtNbufrs2fPHjTT9sc//jG9//779J3vfGfA/bNmzRrwnJ9//vmgzwkAzqfuqXGh0THj3FJVY7I8VdkxrTUos6ffQ59OT+/sUTUlm53rsNcGoHX/tbBQ1Jllr249K8q7OdsJVQY/92sBz4fALXi0lCjbM265Yytnf7FJWdpp5ONNcuK1U+f2RHWLEijLjLOueV1/uQnhynQuLpnAATOt+br0ktKYy5ZsW9lPryhQLr+67awm36M5HPR6Y0epcv3+ecb3oXULx6Uqlznr1lanLrZSvWHwNyMvXmQba5G6hIO6tIMv1LedP3pgdv6olCi6wnA7N7fhUhng+bg8wR//+Ed66623qLi4WDQVKy8vp+XLlyslDO68806ToC1f59q2M2fOFJm1fOJafLIHH3xQBGqfffZZOnHihDj/4osvaOXKlW55jwAgSVcFbisbOx3amIzlJUZoalVPyjT+XpKTX2wtH1RmKJ/GB61HptiXSAHgiUYkR9KS6VnicktXL72y5YzLfv/a2+MFtMftgds1a9ZQXl6eqO/A2Qo7duywuGxVVRXdcccdNHr0aJFWbGng+tFHH9HYsWPFVDE+37BhgxPfAbhTbHiQmG7MuGu5NQ6Wq8skSJlg4JyMW+bOOrdNHT0iMCJn29o7RZsfJ2fdch1Y+Tm1WibBnlqn3MxsQoY0MD92oZl2njHWy9Wyd/eUKQcH+MeAFrNOLblmbIpyBH7T0Wqbg+V7VDWN1bVktV3n1ljawdvr2/L/du4I82VV7lNl3b6xvcRjDpSAZUuWLKHnn3+ennrqKZo8eTJt376dNm7cSDk5OcoYlgO5stdee416e3vpZz/7GaWlpSknDtbKOLP2ww8/pLfffpsmTpxI69atE6UVZsyYgX8FgBulx4Y6POOWG+BqNXA7cZgzz7gZpwzZtuCLHrx6FIUGSTGLP+0powonJzbJGbdRIYEmMwTAc7k1cMuDTw6+Pv7443Tw4EGaO3cuLV682GRgq9bV1SUKBfPykyZNMrvMnj17xOB56dKldPjwYXHOHXr37dvn5HcD7sABNblcgrUZt6aNyZBx6wzZCdrIuD3pwKONpnVubc82cLZdhkArx6Zn5iXY9VlaPt+Yrbp261nSuv1lDfSbjcXKdVfUjHKk+IhgmmH4X52rb6eThu6vdtW31WBjMtm49BgxcGRc2sGbg5Q8ED9ryJqakh1HMeFBFg+UjDXU3D58vom+Ptfg0tcJzrFixQo6d+6cGK/u37+f5s2bp9zHQdetW7cq1/kyfxb6n3g5tVtuuUVk23Z3d4tM3ptuugn/PgA3iwoNUr7XLjQNP3DLn/0SQykhDrKEBrmvN4Q56TGhlBgpNX09Utlk0/c4N0nacVoao+YkhNOVo+1rbgbgyVJjQumeOVJPA+5v8dzmU077W03tPXShqVP5/evtvSV8hVsDt6tXrxYNGe69914aM2aMyFTgzrdr1641u3xubi698MILYmpZTIz5gBs/x7XXXiumpBUWForzq6++WtwO3kmuUcs1LrkR1lDkoBvvw+QMQ3AsHpjJ5KlRbm9MNsz6PpNVQf5DFdoKstS3dilTYsanx1gMFg1l0fhUURZCzuC1p46ZK9/zA+8foF5DfYifzMvXdNbpYOtc9pkNtYW5VvfeUinLmst4jNFw/Sou4XBZXry4zKUdTtd4b53b7aeNZRKuGKSJIQ+i75tnbEr2xo4Sp782AABwfLmEqqZO8Z08HFzzsrmzV5PZtvJ3llzntrG9x6akDHW27Z2zcu1qxArgDX4yv0ApvbfhUCUVq+rQavX3L2iH2wK3nDnA2QgLFiwwuZ2v79692+7n5Yzb/s+5cOHCYT0naFuKqkFZzRANyrjbt7yTHJEUKY6YgxP+J1GhFBwo7V6cPRVkMOovRHVnd3tMytRuxq0685Iz+YYTYFPXiOVat1rETS4e/PCQ+LHEOCj4XwtHkydaMM7YHZ47zlqLA/X840mub6v1H0K+Uud268nB69uqfXdiumiQyb4ovqhkWwEAgOeUS+ju1Sn15u1VqiqTkJ+kvcAtm6iqc8v9HqzN/Pv4QKW4HBEcQLdOy3Ta6wPQOg7aPmCYHchJ67/97IRT/g7q23onaY6HG9TV1VFfXx+lpBh/tDK+zs0Z7MWPtfU5eUobn2TNzVKwR6fTiZOz8d/gKSeu+FuexNr1khRpDNxWN3VQhqruVH/HKhuVDD0egHjqOveEbSYrLkxMGeaj8vxZd8U0jf7rRR24HZkcOaz1FRceJN5TRUOHmCbW3dNLgYb6yu6264wxWDQzP37A+7Rle7lxchqt3nxS1PLlpklnalooX2PZH89vPqXU4OWpey8umSTqidr6/9XC5yglKkQ0/eDp8ry9lta2UE7C0Ot799nB/+fD4Yz1cllunElt3qUzs8nTDLVe+Mf7bsN2mRARTGNTowZdhwF+XOsvh/7vs5NiAP/HHSX0P98fT57GHZ8jLX/3AYDvNSjjOrdJUcbfI97UmMxcAgM3KLthcsaQj/nLNxXU0SPNhrylKJOikTADPm7prBx6e1epKGWw5WStSGZwdLkzZNx6J7cFbmX9gzk8+B9ugMfW53zmmWfoySefHHB7bW0tdXY6plPoUD9AuIswv05uuga2rZcIf2lqETt9voaywqQsNHN2FktNY1h+TADV1BivexJP2GZSIgKIY0s8YDtx7gIlRAS5dL1wLYwTVVL5gIyYYGpvukTDzf0dnRQqArf8nvadKKeRScaSEO6087S0HXMcOSe8d8B2bev2ctukJFqzq1IEk176/Dg9do3UXEcLdpc20UtbpExgDtY+uTCXqLOZajqbPfZzNCcnUgRu2cdfnaUfFhnLJ1iyrbhKuTwq1s+h+zJnrJeEAD1FhQRQS1efCNxWX7xI/h5Wc2uo9bK/ooXauqUfqNOzIqmuzhhct+Tq3FB6Mcif2nt09NH+87R0cpw4SORJ3PE5ammxrR40AICzA7dyE1tva0xmLuP2WysalPHsqHf2qMokzM512msD8BRcv/rhBaPpP/96WFz/v89O0N9XzHZoglOx4fcvG506vBmnoB1uC9wmJiZSQEDAgExY/vHZP2PWFqmpqTY/J9fBffjhh00ybrnWLjdCi46OdsmPHv6w8t/TahDOHaxdL/lpHKiVpuF0+YVQcrLlovdnGy8ol+eOzaTkZM+scesJ28zItDrafU4KprX5h9OYZGPGnSvWS3lDB3X2SllZ4zLiBt0urHXZiDb64pRU37aiPYDmOOA5h6uqqYPKG6QZA5Oz4ig3M23Y28v9V8fRu99cpNauXvq0uJ4e++4ESjZM6XanyoYOeurzb5Xr/7lgFC0uMpZ28NTP0U0zIkSgnO0qa6OHFicP+WPo8AVpwMdBvpmF2Q4tleCs9TIjP4G+KK6hps4+atSHU2GKZw0mh1ovhw8YS5YsmMjfL0PvH3iJ2y9rord2naOuPj1tOttOv7h6JHkSd3yOQkPdvz8CAN+m7tRe2Ti8BmWldcZSOQVJkaRFCZEh4j3zez1a2Uy9fbpBZ55xCaDzDdJ6mT8qSbPvC8DVbpySQW9sLxFNibmfCPe4WDxh4O83e3C97VOGZsfZ8eEUaWiiCJ7Pbf/J4OBgKioqos2bN9ONN96o3M7Xb7jhBrufd9asWeI5HnroIeW2zz//nGbPnm3xMSEhIeLUH/8AcdWPEP7R48q/5ymsWS+pMcaBU01r96DL8tQexvVXx6THePT61vo2k62a7l1xqYMuy0tw6Xo5ddE4CC5Mi3bIepqaHWdS5/aOGe7PRN1XamyUNqcgweL7tGV7iQ0PoR/NzBE1brv79PT2njJ6bPEYciduPPjABwepsUPKqL9mTAr99IoRDpmh4e7P0YjkKBqdEiUGcAfKG6m2tVtpumjO8aompYkJN2QLDHR892lnrJdZBYkicMv2lV6isemed+BssPWy/ZRUJoE3yfmjkq1ed/dcnkfv7CkTAfk/7S2n5VeM0FxHca19jrT6vQcAvppxO7wZmnKphOAAf8PzDq/ZmbNMyooRgVueeXamtnXQxkfrdhmzbe+eg2xbAHVPkUcXj6Z71n0jrv9u00m6ZmwKBTmgBF9FQzu1G2Z/FSLb1qu4deTLWa5//OMf6a233qLi4mIRbC0vL6fly5crmbB33nmnyWMOHTokTq2traKUAV8+fvy4cv+DDz4oArXPPvssnThxQpx/8cUXtHLlSpe/P3B9c7KLzZYHTo3t3XSuXposPz492iE7R7AsJ95YRsCW7rPOmCYyxkFfXOPSY8SXLTtsxTQxV9itavTEgTFHuWdOrvgBwd7fW07NnZZLkLjC//y/YqWcAB9B/sNtk1xSN9lVFqqalH1+fPAmZermXo6ui+VMXItXtrfEuxqUVTd1Ks0gJmbEiMwka2XGhdPi8VJ5DG5ws+GglH0NAADalRYTalIqwV580K7M8PskJyFcGWdq0UR1ndtBGvVyjc09hu957pMwb+TgzToBfM2Vo5NFc2W5VArXg3b0719OXALv4dbI1ZIlS+j555+np556iiZPnkzbt2+njRs3Uk6OlMVWVVUlArlqU6ZMEaf9+/fT+++/Ly5fd911yv2cWfvhhx/S22+/TRMnTqR169bR+vXracaMGS5/f+AayVHGgVNNs7HJXH9y0IcNpw4VWCc7wb2BW5PC7A764goLDhCZkYynobR1GesruwPXlJSDeCGB/jQ1x3HbNZdGuLlIajzR0tVLf95bRu7yyaFK+pPh73O2/JofThWdWb3JQkPgjm06OniDTvnHEJuV7zmB2zGp0cr/jTNueTqXt9h2ylhjeP5o20uo3D8vX7nMTcq8ad0AAHij1JhQMcNCLltlLw76dvdJpb3yk7RZ39ZcndvBEhje2W3Mtr1rdq5DyzkBeANOPlm1uFC5/vwXp6m9u9ehv38dlbgE2uD2lMMVK1bQuXPnqKurSwRj582bp9zHQdetW7cOCFT0P/Hj1W655RaRbdvd3S0yeW+66SaXvR9wveiwQBG0GirjlmvIyCYjcOt0WXHuDtxKRxzDggJEhqajTM6WgqMcVzlSaTnbwBV4vcp11abnxlOIg6fM3z+vQPlR8tbOc9Rp6AzsShwgX/XREeX60zeMo/EZnjfFfihj06IpKz5MCczyDAFzuKbc16VSLdXEyGAakew5NeP4h9sMQ3ZBY3uP8hn1BttOGRuRcS0/e7KY5MyLs7VttOWkZzbOBADwFTxzL8WQPFI5jFIJZ2uNpb3yErX9nT4hI0YZF8rl5/praOumjw9IM0eiQgLp5qJMV75EAI/BJfgWjZMSN2pbuuitnaXDfk65MTdDxq13cXvgFsARR6zkepA1LV1WBW4nqab6gHNwdmpylDRdWJ4C5ircVEv+m6NSoxw67WyyattRb1PusOuMc6fMc2djeQp3XWuXMhB35f9x+Z/3i1pq7NaiTFoyPZu8dT8mD9542qRcC7a/YxeaRQa03OzL08pFqLdTdeawJ+Ng+o7TUn1bzii298Dg/XONWbdv7Chx2OsDAADnSI8NVcZI9h7cLq2T6tvKZQW0LCo0SHmNnNnH/Qf6+/DrCuoyNAe+dVoWmiMBDOK/Fo1Wfqe+uq2ELrWZT9ywNePW0YlL4H4I3IJX1blt6ugxO3DizOxDhiBbbHiQqCEFzievZx7QOmL6h7XkbppsbJpjp4moy2y4u87t7rNSsIjNdlKt0+XzC5TLr28/K4KKrsCf2Uc/+lZp2MEF9p+6YTx5s0WqcgncYdabyiTIuJmat9W5PVjRSC2GZnFzRybafaDoqsJkZZrs3pJLdMRCNhMAAGivQRnXOh924FbjpRLUyS89fXqTeprygcw/7ZFmwvJx5Ttnub+JL4CWFSRF0m3TMpWElVe2nLH7ubiEX9kl5yQugfshcAtegetxDlbn9nxDh2j6Ig84PC1LzVNlualBmck0kUE63tqDp6ZHBEslCQ6VN2qivm1kSKCYvuYMPIV7zggp2MbN/SwFFB2N66P969sqZardqz8qElnc3mxKVhwlGbLUd5yuNVtD2VMbk8m4RnRcuKHObUm9yw4EONO2k8YyCVfYUd9WXUpi2eV5ynVk3QIAaFuGKnBrb4My+QC1PNNJ69R1br/tl8DAzVUvGALYV41OplwPeD8A7vbg1aMoNEgKy/1pTxlV2PmbmROX9IZhNerbeh8EbsEryFPy2cWWgUe81ZmRaEzmOjnxxgFbuQvLJahrZ3KmpiPx0csJhkErD05rBqmr7EynLrYqByO4bmhggPN25+qs21e3nRVBY2c6UN5A/7uxWLn+u1sn+cTgnwN3C8amiMs8zVBdN5X19Onom3NSfVsO8Gp9SqXlOrdSwLm5s5eKq4xNFDzVVlVjsnkjE4f1XDdPzaT4iGBx+V9HqpQa1gAAoO2MW3v313LGbXRooLL/17KJ6plnFaYzQ9btMvaduXuO8UAkAAze6PAew+eFGxU+t/mU5n7/gvshcAteQa5xa6lBmWljMu9rbKRV6pIULs24rXZexu3AcglNbi+T4OzMy8tHJNK4dGk9ckM2dW1dR6tv7aKfvXdATMFj98/LNykh4O0GK5fA676tu08pk+CpMwfU26unl0vgZhJHK5uVBnPq2R/2CA0KoKUzpamlnI38tgMaVQAAgHOkxRj3+RfsaFDG5d3kgG9+UqRHfK/zd12gYQq2OuP2aGUTfWU4uMyz0+TZWgAwtJ/MLxDlHNmGQ5V0/ILtiQ0nVMkQaEzmfRC4Ba+qcWupVIL6iDAak3l3qQTOBpUDt+kxoRRj+BJ0pCmqwO2higZyh92qKfOzC4aX5TcU/iHx0ytMs26dgQNVK9cfoirDNLvLcuPpkYWjyZdwDVjOumFfnqgxafzh6WUSvLHO7XZVVvQVo5Mc8pxLZ+VQSKC/0uSlubPHIc8LAADOy7i1p1SCJzUmUx9gLDT0jzhT2yrqcsolrmQ/np3rEUFoAK3g5rYPXDlCXOaJjb/ddMLm5yhGxq1XQ+AWvEJKVKjFUglcKJ8z1VhWfBglRBqDvOC6jNsyF5VKqG7pVgaRzjraOGmQaWKuwAFOOeDF9UJdMR1m8fg05f+580ydUxonvfDv07TjtJRJnBgZQi/fMcWpJSC0KCjAn64xlEvg7VgdoN/r4Y3JZKNSIpXpoPtKL3l0nVt1OYv5oxwTuOVt/6apxkYVH35V7pDnBQAAJ9a4berw+sZk6v4HcoCJM215ttQnhy+I2/jg801TM9z8CgE8z49m5ij7lK0na01mV1qVuGTIuE2NDqXYcO2XXQHb+NYvYvDJ5mRcC7SjR8paQ7atayVEBFO4oaGUvYXWbXWmzjhwdlZAMy0mTMny5vrJOhcHno5daFK62HPmJdcNdTau7ctlC5yVdbv1ZA299OVpcZnfzks/mDLsaeeeauE4Y7mETYZyCd29XN+2QZmaqT4o4mk4C2dmfry4zNuxPdPBtIADzttP1yoN9KbmxDnsudVNyt7edU7UNwYAAG3hqc1hQQEOybjNS4wkTzGpX4OyD74qF+MUdvtl2RQeLM0cAgDbstkfvnaUcv3ZT09Y3VeEZyty7wgmZ8SDd0HgFryuVEL/GrfqxmSTVZmS4JoATbahXEJFQ7tLMutO16oCt07KuFUfBODAU4lq4O0K6izMWU4uk9C/cRJnA7JPj1aZ/OAYjvMN7aJEgjw2+c+Foz26FMBwzRuZpPwQ5A7N/LnhH0byASguNeDpUxDVGcN7SqzPKNAS/p80tktlDOaMSBTZ0o7C9QGvGZOsDMY3Hqly2HMDAIBj8HdxemyoUuPW1uatZ2tblct5HlIqQZ1xy/aXNdCf9pYpB97lOu0AYLvvT8lQEo+4j8qn/fpdWHKiutmp/V3A/RC4Ba8QGRKoBDoGBG5VjcnUU9zBNeTALTebqrJjGpmtzqoybsc68YijabkE4zbm6sDtHBcGOPlI8N1zcsVljsG/vr1k2M/JNVx/9v5BJQDGwarl84z1dH1RWHCAUi/1Uls3fX3ukml9Ww8uk2C+zq3UzMTT8DQ2R9e3Vbt3rjHDnT9rtgYEAADAdXVu+eCqPJaxL+PWcwK3I5MjKTTIXznAfNEw2/GaMSkm/S0AwPYZjo8uKlSu/27TSatmXRVXGRtzj0HGrVdC4Ba85oi3nHXbv1TCIUNQjXeE49JxBMrV1FO6XdGg7Eyd9DeCA/0pN8F5g2B1gzJ1Vrez8VS0r0svKTWMXD3Q5/pLfKCEfXTgPNX0qyltq//9V7ES+OYa1H+4dbJLSj9o3aLxxnIJnx2tpj3q+rZekI3MGaWJkVL9ra9KL4la5B5d39YJgdsZefE00TAd9diFZpNtAAAAtFfnttLGcgly4Jab6fJBW0/B/QfGp0vfT+pjinfPMZb5AQD7cDLAZXnxyj7iL99UDPkYuTE3Q8atd0LgFryGXA+zpauX2rulGi98fuqitCMblRKFmktuzLhl5U5uUNbR3UcVjV1KAyRnNrYanxlD8mx1+eCAK/DfkqfMzy5w/ZR57nr6wxnZShCZ62/a65NDlfTunjIl0L72h0UUEx7ksNfqya4sTKagAD8lcMtTEeUfiN6QzcLb7QxD1i034OLApCdpaOtWDtiMTokSda+dsY7UWbdvOCDDHQAAnJNxa2udW55RI2fo5nlQYzJz5RIYT++W69cDwPDGf6sWG7Nun//itBLbsERuTMa/HTyp0SFYD4Fb8BopZhqUHa1sFlO6Gerbuke2KuvV2Rm3p2talf+3s482RocGUUGS1EiiuKqZOg3BVGdTdxh1V+blPZfnUbAhKP7nPWXU3Gnb1EB2+mILrfroiHL9qe+No/EZxmYXvo63r9mG+sXVzZ3UZWj6oS4x4OlM69x6VjYpNyWTs4yckW0ru258qpLNteVkrfjcAACAdnDDUHsCt6V1xvq2+R7UmEw2Kct0zPbj2bkeX38fQCumZsfRIkOz4tqWLnprZ6nFZfk3qNxvZURylEN7LoB24L8KXiMlamCDskMVUpYam9xvgAGuz7gtc3Lg1rQwu/M7asoHA7h+73HDkU7XNiZLcNtBkpumZigZ7u/vK7fp8ZxhufzP+5XM4VuKMmnJ9CynvFZvKZfgTWUSzNe5rffYMglXjHJe4JZnDch1pdkfd1geuAMAgHtLJXAzSWuV1HpmfVtzGbex4UF0w2RpXAgAjvFfi0aLUo/s1W0lIkvfnDM1rUoD8DEu+P0L7oHALXiNZEONW3axRcq4PVzRpNyGxmTuG9DKJUsrnB64VRdmd349Y1c3KONSEAfLG5TawZlx7psyf/+8fKVUxJs7S63OOOYGS6s++pbOGn6wcID96RvGI0vDjGvHpijr2BsDtwVJEZRkOODGdZutab6gBTqdnrYbArfhwQFUlBvn1L/HBzWiDHWlNxysFJkXAACgvVIJttS4lTPkPLVUQm5COM0ZIY1JVl490qNq9AJ4Ap7Zedu0LCXp5eUvzwxd3xaNybwWArfgpaUS5IzbRuXH9chkHIFyB65dKtd/LHNyjdsTqo6aLsm4zXRt4PabMg5u6ZX6tu6UnxRJC8cap/BwQMka7+w+R//v2ypxmYNRa39UhMG+BYmRITQ9N94ke12d2ePpeEqlnHXb1t1HRyuNB9q0jLPr61q7lc9hSKBzf6xGhQbRHXJd6T4d/WmP/XWlAQDAsVLtLZWgyrgt8MBSCfwd/qd7ZtDBJ66lH6MpGYBTrLxmJIUGSSG7P+09ZzYJSq5vy9CYzHshcAteIzlKFbht6RLBJPnIN9fOlKcagOtxdihr6uihJkMjBkfjTE75iCNn8SVEGjOwnYWPanJg2lUNykzLJEj1T91p+RUFyuXXt5co03QsOVDeQP+7sVi5/rtbJ3rk9EBXkutbMW9s+qF+T+rt21PKJMwfneySv/njObkUaPgO+9PeMpF9DwAA7hcaFCAOtLILjTaUSjDUuOVmQhlxnnlQ1t/fj+Iigt39MgC8OjFt2eV54jIn76zefGrAMsi49Q0I3ILXSFGXSmjupG8NHb8ZGpNpI3DrzAZlF5u7qLGjx6X1fbj4+/h0qSTDufp2amw3X3vIKYFbDTSp4s+V/DpK69ro82PVFpflukwPvHdAyRi+b24eLRqf5rLX6qm+PyVD7Nv4AMHtl0lZl97k8hHGAxAffFXuEeUStp2qc0l9WzWetfDdidLnpaG9h/524LxL/i4AAAwtI1ZKHrnY0mnV9xgf6OZxI8tJiEByCQBY9JP5BaKONPv7oUo6dqHJbI+XhIhgSnJB4hK4BwK34DWSVaUSOHCrzoBE4Na9suKdH7gtdnFjMrN1bs87b6p3c2cPHTEcjBiVEqnUBnW3n6qybtduOysyn839QHnww4N0wdC0Y3puHD2yqNClr9NTxUcE045HrqJvfnmN6DDrbfgH63xD8PN8Qwd9cugCaVlLZy8dNHy35CdFmOzbnO3eufnK5Td3DJ3hDgAArq1zy0OgaisalHFJhe5eKcCbj5lHADCI6NAgeuDKEco+5refnVTu4xnGcvkungnKJUzAOyFwC14jMiRQnFhNc5dJ4BaNydwrJ944Hb7skrGmlyfXtzV3UOBQufPKJXxVconkOM1sDZRJkM0dmUjjDFnH355voj1mpru/+O/TtOO0lKXI0wlfvmOqyFYG63C2LQ/avNUDV0mDUbZm6xlNByS/rmhRXp8ccHYVLvkj17bmTK0vii+69O8DAIB5ci8Ha+vcenpjMgBwraWzcpQ+F1yya/fZOpNsW4b6tt4Nv5zBqyQbshCrRamEJiVQlK5qHACux02VZOaKqjuC+otrtJsCt4dV5TmcWSbB3Y3J1PjILk/hUWfdqm09WUMvfnlaXOYSnS/+YLJJI0EAbsA2I0+qdVtS20afHbVccsPd9pwzZtVf4aL6tmr3zTNm3b6xvcTlfx8AAAZKN5RKYFVWZNyW1kr1bRkybgFgKNwI9+FrRynXn/30hNTfxU2JS+B6CNyCV0k21Llt7+4TjbDY5KwYTBtws2xVjdsyQ00vR5O/uDiRsyAp0qVB6ThD3aHDFY1mSwU4gnxklYOfMzRQ31btuvGpSnCeM2uPVkrBLW4OuHL9ITGth/3HgtGayhYGbWbdvrzljNM+R8PBr2lvmXSAKCTQXwk2uxLX1B2ZLO3fvilroIPlDS5/DQAAYErOhGNyY+TBcF8AWb4Lx6wA4Nl9L+TgLJfn+/RotUmpwDFp0gxI8E4I3IJXMZfJNynTmBEJ7hETFiROzgrcdvX20VlD9kJufJiYWu7KjFO5FEd9W7eo0+loda1dSsdQni4tr0utCAzwN8kEfHXbWfE/WfHeAWpslw6gXF2YTD9VZeYC9G9SNikzRlwurmqmL0/UaG4FnbzYSrWt0vY8qyBBdBJ3Nd7f3DtX6i7M/rij1OWvAQAAzNe4tatUAmrcAoAVAvz96FFVj5DfbTpJxyqblcSeEYYD++CdELgFrw/cTs5G4FYLcgxZt1VNxoYMjnKmppV6DXUnRyQaB8+uoj44oK6t7Ch7S4xlEjhgpEW3FmVSYmSwuLzxSBWt/PCQyEBmWfFhtPq2yeTPowoACwHJB64aqVx/6UvtZd1yTTGZq+vbqt0wOUOUAGKfHq1yWvkZAABwUuC2VgrcRoUGik7wAADWuGJ0kjLjizP3T15sUTL33ZFQAK6DwC14ZY1btYkZCNxqgdx9neOr1kwjs4W6vs9INwRu1QcH5GCl8+rbarPUAA8W7p6Tp/yPefoO4+zntT8sohhDOQkASzgrW54CxgdA1Nu9FmzXSOCWP2t3zcpRPmtv7kTWLQCAO3HwVZ7tdaFx8Bq3nT19dKGpQwm2oAs8AFiL9xerFhuzbmWob+v9ELgFr5LcL+OWC/4jYKQNOaoGZeUOzhBTNybzxozbPYYAVqC/H03PjSOt+tGMHIoINj3a++T3xonyDgBD4YzsFVeqat1+eUYzK621q1fUlGXZ8WFun9r6o5k5FBokDeH+8k0FNRlKkgAAgHu+v+RGyENl3J6rb1Nq/6MxGQDYakp2HC0en2pyG+rbej8EbsGrpPTLuJVrj4L7yc2rWHm9sbaXI8j1X9mIJOPfcZX4iGDl/R290EQ9fY4rBcE/AOQmFlOyYyk8OJC0ig+S3DEjW7l+89RMun16lltfE3iW70xIU4Kie0rqaX/ZJdKC3WfqqKdP+qU9b2SS2zOk4iKC6daiLKUZ53tflbn19QAA+Lq0GClxoKWrl5o7LR9MKzWUSWDuPggIAJ7pPxeOFjVvZci49X4I3IJX17iVm92A+2Ubatw6I+O22FAqIT48iBLC3RPYnGw4SNDZo6NThnpDjsy2ZbM0WiZB7cFrRtEtRZm0dGYO/c/3x7s9wAWehQehP72iQHNZt1vVZRJGu69Mgtqyy/NI/nit23XO4bXDAQDAvjq3VYOUS1A3JstPQuAWAGxXkBRJd1wmJcuEBPojWc0HIHALXiU5Ghm3npBxW1bvuMBtbUsX1bV2icujU6PdFihUZ3c7slyCaX1bbTYmU4sMCaTf3zqJnv7+eArrVzYBwBo3TsmgDMMP4C0na+loZZNbVxw3Sdt2UgrcBgX40ax8qSmEu+UmRtCCsSnick1LF/3j8AV3vyQAAJ+VEWtMHhmsXILcmIwh4xYA7PXEd8fS/944nt6/b6bStBa8FwK34FV4Gjl3aJV/YI9Nj3b3SwLVFDL+nzg64/akqkxCYZrU2MgdJmfFOLxBGQeM9pytU46mcqkEAG8XFOBPy+fnK9fXbHVv1u3Z2laloeLkjEhNlSu5b65xPf1xR4nYZ7hafWsXbT55iXacNmYlAwD4csbtYE14S+talcsI3AKAvbgh4g9n5FBRjnb7n4DjIHALXufK0cnifNH4NAoJRMaflqZAZ8WFK4FbRwUY1I3J3FnfZ1x6jGgexg5XOCZDkDOTLzRJ0+2m58Zjewafceu0LEoy1Cz/9Gg1nalxXPkRW201ZNuymTnaKr/Dg3X5gA7X+t5xWjrQ40wd3X207VQt/WZjMV33wg6a/psv6YlPS+nNneec/rcBADwhcDtYxq3ctyAtJlRTBwIBAEC78G0BXue5JZPpJ/PzaVSK+4J4YF5WfLio7cXNdOrbuh0yreN4Vf/ArVQ2wdVCgwJExu/RymY6VdMiutBz2QCHlUkYof0yCQCO/DzdNzePfrPxhOi+vWbLWVq9ZLJbVjAHKWWzc7U1i4NLw3DW7Yr3Dojrb+wooXmjHFuDt7dPR0cqm2jXmTraeaaODpQ1UreZBoxfnbtEXb19OMAEAD7JmsBtQ1s3NbRLjcuQbQsAANZC4Ba8MrOTsx9Be3JUDco4m9QRgdsThsZknOw6KjmSmhrcE7hlkzJjReCWA01HzjfRrGHWpN1tKJPAZntAYzIAR+LpX2u2nqXG9h765PAFWnnNKJMmh67A2aX7Si8p2VG58aYNMLVg4bhUyooPo4pLHSLjtriqmcak2R9g5tkQnBHGgVp+vj0l9dTS2Wt2WS4pPi49mqakhdG1E7MpAM0IAcBHpZvUuDXfnAyNyQAAwB4I3AKAWxqUVVxqH3ZNnp4+HZ2pkWqF5SdFUkiQe0tjTM6Kpff2lSsNyoYTuNXpuL6tlHEbFRJI41GvGXxMREgg3TMnj1ZvPkV9Oj2t3XaWnrlpgktfw96SeurulbJL549Kclvzw6EOVi6bk0e//udxcf2PO0rpD7dNsrnJIx8o2nm6TgRs5RItlvbjc0Yk0uUjEsU+LjYskGpqaig5OZH8/VGBCwB8E5c9iAsPEhm1lmrcymUSWF5ipAtfHQAAeDIEbgHALYFbzrgdLh4Ay1N23VnfVh24dVSDMi63wOUk2Iz8eAoMQEAEfM9ds3Lp9e0lovTIR/vP04NXj6TUGNdlvW49WaNcnj8qUdM1gTnA3dzZS/84XEmPLBpNKdGW11NbVy99VXpJlD7gQC3Xx7WEAxGzDYHaOQWJA7KedbqBZRMAAHy1ES8Hbi82d4oDjnxgTa2k1tiYLD8xwg2vEAAAPBECtwDgMuof/GWXjFkH9uIpwbLhTA12FM765bq2HGQ6fH54gdvdZ4z1bWehTAL4qJjwILpzllQygQ/ScBD3/7t+rMvr23LjwdkFCdTR3EBazU7+0UxpPfX06Wnd7nP06KJCkzq1h88b6tSerqMD5Q3UqzPfIDIk0J8uy4uXArUjEmlsWjT59ws+AACA+Tq33HuB9688k6H/gUZ1xm1+EgK3AABgHaRwAYDbSiUMlzpLTAsZt5xZMTFTqq9c1dQpMi4c0phsmLVyATzZssvzKDRIGq68/1UZ1be6po71ubo2OmeYGcBlXaJCg0jL7pqdS0EBUoD1vb1ldLSyidbtKqV73/mGJj+1mW5eu1tk5XITMXXQlqs/TMqMoRVXFND7986gw79aQH9aNoN+Mr+AxmfEIGhrgzVr1lBeXh6FhoZSUVER7dixw+KyVVVVdMcdd9Do0aNFiYmVK1cOWGbdunWiPEf/U2en/d8tAOA8Gao6t+bKJciBW95XZ6iamQEAAAwGGbcA4NL6X9yQrK61yyGlEk6oMm4LNZBxyyZlxSpBV65zy42DbMXZcftKpOeIjwim0SnuD0oDuEtCZAj94LJsenvXOers0dGbO0vpEVU2qbOzbdn80UmkdVwa4XuTMuijA+dFyYTvvrTT4rLczXzOiASRVTszP4Fiw4Nd+lq90fr160XwlYO3c+bModdee40WL15Mx48fp+zs7AHLd3V1UVJSEj3++OP03HPPWXze6OhoOnnypMltHBgGAG1m3MouNHaY9HLg3gVy4JYTGVACCwAArIXALQC4VE5CuAjc1rR0iY7tYcEBw864jQoNpPSYUNEN3d0mZZrWubUncHvsQjO1dEld3GflJyDjDXze/fPy6b295aJcwp/2lIls0JiwIJfVt71iVLJH/A/um5cnArf9JUQEG+rUJojyB5lxpnVqYfhWr15Ny5Yto3vvvVdcf/7552nTpk20du1aeuaZZwYsn5ubSy+88IK4/NZbb1l8Xs6wTU21/XsEANwfuFW70NRBXYZml1xaCwAAwFoI3AKAS3GWwf4yqU5kRUM7jbIzm7SxvVuUI2BjUqPFj1stBG6nZBsDt5xxO9wyCdy1HcDXccOXm4sy6YOvysVBjXd3n6OfXz3SaX+vs6eP9hiy3pOjQmhMWpQm9i9DKUyNpl9cNYL+tv88jUyJUurUcikZ1Kl1nu7ubtq/fz+tWrXK5PYFCxbQ7t27h/Xcra2tlJOTQ319fTR58mR6+umnacqUKRaX50xePsmam5uVJnKuaCTHf4M/K2hah/Xii9tLWkyIcrmyocPkfZ2tMZb3yksIH/Q9e9t6cRSsF6wbbDP4LHnTPsaWv4PALQC4rc5teb39gdviKuMAmIMqWpqunBodStXNnfTt+SYxNc7WgMnus3XKZdS3BZD8dH4B/eWbCtGp+81dpXTP5XmiKZczfH3ukijLwOaPStLMgSFrPLxgtDiB69TV1YnAakpKisntfL26utru5y0sLBR1bidMmCACsJyhy2UYDh8+TCNHmj9wwdm9Tz755IDba2trXVIbl3+ENDU1ic8L1+4FrBdf2l6Ce7uVy6U1jVRTY5y58W2p8XJCiM7kPm9fL46C9YJ1g20GnyVv2se0tBjjGUNB4BYA3Ba4LRtGg7IT1dqrbyubnBVLnx2rptauXiqpa6URydYHlrt7dSJoxDgAzLUoAYAoOyGcvjcpnTYcrKTG9h56f1853Tcv3ymrZutJz6pvC9rAAX41Hvj3v80WM2fOFCcZB22nTp1KL730Er344otmH/PYY4/Rww8/rFzngG9WVpaop8v1cl3xo4ffM/89BJywXnxte0lI1FOg/1HRALK+Q0fJycYyO3VdxoPyk/JSKTk53mfWi6NgvWDdYJvBZ8mb9jG29CxA4BYAXF7jVlYxnMCtKuOWpwFrySRD4JYdLG+0KXDL5RXkTL/ZIxKG9aMfwNusuKKA/n6okjj59fUdJbR0Vg6FBtlfJ3uoxmScLM/lBgAGk5iYSAEBAQOyazmjrn8W7nDwj4jp06fT6dOnLS4TEhIiTuYe66oAEH9vufLveQqsF+9fL/wWeOZVZWOHKOelfk8lhsZkrCA5asj3603rxZGwXrBusM3gs+Qt+xhb/ga+CQDA5VlzsrJ64yDW3oxbjmvaW27BWSZlxSiXD5+3rc7trjPqMgkIGAGocd3WRYaGf7UtXfTXbyocvoLON7TTmZpWcXlKdhzFhgfjnwCDCg4OpqKiItq8ebPJ7Xx99uzZDlt7nMF76NAhSktLw38EQKMyDA3KGtp7qL1bajTLSg2B26iQQEqMxPcKAABYD4FbAHCppMgQCjNkyJXbmXHLNS5PXpQybnPiw51W59JeEzNjRUCZHa5osumxe9CYDGBQP7tyhHL51W0l1NOnc0q2rVzfFsAaXJ7gj3/8I7311ltUXFxMDz30EJWXl9Py5cuVEgZ33nmnyWM4CMsnbkDGNWj58vHjx5X7uVbtpk2bqKSkRNy3bNkycS4/JwBoT3qscerrhcZOpeElZ+Gy/KQIzKYCAACbaCvaAQA+Mf2A69xy4LVCdNy1vXkXZ+rK5QS4i7rWRIYE0sjkSDp1sZWKq5rFgN2a6dycmXGwokFczk0IV7I2AMBofEYMXTk6ibacrBU/hP9+sJJunZbllPq2V6C+LVhpyZIlVF9fT0899RRVVVXR+PHjaePGjZSTkyPu59s4kKs2ZcoU5fL+/fvp/fffF8ufO3dO3NbY2Ej333+/KMEQExMjlt++fTtddtll+L8AaFS6aux2obGDRiRHUll9uyjxw9C7AAAAbIXALQC4XJYhcMuNuC62dFJajG0ByhPVqvq2adoqkyCblBkrArfcoOLYhWYqyokb8jHfnGugnj5pZD8LZRIALHrgqhEicMvWbD1LN03NpAAbDwCZw/uk3YZyJQkRwTQ+3Vj2BGAoK1asECdz1q1bZ7b0wWCee+45cQIAzw3cstI6qfwOy0uMdMvrAgAAz4VSCQDg1gZlnIVgK85ilWkx45ZNzo5VLh+usK7O7W5VmYTZBQlOeV0A3qAoJ55m5scrdQM3HqlyyPN+U3aJ2rr7xOV5o7ijLJoDAgCA9TLMBG7Vjcm4VAIAAIAtELgFAJfjUgmycrsCt8aM27Fp0ZrNuJUdsjJwu+essTHZzHwEbgEG8/OrRiqXX9lyRpRdGS7UtwUAgOFIU9W4rTTUuC2pNQZuUSoBAABshcAtALhctirj1p4GZSeqpYzbiOAAyozTZh3Y0alRFBIo7WIPnx86cNvU0UNHKqVGZqNToigpKsTprxHAk3FW+uSsWKV8yr9P1Az7ObcZyi9wc8G5IxOH/XwAAOC7pRKqmuRSCQjcAgCA/RC4BQC3ZtyW2Ri4be7sofMNHUpwVKtTmYMC/GlCRoxSDuJSW/egy39VeonkhMFZKJMAYFWjwweuHKFcf3nLmSFrhg6muqlTqZ89MSOGEiJx8AQAAGwTHRpEUSGB/WrcSoHb1OhQijDcBwAAYC0EbgHA5ThLljPa7Mm4PWXSmEybZRJkkwzZgNZk3e5WlUlAfVsA61w9JpnGGPYDXEt61xljnWhbbT8lZduy+aOT8S8AAIBhZd1eaOqkhrZu5eA9yiQAAIA9ELgFAJcLCQygtGipBlh5vXH6mDWKVYHbMalR5DGB2yHq3O4xNCbjBOIZqG8LYHXW7c+uLFCuv/TlabvX3NZTxlIL80cl4T8AAAB2STfUue3u1dHX5y4pt6MxGQAA2AOBWwBwa53bhvYeUf7AWieqpPq2npBxOyXLugZlda1dyhRtLq8QExbkktcH4A0Wj09TfgzvK71E36h+JFurt09HO05LWe/8+ZNr5wIAAAynzu2uM8YZVci4BYt0fURdrURt9UTdbUQ6HVYWAChQZAcA3CInPoL2lkgBlvL6dhpvqAc7FDnAKde41XpJiPiIYDFFjjNuuf4mZwhayrZlswrQEAnAFgH+frTiihH0n389rNS6XXf3ZTY9x8GKRmrp7BWXuSkZPycAAMBwA7c7VIFbZNx6KA6i9nYQdbcT9fCpg6inzXDOp/Z+96nvl+/rGPyxfV0D/25QBFFwOFFwhOGyfD2SKCjc9HJQOIV36YgSUg3LRZp/LF8OQAgIwNPgUwsAbs24ZRWXrAvc6nR6JeM2IzZMNIDQMg7STsqMoS0na0VmccWlDpP3LdutCtyivi2A7W6YnE7Pf3FKNC7cerKWjpxvogmZ1h0MYttOqurbokwCAAAMA49RZSW1xpJg+YmRWK/Ows1J+7qlbFURDG0znsT1VilAKq7L97WbXuZllMeqrvd2uuf/JgK8bURtxjHKYNOorZ6HGBBiCOQaTmFxROEJROHx0nmY4Vw58fV4opAYIn9M2AZwBwRuAcAtsuONAcwyKxuUcVCmrbtPXJYbEmnd5Kw4EbhlBysazAZu9xgakwUF+NG03DiXv0YATxcU4E8/mV9AT/z9qLj+ypYz9OrSIqsfj/q2AADgKGkxUo1btUB/PzETC6zU00nUXEnUdF45+TVVUFxdGfn59fQLsBoCnDpp5ozmBQQTBYUZMmX5PMJwHkYUGCIFivu/Nz53VACZs3s7+GRjaSm/ACmAqwR2+58bTuJ+w22hMZzJ4pjXDeDD3B64XbNmDf3ud7+jqqoqGjduHD3//PM0d+5ci8tv27aNHn74YTp27Bilp6fTI488QsuXL1fuX7duHd19990DHtfR0UGhoQO/RAHA/YHbcisDt8XVxvq2Y9K0XSZBNinLmPV3uKKJbpicYXJ/ZWMHnauX3v+UrDgKD3b7bhnAI91alEkv/fs01bR00WfHqunUxRYalTL0fqK2pYuOVkr7lrFp0ZRsaJwIAAAw3FIJMj5wHxiAbEUlO5azSJsqiJrUwdkK4+U2Y8NQGYf/Qpy+SfoZygsYygzIl9WBVlFyQH1b//vlQKyFZewtVcB1cM1mFLeRrquNmuuqKDosgPzl8gsmGcTq7GPVdXkZa+j7pP+bFRnAA4K9SlA3jigkWpXxG2ma/Wtyvd9llHgAH+bWCMH69etp5cqVIng7Z84ceu2112jx4sV0/Phxys7OHrB8aWkpXXfddXTffffRn//8Z9q1axetWLGCkpKS6Oabb1aWi46OppMnT5o8FkFbAG3JUWWeco1ba5yoMta3LUz1lIxbY5Ojw+cbh6hvm+Cy1wXgbUKDAuj+efn0P/8qFtfXbDlDz98+ZcjHbT9l/AFyxegkp75GAADwfqkxoSLJkOOTPlkmgYOGIltWFYg1CcxWmq/pagsOCJrUcTXUex20JqwqQGhpeQ6uajVD1D+AKDRaOvWn01FnTQ1FJyfbXs6As5s5+7adT/XGU0eD6fV21TKcBeysYK8lgaFWBHj7XQ8Mo5C2LqKGROnxAUFSVjOfc+azOFm47B/onm2BdxycPd7XQ6TrIerrla6Lyz2m9/FlP3/ptfrzaw+SthPlcqDxJF/X6vYN2g3crl69mpYtW0b33nuvuM7Ztps2baK1a9fSM888M2D5V199VQR0eTk2ZswY+uabb+j3v/+9SeCW60qmpqa68J0AgK24c3tUaKBoCGRtxu0JVcZtoYdk3MaGB1NuQrjIqj1a2UQ9fToxrVu221AmgaG+LcDw3DEjW5RJ4JrS/zh8gR66dhTlJEQM+phtqsAt6tsCAMBw8TgvJSqUqps7vbMxWVcrUUMp0aVSosaygYFZDuzZzY8oKo0oJlN1yhLnuugMqu0KoqSMPPIPCkUAylF4XQalE0Wn2xHstRDYFYFf+bIc7LUys9cSLhXBJxu2L/7FNawidAMCuuqgr7mAbxCRXmcMsA4IwKoDrxbuc3bJD78A8gsIomTDuRTQNQR1OavZ7GVVEJgPdoRESTWPxXmUdDBBvswZ1SGq6xxIR21kzw3cdnd30/79+2nVqlUmty9YsIB2795t9jF79uwR96stXLiQ3nzzTerp6aGgIKlRUWtrK+Xk5FBfXx9NnjyZnn76aZoyxXLWTVdXlzjJmpul4JBOpxMnZ+O/wd3m2IWnUQAANG9JREFUXfG3PAnWi/evm5z4cDp6oVmUC+jq6TUJaJpTbGhMFhLoT9lxYQPev1bXy8TMGBG47erVUfGFJqURG79WOeM2NMifJmZGO+W1a3W9uBvWi/etl9BAf7pnTi79YfNp0umJ1m49S7+5cbzF5ft0etpxWgrcRoYE0uSsGIvv25PXizO5Y73gfwAAWpceaxq4zUuM8LxSBhyYlQO06vPhZE8GR/ULyhoDs+LEwUMOEpnD3zc1NVLGJLIGPTDY2yEFceUSDepyDSblG1oGuU91fbiBYGtwwzs+eRN9H/n19onSI9Tjij/opwrqyoFd1XWug2z2PkN2OZ+HxUrZ8D7MbYHburo6EVhNSUkxuZ2vV1dXm30M325u+d7eXvF8aWlpVFhYKOrcTpgwQQRgX3jhBVGG4fDhwzRy5Eizz8vZvU8++eSA22tra6mzs9MlP0CamprEDx9/HI3AevGhbSY5wl8Jnhw5W0mZsZYrV3X09FGZoaRCfkIo1dfVesx6KYg17mp3Fp+n5CDpQFF5QydVNUn7mIlpEdR0aTgZCpZpdb24G9aLd66XRQXh9Oo2f2rr1tHf9p+nOybGUnJUsNllj1a1iexcNi0rkhrqjRnw3rZenMUd66WlxVg2BwBAq3VuD5QbS2Tlay1wyxl+nCE7IDB7TjpxgMye8gUcyBssMMtBGvBNHHiLMe31MSxc89ekZu/AYLCuq5VaG+spMiyY/EWGqyEQy5muJuf9L3dbv6w1RDmDfuUL5ExXObN1wH3qZcyUQJDPRWkFcyUV+kzLK6gyffW6Hurr7qQAPyK/AY9VXXZI9q+eqKtZOg1HQIi0/+Agbmis4TxGddnCbXJg2MMP9ri9Cw6XNVDjgX//24ZaXn37zJkzxUnGQdupU6fSSy+9RC+++KLZ53zsscdEwzMZB3yzsrJE7Vyul+uKHz38+vnv4ccg1osvbTMj0xroy9PSoLbNL4ySkxMtLnuoopF3+8L4zHhK5hpOHrJeLh8TRM9tqxCXzzb2Ka/9i9JyZZn5Y9LMvidH0Op6cTesF+9cL/wpumt2K63ZepZ6dXr6+Hgz/X/XjzW77JEjp5XLCyZkDvoZ9PT14izuWC/oWwAAWpfRr0FZnjtKJXCtWQ7CXioZGKDloK09QRkuYxCXRxSfJ53H5RLFGgKzkaloIAWuw4FMOTvTEp2O2mtqKNKe2r821aNVBXTlmrNKIJbPtTVu1Ot0VFdTI8a9foO9NvH++gWAOTDe1WI4GQKyfLnTcK6cmkyvy/dbWx+5v74uqWmhmcaFVh1UUoK+gwR7Q2MomHOqwmcRRaeRlrgtcJuYmEgBAQEDsmtramoGZNXKuG6tueUDAwMpIcF8Ux/+ETF9+nQ6fdr446y/kJAQcTL3WFf9COEfPa78e54C68W714269mRFQ8eg7+XkReOR/zFp0RaX1eJ6GZcRS0EBftTTp6dvzzcpr21P6SVlmTkjnBv00OJ60QKsF+9cL8suz6O3d50TmfofflNBD1w9khIjB37PbztlzLC9YnTykO/X09eLs7h6vWD9A4DWpcWEKpe5FE+Sme8gh+GASvURovK90rkcnG01P4t1UBxois02Dc6qg7Rc3xIAJJw8KNeJJY1l1Tvs/Rnq3cqlCsLjh/ecnNHL5TAGBHXVgV9VMLizyXBqJOpolM5tnRHATfK45jKfBsGjWH53uu+9QjT1R6QlbgvcBgcHU1FREW3evJluvPFG5Xa+fsMNN5h9zKxZs+if//ynyW2ff/45TZs2Talv2x9n5B46dEiUTgAAbclJMA7+KoZoUHbCUN9WDtx6Wrd7fs0ctD1T20otnT0UERxIew31bblJ2/h0z3pPAFqWEBkiGpW9ubOUOnt04vzRRYUmyzS0ddPh81LG/6iUSDGtFQAAwBHU3yncmGywGaU242DG+a+JKvYRle8hOv+NbfU+uVmQCMjmDgzQRmciaxYAnIeDwGFx0mk4wd9OdTC3QbouB3bl8wG3GYLAyjxeCzgLV2PcWiqByxMsXbpUBF45KPv6669TeXk5LV++XClhUFlZSe+++664zre//PLL4nH33XefaFbGjck++OAD5Tm5Vi2XSuB6tlzygMsjcOD2lVdecdv7BADzsuONgVu5fq0lxdXGmoaFqYNMidGoSZmxInDLM06OnG+iuIhgqm+T6iLNyEugwCEaswGAbe6fl09/2lNG3X06cb58XgHFhBsP8m4/XSs+j3K2LQAAgKNkxoU7rr5t8wUpQFtuCNRePCp1rh9MRNLAoGx8vnQ5ItHj6z0CgI8HfyMSpJOtuJkuZ/SaBHOly7qOBmqvv0DhiaNJa9wauF2yZAnV19fTU089RVVVVTR+/HjauHEj5eTkiPv5Ng7kyvLy8sT9Dz30kAjEpqeni8DszTffrCzT2NhI999/vyipEBMTQ1OmTKHt27fTZZdd5pb3CACDTyML9PcTdSjLB8m45cx5OeM2NTpUBD09zaSsWPrT3jJx+dD5RgoJDFDum11gx5cOAAwqJTqUbpmWSe/vK6fWrl5at/scPXiNsUnptlPGBofzRyVhbQIAgMOMSYui70xIo4PlDfTjOXm2BRVqjlPYsc3kt+uYlFXbaPw9bFZ0BlH2TKLsWUSZ04gSRgxe9xMAwFf5+0sZtXzqn/Sr01FrTQ2FJ2gvocPtzclWrFghTuasW7duwG3z58+nAwcOWHy+5557TpwAQPs4yzQzLozO1beLwK2l5oRVTZ3U3Ck1UChM88yB6OQs45SLwxWN1KczTtGYPQKBWwBn+On8Alr/dYX4vL29u5SWzc0TtQZ1Oj1tNwRuw4MDaFruMKZrAQAA9MPj2Vd+OHXIxtvU00l04YAho3avCNT6dzZRjMUH+BGljCPKmiEFajlgy83BAADAa7k9cAsAvi0rPlwEbjkjrqG9h+LNZNOeqDbWty1M9cxasDxNLiokkFq6eulAeSN1dveJ2xMigmlUsmcGowE8Yf9yw+R0+vhAJTW299B7e8voJ/ML6HhVM9W1disZ7+oMeAAAAEcZELRtqzfWpuVA7YWDUsd2SwJDiTKmGTJqZxJlTtdk/UUAAHAeBG4BwO0Nynacli6X1beZDdwWV7WYTD3zRP7+fjQxK4Z2namn2pYu5faZBQniPgBwjhVXjKANBytFPds3dpTSXbNzTcskoL4tAAA4A3/xXCoxDdTWnRr8MeGJpM+aQS3x4ylyzDXknz6ZKNDzSoQBAIDjIHALAJppUMblEqZkD5yyXGyob+vJGbdyuQQO3Kqhvi2Ac41IjqTrxqfRv45UUV1rF/3lmwraerJGuX/+SNS3BQAAOzubt1QRNVUQNVYQNZUTNZ03XObTeaKewZvvinq0WYZsWi59kFAgyiu019RQZHKyVI8RAAB8GgK3AOBW2fHGTrvl9eYHtyeqpYzb4AB/yk8aZmdeN5qUOXBq2+yCRLe8FgBfsuLKAhG4Za9sOaOUSeASJtkJxoNHAAAAip4OKfiqBGb7nTdXEuml0ldW8Q8kSptsLHvAAdvIJPOZugAAAAYI3AKApjJu++vs6aOS2lYlcy4owHMzD9QNylhaTCjlImgE4HTj0mPoqsJk+vJEDV1sNpYqmT8a2bYAAD6ro7FfMLbc9HqbsayOzQLDpKZhcXlEWdOlIG1GEVEwDhYCAIBtELgFALdSZ7uVmQncnqlpJZ0h8aDQQ+vbypKjQyk9JpQuNHWK67MKEgbvNAwADvOzK0eIwK3a/FEI3AIAeLXuNqKaE0Q1x4lqionqzxizaLuMpbhsFhZHFJNJFJMtBWhjslTn2UThCdyZzJHvBAAAfBQCtwDgVpEhgZQQEUz1bd1UYSZwq65vO8aD69vKJmXF0oWmanEZZRIAXKcoJ07UlN59VqozHRLoTzPzE/AvAADwBr3dUlBWBGgNQVo+bzhnx5P5EUWl9gvGZqmCtJlEIZ6dTAAAAJ4DgVsA0ETWLQduq5s7RWmE0KCAAfVtvSHjll0/KZ0+PVpNceFBYuo2ALjOA1eOUAK3nPGu3tcAAIAH0OmIGs9JgdmLqiBt/WkiXa91z+EfJAVfTYKxqiBtdAZRYLCz3wkAAIBVELgFAE3UuT1Y3ih6MZxvaKcRycYA7YlqY8ZtoRdk3F43IY2+eHgexUeEUHwEfhQAuBIHax++dhTtOVtPv/zOWKx8AACt4kFhS7Uqe5ZPx4hqTxL1mG9mO0BQBFFyIVHyWMNpDFHSaKLIVCJ/z+2ZAAAAvgWBWwBwu5x+DcrkwK1er6fiKinjNjEymJKiQsgbqAPTAOA6XFP6F1ePFCcAANBQk7A6VR1aucxBR4P1GbSJo6TAbIoqSMvZtAjQAgCAh0PgFgDcLksVuC2rN2ZR1LZ00aW2bq/JtgUAAADw6UZhnDFrCMz61RRTUvVR8m+7aOUT+BHF5xkDs3ImbUIBUUCQk188AACAeyBwCwBul5MQYZJxKytW17dNRZYqAAAAgGc1Civu1yhMryzmR0QWK41HpRuCs2NUZQ4KiYKNB/sBAAB8AQK3AOB2OQmqUgmqjNsTVcb6tmPSkHELAAAAoBm6PikYqw7O2tgoTBcSQ34pY8kvZZwxSMsB2vB4p798AAAAT4DALQC4XVJkCIUE+lNXr84k4/aEOuM2DRm3AAAAAG5pFNZ8wTQ4y+dc9qC3w7rnCAqXArJKmYMxpEsqpJp2f0pOSSE/1KIFAAAwC4FbAHA7f38/yo4Pp9M1rSJwq9PpxW3FhozbAH8/GpEc6e6XCQAAAODd2upNg7NyNm1Xk+2NwtRlDmJzBjYK0+mIOmqc8jYAAAC8BQK3AKAJcuCWs25rW7soLjyYzta2ivsKkiIoJNBiFTQAAAAAsEdPJ9G5HUSnPiM6/TlRY7kNjcLyTYOzaBQGAADgcAjcAoAmZKvq3JbVt1NDezf19EkNLApTUd8WAAAAwCGaq4hObyI6tYmoZCtRj7FMlVnRmWYahY0mCgrDPwQAAMDJELgFAM1k3Mq4XEKgP/calqC+LQAAAICduCTBhYOGYO1nRFWHLZc5yLqMKGW8KkhbSBQag1UPAADgJgjcAoAm5Kgybsvr20TJBNkYZNwCAAAAWK+rhejsFimrlksgtFmoJRuRTDRqAdGoRUT5VxCFoBksAACAliBwCwCazLi91N6jXEfGLQAAAMAQLpUQnfpcyqo9t5NIZxxLmUibJAVqRy0kSpsysGkYAAAAaAYCtwCgCZlxqhq3l9qpsqFDXI4ND6LU6FA3vjIAAAAADerrJarYK2XV8qnupPnlgsKJ8q+UMmtHLiCKTnf1KwUAAAA7IXALAJoQGhQgArTVzZ10oqqFOnr6xO2FqVHk52esdwsAAADgs9ovEZ35Qsqq5fPOJvPLxWRLGbWcWZt7OVEQDoIDAAB4IgRuAUAzshPCReBWDtqyQtS3BQAAAF+l1xPVnpACtZxVW7GPSG/sA6Dw8yfKvMwYrOXmYjjwDQAA4PEQuAUATdW5/ar0ksltY9LQJAMAAAB8iE4nBWiPbSA69SlRY7n55UJiiEZeIwVqR1xDFB7v6lcKAAAAToZK9ACgGTmqBmUyZNwCAIAnWLNmDeXl5VFoaCgVFRXRjh07LC5bVVVFd9xxB40ePZr8/f1p5cqVZpf76KOPaOzYsRQSEiLON2zY4MR3AO4P1n5F9OkqoufGEr29iOir1wYGbRNHEc3+OdGP/0X0yFmiW94imngbgrYAAABeChm3AKCpUglqPMNvVAoybgEAQNvWr18vgq8cvJ0zZw699tprtHjxYjp+/DhlZ2cPWL6rq4uSkpLo8ccfp+eee87sc+7Zs4eWLFlCTz/9NN14440iaHvbbbfRzp07acaMGS54V+CSMgiVB4iOfUx07O9EzecHLuMfJNWo5axabi4Wn49/DAAAgA9B4BYANFUqQS0vIYLCggPc9noAAACssXr1alq2bBnde++94vrzzz9PmzZtorVr19IzzzwzYPnc3Fx64YUXxOW33nrL7HPyc1x77bX02GOPiet8vm3bNnH7Bx98gH+MJwdrqw4RHTUEa5vKzQdrufTBuBuJRi8iCo1xxysFAAAADUDgFgA0IychwuT6mLRot70W0NiPXF0vUV8PUV+36lx1mQWGEAUE9zvnE77qAMB5uru7af/+/bRq1SqT2xcsWEC7d++2+3k54/ahhx4yuW3hwoUicAseRq+nwLrj5HdkLdHxvxM1nBu4jH8gUcFVhmDtdURhse54pQAAAKAx+DULAJoRFx5EkSGB1NrVK64XpqJMgksCor1dqiBol2lgtFcOkKrvVwVMxWPVgdR+AVWTyz2D3N5NpLN0vyEway/utM0B3MBgw7kU2PULDKYEvT/5hURYCPqqgr/KYw3nQaFEQRFEwXwKJwqOJAric/m2COl+f5SSB/B2dXV11NfXRykpKSa38/Xq6mq7n5cfa+tzcgkGPsmam5vFuU6nEydn47+h1+td8rc84ju25hj5Hfs7+R3/OyVeOjtwEb8AovwrSD/2+0SF3yEKizPe6QPrENsL1gu2F3yWsI/BvtdXv5N0NvwdBG4BQDP8/PxEuYTjVdIPzUJk3A78EdjTQdTZZDx1NRsuNxJ1Npu5vYn8OpspqbOV/KhvYIDVF+h1RL0d0knFj4iCnP23A8MMgV1DIFcd2BW3GYK+A5bpFwwOCjMfSA4IkopBA4AmvsPUePDf/zZnPyeXZXjyyScH3F5bW0udnZ3kih8hTU1N4nVy0zVfFHDpDIWd3UihZz+lwMaSAffr/fypO30mdRYsps68a0gfFi/d0dJD1FJDvgTbC9YLthd8lrCPwb7XV7+TWlparF4WgVsA0JQRyZFK4HZserT3BV6724g6GgYNtA44qe/jDFkb8U987VYK9pMCkuIUZOZyUL/LZpbl6aVMyQCWz7sMGcPmzrtIb1jOT9/nvLcnB4zb6533N1RZxMq5uGyaYTx4FrHqsn8whbV3Ep2Pk9azf4C0jjlzmc/FiW8LIOJsMUfcxs/N/wcOsusM5+qTcltfv9v0Fh5nuM/S40gv/U0/1WsR76/fufp+XtXNDUQhXYaAufp+f9Xj+t2GwLrXS0xMpICAgAGZsDU1NQMyZm2Rmppq83NyHdyHH37YJOM2KytLNEKLjo52yY8eDizz3/OpwG3daaJjG8jv+Abyqz1hPlibNp0CJ91KfmO/R0ERSeLAoa/PK/LZ7WUIWC9YL9hm8FnCPsb7972hoaFWL4vALQBoyoorC6iutYsuH5lIGbFhpPkArDhdMl5uly83DryPT27IctUHR5IuIJT8g0LITwncqYOgqpMSxJPvVy1r8XFBqoCh+nGBQwRlOUjovpCyXqcTQZDkxATyF2UazAd4BwaEu6XM5552aTuQTz3yZb691cz97dLJ0UT5CuPU6OHiYQra4JhfL0n2rFA54B0YKn1OhjwPs3I5PueSHaGD3MeZ2k7PK/d5wcHBVFRURJs3b6Ybb7xRWR98/YYbbrB7/cyaNUs8h7rO7eeff06zZ8+2+JiQkBBx6o9/gLgqMMY/elz599ym/izRMUODsYtHzSzgR5QzW9Ss1Rd+lxra/Sg5Odn714uNfGZ7sRHWC9YLthl8lrCP8e59r78NfwOBWwDQlMLUaHr/vpmu+4N9vUStF6WMyP5BVhGEdXMAloM+IdFSR+n+J5Pbo83fFxItMn1qOUCZnEx++GE0EAePAzm4Fe78/yfXMpIDutYEevl2vp8DxeYCyUodYgtBZg5Ig3txlq/8v3JcfN16nAHMAVw+cVBYDvSK63webrgtzPTcZHn1ufxccmA4hPzbeTsNl/ZDPoqzXJcuXUrTpk0TAdfXX3+dysvLafny5UombGVlJb377rvKYw4dOiTOW1tbRSkDvs5B4LFjx4rbH3zwQZo3bx49++yzIgD8ySef0BdffEE7d+5007sE0VTsKAdrNxBVf2t+hWTNlBqMjb2BKDrNuO9v960yCAAAAOAYCNwCgPfizFgOyDadJ2qulM5NLlcStVRJ06idiQMjXMOOm45wl2j5XAmy9g/KqoKwXOd0uFOtfaDBicfgwHlIpHRyBZ0cNDQ0kbNYQsIY7NX1dlJLQz1FRUaQPxlKC4hTr3Tiz4vdt+kMl/vf1mem5IChFIFym1x6wNxy5q4HWH4cf6aU8gpyqQVDSQV1eQVV+QW9rpc6O9opNDiI/EzKNahLNfBjVOUalNu4CSCv305pXYsSGnzu/Jqj4u+LAwCtTnl6zhVI5j8Tl0v04GHyVUuWLKH6+np66qmnqKqqisaPH08bN26knJwccT/fxoFctSlTpiiX9+/fT++//75Y/ty5c+I2zqz98MMP6Ze//CU98cQTVFBQQOvXr6cZM2a4+N35OC5TxIHawx8Sle8xv0zmdKJxN0nB2pgMV79CAAAA8GII3AKA5+pqkYKvIhh7nvwaz1PMxTPk110vBWf55MjAiAjAxhmCsIYAbLgckJVPqut8X2islKkG4A4ctPQ3TKe3lk5HHTU1FJWcLD0elNIaTTU1FOLIzHU+uNSnDuiaOe/hy52DL9M/GCw/hjO1+XZxvcP0dkdnY3P2rY9bsWKFOJmzbt26Abdx84uh3HLLLeIELsazcUq2EB16n+jkRvNjifSpROMNwdrYbPyLAAAAwCkQuAUAbeIARPMFC9myhutdTSYP4bxUm0IH4QlE0RlEMZlEEUmDB2H5hAAsADgSZ/6KmrQDa5K6JDA1IKhrOOcyHUrgt995v9v0Pe3U1dZEIUkFrn8PAI5WfZTo8AdER/4qlVHqL6mQaOISKWDLWeYAAAAATobALQA4FmcQcdCVs2G7mg3n6lOzhdtVy3c2E7XXDe91cIkBOSjL0xajM00vR6cTBbugpikAgBaJ5oFRRCFRw85EbpRraDvsxQG4UGuNFKjlgG31EfMHeSfcSjTpdqK0ycMvXwQAAABgAwRuAWBgFlZno6Exl6oplxxQHSroyidnN0QKCJYCryIYawjORmeQLiqdLvWFU3zeRPLnUgb4cQUAAAD9cWb5qU+JDn1AdOaLgbXu/YOIRi8imnQH0YhriAKDsQ4BAADALRC4BfBW3CCHSwlw0LW9wRiE7R+QFdflyw0Dyg+4FDcP4sZcwVFEkcmGDFkpKGuSLctlDczVmNTpqLemRmrqhaAtAAAAqGcEVXwlZdYe+1hqOtZfxjQps3b8zVL5JAAAAAA3Q+AWwBMyYDmblQOrnAnbwacGCqspJzphyI41F5DlE3c2dwXOgA2JlqbcipP6ctQQtxtu44BtYCgCrgAAAOA4DWVE366XAraXSgbezweHuW7tpB8QJY3CmgcAAABNQeAWwBV6u41BV+W8ycxthtvVt3W3DHg6zjWNcegL9CPi0gJyMy7RpEt9OU7KYrUUdHVHYx0AAAAAc7hs0/FPpFIIZTsH3h8UQTT2e1J2be4887N4AAAAADQAgVsAezJg22qJWqqkjsPivMaQ5WohIMudul2Fg6lyEFYOug4WkBVB2Vj8aAEAAADPpesjKtlKdPhDouJ/mhl7+RHlzZXq1o65nigk0k0vFAAAAMB6CNwCyPp6pABsazVRi+qkvs6BWl6G9M5db9wUg4OvHFAV5zGqy7GkC4mmlt5AikrJIX/udqwOwgYE4X8KAAAAvqHmBNHh94m+/Yt0ML2/hBFSGQQuhxCb5Y5XCAAAAGA3BG7BRwKynBkrZ8daCMy21Tk2IBsYNmjwddDbgsIHr/Wq01FHTQ1FJScjUxYAAAB8p8FY03miin1So7Gy3UQXjwxcjsdUE26RArYZRaifDwAAAB4LgVvw3Olw7fVS9msbn+qMl1trpXM5MNvOAVkH8Asgikwhiko1niL5PEU656xXdfAVdV8BAAAA7NfbRVT1LdH5r4zBWnNZtcw/kGjkAilYO2ohxmEAAADgFRC4BW018GqXA7BcQ/YiRVwsIT/qIGrnYGytMSjLQVu9zjF/lwf66gDsgMCs4cQlCfwDHPM3AQAAAMAUz45SB2kvHCLq6xp8LaVNloK1nGEbkYg1CgAAAF4FgVtwblYsN+oSTbsajAFZdVascl4jNfJS4f6+UcOtEyuCr+ayZNOkQC2fc7MudBMGAAAAcG2z15pjUoBWnPYRNZYN/pjgSKLMaUSZlxFlzSDKLJLq+wMAAAB4KQRuYehaYj0dxuArB1fF5cahb+OgraMFBBNFJBNFJvU7TyaK4MtJhsvJ0kAeAVkAAAAA92u/RHT+a2OQtvIAUU/b4I+Jy5MCtFkcqL2MKHksZj8BAACAT0Hg1huzXLkeGE8r49IDfYaTfBs36uLLvZ3WBV/5nB/vTEER/QKwieKyLiKRmnpDKCZ9BPmLTNkkopBoNJgAAAAA0DIuZ1VzyljygMsf1J0a/DGBoUTpU4myphuyaS+Txn4AAAAAPgyBW3fraiW/nc9TZEsD+YUESoFVJehqIfg62G36Pve+Hz9/Q4OuOMPJcJlvG5AVazgPjjD/XDodddXUECUnI3MWAAAAQMvK9xKVbKO4szvIr/bboWdeRWcag7ScTZsygSgw2FWvFgAAAMAjIHDrbn3d5LfjdxRJGsNZsOrAK58rAVlVYLb/bcFRCLICAAAA+Jo9L5N/8T8pxFIj2LRJhkxaDtZeRhST6frXCAAAAOBhELh1t0Czw1vL/AKkx3CtV/lcfdnibUFEASGq20L7BWP7Zcci4wEAAAAArMVB2eJ/iov6iCTyEw3EDE3E0icTBYVhXQIAAADYCIFbdwsMI90PP6LG5jaKTUwh/6DQwQOy/gHufsUAAAAAAKZGX0e68ESqDyughBFF5BeAMSsAAADAcCFw627+/kQFV1E3arkCAAAAgKdKKCCKy6M+HtP6+bn71QAAAAB4BX93vwAAAAAAAAAAAAAAMIXALQAAAAAAAAAAAIDGuD1wu2bNGsrLy6PQ0FAqKiqiHTt2DLr8tm3bxHK8fH5+Pr366qsDlvnoo49o7NixFBISIs43bNjgxHcAAAAAAAAAAAAA4EWB2/Xr19PKlSvp8ccfp4MHD9LcuXNp8eLFVF5ebnb50tJSuu6668RyvPx///d/0y9+8QsRqJXt2bOHlixZQkuXLqXDhw+L89tuu4327dvnwncGAAAAAAAAAAAA4KGB29WrV9OyZcvo3nvvpTFjxtDzzz9PWVlZtHbtWrPLc3Ztdna2WI6X58fdc8899Pvf/15Zhu+79tpr6bHHHqPCwkJxfvXVV4vbAQAAAAAAAAAAADxBoLv+cHd3N+3fv59WrVplcvuCBQto9+7dZh/D2bR8v9rChQvpzTffpJ6eHgoKChLLPPTQQwOWGSxw29XVJU6y5uZmca7T6cTJ2fhv6PV6l/wtT4L1gnWDbQafJexjsO/VCnwnaWe9YLwEAAAAAL7CbYHburo66uvro5SUFJPb+Xp1dbXZx/Dt5pbv7e0Vz5eWlmZxGUvPyZ555hl68sknB9xeW1tLnZ2d5IofIE1NTeKHj7+/28sOawbWC9YNthl8lrCPwb5XK/CdpJ310tLS4pK/AwAAAADgs4FbmZ+fn8l1Hvj3v22o5fvfbutzcjmFhx9+2CTjlks2JCUlUXR0NLniRw+/Pv57CNxivWCbwWcJ+xjXwL4X6wXbi2d+jrhBLQAAAACAL3Bb4DYxMZECAgIGZMLW1NQMyJiVpaamml0+MDCQEhISBl3G0nOykJAQceqPf4C46kcI/+hx5d/zFFgvWDfYZvBZwj4G+16twHeSNtYLxkoAAAAA4CvcFiUMDg6moqIi2rx5s8ntfH327NlmHzNr1qwBy3/++ec0bdo0Ud92sGUsPScAAAAAAAAAAACA1ri1VAKXJ1i6dKkIvHLA9fXXX6fy8nJavny5UsKgsrKS3n33XXGdb3/55ZfF4+677z7RiIwbk33wwQfKcz744IM0b948evbZZ+mGG26gTz75hL744gvauXOn294nAAAAAAAAAAAAgMcEbpcsWUL19fX01FNPUVVVFY0fP542btxIOTk54n6+jQO5sry8PHH/Qw89RK+88gqlp6fTiy++SDfffLOyDGfWfvjhh/TLX/6SnnjiCSooKKD169fTjBkz3PIeAQAAAAAAAAAAADyuOdmKFSvEyZx169YNuG3+/Pl04MCBQZ/zlltuEScAAAAAAAAAAAAAT4ROWAAAAAAAAAAAAAAa4/aMWy3S6/XivLm52SV/T6fTUUtLC4WGhqJTMtYLthl8lrCPcRHse7FesL145udIHp/J4zWwDGNabcD3DdYLthd8jrCPwb5XK/CdpI31Yst4FoFbM/ifxbKyshz9vwEAAAAAB43XYmJisC6HWEcMY1oAAAAAzxzP+umRrmA20n7hwgWKiooiPz8/ckWknQfUFRUVFB0d7fS/5ymwXrBusM3gs4R9DPa9WoHvJO2sFx668iCXm9S6KsvXU2FMqw3Yf2C9YHvB5wj7GOx7tQLfSdpYL7aMZ5FxawavtMzMTHI13jgQuMV6wTaDzxL2Mdj3agG+k7BetLy9INPWOhjTagv2q1gv2F7wOcI+BvtercB3kvvXi7XjWaQpAAAAAAAAAAAAAGgMArcAAAAAAAAAAAAAGoPArQaEhITQr371K3EOWC/YZvBZwj4G+153wncS1gu2F8D+A/tVfN+4D76HsV6wzeCzhH0M9r1qaE4GAAAAAAAAAAAAoDHIuAUAAAAAAAAAAADQGARuAQAAAAAAAAAAADQGgVsAAAAAAAAAAAAAjUHgFgAAAAAAAAAAAEBjELh1kTVr1lBeXh6FhoZSUVER7dixY9Dlt23bJpbj5fPz8+nVV18lb/LMM8/Q9OnTKSoqipKTk+n73/8+nTx5ctDHbN26lfz8/AacTpw4Qd7k17/+9YD3mJqa6tPbC8vNzTX7///Zz37mU9vL9u3b6frrr6f09HTxfv7+97+b3K/X68U2xPeHhYXRFVdcQceOHRvyeT/66CMaO3as6GTM5xs2bCBvWS89PT306KOP0oQJEygiIkIsc+edd9KFCxcGfc5169aZ3YY6OzvJW7aXH//4xwPe38yZM316e2Hm/u98+t3vfufV24s1382+uo8BI4xpTWFMax7Gs+ZhPCvBeNYyjGltXy8MY1qMab15PIvArQusX7+eVq5cSY8//jgdPHiQ5s6dS4sXL6by8nKzy5eWltJ1110nluPl//u//5t+8YtfiI3EW3CgkQNue/fupc2bN1Nvby8tWLCA2trahnwsf+iqqqqU08iRI8nbjBs3zuQ9HjlyxOKyvrC9sK+//tpknfB2w2699Vaf2l74MzJp0iR6+eWXzd7/29/+llavXi3u53XGQf9rr72WWlpaLD7nnj17aMmSJbR06VI6fPiwOL/tttto37595A3rpb29nQ4cOEBPPPGEOP/444/p1KlT9L3vfW/I542OjjbZfvjEB0i8ZXthixYtMnl/GzduHPQ5vX17Yf3/52+99Zb4kXDzzTd79fZizXezr+5jQIIx7UAY01qG8exAGM9KMJ61DGNa29eLDGPagXxxTLvNG8ezenC6yy67TL98+XKT2woLC/WrVq0yu/wjjzwi7lf7yU9+op85c6beW9XU1Oh5c9y2bZvFZbZs2SKWaWho0HuzX/3qV/pJkyZZvbwvbi/swQcf1BcUFOh1Op3Pbi/8/jZs2KBc53WRmpqq/7//+z/lts7OTn1MTIz+1Vdftfg8t912m37RokUmty1cuFB/++23671hvZjz1VdfieXKysosLvP222+LdectzK2Xu+66S3/DDTfY9Dy+uL3wOrrqqqsGXcbbthdz383YxwDGtLZ/bnx1jILxrHUwnsV4djAY01q/XjCmxZjWm8ezyLh1su7ubtq/f7+I8Kvx9d27d1uM5PdffuHChfTNN9+IKb/eqKmpSZzHx8cPueyUKVMoLS2Nrr76atqyZQt5o9OnT4u0fS6vcfvtt1NJSYnFZX1xe+HP1Z///Ge65557xBFDX99e1NnX1dXVJtsDT+OYP3++xf3NYNvQYI/xhn0ObzuxsbGDLtfa2ko5OTmUmZlJ3/3ud0VWu7fhsiI8jWjUqFF03333UU1NzaDL+9r2cvHiRfrXv/5Fy5YtG3JZb9te+n83Yx/j2zCmtQ7GtEYYzw79mcJ4diB819gGY1ojjGkH56tj2iYvGM8icOtkdXV11NfXRykpKSa383XeWMzh280tzyne/Hzehg8OPfzww3T55ZfT+PHjLS7HwbfXX39dlADgqc6jR48WwTiud+NNZsyYQe+++y5t2rSJ3njjDbE9zJ49m+rr680u72vbC+OaRo2NjaKWka9vL2ryPsWW/Y38OFsf48m45uiqVavojjvuENOALCksLBR1S//xj3/QBx98IKYHzZkzR/wQ9RZctue9996jL7/8kv7whz+IqUJXXXUVdXV1WXyMr20v77zzjqiRddNNNw26nLdtL+a+m7GP8W0Y0w4NY1ojjGeHhvGsefiusR7GtEYY0w7NF8e0ei8ZzwY6/S+A0D8rkDegwTIFzS1v7nZv8MADD9C3335LO3fuHHQ5DrzxSTZr1iyqqKig3//+9zRv3jzypi8dGTdT4vdZUFAgdrS80/H17YW9+eabYj1xVrKvby+O2N/Y+xhPxFnonMWu0+lEg53BcJMudaMuHrBMnTqVXnrpJXrxxRfJG3CdJhkPZqZNmyaOrvPR+MEGdb6yvTCuBfbDH/5wyLpe3ra9DPbdjH2Mb8OY1jKMaY0wnh0axrOO3dfY+xhPhTGtKYxph+aLY9oHvGQ8i4xbJ0tMTKSAgIABUXieito/Wi/jwsjmlg8MDKSEhATyJj//+c/FkRyews5p+LbiHYonHvmxRUREhAjgWnqfvrS9sLKyMvriiy/o3nvvtfmx3r698LbAbNnfyI+z9TGeOsDlAvI8PYYL1Q+WbWuOv7+/6FDqzdsQZ6pz4Haw9+gr2wvbsWOHaHBoz/7Gk7cXS9/N2Mf4NoxpB4cx7eAwnjWF8axl+K4ZGsa0Q8OY1pQvjml/7kXjWQRunSw4OJiKiopEkECNr/P0d3M4M7D/8p9//rnIhAoKCiJvwEcm+OgHT2HnKbpcy9UeXGuFd8rejKcsFxcXW3yfvrC9qL399tuiHud3vvMdmx/r7dsLf474C0W9PXD9NO6saWl/M9g2NNhjPHWAywMODvzbc1CD91uHDh3y6m2IS7JwZvpg79EXthd1NhR/h3MXY1/YXob6bsY+xrdhTGsexrTWwXjWFMazluG7ZnAY01oHY1rfHdPqvXE86/T2Z6D/8MMP9UFBQfo333xTf/z4cf3KlSv1ERER+nPnzom1s2rVKv3SpUuVNVVSUqIPDw/XP/TQQ2J5fhw//m9/+5vXrM2f/vSnomvf1q1b9VVVVcqpvb1dWab/ennuuedE98hTp07pjx49Ku7nTfijjz7Se5P/+I//EOuFt4O9e/fqv/vd7+qjoqJ8enuR9fX16bOzs/WPPvrogPt8ZXtpaWnRHzx4UJz4/axevVpcLisrE/dzd0z+bH388cf6I0eO6H/wgx/o09LS9M3Nzcpz8Hri9SHbtWuXPiAgQDy2uLhYnAcGBortzxvWS09Pj/573/uePjMzU3/o0CGTfU5XV5fF9fLrX/9a/9lnn+nPnj0rnuvuu+8W62Xfvn16b1gvfB/vb3bv3q0vLS0VXc5nzZqlz8jI8OntRdbU1CT2rWvXrjX7HN64vVjz3eyr+xiQYEw7EMa05mE8axnGsxjPDgZjWtvXC8a0GNN6+3gWgVsXeeWVV/Q5OTn64OBg/dSpU/Xbtm1T7rvrrrv08+fPN1meN7IpU6aI5XNzcy3+cPRUvLM1d3r77bctrpdnn31WX1BQoA8NDdXHxcXpL7/8cv2//vUvvbdZsmSJ2Glw8DU9PV1/00036Y8dO+bT24ts06ZNYjs5efLkgPt8ZXvh4Jq5zw6/f6bT6fS/+tWv9KmpqfqQkBD9vHnzxJeRGq8neXnZX//6V/3o0aPFdldYWOhxAe7B1gsHJS3tc/hxltYLH2TjAwX8uUpKStIvWLBABDm9Zb3w4IXfE783/r/ze+Xby8vLfXp7kb322mv6sLAwfWNjo9nn8MbtxZrvZl/dx4ARxrSmMKY1D+NZyzCexXh2MBjT2r5eMKbFmNbbx7N+hjcGAAAAAAAAAAAAABqBGrcAAAAAAAAAAAAAGoPALQAAAAAAAAAAAIDGIHALAAAAAAAAAAAAoDEI3AIAAAAAAAAAAABoDAK3AAAAAAAAAAAAABqDwC0AAAAAAAAAAACAxiBwCwAAAAAAAAAAAKAxCNwCAGhUb28vPfvss3T27Fl3vxQAAAAAALtgTAsAYD8EbgEANCowMJBSUlLorrvuIp1O5+6XAwAAAABgM4xpAQDsFziMxwIAgJP9+Mc/pp6eHiopKaERI0ZgfQMAAACAx8GYFgDAPn56vV5v52MBAAAAAAAAAAAAwAlQKgEAQKNZCX5+fgNOixYtcvdLAwAAAACwCsa0AADDg1IJAAAaxUHat99+2+S2kJAQt70eAAAAAABbYUwLAGA/ZNwCAGgUB2lTU1NNTnFxceI+zr5du3YtLV68mMLCwigvL4/++te/mjz+yJEjdNVVV4n7ExIS6P7776fW1laTZd566y0aN26c+FtpaWn0wAMPKPetXr2aJkyYQBEREZSVlUUrVqwY8HgAAAAAAIxpAQCcA4FbAAAP9cQTT9DNN99Mhw8fph/96Ef0gx/8gIqLi8V97e3tIruBA71ff/21COp+8cUXJoFZDvz+7Gc/EwFdDvL+4x//MGmA5u/vTy+++CIdPXqU3nnnHfryyy/pkUcecct7BQAAAADvhDEtAIBlaE4GAKDRemB//vOfKTQ01OT2Rx99VAxuOeN2+fLlIvgqmzlzJk2dOpXWrFlDb7zxhli2oqJCZMyyjRs30vXXX08XLlyglJQUysjIoLvvvpv+53/+x6rXxMHfn/70p1RXV+fgdwsAAAAA3ghjWgCA4UGNWwAAjbryyitNArMsPj5euTxr1iyT+/j6oUOHxGXOvJ00aZIStGVz5swhnU5HJ0+eFIFfDuBeffXVFv/+li1b6De/+Q0dP36cmpubqbe3lzo7O6mtrc3keQEAAAAAMKYFAHA8BG4BADSKg6Pq0gXW4IAs0+v1ymVzy3Dd28GUlZXRddddJ7J6n376aREw3rlzJy1btox6enpsek0AAAAA4LswpgUAsB9q3AIAeKi9e/cOuF5YWCgujx07VmTfcnasbNeuXaJu7ahRoygqKopyc3Pp3//+t9nn/uabb0SG7R/+8AdRgoEfwxm6AAAAAACOhDEtAIBlyLgFANCorq4uqq6uNrktMDCQEhMTlZqz06ZNo8svv5zee+89+uqrr+jNN98U9/3whz+kX/3qV3TXXXfRr3/9a6qtraWf//zntHTpUlHflvHtnFGbnJxMixcvppaWFhHc5eUKCgpE4Pall14SdXH59ldffdUNawEAAAAAPBnGtAAA9kPGLQCARn322WeUlpZmcuIgrezJJ5+kDz/8kCZOnEjvvPOOCN5ypi0LDw+nTZs20aVLl2j69Ol0yy23iHq2L7/8svJ4Duo+//zzopnZuHHj6Lvf/S6dPn1a3Dd58mRavXo1PfvsszR+/Hjx3M8884wb1gIAAAAAeDKMaQEA7Oen50KIAADgUbhO7YYNG+j73/++u18KAAAAAIBdMKYFABgcMm4BAAAAAAAAAAAANAaBWwAAAAAAAAAAAACNQakEAAAAAAAAAAAAAI1Bxi0AAAAAAAAAAACAxiBwCwAAAAAAAAAAAKAxCNwCAAAAAAAAAAAAaAwCtwAAAAAAAAAAAAAag8AtAAAAAAAAAAAAgMYgcAsAAAAAAAAAAACgMQjcAgAAAAAAAAAAAGgMArcAAAAAAAAAAAAAGoPALQAAAAAAAAAAAABpy/8P/qVUYzUhJfsAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1400x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "# Loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Train Loss', linewidth=2)\n",
    "plt.plot(history.history['val_loss'], label='Val Loss', linewidth=2)\n",
    "plt.xlabel('Època')\n",
    "plt.ylabel('Loss (MSE)')\n",
    "plt.title('Evolució del Loss')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "# MAE\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['mae'], label='Train MAE', linewidth=2)\n",
    "plt.plot(history.history['val_mae'], label='Val MAE', linewidth=2)\n",
    "plt.xlabel('Època')\n",
    "plt.ylabel('MAE')\n",
    "plt.title('Evolució del Mean Absolute Error')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c4f88d",
   "metadata": {},
   "source": [
    "## 9. AVALUACIÓ FINAL DEL MILLOR MODEL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48c49475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "RESULTATS FINALS EN EL CONJUNT DE VALIDACIÓ\n",
      "======================================================================\n",
      "MAPE (Mean Absolute Percentage Error): 0.51%\n",
      "RMSE (Root Mean Squared Error): 0.123\n",
      "MAE (Mean Absolute Error): 0.118\n",
      "R² (Coeficient de determinació): 0.987\n",
      "======================================================================\n",
      "\n",
      "=== INTERPRETACIÓ ===\n",
      "✓ Excel·lent! MAPE < 15% - El model és molt precís\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Prediccions en el conjunt de validació (normalitzat)\n",
    "y_val_pred_scaled = millor_model.predict(X_val_scaled, verbose=0).flatten()\n",
    "\n",
    "# Desnormalitzar les prediccions per obtenir valors reals\n",
    "y_val_pred = scaler_y.inverse_transform(y_val_pred_scaled.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Calcular mètriques\n",
    "mape = mean_absolute_percentage_error(y_val, y_val_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_val, y_val_pred))\n",
    "mae = np.mean(np.abs(y_val - y_val_pred))\n",
    "r2 = r2_score(y_val, y_val_pred)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"RESULTATS FINALS EN EL CONJUNT DE VALIDACIÓ\")\n",
    "print(\"=\"*70)\n",
    "print(f\"MAPE (Mean Absolute Percentage Error): {mape*100:.2f}%\")\n",
    "print(f\"RMSE (Root Mean Squared Error): {rmse:.3f}\")\n",
    "print(f\"MAE (Mean Absolute Error): {mae:.3f}\")\n",
    "print(f\"R² (Coeficient de determinació): {r2:.3f}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Interpretació dels resultats\n",
    "print(\"\\n=== INTERPRETACIÓ ===\")\n",
    "if mape < 0.15:\n",
    "    print(\"✓ Excel·lent! MAPE < 15% - El model és molt precís\")\n",
    "elif mape < 0.20:\n",
    "    print(\"✓ Acceptable. MAPE entre 15-20% - El model és força bo\")\n",
    "else:\n",
    "    print(\"✗ Millorable. MAPE > 20% - Caldria més dades o millor preprocessament\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4869a1d3",
   "metadata": {},
   "source": [
    "## 10. VISUALITZACIÓ DE PREDICCIONS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84b4ed69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "# Gràfic de dispersió: valor real vs predit\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(y_val, y_val_pred, alpha=0.6, edgecolor='black')\n",
    "plt.plot([y_val.min(), y_val.max()], [y_val.min(), y_val.max()], \n",
    "         'r--', linewidth=2, label='Predicció perfecta')\n",
    "plt.xlabel('MS Real (%)')\n",
    "plt.ylabel('MS Predita (%)')\n",
    "plt.title(f'Prediccions vs Valors Reals\\nR² = {r2:.3f}')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "# Distribució dels errors\n",
    "plt.subplot(1, 2, 2)\n",
    "errors = y_val - y_val_pred\n",
    "plt.hist(errors, bins=20, edgecolor='black', alpha=0.7)\n",
    "plt.axvline(x=0, color='r', linestyle='--', linewidth=2)\n",
    "plt.xlabel('Error (Real - Predit)')\n",
    "plt.ylabel('Freqüència')\n",
    "plt.title(f'Distribució dels Errors\\nMAE = {mae:.3f}')\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5608dfc5",
   "metadata": {},
   "source": [
    "## 11. FUNCIÓ PER PREDIR NOVES MOSTRES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a1f27fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== EXEMPLE DE PREDICCIÓ ===\n",
      "Mostra: {'color_promig_R': 150.0, 'color_promig_G': 140.0, 'color_promig_B': 120.0, 'desviació_R': 20.0, 'desviació_G': 18.0, 'desviació_B': 15.0, 'canal_NIR': 0.65}\n",
      "MS predita: 19.15%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def predir_ms(nova_mostra, scaler_X, scaler_y, model):\n",
    "    \"\"\"\n",
    "    Prediu el % de MS per una nova mostra.\n",
    "    \n",
    "    Paràmetres:\n",
    "    -----------\n",
    "    nova_mostra : dict o array\n",
    "        Si és dict, ha de tenir les claus: 'color_promig_R', 'color_promig_G', \n",
    "        'color_promig_B', 'desviació_R', 'desviació_G', 'desviació_B', 'canal_NIR'\n",
    "        Si és array, ha de tenir els valors en aquest ordre\n",
    "    \n",
    "    Retorna:\n",
    "    --------\n",
    "    ms_predita : float\n",
    "        Percentatge de matèria seca predit\n",
    "    \"\"\"\n",
    "    # Convertir a array si és diccionari\n",
    "    if isinstance(nova_mostra, dict):\n",
    "        X_nova = np.array([[\n",
    "            nova_mostra['color_promig_R'],\n",
    "            nova_mostra['color_promig_G'],\n",
    "            nova_mostra['color_promig_B'],\n",
    "            nova_mostra['desviació_R'],\n",
    "            nova_mostra['desviació_G'],\n",
    "            nova_mostra['desviació_B'],\n",
    "            nova_mostra['canal_NIR']\n",
    "        ]])\n",
    "    else:\n",
    "        X_nova = np.array(nova_mostra).reshape(1, -1)\n",
    "    \n",
    "    # Normalitzar\n",
    "    X_nova_scaled = scaler_X.transform(X_nova)\n",
    "    \n",
    "    # Predir\n",
    "    y_pred_scaled = model.predict(X_nova_scaled, verbose=0)\n",
    "    \n",
    "    # Desnormalitzar\n",
    "    y_pred = scaler_y.inverse_transform(y_pred_scaled).flatten()[0]\n",
    "    \n",
    "    return y_pred\n",
    "\n",
    "\n",
    "# Exemple d'ús\n",
    "print(\"\\n=== EXEMPLE DE PREDICCIÓ ===\")\n",
    "mostra_exemple = {\n",
    "    'color_promig_R': 150.0,\n",
    "    'color_promig_G': 140.0,\n",
    "    'color_promig_B': 120.0,\n",
    "    'desviació_R': 20.0,\n",
    "    'desviació_G': 18.0,\n",
    "    'desviació_B': 15.0,\n",
    "    'canal_NIR': 0.65\n",
    "}\n",
    "\n",
    "ms_predita = predir_ms(mostra_exemple, scaler_X, scaler_y, millor_model)\n",
    "print(f\"Mostra: {mostra_exemple}\")\n",
    "print(f\"MS predita: {ms_predita:.2f}%\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc19f0d",
   "metadata": {},
   "source": [
    "## 12. GUARDAR EL MILLOR MODEL I SCALERS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1410d3fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Millor model guardat com 'model_prediccio_ms_final_MAPE_0.51.h5'\n",
      "✓ Còpia guardada com 'model_prediccio_ms.h5'\n",
      "✓ Scalers guardats com 'scaler_X.pkl' i 'scaler_y.pkl'\n",
      "✓ Informació del model guardada a 'info_millor_model.json'\n",
      "\n",
      "======================================================================\n",
      "PROCÉS COMPLETAT\n",
      "======================================================================\n",
      "\n",
      "Arxius generats:\n",
      "  - model_prediccio_ms_final_MAPE_0.51.h5\n",
      "  - model_prediccio_ms.h5\n",
      "  - scaler_X.pkl\n",
      "  - scaler_y.pkl\n",
      "  - info_millor_model.json\n",
      "  - checkpoints/ (directori amb tots els checkpoints en format .h5)\n",
      "  - checkpoints/resultats_gridsearch.json\n",
      "\n",
      "Per carregar el model en el futur:\n",
      "  model = keras.models.load_model('model_prediccio_ms.h5')\n",
      "  with open('scaler_X.pkl', 'rb') as f: scaler_X = pickle.load(f)\n",
      "  with open('scaler_y.pkl', 'rb') as f: scaler_y = pickle.load(f)\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Guardar el millor model amb un nom descriptiu (format .h5 per compatibilitat)\n",
    "nom_model_final = f\"model_prediccio_ms_final_MAPE_{mape*100:.2f}.h5\"\n",
    "millor_model.save(nom_model_final)\n",
    "print(f\"\\n✓ Millor model guardat com '{nom_model_final}'\")\n",
    "\n",
    "# També guardar una còpia com a model per defecte\n",
    "millor_model.save('model_prediccio_ms.h5')\n",
    "print(\"✓ Còpia guardada com 'model_prediccio_ms.h5'\")\n",
    "\n",
    "# Guardar els scalers amb numpy\n",
    "import pickle\n",
    "with open('scaler_X.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler_X, f)\n",
    "with open('scaler_y.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler_y, f)\n",
    "print(\"✓ Scalers guardats com 'scaler_X.pkl' i 'scaler_y.pkl'\")\n",
    "\n",
    "# Guardar informació del millor model\n",
    "info_model = {\n",
    "    'arquitectura': millor_config['config']['arquitectura'],\n",
    "    'learning_rate': millor_config['config']['learning_rate'],\n",
    "    'dropout_rate': millor_config['config']['dropout_rate'],\n",
    "    'batch_size': millor_config['config'].get('batch_size', 16),\n",
    "    'mape': float(mape),\n",
    "    'rmse': float(rmse),\n",
    "    'mae': float(mae),\n",
    "    'r2': float(r2),\n",
    "    'n_mostres_train': X_train.shape[0],\n",
    "    'n_mostres_val': X_val.shape[0],\n",
    "    'data_entrenament': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "}\n",
    "\n",
    "with open('info_millor_model.json', 'w') as f:\n",
    "    json.dump(info_model, f, indent=2)\n",
    "print(\"✓ Informació del model guardada a 'info_millor_model.json'\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PROCÉS COMPLETAT\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nArxius generats:\")\n",
    "print(f\"  - {nom_model_final}\")\n",
    "print(\"  - model_prediccio_ms.h5\")\n",
    "print(\"  - scaler_X.pkl\")\n",
    "print(\"  - scaler_y.pkl\")\n",
    "print(\"  - info_millor_model.json\")\n",
    "print(\"  - checkpoints/ (directori amb tots els checkpoints en format .h5)\")\n",
    "print(\"  - checkpoints/resultats_gridsearch.json\")\n",
    "print(\"\\nPer carregar el model en el futur:\")\n",
    "print(\"  model = keras.models.load_model('model_prediccio_ms.h5')\")\n",
    "print(\"  with open('scaler_X.pkl', 'rb') as f: scaler_X = pickle.load(f)\")\n",
    "print(\"  with open('scaler_y.pkl', 'rb') as f: scaler_y = pickle.load(f)\")\n",
    "print(\"=\"*70)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (prediccio_ms_patates)",
   "language": "python",
   "name": "prediccio_ms_patates"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
