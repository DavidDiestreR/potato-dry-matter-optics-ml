{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a695988e",
   "metadata": {},
   "source": [
    "# Notebook per Predicció de Matèria Seca (MS) en Patates\n",
    "\n",
    "Aquest notebook entrena una xarxa neuronal per predir el percentatge de \n",
    "matèria seca a partir de les característiques de color i NIR de les patates.\n",
    "\n",
    "Columnes del dataset:\n",
    "- id_mostra: identificador únic\n",
    "- ruta_imatges: ruta a la imatge\n",
    "- color_promig_R, color_promig_G, color_promig_B: colors mitjans RGB\n",
    "- desviació_R, desviació_G, desviació_B: desviacions estàndard dels canals\n",
    "- canal_NIR: valor del canal infraroig proper\n",
    "- MS_experimental: percentatge de matèria seca (TARGET)\n",
    "- lot: identificador del lot\n",
    "- data: data de captura\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab53925",
   "metadata": {},
   "source": [
    "## 1. IMPORTACIÓ DE LLIBRERIES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a675944c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error, r2_score\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuració per reproducibilitat\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU disponible: {tf.config.list_physical_devices('GPU')}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b400c2",
   "metadata": {},
   "source": [
    "## 2. CÀRREGA I EXPLORACIÓ DE DADES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2d0336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT: Canvia aquesta ruta per la del teu dataset\n",
    "os.chdir(\"D:/potato-dry-matter-optics-ml\")\n",
    "RUTA_DATASET = \"data/input/training/training_set.csv\"\n",
    "\n",
    "# Carregar les dades\n",
    "df = pd.read_csv(RUTA_DATASET)\n",
    "\n",
    "print(\"\\n=== INFORMACIÓ DEL DATASET ===\")\n",
    "print(f\"Nombre de mostres: {len(df)}\")\n",
    "print(f\"\\nColumnes disponibles:\\n{df.columns.tolist()}\")\n",
    "print(f\"\\nPrimeres files:\")\n",
    "print(df.head())\n",
    "\n",
    "# Estadístiques descriptives\n",
    "print(\"\\n=== ESTADÍSTIQUES DESCRIPTIVES ===\")\n",
    "print(df.describe())\n",
    "\n",
    "# Comprovar valors nuls\n",
    "print(\"\\n=== VALORS NULS ===\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Visualització de la distribució de MS\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.hist(df['MS_experimental'], bins=30, edgecolor='black', alpha=0.7)\n",
    "plt.xlabel('MS Experimental (%)')\n",
    "plt.ylabel('Freqüència')\n",
    "plt.title('Distribució de Matèria Seca')\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.boxplot(df['MS_experimental'])\n",
    "plt.ylabel('MS Experimental (%)')\n",
    "plt.title('Boxplot de MS')\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "# Correlació entre features i MS\n",
    "features_cols = ['color_promig_R', 'color_promig_G', 'color_promig_B', \n",
    "                 'desviació_R', 'desviació_G', 'desviació_B', 'canal_NIR']\n",
    "correlations = df[features_cols + ['MS_experimental']].corr()['MS_experimental'].drop('MS_experimental')\n",
    "correlations.plot(kind='barh')\n",
    "plt.xlabel('Correlació amb MS')\n",
    "plt.title('Correlacions amb MS')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6d1c39",
   "metadata": {},
   "source": [
    "## 3. PREPARACIÓ DE LES DADES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103c6069",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Seleccionar les columnes d'entrada (features) i sortida (target)\n",
    "feature_cols = ['color_promig_R', 'color_promig_G', 'color_promig_B',\n",
    "                'desviació_R', 'desviació_G', 'desviació_B', 'canal_NIR']\n",
    "target_col = 'MS_experimental'\n",
    "\n",
    "# Extreure X (inputs) i y (target)\n",
    "X = df[feature_cols].values\n",
    "y = df[target_col].values\n",
    "\n",
    "print(\"\\n=== PREPARACIÓ DE DADES ===\")\n",
    "print(f\"Shape de X (features): {X.shape}\")\n",
    "print(f\"Shape de y (target): {y.shape}\")\n",
    "\n",
    "# Separar en conjunt d'entrenament (80%) i validació (20%)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\nConjunt d'entrenament: {X_train.shape[0]} mostres\")\n",
    "print(f\"Conjunt de validació: {X_val.shape[0]} mostres\")\n",
    "\n",
    "# Normalització (StandardScaler)\n",
    "# És important normalitzar per ajudar a la xarxa neuronal a convergir millor\n",
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "X_val_scaled = scaler_X.transform(X_val)\n",
    "\n",
    "y_train_scaled = scaler_y.fit_transform(y_train.reshape(-1, 1)).flatten()\n",
    "y_val_scaled = scaler_y.transform(y_val.reshape(-1, 1)).flatten()\n",
    "\n",
    "print(\"\\n=== NORMALITZACIÓ COMPLETADA ===\")\n",
    "print(f\"Mitjana X_train: {X_train_scaled.mean(axis=0)}\")\n",
    "print(f\"Desviació estàndard X_train: {X_train_scaled.std(axis=0)}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430160d2",
   "metadata": {},
   "source": [
    "## 4. DEFINICIÓ DEL MODEL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81147f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def crear_model(n_features, arquitectura=[64, 32, 16], \n",
    "                learning_rate=0.001, dropout_rate=0.2):\n",
    "    \"\"\"\n",
    "    Crea una xarxa neuronal densa per regressió amb arquitectura flexible.\n",
    "    \n",
    "    Paràmetres:\n",
    "    -----------\n",
    "    n_features : int\n",
    "        Nombre de features d'entrada\n",
    "    arquitectura : list\n",
    "        Llista amb el nombre de neurones per cada capa oculta\n",
    "        Exemple: [64, 128, 20, 10] crea 4 capes amb 64, 128, 20 i 10 neurones\n",
    "    learning_rate : float\n",
    "        Taxa d'aprenentatge per Adam\n",
    "    dropout_rate : float\n",
    "        Taxa de dropout per regularització (s'aplica després de cada capa)\n",
    "    \n",
    "    Retorna:\n",
    "    --------\n",
    "    model : keras.Model\n",
    "        Model compilat\n",
    "    \"\"\"\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    # Capa d'entrada\n",
    "    model.add(layers.Input(shape=(n_features,)))\n",
    "    \n",
    "    # Afegir capes ocultes segons l'arquitectura especificada\n",
    "    for i, n_neurons in enumerate(arquitectura):\n",
    "        model.add(layers.Dense(n_neurons, activation='relu', \n",
    "                              name=f'hidden_{i+1}'))\n",
    "        model.add(layers.Dropout(dropout_rate, name=f'dropout_{i+1}'))\n",
    "    \n",
    "    # Capa de sortida (regressió, 1 neurona sense activació)\n",
    "    model.add(layers.Dense(1, name='output'))\n",
    "    \n",
    "    # Compilar el model\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='mse',  # Mean Squared Error per regressió\n",
    "        metrics=['mae']  # Mean Absolute Error com a mètrica addicional\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# NOTA: No creem el model aquí perquè ho farem després del GridSearch\n",
    "n_features = X_train_scaled.shape[1]\n",
    "print(f\"\\n=== NOMBRE DE FEATURES: {n_features} ===\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc68953",
   "metadata": {},
   "source": [
    "## 5. GRIDSEARCH PER TROBAR LA MILLOR CONFIGURACIÓ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a91f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Crear directori per guardar checkpoints\n",
    "os.makedirs('checkpoints', exist_ok=True)\n",
    "\n",
    "def gridsearch_amb_checkpoints(X_train, y_train, X_val, y_val, configuracions):\n",
    "    \"\"\"\n",
    "    Cerca manual de la millor configuració d'hiperparàmetres amb checkpoints.\n",
    "    \n",
    "    Paràmetres:\n",
    "    -----------\n",
    "    configuracions : list of dict\n",
    "        Llista de diccionaris amb diferents configuracions a provar\n",
    "        Cada config ha de tenir: 'arquitectura', 'learning_rate', 'dropout_rate'\n",
    "    \n",
    "    Retorna:\n",
    "    --------\n",
    "    millor_config : dict\n",
    "        Millor configuració trobada\n",
    "    resultats : list\n",
    "        Resultats de totes les configuracions\n",
    "    \"\"\"\n",
    "    resultats = []\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"INICI DEL GRIDSEARCH\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    for i, config in enumerate(configuracions):\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"CONFIGURACIÓ {i+1}/{len(configuracions)}\")\n",
    "        print(f\"{'='*70}\")\n",
    "        print(f\"Arquitectura: {config['arquitectura']}\")\n",
    "        print(f\"Learning rate: {config['learning_rate']}\")\n",
    "        print(f\"Dropout rate: {config['dropout_rate']}\")\n",
    "        print(f\"Batch size: {config.get('batch_size', 16)}\")\n",
    "        \n",
    "        # Crear nom únic per aquesta configuració\n",
    "        config_name = f\"config_{i+1}_arch_{'_'.join(map(str, config['arquitectura']))}\"\n",
    "        checkpoint_path = f\"checkpoints/{config_name}.keras\"\n",
    "        \n",
    "        # Crear i entrenar model\n",
    "        model_temp = crear_model(\n",
    "            n_features, \n",
    "            arquitectura=config['arquitectura'],\n",
    "            learning_rate=config['learning_rate'],\n",
    "            dropout_rate=config['dropout_rate']\n",
    "        )\n",
    "        \n",
    "        # Callbacks per aquest entrenament\n",
    "        callbacks_temp = [\n",
    "            EarlyStopping(\n",
    "                monitor='val_loss', \n",
    "                patience=20, \n",
    "                restore_best_weights=True, \n",
    "                verbose=1\n",
    "            ),\n",
    "            ReduceLROnPlateau(\n",
    "                monitor='val_loss',\n",
    "                factor=0.5,\n",
    "                patience=10,\n",
    "                min_lr=1e-7,\n",
    "                verbose=1\n",
    "            ),\n",
    "            # Guardar el millor model d'aquesta configuració\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                checkpoint_path,\n",
    "                monitor='val_loss',\n",
    "                save_best_only=True,\n",
    "                verbose=1\n",
    "            )\n",
    "        ]\n",
    "        \n",
    "        # Entrenar\n",
    "        history_temp = model_temp.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=200,\n",
    "            batch_size=config.get('batch_size', 16),\n",
    "            callbacks=callbacks_temp,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        # Carregar el millor model guardat\n",
    "        model_temp = keras.models.load_model(checkpoint_path)\n",
    "        \n",
    "        # Avaluar amb el conjunt de validació\n",
    "        y_pred_temp = model_temp.predict(X_val, verbose=0).flatten()\n",
    "        \n",
    "        # Desnormalitzar per calcular mètriques reals\n",
    "        y_pred_real = scaler_y.inverse_transform(y_pred_temp.reshape(-1, 1)).flatten()\n",
    "        y_val_real = scaler_y.inverse_transform(y_val.reshape(-1, 1)).flatten()\n",
    "        \n",
    "        # Calcular mètriques\n",
    "        mape_temp = mean_absolute_percentage_error(y_val_real, y_pred_real)\n",
    "        rmse_temp = np.sqrt(mean_squared_error(y_val_real, y_pred_real))\n",
    "        mae_temp = np.mean(np.abs(y_val_real - y_pred_real))\n",
    "        r2_temp = r2_score(y_val_real, y_pred_real)\n",
    "        \n",
    "        # Guardar resultats\n",
    "        resultat = {\n",
    "            'config_id': i + 1,\n",
    "            'config': config,\n",
    "            'checkpoint_path': checkpoint_path,\n",
    "            'mape': mape_temp,\n",
    "            'rmse': rmse_temp,\n",
    "            'mae': mae_temp,\n",
    "            'r2': r2_temp,\n",
    "            'val_loss_final': min(history_temp.history['val_loss']),\n",
    "            'epochs_entrenats': len(history_temp.history['loss'])\n",
    "        }\n",
    "        resultats.append(resultat)\n",
    "        \n",
    "        print(f\"\\n{'─'*70}\")\n",
    "        print(f\"RESULTATS CONFIG {i+1}:\")\n",
    "        print(f\"  MAPE: {mape_temp*100:.2f}%\")\n",
    "        print(f\"  RMSE: {rmse_temp:.3f}\")\n",
    "        print(f\"  MAE: {mae_temp:.3f}\")\n",
    "        print(f\"  R²: {r2_temp:.3f}\")\n",
    "        print(f\"  Èpoques entrenades: {len(history_temp.history['loss'])}\")\n",
    "        print(f\"  Checkpoint guardat a: {checkpoint_path}\")\n",
    "        print(f\"{'─'*70}\")\n",
    "    \n",
    "    # Trobar la millor configuració (menor MAPE)\n",
    "    millor = min(resultats, key=lambda x: x['mape'])\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"MILLOR CONFIGURACIÓ TROBADA\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"Config ID: {millor['config_id']}\")\n",
    "    print(f\"Arquitectura: {millor['config']['arquitectura']}\")\n",
    "    print(f\"Learning rate: {millor['config']['learning_rate']}\")\n",
    "    print(f\"Dropout rate: {millor['config']['dropout_rate']}\")\n",
    "    print(f\"\\nMÈTRIQUES:\")\n",
    "    print(f\"  MAPE: {millor['mape']*100:.2f}%\")\n",
    "    print(f\"  RMSE: {millor['rmse']:.3f}\")\n",
    "    print(f\"  MAE: {millor['mae']:.3f}\")\n",
    "    print(f\"  R²: {millor['r2']:.3f}\")\n",
    "    print(f\"\\nCheckpoint: {millor['checkpoint_path']}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    # Guardar tots els resultats en un JSON\n",
    "    with open('checkpoints/resultats_gridsearch.json', 'w') as f:\n",
    "        # Convertir a format serialitzable\n",
    "        resultats_serialitzable = []\n",
    "        for r in resultats:\n",
    "            r_copy = r.copy()\n",
    "            for key in ['mape', 'rmse', 'mae', 'r2', 'val_loss_final']:\n",
    "                r_copy[key] = float(r_copy[key])\n",
    "            resultats_serialitzable.append(r_copy)\n",
    "        \n",
    "        json.dump({\n",
    "            'data_execucio': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            'millor_config_id': millor['config_id'],\n",
    "            'resultats': resultats_serialitzable\n",
    "        }, f, indent=2)\n",
    "    \n",
    "    print(\"✓ Resultats guardats a 'checkpoints/resultats_gridsearch.json'\\n\")\n",
    "    \n",
    "    return millor, resultats\n",
    "\n",
    "\n",
    "# Definir les configuracions a provar\n",
    "configuracions = [\n",
    "    # Configuracions simples (poques capes, poques neurones)\n",
    "    {\n",
    "        'arquitectura': [32, 16],\n",
    "        'learning_rate': 0.001,\n",
    "        'dropout_rate': 0.1,\n",
    "        'batch_size': 16\n",
    "    },\n",
    "    {\n",
    "        'arquitectura': [64, 32],\n",
    "        'learning_rate': 0.001,\n",
    "        'dropout_rate': 0.2,\n",
    "        'batch_size': 16\n",
    "    },\n",
    "    \n",
    "    # Configuracions mitjanes\n",
    "    {\n",
    "        'arquitectura': [64, 32, 16],\n",
    "        'learning_rate': 0.001,\n",
    "        'dropout_rate': 0.2,\n",
    "        'batch_size': 16\n",
    "    },\n",
    "    {\n",
    "        'arquitectura': [128, 64, 32],\n",
    "        'learning_rate': 0.0005,\n",
    "        'dropout_rate': 0.2,\n",
    "        'batch_size': 16\n",
    "    },\n",
    "    \n",
    "    # Configuracions més complexes\n",
    "    {\n",
    "        'arquitectura': [128, 64, 32, 16],\n",
    "        'learning_rate': 0.001,\n",
    "        'dropout_rate': 0.3,\n",
    "        'batch_size': 16\n",
    "    },\n",
    "    {\n",
    "        'arquitectura': [64, 128, 64, 32],\n",
    "        'learning_rate': 0.0005,\n",
    "        'dropout_rate': 0.25,\n",
    "        'batch_size': 16\n",
    "    },\n",
    "    \n",
    "    # Provar amb learning rates diferents\n",
    "    {\n",
    "        'arquitectura': [64, 32, 16],\n",
    "        'learning_rate': 0.01,\n",
    "        'dropout_rate': 0.2,\n",
    "        'batch_size': 16\n",
    "    },\n",
    "    {\n",
    "        'arquitectura': [64, 32, 16],\n",
    "        'learning_rate': 0.0001,\n",
    "        'dropout_rate': 0.2,\n",
    "        'batch_size': 16\n",
    "    },\n",
    "    \n",
    "    # Provar amb dropouts diferents\n",
    "    {\n",
    "        'arquitectura': [64, 32, 16],\n",
    "        'learning_rate': 0.001,\n",
    "        'dropout_rate': 0.4,\n",
    "        'batch_size': 16\n",
    "    },\n",
    "    \n",
    "    # Provar arquitectures més profundes\n",
    "    {\n",
    "        'arquitectura': [128, 128, 64, 32, 16],\n",
    "        'learning_rate': 0.0005,\n",
    "        'dropout_rate': 0.3,\n",
    "        'batch_size': 16\n",
    "    },\n",
    "]\n",
    "\n",
    "print(f\"\\nS'executarà GridSearch amb {len(configuracions)} configuracions diferents\\n\")\n",
    "\n",
    "# EXECUTAR GRIDSEARCH\n",
    "millor_config, tots_resultats = gridsearch_amb_checkpoints(\n",
    "    X_train_scaled, y_train_scaled, \n",
    "    X_val_scaled, y_val_scaled,\n",
    "    configuracions\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2ce793",
   "metadata": {},
   "source": [
    "## 7. CARREGAR I AVALUAR EL MILLOR MODEL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb80d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"\\n=== CARREGANT EL MILLOR MODEL ===\")\n",
    "print(f\"Checkpoint: {millor_config['checkpoint_path']}\")\n",
    "\n",
    "# Carregar el millor model\n",
    "millor_model = keras.models.load_model(millor_config['checkpoint_path'])\n",
    "\n",
    "print(\"\\n=== ARQUITECTURA DEL MILLOR MODEL ===\")\n",
    "millor_model.summary()\n",
    "\n",
    "# Re-entrenar breument per obtenir l'historial (opcional, per visualització)\n",
    "print(\"\\n=== ENTRENAMENT FINAL AMB LA MILLOR CONFIGURACIÓ ===\")\n",
    "print(\"(Això és només per generar gràfics d'entrenament)\\n\")\n",
    "\n",
    "callbacks_final = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=20,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=10,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "history = millor_model.fit(\n",
    "    X_train_scaled, y_train_scaled,\n",
    "    validation_data=(X_val_scaled, y_val_scaled),\n",
    "    epochs=200,\n",
    "    batch_size=millor_config['config'].get('batch_size', 16),\n",
    "    callbacks=callbacks_final,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n=== ENTRENAMENT COMPLETAT ===\")\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "# Loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Train Loss', linewidth=2)\n",
    "plt.plot(history.history['val_loss'], label='Val Loss', linewidth=2)\n",
    "plt.xlabel('Època')\n",
    "plt.ylabel('Loss (MSE)')\n",
    "plt.title('Evolució del Loss')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "# MAE\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['mae'], label='Train MAE', linewidth=2)\n",
    "plt.plot(history.history['val_mae'], label='Val MAE', linewidth=2)\n",
    "plt.xlabel('Època')\n",
    "plt.ylabel('MAE')\n",
    "plt.title('Evolució del Mean Absolute Error')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a86487f",
   "metadata": {},
   "source": [
    "## 8. VISUALITZACIÓ DEL PROCÉS D'ENTRENAMENT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18871ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "# Loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Train Loss', linewidth=2)\n",
    "plt.plot(history.history['val_loss'], label='Val Loss', linewidth=2)\n",
    "plt.xlabel('Època')\n",
    "plt.ylabel('Loss (MSE)')\n",
    "plt.title('Evolució del Loss')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "# MAE\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['mae'], label='Train MAE', linewidth=2)\n",
    "plt.plot(history.history['val_mae'], label='Val MAE', linewidth=2)\n",
    "plt.xlabel('Època')\n",
    "plt.ylabel('MAE')\n",
    "plt.title('Evolució del Mean Absolute Error')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf8110e",
   "metadata": {},
   "source": [
    "## 9. AVALUACIÓ FINAL DEL MILLOR MODEL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6827e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Prediccions en el conjunt de validació (normalitzat)\n",
    "y_val_pred_scaled = millor_model.predict(X_val_scaled, verbose=0).flatten()\n",
    "\n",
    "# Desnormalitzar les prediccions per obtenir valors reals\n",
    "y_val_pred = scaler_y.inverse_transform(y_val_pred_scaled.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Calcular mètriques\n",
    "mape = mean_absolute_percentage_error(y_val, y_val_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_val, y_val_pred))\n",
    "mae = np.mean(np.abs(y_val - y_val_pred))\n",
    "r2 = r2_score(y_val, y_val_pred)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"RESULTATS FINALS EN EL CONJUNT DE VALIDACIÓ\")\n",
    "print(\"=\"*70)\n",
    "print(f\"MAPE (Mean Absolute Percentage Error): {mape*100:.2f}%\")\n",
    "print(f\"RMSE (Root Mean Squared Error): {rmse:.3f}\")\n",
    "print(f\"MAE (Mean Absolute Error): {mae:.3f}\")\n",
    "print(f\"R² (Coeficient de determinació): {r2:.3f}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Interpretació dels resultats\n",
    "print(\"\\n=== INTERPRETACIÓ ===\")\n",
    "if mape < 0.15:\n",
    "    print(\"✓ Excel·lent! MAPE < 15% - El model és molt precís\")\n",
    "elif mape < 0.20:\n",
    "    print(\"✓ Acceptable. MAPE entre 15-20% - El model és força bo\")\n",
    "else:\n",
    "    print(\"✗ Millorable. MAPE > 20% - Caldria més dades o millor preprocessament\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b59d74",
   "metadata": {},
   "source": [
    "## 10. VISUALITZACIÓ DE PREDICCIONS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a61c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "# Gràfic de dispersió: valor real vs predit\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(y_val, y_val_pred, alpha=0.6, edgecolor='black')\n",
    "plt.plot([y_val.min(), y_val.max()], [y_val.min(), y_val.max()], \n",
    "         'r--', linewidth=2, label='Predicció perfecta')\n",
    "plt.xlabel('MS Real (%)')\n",
    "plt.ylabel('MS Predita (%)')\n",
    "plt.title(f'Prediccions vs Valors Reals\\nR² = {r2:.3f}')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "# Distribució dels errors\n",
    "plt.subplot(1, 2, 2)\n",
    "errors = y_val - y_val_pred\n",
    "plt.hist(errors, bins=20, edgecolor='black', alpha=0.7)\n",
    "plt.axvline(x=0, color='r', linestyle='--', linewidth=2)\n",
    "plt.xlabel('Error (Real - Predit)')\n",
    "plt.ylabel('Freqüència')\n",
    "plt.title(f'Distribució dels Errors\\nMAE = {mae:.3f}')\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148c4efd",
   "metadata": {},
   "source": [
    "## 11. FUNCIÓ PER PREDIR NOVES MOSTRES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d32bd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predir_ms(nova_mostra, scaler_X, scaler_y, model):\n",
    "    \"\"\"\n",
    "    Prediu el % de MS per una nova mostra.\n",
    "    \n",
    "    Paràmetres:\n",
    "    -----------\n",
    "    nova_mostra : dict o array\n",
    "        Si és dict, ha de tenir les claus: 'color_promig_R', 'color_promig_G', \n",
    "        'color_promig_B', 'desviació_R', 'desviació_G', 'desviació_B', 'canal_NIR'\n",
    "        Si és array, ha de tenir els valors en aquest ordre\n",
    "    \n",
    "    Retorna:\n",
    "    --------\n",
    "    ms_predita : float\n",
    "        Percentatge de matèria seca predit\n",
    "    \"\"\"\n",
    "    # Convertir a array si és diccionari\n",
    "    if isinstance(nova_mostra, dict):\n",
    "        X_nova = np.array([[\n",
    "            nova_mostra['color_promig_R'],\n",
    "            nova_mostra['color_promig_G'],\n",
    "            nova_mostra['color_promig_B'],\n",
    "            nova_mostra['desviació_R'],\n",
    "            nova_mostra['desviació_G'],\n",
    "            nova_mostra['desviació_B'],\n",
    "            nova_mostra['canal_NIR']\n",
    "        ]])\n",
    "    else:\n",
    "        X_nova = np.array(nova_mostra).reshape(1, -1)\n",
    "    \n",
    "    # Normalitzar\n",
    "    X_nova_scaled = scaler_X.transform(X_nova)\n",
    "    \n",
    "    # Predir\n",
    "    y_pred_scaled = model.predict(X_nova_scaled, verbose=0)\n",
    "    \n",
    "    # Desnormalitzar\n",
    "    y_pred = scaler_y.inverse_transform(y_pred_scaled).flatten()[0]\n",
    "    \n",
    "    return y_pred\n",
    "\n",
    "\n",
    "# Exemple d'ús\n",
    "print(\"\\n=== EXEMPLE DE PREDICCIÓ ===\")\n",
    "mostra_exemple = {\n",
    "    'color_promig_R': 150.0,\n",
    "    'color_promig_G': 140.0,\n",
    "    'color_promig_B': 120.0,\n",
    "    'desviació_R': 20.0,\n",
    "    'desviació_G': 18.0,\n",
    "    'desviació_B': 15.0,\n",
    "    'canal_NIR': 0.65\n",
    "}\n",
    "\n",
    "ms_predita = predir_ms(mostra_exemple, scaler_X, scaler_y, millor_model)\n",
    "print(f\"Mostra: {mostra_exemple}\")\n",
    "print(f\"MS predita: {ms_predita:.2f}%\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeab7934",
   "metadata": {},
   "source": [
    "## 12. GUARDAR EL MILLOR MODEL I SCALERS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5ad3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Guardar el millor model amb un nom descriptiu\n",
    "nom_model_final = f\"model_prediccio_ms_final_MAPE_{mape*100:.2f}.keras\"\n",
    "millor_model.save(nom_model_final)\n",
    "print(f\"\\n✓ Millor model guardat com '{nom_model_final}'\")\n",
    "\n",
    "# També guardar una còpia com a model per defecte\n",
    "millor_model.save('model_prediccio_ms.keras')\n",
    "print(\"✓ Còpia guardada com 'model_prediccio_ms.keras'\")\n",
    "\n",
    "# Guardar els scalers amb numpy\n",
    "import pickle\n",
    "with open('scaler_X.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler_X, f)\n",
    "with open('scaler_y.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler_y, f)\n",
    "print(\"✓ Scalers guardats com 'scaler_X.pkl' i 'scaler_y.pkl'\")\n",
    "\n",
    "# Guardar informació del millor model\n",
    "info_model = {\n",
    "    'arquitectura': millor_config['config']['arquitectura'],\n",
    "    'learning_rate': millor_config['config']['learning_rate'],\n",
    "    'dropout_rate': millor_config['config']['dropout_rate'],\n",
    "    'batch_size': millor_config['config'].get('batch_size', 16),\n",
    "    'mape': float(mape),\n",
    "    'rmse': float(rmse),\n",
    "    'mae': float(mae),\n",
    "    'r2': float(r2),\n",
    "    'n_mostres_train': X_train.shape[0],\n",
    "    'n_mostres_val': X_val.shape[0],\n",
    "    'data_entrenament': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "}\n",
    "\n",
    "with open('info_millor_model.json', 'w') as f:\n",
    "    json.dump(info_model, f, indent=2)\n",
    "print(\"✓ Informació del model guardada a 'info_millor_model.json'\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PROCÉS COMPLETAT\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nArxius generats:\")\n",
    "print(f\"  - {nom_model_final}\")\n",
    "print(\"  - model_prediccio_ms.keras\")\n",
    "print(\"  - scaler_X.pkl\")\n",
    "print(\"  - scaler_y.pkl\")\n",
    "print(\"  - info_millor_model.json\")\n",
    "print(\"  - checkpoints/ (directori amb tots els checkpoints)\")\n",
    "print(\"  - checkpoints/resultats_gridsearch.json\")\n",
    "print(\"\\nPer carregar el model en el futur:\")\n",
    "print(\"  model = keras.models.load_model('model_prediccio_ms.keras')\")\n",
    "print(\"  with open('scaler_X.pkl', 'rb') as f: scaler_X = pickle.load(f)\")\n",
    "print(\"  with open('scaler_y.pkl', 'rb') as f: scaler_y = pickle.load(f)\")\n",
    "print(\"=\"*70)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
