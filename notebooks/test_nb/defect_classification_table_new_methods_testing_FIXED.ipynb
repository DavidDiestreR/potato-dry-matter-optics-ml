{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fbf8e61",
   "metadata": {},
   "source": [
    "# Tabla de clasificación de defectos — *new methods testing*\n",
    "\n",
    "Este notebook es una copia “extendida” del flujo de `defect_classification_table_fixed.ipynb`, pero añadiendo **preprocesados más robustos** para intentar que el modelo de Roboflow sea menos sensible a iluminación/reflejos.\n",
    "\n",
    "### Métodos añadidos\n",
    "- **Percentile stretch (autocontrast por percentiles)**: comprime highlights y levanta sombras (lo que pedías: “bajar muy brillantes y subir muy oscuros”).\n",
    "- **Curva S (sigmoid / tone curve)**: similar a “Shadows/Highlights” de edición fotográfica.\n",
    "- **White balance (gray-world)**: corrige dominantes (amarillo/azul) entre sesiones.\n",
    "- **CLAHE en luminancia (LAB)**: realza contraste local (defectos pequeños).\n",
    "- **Retinex (SSR)**: normaliza iluminación (sombras y gradientes).\n",
    "- **Highlight compression en canal V (HSV)**: baja reflejos especulares sin tocar tanto el resto.\n",
    "- **Padding a cuadrado + resize**: hace que el encuadre/escala sea más consistente con el dataset de Roboflow.\n",
    "\n",
    "> Nota: estos métodos **no siempre mejoran** (a veces te alejan de la distribución de entrenamiento). Por eso aquí los probamos de forma sistemática y resumimos por lote.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40753041",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "from typing import Any, Dict, List, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import Image, ImageEnhance, ImageOps\n",
    "\n",
    "# OpenCV (para LAB/HSV/CLAHE/Retinex)\n",
    "import cv2\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Localiza el root del repo (buscando 'data/')\n",
    "# ---------------------------------------------------------------------\n",
    "def find_project_root(start: Path | None = None, marker_dir: str = \"data\") -> Path:\n",
    "    start = Path.cwd() if start is None else Path(start).resolve()\n",
    "    for p in [start, *start.parents]:\n",
    "        if (p / marker_dir).exists() and (p / marker_dir).is_dir():\n",
    "            return p\n",
    "    raise FileNotFoundError(f\"No he encontrado '{marker_dir}/' subiendo desde {start}\")\n",
    "\n",
    "PROJECT_ROOT = find_project_root()\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Imports del proyecto (usa tus funciones existentes cuando convenga)\n",
    "# ---------------------------------------------------------------------\n",
    "try:\n",
    "    from src.raw_image_treatment import potato_pixels_rgb_img  # recorte por detección\n",
    "except Exception as e:\n",
    "    raise ImportError(\n",
    "        \"No he podido importar desde src/raw_image_treatment.py.\\n\"\n",
    "        \"Asegúrate de ejecutar este notebook dentro del repo y que existe src/raw_image_treatment.py.\\n\"\n",
    "        f\"Error: {e}\"\n",
    "    )\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Roboflow inference SDK (para NO llamar N veces solo por cambiar threshold)\n",
    "# ---------------------------------------------------------------------\n",
    "try:\n",
    "    from inference_sdk import InferenceHTTPClient\n",
    "except Exception as e:\n",
    "    raise ImportError(\n",
    "        \"No he podido importar inference_sdk. Instálalo en tu env:\\n\"\n",
    "        \"  pip install inference-sdk\\n\"\n",
    "        f\"Error: {e}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589e3d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Rutas de imágenes (ajusta si tu repo usa otras)\n",
    "# ------------------------------------------------------------\n",
    "DIR_DEFINITIVE = PROJECT_ROOT / \"data/input/raw/raw_images/definitive\"\n",
    "DIR_TEST = PROJECT_ROOT / \"data/input/raw/raw_images/test_1\"\n",
    "DIR_CROPPED_DEF = PROJECT_ROOT / \"data/input/processed/cropped_def\"\n",
    "\n",
    "def natural_sort_key(p: Path):\n",
    "    parts = re.split(r\"(\\d+)\", p.name)\n",
    "    key = []\n",
    "    for part in parts:\n",
    "        if part.isdigit():\n",
    "            key.append(int(part))\n",
    "        else:\n",
    "            key.append(part.lower())\n",
    "    return key\n",
    "\n",
    "def list_images(source: str, pattern: str) -> List[Path]:\n",
    "    if source == \"definitive\":\n",
    "        base = DIR_DEFINITIVE\n",
    "    elif source == \"test_1\":\n",
    "        base = DIR_TEST\n",
    "    elif source == \"cropped_def\":\n",
    "        base = DIR_CROPPED_DEF\n",
    "    else:\n",
    "        raise ValueError(\"source debe ser 'definitive', 'test_1' o 'cropped_def'\")\n",
    "\n",
    "    if not base.exists():\n",
    "        raise FileNotFoundError(f\"No existe la carpeta: {base}\")\n",
    "\n",
    "    paths = sorted(base.glob(pattern), key=natural_sort_key)\n",
    "    return paths\n",
    "\n",
    "def infer_lot_from_name(name: str) -> Optional[int]:\n",
    "    \"\"\"Intenta extraer el lote desde nombres tipo p3_..., p4_..., p5_..., p6_...\"\"\"\n",
    "    m = re.search(r\"(?:^|_)p(\\d+)_\", name)\n",
    "    if m:\n",
    "        return int(m.group(1))\n",
    "    m = re.search(r\"^p(\\d+)_\", name)\n",
    "    if m:\n",
    "        return int(m.group(1))\n",
    "    return None\n",
    "\n",
    "print(\"definitive exists:\", DIR_DEFINITIVE.exists(), \"|\", DIR_DEFINITIVE)\n",
    "print(\"cropped_def exists:\", DIR_CROPPED_DEF.exists(), \"|\", DIR_CROPPED_DEF)\n",
    "print(\"test_1 exists:\", DIR_TEST.exists(), \"|\", DIR_TEST)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b9c311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Utils de conversión\n",
    "# ------------------------------------------------------------\n",
    "def to_pil_rgb(img_in: Any) -> Image.Image:\n",
    "    if isinstance(img_in, Image.Image):\n",
    "        return img_in.convert(\"RGB\")\n",
    "    if isinstance(img_in, (str, Path, os.PathLike)):\n",
    "        return Image.open(str(img_in)).convert(\"RGB\")\n",
    "    if isinstance(img_in, np.ndarray):\n",
    "        arr = img_in\n",
    "        if arr.ndim == 2:\n",
    "            arr = np.stack([arr, arr, arr], axis=-1)\n",
    "        if arr.ndim != 3 or arr.shape[2] not in (3, 4):\n",
    "            raise ValueError(f\"numpy array con forma inválida: {arr.shape}\")\n",
    "        if arr.shape[2] == 4:\n",
    "            arr = arr[:, :, :3]\n",
    "        if arr.dtype != np.uint8:\n",
    "            arr = np.clip(arr, 0, 255).astype(np.uint8)\n",
    "        return Image.fromarray(arr, mode=\"RGB\")\n",
    "    raise TypeError(\"img_in debe ser Path/str, PIL.Image o np.ndarray\")\n",
    "\n",
    "def pil_to_bgr_uint8(pil: Image.Image) -> np.ndarray:\n",
    "    rgb = np.array(pil.convert(\"RGB\"), dtype=np.uint8)\n",
    "    return cv2.cvtColor(rgb, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "def bgr_to_pil_rgb(bgr: np.ndarray) -> Image.Image:\n",
    "    rgb = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)\n",
    "    return Image.fromarray(rgb.astype(np.uint8), mode=\"RGB\")\n",
    "\n",
    "def pad_to_square(pil: Image.Image, fill=(0,0,0)) -> Image.Image:\n",
    "    w, h = pil.size\n",
    "    m = max(w, h)\n",
    "    out = Image.new(\"RGB\", (m, m), fill)\n",
    "    out.paste(pil, ((m - w)//2, (m - h)//2))\n",
    "    return out\n",
    "\n",
    "def resize_max_side(pil: Image.Image, max_side: int = 640) -> Image.Image:\n",
    "    w, h = pil.size\n",
    "    s = max(w, h)\n",
    "    if s <= max_side:\n",
    "        return pil\n",
    "    scale = max_side / s\n",
    "    new_w, new_h = max(1, int(w*scale)), max(1, int(h*scale))\n",
    "    resample = Image.Resampling.LANCZOS if hasattr(Image, \"Resampling\") else Image.LANCZOS\n",
    "    return pil.resize((new_w, new_h), resample=resample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e94cd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Preprocesados \"nuevos\"\n",
    "# ------------------------------------------------------------\n",
    "def percentile_stretch(pil: Image.Image, p_low: float = 1.0, p_high: float = 99.0) -> Image.Image:\n",
    "    \"\"\"Autocontrast por percentiles en luminancia (LAB-L).\"\"\"\n",
    "    bgr = pil_to_bgr_uint8(pil)\n",
    "    lab = cv2.cvtColor(bgr, cv2.COLOR_BGR2LAB)\n",
    "    L, a, b = cv2.split(lab)\n",
    "    lo = np.percentile(L, p_low)\n",
    "    hi = np.percentile(L, p_high)\n",
    "    if hi <= lo + 1e-6:\n",
    "        return pil\n",
    "    L2 = np.clip((L.astype(np.float32) - lo) * (255.0 / (hi - lo)), 0, 255).astype(np.uint8)\n",
    "    lab2 = cv2.merge([L2, a, b])\n",
    "    return bgr_to_pil_rgb(cv2.cvtColor(lab2, cv2.COLOR_LAB2BGR))\n",
    "\n",
    "def sigmoid_tone_curve(pil: Image.Image, k: float = 6.0, mid: float = 0.5) -> Image.Image:\n",
    "    \"\"\"Curva S (sigmoid) aplicada a luminancia (LAB-L).\"\"\"\n",
    "    bgr = pil_to_bgr_uint8(pil)\n",
    "    lab = cv2.cvtColor(bgr, cv2.COLOR_BGR2LAB)\n",
    "    L, a, b = cv2.split(lab)\n",
    "    x = (L.astype(np.float32) / 255.0)\n",
    "    y = 1.0 / (1.0 + np.exp(-k * (x - mid)))\n",
    "    # re-normaliza a [0,1]\n",
    "    y = (y - y.min()) / (y.max() - y.min() + 1e-8)\n",
    "    L2 = np.clip(y * 255.0, 0, 255).astype(np.uint8)\n",
    "    lab2 = cv2.merge([L2, a, b])\n",
    "    return bgr_to_pil_rgb(cv2.cvtColor(lab2, cv2.COLOR_LAB2BGR))\n",
    "\n",
    "def gray_world_white_balance(pil: Image.Image) -> Image.Image:\n",
    "    \"\"\"White balance simple: escala cada canal para igualar medias (gray-world).\"\"\"\n",
    "    rgb = np.array(pil.convert(\"RGB\"), dtype=np.float32)\n",
    "    means = rgb.reshape(-1, 3).mean(axis=0)\n",
    "    target = means.mean()\n",
    "    scale = target / (means + 1e-8)\n",
    "    out = np.clip(rgb * scale[None, None, :], 0, 255).astype(np.uint8)\n",
    "    return Image.fromarray(out, mode=\"RGB\")\n",
    "\n",
    "def clahe_luminance(pil: Image.Image, clip_limit: float = 2.0, tile_grid_size: int = 8) -> Image.Image:\n",
    "    bgr = pil_to_bgr_uint8(pil)\n",
    "    lab = cv2.cvtColor(bgr, cv2.COLOR_BGR2LAB)\n",
    "    L, a, b = cv2.split(lab)\n",
    "    clahe = cv2.createCLAHE(clipLimit=float(clip_limit), tileGridSize=(int(tile_grid_size), int(tile_grid_size)))\n",
    "    L2 = clahe.apply(L)\n",
    "    lab2 = cv2.merge([L2, a, b])\n",
    "    return bgr_to_pil_rgb(cv2.cvtColor(lab2, cv2.COLOR_LAB2BGR))\n",
    "\n",
    "def retinex_ssr(pil: Image.Image, sigma: float = 50.0) -> Image.Image:\n",
    "    \"\"\"Single-Scale Retinex en luminancia (LAB-L) para corregir iluminación.\"\"\"\n",
    "    bgr = pil_to_bgr_uint8(pil)\n",
    "    lab = cv2.cvtColor(bgr, cv2.COLOR_BGR2LAB)\n",
    "    L, a, b = cv2.split(lab)\n",
    "    Lf = L.astype(np.float32) + 1.0\n",
    "    blur = cv2.GaussianBlur(Lf, (0, 0), sigmaX=float(sigma), sigmaY=float(sigma))\n",
    "    r = np.log(Lf) - np.log(blur + 1e-6)\n",
    "    r = (r - r.min()) / (r.max() - r.min() + 1e-8)\n",
    "    L2 = np.clip(r * 255.0, 0, 255).astype(np.uint8)\n",
    "    lab2 = cv2.merge([L2, a, b])\n",
    "    return bgr_to_pil_rgb(cv2.cvtColor(lab2, cv2.COLOR_LAB2BGR))\n",
    "\n",
    "def highlight_compress_hsv(pil: Image.Image, knee: float = 0.80, strength: float = 0.65) -> Image.Image:\n",
    "    \"\"\"Comprime highlights del canal V (HSV) con 'soft knee'.\"\"\"\n",
    "    bgr = pil_to_bgr_uint8(pil)\n",
    "    hsv = cv2.cvtColor(bgr, cv2.COLOR_BGR2HSV).astype(np.float32)\n",
    "    H, S, V = cv2.split(hsv)\n",
    "    v = V / 255.0\n",
    "    # soft-knee: para v>knee, aplana\n",
    "    t = np.clip((v - knee) / (1.0 - knee + 1e-8), 0, 1)\n",
    "    v2 = v - strength * (t**2) * (v - knee)\n",
    "    V2 = np.clip(v2 * 255.0, 0, 255).astype(np.uint8)\n",
    "    hsv2 = cv2.merge([H.astype(np.uint8), S.astype(np.uint8), V2])\n",
    "    return bgr_to_pil_rgb(cv2.cvtColor(hsv2, cv2.COLOR_HSV2BGR))\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Wrapper: define métodos y parámetros\n",
    "# ------------------------------------------------------------\n",
    "def apply_preprocess(pil: Image.Image, method: str) -> Image.Image:\n",
    "    pil = pil.convert(\"RGB\")\n",
    "\n",
    "    if method == \"none\":\n",
    "        return pil\n",
    "\n",
    "    if method == \"wb\":\n",
    "        return gray_world_white_balance(pil)\n",
    "\n",
    "    if method == \"pct_stretch\":\n",
    "        return percentile_stretch(pil, p_low=1.0, p_high=99.0)\n",
    "\n",
    "    if method == \"sigmoid\":\n",
    "        return sigmoid_tone_curve(pil, k=6.0, mid=0.5)\n",
    "\n",
    "    if method == \"clahe\":\n",
    "        return clahe_luminance(pil, clip_limit=2.0, tile_grid_size=8)\n",
    "\n",
    "    if method == \"retinex\":\n",
    "        return retinex_ssr(pil, sigma=50.0)\n",
    "\n",
    "    if method == \"hl_comp\":\n",
    "        return highlight_compress_hsv(pil, knee=0.80, strength=0.65)\n",
    "\n",
    "    if method == \"wb+clahe\":\n",
    "        return clahe_luminance(gray_world_white_balance(pil), clip_limit=2.0, tile_grid_size=8)\n",
    "\n",
    "    if method == \"retinex+clahe\":\n",
    "        return clahe_luminance(retinex_ssr(pil, sigma=50.0), clip_limit=2.0, tile_grid_size=8)\n",
    "\n",
    "    if method == \"square_640\":\n",
    "        return resize_max_side(pad_to_square(pil, fill=(0,0,0)), max_side=640)\n",
    "\n",
    "    raise ValueError(f\"Método no soportado: {method}\")\n",
    "\n",
    "METHODS = [\n",
    "    \"none\",\n",
    "    \"square_640\",\n",
    "    \"pct_stretch\",\n",
    "    \"sigmoid\",\n",
    "    \"hl_comp\",\n",
    "    \"wb\",\n",
    "    \"clahe\",\n",
    "    \"retinex\",\n",
    "    \"wb+clahe\",\n",
    "    \"retinex+clahe\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af9c0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Roboflow: inferencia 1 vez y luego thresholding local\n",
    "# ------------------------------------------------------------\n",
    "ROBOFLOW_MODEL_ID = \"potato-detection-3et6q/11\"\n",
    "ROBOFLOW_API_URL = \"https://serverless.roboflow.com\"\n",
    "ROBOFLOW_API_KEY_ENV = \"ROBOFLOW_API_KEY\"  # debe existir en tu entorno\n",
    "\n",
    "def roboflow_infer(pil_img: Image.Image) -> Dict[str, Any]:\n",
    "    api_key = os.environ.get(ROBOFLOW_API_KEY_ENV)\n",
    "    if not api_key:\n",
    "        raise RuntimeError(f\"Falta la variable de entorno {ROBOFLOW_API_KEY_ENV}\")\n",
    "    client = InferenceHTTPClient(api_url=ROBOFLOW_API_URL, api_key=api_key)\n",
    "    return client.infer(pil_img, model_id=ROBOFLOW_MODEL_ID)\n",
    "\n",
    "def pick_best_prediction(result: Dict[str, Any], thr: float) -> Optional[Dict[str, Any]]:\n",
    "    preds = result.get(\"predictions\", []) if isinstance(result, dict) else []\n",
    "    if not preds:\n",
    "        return None\n",
    "    best = max(preds, key=lambda p: float(p.get(\"confidence\", 0.0)))\n",
    "    return best if float(best.get(\"confidence\", 0.0)) >= thr else None\n",
    "\n",
    "def bbox_from_pred(pred: Dict[str, Any]) -> Optional[Tuple[float, float, float, float]]:\n",
    "    if all(k in pred for k in (\"x\", \"y\", \"width\", \"height\")):\n",
    "        x = float(pred[\"x\"])\n",
    "        y = float(pred[\"y\"])\n",
    "        w = float(pred[\"width\"])\n",
    "        h = float(pred[\"height\"])\n",
    "        return (x - w/2.0, y - h/2.0, x + w/2.0, y + h/2.0)\n",
    "    if all(k in pred for k in (\"x1\", \"y1\", \"x2\", \"y2\")):\n",
    "        return (float(pred[\"x1\"]), float(pred[\"y1\"]), float(pred[\"x2\"]), float(pred[\"y2\"]))\n",
    "    return None\n",
    "\n",
    "def classify_from_result(result: Dict[str, Any], thr: float) -> Tuple[str, float]:\n",
    "    best = pick_best_prediction(result, thr)\n",
    "    if best is None:\n",
    "        return \"Unable to classify\", 0.0\n",
    "    return str(best.get(\"class\", \"unknown\")), float(best.get(\"confidence\", 0.0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a56982b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Runner: recorte opcional + preprocs + inferencia + thresholds\n",
    "# ------------------------------------------------------------\n",
    "def run_defect_table_new_methods(\n",
    "    *,\n",
    "    source: str,\n",
    "    pattern: str = \"*.png\",\n",
    "    max_images: int | None = None,\n",
    "    do_cut: bool = False,\n",
    "    cut_margin: int = 35,\n",
    "    cut_min_conf: float = 0.01,\n",
    "    methods: List[str] = METHODS,\n",
    "    thresholds: List[float] = [0.20, 0.30, 0.40, 0.50],\n",
    ") -> pd.DataFrame:\n",
    "    paths = list_images(source, pattern)\n",
    "    if max_images is not None:\n",
    "        paths = paths[: int(max_images)]\n",
    "\n",
    "    rows: List[Dict[str, Any]] = []\n",
    "\n",
    "    # Cache para evitar recalcular / reinferir\n",
    "    infer_cache: Dict[Tuple[str, str], Dict[str, Any]] = {}  # (filename, method) -> result\n",
    "\n",
    "    for i, p in enumerate(paths, start=1):\n",
    "        lot = infer_lot_from_name(p.name)\n",
    "\n",
    "        # carga base\n",
    "        base_pil = Image.open(str(p)).convert(\"RGB\")\n",
    "\n",
    "        # cut opcional (si la imagen NO está ya recortada)\n",
    "        pil_for_pre = base_pil\n",
    "        if do_cut and source != \"cropped_def\":\n",
    "            cropped, _vis = potato_pixels_rgb_img(pil_for_pre, margin=cut_margin, min_conf=cut_min_conf)\n",
    "            if cropped is None:\n",
    "                for thr in thresholds:\n",
    "                    rows.append({\n",
    "                        \"image\": p.name,\n",
    "                        \"lot\": lot,\n",
    "                        \"source\": source,\n",
    "                        \"method\": None,\n",
    "                        \"thr\": float(thr),\n",
    "                        \"pred_class\": None,\n",
    "                        \"confidence\": 0.0,\n",
    "                        \"status\": \"no_potato_detected\",\n",
    "                    })\n",
    "                continue\n",
    "            pil_for_pre = cropped.convert(\"RGB\")\n",
    "\n",
    "        for method in methods:\n",
    "            try:\n",
    "                proc = apply_preprocess(pil_for_pre, method)\n",
    "\n",
    "                cache_key = (p.name, method)\n",
    "                if cache_key not in infer_cache:\n",
    "                    infer_cache[cache_key] = roboflow_infer(proc)\n",
    "\n",
    "                result = infer_cache[cache_key]\n",
    "\n",
    "                for thr in thresholds:\n",
    "                    cls, conf = classify_from_result(result, float(thr))\n",
    "                    rows.append({\n",
    "                        \"image\": p.name,\n",
    "                        \"lot\": lot,\n",
    "                        \"source\": source,\n",
    "                        \"method\": method,\n",
    "                        \"thr\": float(thr),\n",
    "                        \"pred_class\": cls,\n",
    "                        \"confidence\": float(conf),\n",
    "                        \"status\": \"ok\" if cls != \"Unable to classify\" else \"no_pred_above_thr\",\n",
    "                    })\n",
    "\n",
    "            except Exception as e:\n",
    "                for thr in thresholds:\n",
    "                    rows.append({\n",
    "                        \"image\": p.name,\n",
    "                        \"lot\": lot,\n",
    "                        \"source\": source,\n",
    "                        \"method\": method,\n",
    "                        \"thr\": float(thr),\n",
    "                        \"pred_class\": None,\n",
    "                        \"confidence\": None,\n",
    "                        \"status\": \"error\",\n",
    "                        \"error\": repr(e),\n",
    "                    })\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print(f\"Procesadas {i}/{len(paths)}\")\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "\n",
    "    # limpieza tipos\n",
    "    if \"confidence\" in df.columns:\n",
    "        df[\"confidence\"] = pd.to_numeric(df[\"confidence\"], errors=\"coerce\")\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561f8ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# PARÁMETROS (edita aquí)\n",
    "# ==============================\n",
    "SOURCE = \"definitive\"    # 'definitive', 'cropped_def', 'test_1'\n",
    "PATTERN = \"p3_*.png\"     # ej: \"p3_*.png\" o \"*.png\"\n",
    "MAX_IMAGES = 50           # None para todas\n",
    "\n",
    "# Cut (solo si SOURCE != 'cropped_def')\n",
    "DO_CUT = False\n",
    "CUT_MARGIN = 35\n",
    "CUT_MIN_CONF = 0.01\n",
    "\n",
    "# Métodos y thresholds a probar (puedes reducir para ir rápido)\n",
    "METHODS_TO_TEST = METHODS\n",
    "THRESHOLDS = [0.20, 0.30, 0.40, 0.50, 0.60]\n",
    "\n",
    "df = run_defect_table_new_methods(\n",
    "    source=SOURCE,\n",
    "    pattern=PATTERN,\n",
    "    max_images=MAX_IMAGES,\n",
    "    do_cut=DO_CUT,\n",
    "    cut_margin=CUT_MARGIN,\n",
    "    cut_min_conf=CUT_MIN_CONF,\n",
    "    methods=METHODS_TO_TEST,\n",
    "    thresholds=THRESHOLDS,\n",
    ")\n",
    "\n",
    "display(df.head(20))\n",
    "print(\"Rows:\", len(df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc7e3cc",
   "metadata": {},
   "source": [
    "## Resumen útil: clases únicas y mapping “buena vs defectuosa”\n",
    "\n",
    "1) Mira qué clases devuelve el modelo con **tus** imágenes.  \n",
    "2) Decide qué clases son “defectuosa” (normalmente todo lo que no sea `Potato`).\n",
    "\n",
    "> Si el modelo devuelve clases que no esperabas, lo verás aquí enseguida.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbf5091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clases detectadas (con independencia de thr, usando la predicción >= 0.20 por defecto)\n",
    "thr_for_list = float(min(THRESHOLDS))\n",
    "\n",
    "df_thr = df[df[\"thr\"] == thr_for_list].copy()\n",
    "classes = (\n",
    "    df_thr[\"pred_class\"]\n",
    "    .fillna(\"<None>\")\n",
    "    .value_counts(dropna=False)\n",
    "    .to_frame(\"count\")\n",
    ")\n",
    "display(classes)\n",
    "\n",
    "# Define mapping (ajusta según la salida anterior)\n",
    "GOOD_CLASSES = {\"Potato\"}\n",
    "# Por defecto: todo lo que NO sea 'Potato' y NO sea 'Unable to classify' lo consideramos defecto.\n",
    "def is_defective(pred_class: str | None) -> Optional[bool]:\n",
    "    if pred_class is None:\n",
    "        return None\n",
    "    if pred_class == \"Unable to classify\":\n",
    "        return False  # lo tratamos como 'no defecto' (o 'desconocido' -> cámbialo si prefieres)\n",
    "    if pred_class in GOOD_CLASSES:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "df[\"pred_defective\"] = df[\"pred_class\"].apply(is_defective)\n",
    "\n",
    "# Ground truth aproximado por lote (según tu hipótesis)\n",
    "GOOD_LOTS = {3, 4}\n",
    "DEFECT_LOTS = {5, 6}\n",
    "\n",
    "def expected_defective(lot: Optional[int]) -> Optional[bool]:\n",
    "    if lot is None:\n",
    "        return None\n",
    "    if lot in GOOD_LOTS:\n",
    "        return False\n",
    "    if lot in DEFECT_LOTS:\n",
    "        return True\n",
    "    return None\n",
    "\n",
    "df[\"expected_defective\"] = df[\"lot\"].apply(expected_defective)\n",
    "\n",
    "display(df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b6d856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Métricas por método/threshold y resumen por lote\n",
    "# ------------------------------------------------------------\n",
    "def compute_metrics(sub: pd.DataFrame) -> Dict[str, float]:\n",
    "    # filtra donde hay etiqueta esperada\n",
    "    s = sub.dropna(subset=[\"expected_defective\", \"pred_defective\"]).copy()\n",
    "    if len(s) == 0:\n",
    "        return {\"n\": 0}\n",
    "    y = s[\"expected_defective\"].astype(bool).to_numpy()\n",
    "    p = s[\"pred_defective\"].astype(bool).to_numpy()\n",
    "\n",
    "    tp = int(np.sum((p == 1) & (y == 1)))\n",
    "    tn = int(np.sum((p == 0) & (y == 0)))\n",
    "    fp = int(np.sum((p == 1) & (y == 0)))\n",
    "    fn = int(np.sum((p == 0) & (y == 1)))\n",
    "\n",
    "    acc = (tp + tn) / max(1, (tp + tn + fp + fn))\n",
    "    tpr = tp / max(1, (tp + fn))  # recall defectuosas\n",
    "    fpr = fp / max(1, (fp + tn))  # false alarm en buenas\n",
    "    return {\n",
    "        \"n\": int(tp + tn + fp + fn),\n",
    "        \"acc\": float(acc),\n",
    "        \"tpr_defective_recall\": float(tpr),\n",
    "        \"fpr_good_false_alarm\": float(fpr),\n",
    "        \"tp\": tp, \"tn\": tn, \"fp\": fp, \"fn\": fn,\n",
    "    }\n",
    "\n",
    "# tabla métricas\n",
    "metrics_rows = []\n",
    "for (method, thr), sub in df.groupby([\"method\", \"thr\"], dropna=False):\n",
    "    m = compute_metrics(sub)\n",
    "    m.update({\"method\": method, \"thr\": thr})\n",
    "    metrics_rows.append(m)\n",
    "\n",
    "metrics = pd.DataFrame(metrics_rows).sort_values([\"acc\", \"tpr_defective_recall\"], ascending=False)\n",
    "display(metrics.head(30))\n",
    "\n",
    "# resumen por lote (proporción defectuosa predicha)\n",
    "lot_summary = (\n",
    "    df.dropna(subset=[\"lot\"])\n",
    "      .groupby([\"lot\", \"method\", \"thr\"], as_index=False)[\"pred_defective\"]\n",
    "      .mean()\n",
    "      .rename(columns={\"pred_defective\": \"pred_defective_rate\"})\n",
    "      .sort_values([\"lot\", \"pred_defective_rate\"], ascending=[True, False])\n",
    ")\n",
    "display(lot_summary.head(40))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97981760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Visual debug: muestra original vs preprocesado (elige método)\n",
    "# ------------------------------------------------------------\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "SHOW_METHOD = \"pct_stretch\"   # prueba: 'pct_stretch', 'sigmoid', 'hl_comp', 'retinex+clahe', etc.\n",
    "N_SHOW = 12\n",
    "\n",
    "paths = list_images(SOURCE, PATTERN)\n",
    "if MAX_IMAGES is not None:\n",
    "    paths = paths[: int(MAX_IMAGES)]\n",
    "paths = paths[:N_SHOW]\n",
    "\n",
    "fig, axes = plt.subplots(len(paths), 2, figsize=(8, 3*len(paths)))\n",
    "if len(paths) == 1:\n",
    "    axes = np.array([axes])\n",
    "\n",
    "for i, p in enumerate(paths):\n",
    "    base = Image.open(str(p)).convert(\"RGB\")\n",
    "    proc = apply_preprocess(base, SHOW_METHOD)\n",
    "\n",
    "    axes[i, 0].imshow(base)\n",
    "    axes[i, 0].axis(\"off\")\n",
    "    axes[i, 0].set_title(p.name, fontsize=8)\n",
    "\n",
    "    axes[i, 1].imshow(proc)\n",
    "    axes[i, 1].axis(\"off\")\n",
    "    axes[i, 1].set_title(SHOW_METHOD, fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quality_pipeline_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
